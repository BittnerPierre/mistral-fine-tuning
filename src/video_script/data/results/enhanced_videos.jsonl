{"video": {"title": "Diffusion Models: A Complete Guide", "transcript": "####Diffusion Models: A Complete Guide\nby Sharon Zhou - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Sharon Zhou here, and today we're diving into the fascinating world of diffusion models!\n\nDiffusion models are like creating a mosaic. You start with a bunch of tiles and gradually fit them together until you have a beautiful, complex mosaic.\n\nLet's grab our tiles and create our own diffusion model. Open your Python, Tensorflow, or Pytorch, and let's get started. We'll define our data distribution, add noise, and learn how to denoise it.\n\nBut that's not all! Sampling from diffusion models can be as slow as creating a mosaic. So, let's speed things up! I'll introduce you to some robust algorithms that can accelerate sampling by a whopping 10 times!\n\nBy the end of this video, you'll be a diffusion model mosaic artist, ready to build and train your own mosaics. So, keep fitting those tiles, keep learning, and who knows? You might just create the perfect 'diffusion mosaic'!\n\nThanks for watching, and remember to like, share, and subscribe for more exciting content. See you next time!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-04-30"}}
{"video": {"title": "TensorFlow: Model Optimization for Deployment", "transcript": "####TensorFlow: Model Optimization for Deployment\nby Laurence Moroney - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Laurence Moroney, and today we're diving into the world of TensorFlow model optimization for deployment.\n\n[Video hook and introduction]\n\nImagine being able to run your machine learning models on any device, without draining its battery or slowing it down. That's where model optimization comes in!\n\n[Body content]\n\nWith TensorFlow, you have a toolbox full of optimization techniques at your fingertips. We'll explore quantization, pruning, and knowledge distillation, and see how they can make your models leaner and meaner.\n\n[Conclusion and call to action]\n\nSo, are you ready to take your models to the next level? Start experimenting with these techniques and see the difference they can make. Keep learning, keep optimizing, and happy coding!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-04-15"}}
{"video": {"title": "Security Considerations in On-Device AI", "transcript": "####Security Considerations in On-Device AI\nby Krishna Sridhar - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Krishna Sridhar here and today we're diving into the world of On-Device AI! But don't worry, we're not just talking about the cool stuff, we're also going to discuss the not-so-fun part: security considerations.\n\nSo, why should you care? Well, as AI models become more prevalent on edge devices, ensuring their privacy and security is crucial. But don't just take my word for it, let's explore this together!\n\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-10-15"}}
{"video": {"title": "Understanding Diffusion Models: A Comprehensive Guide", "transcript": "####Understanding Diffusion Models: A Comprehensive Guide\nby Sharon Zhou - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Sharon Zhou, and today we're embarking on an exciting journey into the world of diffusion models. We'll demystify how these models work and even show you how to build your own from scratch. But first, don't forget to hit that subscribe button and ring the notification bell so you never miss out on our latest tech tutorials.\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2022-10-15"}}
{"video": {"title": "Introduction to On-Device AI", "transcript": "####Introduction to On-Device AI\nby Krishna Sridhar - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Krishna Sridhar and today we're embarking on an exciting journey into the world of On-Device AI. Are you ready to explore how to deploy AI models on edge devices like smartphones? Let's leverage their local compute power for faster and more secure inference. Trust me, you won't want to miss this!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-10-15"}}
{"video": {"title": "Building AI Solutions with Generative AI", "transcript": "####Building AI Solutions with Generative AI\nby Chris Fregly - 2022-10-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to take your AI game to the next level? Well, you're in luck because today we're diving into the world of generative AI and how you can use it to build and deploy AI solutions. I'm your host, Chris Fregly, and I'm thrilled to have you along for the ride.\n\nBut first, let me ask you a question. Have you ever wondered how AI can create value in business contexts? Well, wonder no more because we're going to explore that and so much more.\n\nSo, buckle up and get ready to learn from some of the top AWS AI practitioners in the game. Trust me, you won't want to miss this.\n#### END TRANSCRIPT ########", "author": "Chris Fregly", "publication_date": "2022-10-19"}}
{"video": {"title": "Real-World LLM Red Teaming Case Studies", "transcript": "####Real-World LLM Red Teaming Case Studies\nby Matteo Dora, Luca Martial - 2023-04-12\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, LLM enthusiasts! I'm Matteo Dora, and welcome back to our series on red teaming for LLM applications.\n\nToday, we're diving into some real-world case studies of LLM red teaming. We'll explore how tech giants like Google, Facebook, and Amazon have used red teaming to enhance the safety and reliability of their LLM applications.\n\nBut wait, there's more! We'll also discuss some valuable lessons learned from these case studies and how we can apply them to our own LLM red teaming efforts.\n\nRemember, learning from others' experiences is a smart way to boost our own skills and knowledge.\n\nSo, let's get started and make our LLM applications even safer.\n\nStay tuned for our next video where we'll share some top-notch best practices for LLM red teaming. Until then, keep exploring and learning.\n\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-04-12"}}
{"video": {"title": "Essential Linear Algebra Concepts for Data Science", "transcript": "Hello, everyone! Elena Sanina here. Today, we're diving into the world of linear algebra and its crucial role in data science. Join me as we explore key concepts and applications that will enhance your understanding of machine learning algorithms.\n\n#### BEGIN TRANSCRIPT ####\n\nHello, data enthusiasts! Elena Sanina here. Are you ready to unlock the secrets of linear algebra and its role in data science? Let's get started!\n\n#### Video hook and introduction ####\n\n- Imagine being able to understand and improve machine learning algorithms by mastering linear algebra.\n- Introduce the topic and its relevance to data science.\n- Preview the key concepts and applications to be covered.\n\n#### Body content ####\n\n- Define linear algebra and its importance in data science.\n- Explain key concepts such as vectors, matrices, and operations.\n- Discuss applications of linear algebra in machine learning, including dimensionality reduction and regression analysis.\n- Provide examples and real-world use cases.\n- Include humor and active voice to keep the audience engaged.\n\n#### Conclusion and call to action ####\n\n- Recap the main points covered in the video.\n- Encourage the audience to apply what they've learned.\n- Provide resources for further learning.\n- End with a memorable and engaging conclusion.\n\n#### END TRANSCRIPT ####", "author": "Elena Sanina", "publication_date": "2022-10-05"}}
{"video": {"title": "Mistral AI: The Benefits of JSON Mode", "transcript": "####Mistral AI: Unleashing the Power of JSON Mode\nby Younes Belkada and Marc Sun - 2023-02-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Younes Belkada here, and today we're diving into the exciting world of Mistral AI's JSON mode. Trust me, you won't want to miss this!\n\nSo, what's the big deal about JSON mode? Well, it allows you to generate LLM responses in a structured JSON format, making it a breeze to integrate LLM outputs into your larger software applications. This means you can harness the power of Mistral AI's advanced LLM capabilities in a more seamless and efficient way.\n\nAnd the best part? JSON mode is incredibly easy to use. All you have to do is specify the JSON output format when making an API call, and Mistral AI will do the heavy lifting for you.\n\nBut wait, there's more! Mistral AI's API allows you to call user-defined Python functions for tasks like web searches or retrieving text from databases. This means you can enhance the LLM's ability to find relevant information and answer user queries more accurately.\n\nSo, what does this all mean for you? It means that now is the time to start exploring Mistral AI's JSON mode and see how it can help you achieve your LLM goals more efficiently. And don't forget to check out Mistral AI, our technology partner for this video.\n\nThanks for watching, and stay tuned for more exciting videos on Mistral AI and LLM. I'm Younes Belkada, and I'll see you in the next one.\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-20"}}
{"video": {"title": "TensorFlow: Generative Deep Learning", "transcript": "####TensorFlow: Generative Deep Learning Unleashed\nby Laurence Moroney, Eddy Shyu - 2022-03-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're going to embark on an exciting journey into the world of generative deep learning with TensorFlow.\n\nGenerative deep learning is like having a magic wand that creates new, synthetic data. In this video, we'll show you how to use variational autoencoders and generative adversarial networks to conjure up your own synthetic data.\n\nWe'll also share some insider tips for working with generative models, and some common pitfalls to dodge.\n\nSo, whether you're looking to create new data for a project, or just want to explore the frontier of deep learning, this video has got you covered. Let's dive in.\n\n[Demonstration of using variational autoencoders and generative adversarial networks]\n\nThanks for watching, and don't forget to check out our other videos on TensorFlow. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-03-29"}}
{"video": {"title": "Building an AI Project: A Step-by-Step Guide", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits.\n- Use of active voice and simple language.\n- Confident and engaging tone.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning.\n- Make the conclusion more memorable and engaging.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Improve the structure and organization of the content.", "author": "Robert Monarch", "publication_date": "2023-04-20"}}
{"video": {"title": "Optimizing Wind Energy with AI: A Beginner's Guide", "transcript": "####Optimizing Wind Energy with AI: A Beginner's Guide\nby Robert Monarch - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the fascinating world of AI and wind energy!\n\nFirst, we'll talk about why renewable energy matters and how wind energy fits into the picture. Then, we'll explore how AI can help us squeeze every last drop of power out of those spinning turbines.\n\nWe'll look at how AI can predict wind patterns, place turbines in the perfect spot, and even keep them running smoothly with smart maintenance schedules.\n\nAnd to top it all off, we'll check out a real-world example where AI has already made a big difference in wind energy production.\n\nSo, are you ready to learn how AI can help us harness the power of the wind? Let's get started!\n\nRemember, every bit of knowledge you gain about AI for good brings us one step closer to a sustainable future.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content on AI. Until next time, let's keep using AI for good!\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-03-25"}}
{"video": {"title": "Future Directions in Generative AI with LLMs", "transcript": "####Future Directions in Generative AI with LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-27\n\n#### BEGIN TRANSCRIPT ####\nHey there, Antje Barth here, and today we're diving into the exciting world of future directions in generative AI with LLMs!\n\nFirst, we'll chat about some of the current trends and developments in generative AI, such as the rise of multimodal models and the use of reinforcement learning.\n\nThen, we'll explore the potential future directions of generative AI, from creating more sophisticated chatbots to generating entirely new forms of media.\n\nWe'll also hear from some of the brightest minds in the field about their visions for the future of generative AI and how LLMs will play a role in it.\n\nAnd let's not forget about the business implications. We'll explore how companies can stay ahead of the curve and leverage generative AI to create value and drive innovation.\n\nBy the end of this video, you'll have a better understanding of the future directions of generative AI with LLMs and how you can contribute to the field.\n\nSo, let's get started! See you in the course.\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-27"}}
{"video": {"title": "Transforming Text with ChatGPT: A Beginner's Guide", "transcript": "####Transforming Text with ChatGPT: A Beginner's Guide\nby Isa Fulford - 2022-10-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford, and today we're diving headfirst into the exciting world of text transformation using ChatGPT. If you're new to LLMs, don't worry, by the end of this video, you'll be summarizing, inferring, and transforming text like a pro. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-20"}}
{"video": {"title": "Quantization vs. Pruning: A Comparison", "transcript": "####Quantization vs. Pruning: A Comparison\nby Marc Sun, Younes Belkada - 2022-04-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc Sun, and today we're diving into the world of model compression! We're comparing two popular techniques: quantization and pruning.\n\nNow, you might be wondering, \"What's the difference?\" Well, let me break it down for you. Quantization reduces the precision of the weights, while pruning removes some of the weights altogether.\n\nBut don't worry, we'll take it step by step. We'll discuss the pros and cons of each technique, and when to use each one. We'll also look at some examples to see these techniques in action.\n\nAnd the best part? By the end of this video, you'll have a solid understanding of the differences between quantization and pruning.\n\nSo, let's get started. And remember, the best way to learn is by doing.\n\nDon't forget to like, share, and subscribe for more great content.\n\nUntil next time, I'm Marc Sun, and this has been Quantization vs. Pruning: A Comparison. Happy learning!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-04-12"}}
{"video": {"title": "Red Teaming for Safer LLM Applications: A Beginner's Guide", "transcript": "Positive Points:\n\n- Clear introduction of the topic and the benefits of red teaming.\n- Use of active voice and simple language.\n- Encouragement of learning and testing.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Leverage curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-03-01"}}
{"video": {"title": "Mastering Mathematics for Machine Learning and Data Science: Bonus - Optimization", "transcript": "####Mastering Mathematics for Machine Learning and Data Science: Bonus - Optimization\nby Lucas Coutinho - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Lucas Coutinho here, and welcome back to our video series on Mathematics for Machine Learning and Data Science. Today, we're diving into a special bonus video on optimization!\n\nOptimization is the art of finding the best solution to a problem, given certain constraints. It's a game-changer in machine learning, as it helps us find the best model parameters that minimize our loss function.\n\nLet's kick things off with the basics: gradient descent. Gradient descent is an optimization algorithm that iteratively updates our model parameters in the direction of steepest descent of the loss function. In other words, it helps us find the minimum of our loss function.\n\nNext up, we have stochastic gradient descent. Stochastic gradient descent is a variant of gradient descent that uses random samples, or mini-batches, of data to update our model parameters. This makes it more efficient and suitable for large datasets.\n\nBut how does this apply to machine learning? Well, many machine learning algorithms use optimization techniques to find the best model parameters. For example, in neural networks, we use stochastic gradient descent to update the weights and biases of our model.\n\nAnd that's a wrap for today's bonus video on optimization! I hope you found this introduction helpful. Remember, optimization is a powerful tool in machine learning, so don't forget to practice and explore more.\n\nThanks for watching, and happy learning!\n\n#### END TRANSCRIPT ########", "author": "Lucas Coutinho", "publication_date": "2023-04-10"}}
{"video": {"title": "LLM Red Teaming 101: Identifying Vulnerabilities", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce stakes and payoff at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insight.\n- Make the conclusion more memorable and engaging.", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-03-08"}}
{"video": {"title": "Building a Multi-Agent System with LlamaIndex", "transcript": "####Building a Multi-Agent System with LlamaIndex\nby Jerry Liu - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and today we're diving into the exciting world of multi-agent systems with LlamaIndex!\n\nImagine a team of superheroes, each with their unique abilities, working together to save the day. That's exactly what we're going to build today!\n\nWe'll start by defining the roles and responsibilities of each agent. Then, we'll learn how to coordinate their actions and handle conflicts like a pro.\n\nBut wait, there's more! We'll also discuss some best practices for building multi-agent systems and share some common pitfalls to avoid.\n\nBy the end of this video, you'll have the skills to build your own multi-agent system and harness the power of collective intelligence.\n\nSo, are you ready to level up your coding skills? Let's get started!\n\nAnd remember, if you have any questions or need further clarification, feel free to leave a comment below. Don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding and see you in the next video!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-25"}}
{"video": {"title": "Mastering Mathematics for Machine Learning and Data Science: Calculus", "transcript": "Positive Points:\n\n- Clear introduction of the topic and its relevance to machine learning.\n- Use of active voice and simple language.\n- Encouragement for viewers to practice and ask questions.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Luis Serrano", "publication_date": "2023-03-15"}}
{"video": {"title": "Simplifying Summarization with Agentic RAG and LlamaIndex", "transcript": "####Simplifying Summarization with Agentic RAG and LlamaIndex\nby Jerry Liu - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and welcome back to our exciting journey with Agentic RAG and LlamaIndex!\n\nToday, we're going to make summarization a breeze with our Agentic RAG. Remember the router agent we built? Now, we're going to put it to use and summarize documents like a pro!\n\nFirst, we'll dive into what makes a good summary. Because the goal isn't just to shrink a document, but to capture its core!\n\nThen, we'll tackle multi-document summarization. Yes, our agent can handle multiple documents at once!\n\nFinally, we'll share some insider tips and tricks to boost the summarization performance of our Agentic RAG.\n\nSo, are you ready to simplify summarization with Agentic RAG and LlamaIndex? Let's do this!\n\nRemember, practice makes perfect. So keep trying, keep building, and most importantly, enjoy the ride!\n\nThanks for watching and don't forget to like, share, and subscribe for more thrilling content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-03-25"}}
{"video": {"title": "Transformer Architecture in Generative AI", "transcript": "####Transformer Architecture in Generative AI: Unleashing Creativity with LLMs\nby Chris Fregly - 2022-01-16\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Chris Fregly, and today we're diving into the transformer architecture that's revolutionizing Generative AI. Get ready to be blown away by how this architecture enables the generation of text and images with jaw-dropping accuracy and creativity. Let's unlock the secrets of transformers in AI!\n#### END TRANSCRIPT ########", "author": "Chris Fregly", "publication_date": "2022-01-16"}}
{"video": {"title": "Machine Learning for Beginners: A Visual Approach", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of simple language and active voice.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Make the introduction more intriguing to capture the audience.\n- Include more critical analysis and personal insights.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-01-01"}}
{"video": {"title": "Serving LLMs at Scale with Predibase's LoRAX Framework", "transcript": "####Serving LLMs at Scale with Predibase's LoRAX Framework\nby Travis Addair - 2023-03-07\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Travis Addair and today we're diving into the exciting world of serving LLMs at scale using Predibase's LoRAX framework.\n\nBut first, let's get our bearings. Serving LLMs at scale means serving a language model to a large number of users while keeping accuracy high and latency low. Sounds like a tall order, right? Well, buckle up, because we're about to make it happen.\n\nNext, we'll explore how to use Predibase's LoRAX framework to serve LLMs at scale. We'll start by fine-tuning a pre-trained language model on our specific task using LoRA. Once we have our fine-tuned model, we'll use LoRAX to serve it to multiple users at once.\n\nBut wait, there's more! We'll also cover how to handle requests from multiple users and balance the load between multiple models. This will ensure that our application is scalable and can handle a large number of requests.\n\nFinally, we'll share some best practices for serving LLMs at scale, such as how to handle input validation and monitor the performance of our application.\n\nThanks for joining me on this journey. Don't forget to like, comment, and subscribe for more videos on GenAI and LLM powered applications. See you in the next one!\n#### END TRANSCRIPT ########", "author": "Travis Addair", "publication_date": "2023-03-07"}}
{"video": {"title": "Advanced Debugging Techniques for Agentic RAG with LlamaIndex", "transcript": "####Advanced Debugging Techniques for Agentic RAG with LlamaIndex\nby Jerry Liu - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow coders! Jerry Liu here, and today we're diving into the exciting world of advanced debugging techniques for our agentic RAG with LlamaIndex.\n\nBut first, let's take a quick look back at our journey so far. We've built an agentic RAG, mastered document Q&A, unleashed the power of summarization, and even built a multi-document research agent. Today, we're going to level up our skills with some advanced debugging techniques.\n\nWe'll start by identifying common issues that can arise in complex agentic RAG systems. Then, we'll explore the advanced debugging techniques and tools available in LlamaIndex.\n\nOnce we've got that down, we'll look at how to use these techniques to improve our agent's accuracy and efficiency.\n\nBy the end of this video, you'll be a debugging pro, ready to tackle even the most complex agentic RAG systems with LlamaIndex.\n\nSo, let's get started! And remember, practice makes perfect. So, don't just watch this video, try debugging your own complex agentic RAG with LlamaIndex.\n\nAnd if you found this video helpful, give it a thumbs up and subscribe to our channel for more exciting content. Until next time, happy coding!\n\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-30"}}
{"video": {"title": "Building Multimodal Search and RAG with Weaviate", "transcript": "####Building Multimodal Search and RAG with Weaviate\nby Sebastian Witalec - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sebastian Witalec and today we're diving into the thrilling world of multimodal search and RAG applications. If you're comfortable with basic Python, you're all set!\n\nFirst, let's demystify multimodality. It's a fancy term, but don't worry, it's not as scary as it sounds. In simple terms, it's the ability to handle different types of data, like text, images, and audio, all at the same time. We'll be using contrastive learning to build modality-independent embeddings. This means you can retrieve any type of data with any type of query. Pretty cool, right?\n\nNext, we'll build a multimodal RAG system. RAG stands for Retrieval Augmented Generation. It's a system that retrieves relevant context and reasons over it to generate more accurate answers. Imagine asking a question about a picture and getting a detailed answer that refers to specific elements in the image. That's the power of multimodal RAG.\n\nBut wait, there's more! We'll also explore some real-world applications of multimodal search. Ever heard of multi-vector recommender systems? They're like regular recommender systems, but on steroids. They can recommend items based on multiple factors, like user preferences and item features.\n\nAnd the cherry on top? We're partnering with Weaviate to bring you this content. They're a leading company in the field of vector search engines, and their technology will make our journey smoother and more exciting.\n\nSo, are you ready to build smarter search and RAG applications? Let's get started! Remember, if you have any questions, feel free to leave a comment below. And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2023-03-15"}}
{"video": {"title": "Mastering Prompt Engineering for Vision Models", "transcript": "####Mastering Prompt Engineering for Vision Models\nby Abby Morgan - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Abby Morgan, and today we're going to have a blast exploring the world of prompt engineering for vision models. We'll be diving into Stable Diffusion and learning some advanced techniques like object detection and in-painting. If you're ready to take your vision model game to the next level, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Abby Morgan", "publication_date": "2022-10-15"}}
{"video": {"title": "Training and Tuning LLMs for Optimal Performance", "transcript": "####Training and Tuning LLMs for Optimal Performance\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Shelbee Eigenbrode, and today we're diving into the exciting world of training and tuning LLMs for optimal performance.\n\nTraining an LLM is like teaching a child to read, but with a lot more data and math. You feed it tons of text, and using backpropagation, you adjust the model's weights. But it's not just about the data. You need to choose the right data, preprocess it correctly, and keep an eye on the model's performance during training.\n\nTuning an LLM is like fine-tuning a race car. You adjust the hyperparameters to improve its performance on specific tasks. This could be the learning rate, batch size, or number of layers. But how do you know which to adjust and when?\n\nIn this video, we'll share best practices for training and tuning LLMs. We'll cover how to choose the right training data, preprocess it correctly, and monitor the model's performance during training. We'll also talk about how to use techniques like early stopping and learning rate schedules to boost the model's performance.\n\nBy the end of this video, you'll have a solid understanding of how to train and tune LLMs for optimal performance. You'll be able to apply these techniques to your own projects and stay ahead of the curve in this rapidly evolving field.\n\nSo, let's get started and learn how to train and tune LLMs like a pro!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-25"}}
{"video": {"title": "RNNs and LSTMs: Unraveling the Mystery", "transcript": "####RNNs and LSTMs: Unraveling the Mystery\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Today, we're diving into the fascinating world of RNNs and LSTMs.\n\nRNNs, or Recurrent Neural Networks, and LSTMs, or Long Short-Term Memory networks, are types of neural networks that excel at understanding sequences. They're the secret sauce behind speech recognition, music composition, and even sentiment analysis.\n\nIn this video, we'll start by demystifying RNNs and LSTMs. Then, we'll roll up our sleeves and build our own models using Python and TensorFlow.\n\nDon't worry if you're feeling a bit lost. We'll take it one step at a time, and by the end of this video, you'll have a solid grasp of these powerful tools.\n\nSo, let's get started! And remember, if you have any questions, feel free to leave them in the comments.\n\nThat's it for today's video. If you found it helpful, give it a thumbs up and subscribe to our channel for more AI content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-01-15"}}
{"video": {"title": "ChatGPT Prompt Engineering: Tips and Tricks for Developers", "transcript": "Positive Points:\n\n- Clear introduction of the topic and its importance.\n- Use of active voice and simple language.\n- Inclusion of humor and enthusiasm.\n- Encouragement of hands-on practice.\n\nAreas for Improvement:\n\n- Add more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.\n- Introduce more critical analysis and personal insights.\n- Improve humor and make it more relatable and enjoyable.", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-19"}}
{"video": {"title": "LangChain and Natural Language Processing: A Match Made in Heaven", "transcript": "####LangChain and Natural Language Processing: A Match Made in Heaven\nby Harrison Chase - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, the creator of LangChain, and today we're going to talk about how LangChain and natural language processing (NLP) are a match made in heaven.\n\nIf you're new to LangChain, you might be wondering how it differs from other chatbot frameworks. Well, one of the key differences is that LangChain is designed to work seamlessly with NLP techniques, making it easier than ever to build chatbots that can understand and respond to natural language queries.\n\nIn this video, we'll cover the basics of NLP and how it can be used in conjunction with LangChain to build more powerful chatbots. We'll start with an overview of NLP and some of the most popular NLP libraries, including spaCy and NLTK.\n\nNext, we'll dive into some examples of how to use NLP techniques to extract information from unstructured data sources, such as emails and chat logs. We'll also cover how to use NLP to build more sophisticated chatbot responses that sound more human-like.\n\nBy the end of this video, you'll have a solid understanding of how to use LangChain and NLP to build more powerful chatbots that can understand and respond to natural language queries.\n\nSo, are you ready to get started? Let's dive in and start exploring the world of LangChain and NLP!\n\nRemember, if you have any questions or need help along the way, feel free to reach out to me on social media or through the LangChain website.\n\nThanks for watching, and happy coding!\n\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-04-05"}}
{"video": {"title": "Deploying Your ML Model: A Step-by-Step Guide", "transcript": "####Deploying Your ML Model: A Step-by-Step Guide\nby Andrew Ng - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Andrew Ng, and today we're diving into the exciting world of deploying your ML model.\n\nNow, I know what you're thinking, \"Deployment? That sounds scary!\" But don't worry, I'm here to guide you through it.\n\nFirst things first, you need to decide where you're going to deploy your model. Cloud or on-premises? Each has its own advantages and disadvantages, so choose wisely!\n\nNext up, it's time to get your model ready for the big leagues. This means optimizing it for performance and making sure it can handle real-time predictions like a pro.\n\nNow, let's get this party started! Deployment can involve setting up servers, configuring networks, and integrating with your existing systems. But don't worry, I've got your back.\n\nBut wait, there's more! Deployment is just the beginning. You need to continuously monitor your model's performance and make improvements as needed. Trust me, your model will thank you.\n\nSo, that's a quick rundown of deploying your ML model. It's a complex process, but with the right tools and strategies, you can ensure your model delivers real value.\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-20"}}
{"video": {"title": "Exploring the Full Potential of LangChain for LLM Application Development", "transcript": "####Exploring the Full Potential of LangChain for LLM Application Development\nby Harrison Chase, Andrew Ng - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Harrison Chase, and today we're diving into the exciting world of LangChain for LLM application development.\n\nLangChain is a game-changer. It's a powerful and extensible framework that lets you use prompts, parsing, memory, chains, question answering, and agents to build some truly amazing applications.\n\nFirst, we'll recap everything we've learned so far. We'll look at how to use LangChain's features to build personal assistants, specialized chatbots, and question answering systems.\n\nNext, we'll explore some advanced topics. We'll look at how to use LangChain to build even more powerful applications.\n\nAnd the best part? We'll explore some real-world use cases and see how LangChain is being used to solve complex problems.\n\nNow, let's wrap up. You've learned how to use LangChain's features to build powerful applications, how to explore some advanced topics, and how to apply what you've learned to real-world use cases.\n\nSo, what's next? I challenge you to explore the full potential of LangChain and build your own applications. Make them unique. Make them powerful.\n\nThanks for watching. If you found this tutorial helpful, give it a thumbs up and don't forget to subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-30"}}
{"video": {"title": "Building a Multi-Vector Recommender System", "transcript": "####Building a Multi-Vector Recommender System\nby Sebastian Witalec - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sebastian Witalec and today we're diving into the world of multi-vector recommender systems!\n\nBut what's that, you ask? Well, imagine a system that can recommend items to you based on multiple factors. That's exactly what we're building today using multimodal search.\n\nFirst, we'll prepare our dataset. Then, we'll build our recommender system and train it on our dataset. And finally, we'll evaluate our system to see just how well it performs.\n\nOur goal here is to create a system that can understand and reason over multimodal data to provide more accurate recommendations. This is a game-changer in many industries, from e-commerce to entertainment.\n\nSo, are you ready to get started? Let's do this! And if you have any questions, don't be shy. Leave a comment and let's learn together.\n\nAnd before we go, don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2023-04-05"}}
{"video": {"title": "Getting Started with GANs: A Beginner's Guide", "transcript": "####Getting Started with GANs: A Beginner's Guide\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-03-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sharon Zhou, and today we're diving into the fascinating world of GANs!\n\n[Video hook and introduction]\n\nGANs can seem daunting at first, but trust me, they're not as scary as they sound. In this video, we'll break down everything you need to know to get started with GANs.\n\n[Body content]\n\nSo, what are GANs? Well, they're a type of machine learning model that can generate new data that's similar to the data it was trained on. They consist of two parts: a generator and a discriminator. The generator creates new data, while the discriminator tries to tell the difference between real data and the data the generator creates.\n\nTo get started with GANs, you'll need a few things. First, you'll need a dataset to train your GAN on. This can be any type of data, but for this video, we'll be using images. You'll also need a programming language like Python, and a machine learning framework like TensorFlow or PyTorch.\n\nOnce you have your dataset and tools, you're ready to start building your GAN. The first step is to define your generator and discriminator networks. These are just like any other neural network, except that the generator creates new data instead of classifying it.\n\nNext, you'll need to train your GAN. This involves feeding your dataset through the generator and discriminator, and adjusting the weights of the networks based on the feedback from the discriminator. Over time, the generator will get better at creating realistic data, and the discriminator will get better at spotting fakes.\n\n[Conclusion and call to action]\n\nSo that's a quick overview of how to get started with GANs. It's a complex topic, but with a little practice, you'll be generating your own data in no time. Thanks for watching, and be sure to check out our other videos on GANs and machine learning. And remember, the only limit is your imagination!\n\n\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-03-08"}}
{"video": {"title": "Building a Multi-Document Research Agent with LlamaIndex", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits of the video.\n- Use of active voice and simple language.\n- Encouragement of audience participation and engagement.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insight.", "author": "Jerry Liu", "publication_date": "2023-03-30"}}
{"video": {"title": "The Latest Research in Generative AI with LLMs", "transcript": "####The Latest Research in Generative AI with LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-05-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Shelbee Eigenbrode, and today we're diving into the thrilling world of Generative AI with LLMs!\n\nThe field of Generative AI is a wild ride, and LLMs are at the forefront of this exciting journey. We'll be discussing some of the latest research in this area, including the development of more efficient and interpretable LLMs, and their use in tasks like machine translation and summarization.\n\nBut it's not all sunshine and rainbows. We'll also be talking about some of the challenges facing the field of Generative AI, such as the need for more diverse and representative training data, and the potential for LLMs to be used for nefarious purposes. And we'll be discussing some potential solutions to these challenges, such as the development of more transparent and explainable LLMs.\n\nBy the end of this video, you'll have a better understanding of some of the latest research in Generative AI with LLMs and some ideas for how this technology could evolve in the future. So buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-05-10"}}
{"video": {"title": "GANs and Unsupervised Learning: A New Frontier", "transcript": "Hi there, I'm Eric Zelikman, and today we're diving into the fascinating world of GANs and unsupervised learning.\n\n[Video hook and introduction]\n\nImagine being able to generate new data that's so realistic, even experts can't tell the difference. That's the power of GANs. But what if we could take it a step further and combine GANs with unsupervised learning? The possibilities are endless. In this video, we'll explore how these two technologies can work together to solve complex problems.\n\n[Body content]\n\nUnsupervised learning is a type of machine learning that involves training models on unlabeled data. The goal is to find patterns and structure in the data, which can be used for tasks like clustering and anomaly detection.\n\nBut what if we could generate synthetic data using GANs to help our models learn more quickly and efficiently? That's exactly what we can do. By generating synthetic data, GANs can help models learn more quickly and efficiently, especially in environments where real data is hard to come by.\n\nBut that's not all. GANs can also be used to improve the performance of unsupervised learning algorithms themselves. For example, you can use GANs to generate synthetic data that's similar to real data, but with certain properties exaggerated or removed. This can help models learn more quickly and efficiently, and can also help them generalize better to new data.\n\n[Conclusion and call to action]\n\nSo there you have it, folks. The combination of GANs and unsupervised learning is a powerful tool that's driving some of the most exciting advances in machine learning today. Thanks for watching, and be sure to check out our other videos on GANs and machine learning. And remember, the future of AI is in your hands. Let's keep pushing the boundaries of what's possible.", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-04-12"}}
{"video": {"title": "Mistral AI: Integrating LLM Outputs into Larger Applications", "transcript": "####Mistral AI: Unleashing LLM Outputs in Larger Applications\nby Younes Belkada, Marc Sun - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Younes Belkada here, and welcome back to our exciting journey with Mistral AI!\n\nToday, we're diving into the world of integrating your LLM outputs into larger software applications using Mistral's JSON mode.\n\nBut first, let's do a quick recap. JSON mode is a nifty feature of Mistral that allows you to generate LLM responses in a neat, structured JSON format. Why is this cool? Well, it makes integrating these responses into other applications a breeze!\n\nSo, how do you do it? First, you generate your LLM response in JSON format. Then, you can use a programming language like Python or JavaScript to parse this JSON response and use it in your application.\n\nSounds complex? Don't worry, once you get the hang of it, it's as easy as pie! And it opens up a whole new world of possibilities for what you can do with Mistral AI.\n\nRemember, if you have any questions, just let us know. And don't forget to like, share, and subscribe for more updates. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-05"}}
{"video": {"title": "TensorFlow: Distributed Training", "transcript": "####TensorFlow: Distributed Training - Turbocharge Your Model Training!\nby Laurence Moroney, Eddy Shyu - 2022-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the world of TensorFlow to show you how to supercharge your model training with distributed training!\n\nAre you tired of waiting hours, or even days, for your models to train? Well, you're in luck! With TensorFlow's distributed training features, you can use multiple processors to cut down on training time and get your models up and running faster than ever before.\n\nIn this video, we'll walk you through the process of setting up distributed training with TensorFlow, and show you how to use it to train your models like a pro. We'll also cover some best practices for using distributed training, and help you avoid some common pitfalls that can trip up even the most experienced machine learning engineers.\n\nSo, if you're ready to take your model training to the next level, let's get started!\n\n[Demonstration of setting up distributed training and training a model]\n\nAnd that's it! With TensorFlow's distributed training features, you can train your models faster and more efficiently than ever before. So why wait? Get started with distributed training today!\n\nThanks for watching, and be sure to check out our other videos on TensorFlow for more tips and tricks to help you become a machine learning master.\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-03-15"}}
{"video": {"title": "TensorFlow: Mobile App Integration", "transcript": "####TensorFlow: Mobile App Integration\nby Laurence Moroney - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the exciting world of integrating TensorFlow models into mobile apps!\n\n[Video hook and introduction]\n\nImagine having a mobile app that's not just smart, but personalized to each user's needs. That's the power of machine learning, and with TensorFlow Lite, it's easier than ever!\n\n[Body content]\n\nTensorFlow Lite allows you to run machine learning models directly on mobile devices. This means you can integrate your TensorFlow models into your Android and iOS apps, making them more intelligent and user-friendly.\n\n[Conclusion and call to action]\n\nSo, what are you waiting for? Start exploring TensorFlow Lite and see how you can take your mobile apps to the next level. Keep learning, keep innovating, and happy coding!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-04-10"}}
{"video": {"title": "The Future of Quantization", "transcript": "####The Future of Quantization: A Revolution in AI Efficiency\nby Marc Sun, Younes Belkada - 2022-05-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Younes Belkada, and today we're diving into the exciting world of quantization.\n\nQuantization is a game-changer in the AI world, making models smaller, faster, and more efficient. And the best part? It's constantly evolving!\n\nWe'll explore the latest trends and research in quantization, and where this revolutionary technology might be headed.\n\nBut don't worry, we'll break it down for you. By the end of this video, you'll have a solid understanding of the future of quantization and how it can supercharge your AI projects.\n\nSo, let's get started. And remember, the best way to learn is by doing.\n\nDon't forget to like, share, and subscribe for more great content.\n\nUntil next time, I'm Younes Belkada, and this has been The Future of Quantization: A Revolution in AI Efficiency.\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-05-03"}}
{"video": {"title": "Preprocessing Unstructured Data for LLM Applications", "transcript": "####Preprocessing Unstructured Data for LLM Applications\nby Matt Robinson - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHello and welcome back, data enthusiasts! I'm Matt Robinson, your guide for today's exciting journey into the world of preprocessing unstructured data for LLM applications. Are you ready to dive in?\n\nLet's get started!\n\n#### END TRANSCRIPT ########", "author": "Matt Robinson", "publication_date": "2022-10-15"}}
{"video": {"title": "AI and Air Quality: Breathing Easier with Machine Learning", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Encouragement of audience engagement.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Robert Monarch", "publication_date": "2023-03-20"}}
{"video": {"title": "Building a Red Team for Your LLM Application", "transcript": "####Building a Red Team for Your LLM Application\nby Matteo Dora, Luca Martial - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, LLM enthusiasts! Luca Martial here, and today we're diving into the exciting world of red teaming for your LLM application.\n\nBut first, let's get you hooked. Imagine having a group of superheroes, each with their unique powers, protecting your LLM application from potential threats. That's what a red team is all about!\n\nNow, how do you assemble this dream team? Start by identifying the right people. You're looking for a diverse mix of skills and perspectives. Think developers, data scientists, and even your end-users.\n\nNext, define their mission. What vulnerabilities will they target? How will they report their findings? Remember, clear communication is key to a successful red team operation.\n\nLastly, equip them with the right tools. This could mean providing training, access to your system, and even incentives for finding vulnerabilities.\n\nSo, are you ready to build your red team? Don't forget to like, share, and subscribe for more exciting content on LLM applications. And remember, with great power comes great responsibility. Until next time, stay secure!\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-04-20"}}
{"video": {"title": "Challenges and Opportunities in Generative AI", "transcript": "####Challenges and Opportunities in Generative AI\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-07\n\n#### BEGIN TRANSCRIPT ####\nHey there, Antje Barth here, and today we're diving into the exciting world of generative AI!\n\nFirst, we'll tackle some of the current challenges in generative AI, like data privacy, bias, and ethical considerations.\n\nBut don't worry, we'll also explore the potential opportunities of generative AI, from creating more personalized user experiences to generating new ideas and solutions.\n\nThen, we'll hear from some of the brightest minds in the field about their experiences and insights into the future of generative AI.\n\nAnd let's not forget about the business use-cases. We'll explore how companies are using generative AI to create value and drive innovation.\n\nBy the end of this video, you'll have a better understanding of the challenges and opportunities in generative AI and how you can contribute to the field.\n\nSo, let's get started! See you in the course.\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-07"}}
{"video": {"title": "Building Your Own LLM from Scratch", "transcript": "Refined Video Script: ####Building Your Own LLM from Scratch\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Shelbee Eigenbrode, and today we're diving into the exciting world of building your own LLM from scratch!\n\nNow, I know what you're thinking, \"Shelbee, building an LLM from scratch sounds like a daunting task!\" But don't worry, we've got you covered. We'll walk you through the entire process, step by step.\n\nWe'll start by preparing our data, then we'll move on to building our LLM using the transformer architecture. And don't forget about training our model and evaluating its performance.\n\nBut wait, there's more! We'll also share some best practices for building LLMs. We'll talk about using pre-trained models and transfer learning to give your model a boost, and implementing regularization techniques to keep it from overfitting.\n\nBy the end of this video, you'll have a solid understanding of how to build your own LLM from scratch and some practical skills for working with this technology. So, are you ready to become an LLM building pro? Let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-12"}}
{"video": {"title": "TensorFlow: From Beginner to Pro", "transcript": "Positive Points:\n\n- Clear introduction of the topic and the structure of the video.\n- Use of active voice and simple language.\n- Encouragement for the audience to engage with the content.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.\n- Improve contrast and pacing to maintain interest.\n- Include more personal insights and real-world applications.\n- Improve the introduction to make it more engaging and memorable.", "author": "Laurence Moroney", "publication_date": "2022-03-08"}}
{"video": {"title": "Scaling Your ML Production System", "transcript": "####Scaling Your ML Production System\nby Andrew Ng - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! Andrew Ng here, and today we're diving into the exciting world of scaling your Machine Learning production system.\n\nScaling is all about ensuring our system can handle a growing amount of data and users. It's about building a system that's not just robust and efficient, but also ready for the next big leap.\n\nFirst things first, we need to understand our scaling needs. This involves analyzing our data volume, user traffic, and performance requirements. Think of it as setting the stage for our scaling journey.\n\nNext, we need to choose the right scaling strategy. This might involve horizontal scaling, vertical scaling, or a combination of both. It's like choosing the right tools for the job.\n\nThen, we need to implement our scaling strategy. This involves setting up our infrastructure, deploying our model, and testing everything thoroughly. It's the part where we roll up our sleeves and get to work.\n\nBut the journey doesn't end there. We also need to monitor our system performance, handle any scaling issues that arise, and continuously improve our scaling processes. It's a never-ending quest for improvement.\n\nSo, are you ready to scale your ML production system? Start planning your scaling strategy today, and remember, a successful scaling strategy is the secret sauce to a successful ML system.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content on Machine Learning. Until next time, keep learning and keep scaling!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-10"}}
{"video": {"title": "Function-Calling and Data Extraction: Scaling and Optimization", "transcript": "####Function-Calling and Data Extraction: Scaling and Optimization\nby Jiantao Jiao, Venkat Srinivasan - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao and welcome back to our series on function-calling and data extraction with LLMs. Today, we're diving into the world of scaling and optimization.\n\nWe'll cover how to optimize performance, how to scale your applications, and how to handle large datasets. We'll also share some best practices for deploying and maintaining your applications.\n\nBy the end of this video, you'll have a better understanding of how to scale and optimize your applications when using function-calling and data extraction.\n\nRemember, the key to success is to keep learning and improving. So, don't just watch the video. Try out the examples yourself and experiment with different techniques.\n\nAnd if you have any questions, feel free to leave them in the comments. We're here to help!\n\nSo, are you ready to learn about scaling and optimization when using function-calling and data extraction with LLMs? Let's get started!\n\nDon't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-04-25"}}
{"video": {"title": "Ensuring Safety and Relevance in LLM Outputs", "transcript": "####Ensuring Safety and Relevance in LLM Outputs\nby Andrew Ng - 2022-10-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Andrew Ng! Are you ready to dive into the world of LLM outputs? Today, we're going to explore how to ensure safety and relevance in these outputs. We'll learn how to evaluate inputs and outputs for accuracy and quality. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-22"}}
{"video": {"title": "Applying Deep Learning to NLP", "transcript": "####Applying Deep Learning to NLP: A Fun and Engaging Journey\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2023-05-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! It's your favorite AI guide, and today we're embarking on an exciting journey to apply deep learning to Natural Language Processing (NLP).\n\nWe'll kick things off with the basics of NLP, including word embeddings, sequence modeling, and attention mechanisms. Then, we'll dive into building our own NLP system using Python, TensorFlow, and Transformers.\n\nBy the end of this video, you'll have built your own NLP system and applied it to a real-world scenario. Trust me, it's going to be a blast!\n\nSo, are you ready to build your own NLP system? Let's get started!\n\nRemember, this video is part of our Deep Learning Specialization, so if you're new to the field, you might want to start with the basics first.\n\nAnd that's it for today! I hope you enjoyed building your own NLP system as much as I did. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and having fun!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2023-05-05"}}
{"video": {"title": "Quantization 101: Shrinking Models with Hugging Face and Quanto", "transcript": "####Quantization 101: Shrinking Models with Hugging Face and Quanto\nby Younes Belkada and Marc Sun - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today, I'm teaming up with my colleague Marc Sun to take you on an exciting journey into the world of model quantization using Hugging Face Transformers library and the Quanto library.\n\nBut first, let's answer the burning question: what is quantization? Simply put, it's a powerful method for compressing models, making them smaller and faster. Think of it as shrinking your model's clothes to fit into a smaller suitcase.\n\nWe'll start by exploring linear quantization, the most common method used in quantization. Don't worry, we'll make it easy to understand.\n\nThen, we'll roll up our sleeves and practice quantizing open source multimodal and language models. Trust us, it's not as hard as it sounds.\n\nAnd the cherry on top? We're partnering with Hugging Face to bring you this content. So, you'll be learning from the best in the industry.\n\nBy the end of this video, you'll be a pro at compressing models with Hugging Face Transformers library and the Quanto library.\n\nSo, are you ready to shrink some models? Let's dive in!\n\nAnd remember, if you have any questions, leave them in the comments below. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, keep learning and keep growing.\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-15"}}
{"video": {"title": "Mistral AI: Exploring the Open-Source Models", "transcript": "####Mistral AI: Unleashing the Power of Open-Source Models\nby Younes Belkada, Marc Sun - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! Marc Sun here, and today we're diving into the exciting world of Mistral AI.\n\nGet ready to explore Mistral's open-source models: Mistral 7B, Mixtral 8x7B, and Mixtral 8x22B. These models are a game-changer for those just starting out with Mistral AI and a fantastic way to learn about and experiment with LLMs.\n\nBut wait, there's more! These models are more powerful than you might think. From generating text to answering questions, they're like having a super-powered assistant at your fingertips.\n\nSo, buckle up and join us on this journey. And remember, if you have any questions, just let us know. Don't forget to like, share, and subscribe for more updates. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-20"}}
{"video": {"title": "Deep Learning Specialization: A Recap and Next Steps", "transcript": "####Deep Learning Specialization: A Recap and Next Steps\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-03-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your guide on this exciting journey and today we're taking a look back at our Deep Learning Specialization and planning our next steps.\n\nWe've come a long way, from building neural networks to exploring real-world applications. But the journey doesn't stop here. There's always more to learn and discover in the world of AI.\n\nSo, let's recap what we've learned and look ahead to the future. And remember, if you have any questions or need guidance, leave a comment below. I'm here to help!\n\nAnd don't forget to give this video a thumbs up and subscribe to our channel for more AI content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-03-05"}}
{"video": {"title": "Real-World Examples: ML Production Systems in Action", "transcript": "####Real-World Examples: ML Production Systems in Action\nby Andrew Ng - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, ML enthusiasts! Andrew Ng here, and today we're diving into the fascinating world of ML production systems.\n\nWe'll explore how tech giants like Google, Facebook, and Amazon are leveraging ML to revolutionize their products and services. We'll discuss their architectures, strategies, and best practices.\n\nBut wait, there's more! We'll also look at some intriguing case studies from various industries, such as healthcare, finance, and transportation.\n\nRemember, the best way to learn is by looking at real-world examples. So, let's get started!\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and keep innovating!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-25"}}
{"video": {"title": "Building an Agentic RAG System from Scratch", "transcript": "####Building an Agentic RAG System from Scratch\nby Jerry Liu - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow tech enthusiasts! Jerry Liu here, and today we're diving into the exciting world of Agentic RAG systems. We're going to learn how to build one from scratch, so buckle up!\n\nFirst things first, let's talk about the basics of building an Agentic RAG system. It's like learning how to build a house before you start building. We'll cover the essentials, so you'll be ready to tackle the project head-on.\n\nNext, we'll talk about designing your system. Because sometimes, you need a blueprint before you start building. We'll go over the best practices for designing an Agentic RAG system that's both efficient and effective.\n\nThen, we'll discuss how to build and test your system. Because sometimes, you need to try things out before you know they'll work. We'll cover the ins and outs of building and testing, so you can be confident in your system's performance.\n\nAnd finally, we'll go over some tips and tricks for building an Agentic RAG system like a pro. We'll share some insider knowledge that will help you take your system to the next level.\n\nSo, are you ready to build your own Agentic RAG system? Let's get started!\n\nRemember, building an Agentic RAG system is all about planning and execution. So, don't be afraid to take your time and plan out your approach. And most importantly, have fun with it!\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-30"}}
{"video": {"title": "Machine Learning Projects: Where to Start?", "transcript": "####Machine Learning Projects: Where to Start?\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-03-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! Are you ready to dive into some exciting projects? Today, we're going to explore where to start and what to build in the world of Machine Learning.\n\nFirst things first, let's talk about why we're here. We want to learn, have fun, and maybe even impress our friends with our new skills. And the best part? We'll be using Python, so you'll get some coding practice too!\n\nNow, let's get down to business. We'll be discussing some project ideas and how to approach them. Remember, the key to successful projects is planning and practice. So, keep coding and experimenting.\n\nBut wait, there's more! We'll also be sharing some tips and tricks to make your projects stand out. And don't worry, we'll translate any jargon into simpler words.\n\nSo, are you ready to take your Machine Learning skills to the next level? Let's get started!\n\nAnd before we go, don't forget to give us a thumbs up and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-03-05"}}
{"video": {"title": "Optimizing RAG Performance in JavaScript Applications", "transcript": "####Optimizing RAG Performance in JavaScript Applications\nby Laurie Voss - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Laurie Voss here! Today, we're diving into the exciting world of optimizing RAG performance in JavaScript applications.\n\nRAG applications can be a real resource hog, so let's get our hands dirty and make them run like a well-oiled machine. We'll be exploring techniques like caching, data preprocessing, and query optimization to boost performance.\n\nFirst things first, we'll use the create-llama command-line tool to set up our project and install the necessary dependencies. Then, we'll create our frontend component using React and integrate it with our RAG-powered backend.\n\nWe'll also cover how to persist your data, enable chatting with your data, and make streaming responses a reality.\n\nThroughout this journey, I'll be sharing my top tips and best practices for building RAG applications in JavaScript. By the end of this video, you'll have a fully functional web app that's optimized for performance.\n\nThanks for tuning in and happy coding! Don't forget to check out LlamaIndex for more resources on building intelligent applications.\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2023-04-15"}}
{"video": {"title": "TensorFlow: Advanced Functional API Techniques", "transcript": "####TensorFlow: Advanced Functional API Techniques\nby Laurence Moroney, Eddy Shyu - 2022-03-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into some advanced techniques with TensorFlow's Functional API.\n\nFirst up, we're going to learn how to create models with shared layers. This is a game-changer for building models that can learn from multiple inputs.\n\nNext, we're going to explore how to create models with multiple inputs and outputs. This is a must-know for tasks like machine translation, where we need to process an input sequence and generate an output sequence.\n\nThen, we're going to get our hands dirty with custom training loops. This is where we can really take control of our training process, and do things like learning rate scheduling and early stopping.\n\nAnd finally, we're going to look at how to use the Functional API with pre-trained models. This can help us get state-of-the-art results with minimal effort.\n\nSo, are you ready to level up your Functional API skills? Let's do this!\n\nRemember, the best way to learn is by doing. So, try out these techniques for yourself, and see what you can create.\n\nThanks for watching, and happy coding!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-03-29"}}
{"video": {"title": "The Lifecycle of Generative AI", "transcript": "####The Lifecycle of Generative AI: A Journey Through Training, Tuning, and Inference\nby Chris Fregly - 2022-10-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to dive into the fascinating world of generative AI? Well, buckle up because we're about to embark on an exciting journey. In this video, we'll explore the lifecycle of generative AI, from training to tuning to inference. Trust me, you won't want to miss this. I'm your host, Chris Fregly, and I'm thrilled to share this knowledge with you. So, let's get started!\n#### END TRANSCRIPT ########", "author": "Chris Fregly", "publication_date": "2022-10-03"}}
{"video": {"title": "Mastering Unstructured Data Preprocessing for LLM Applications", "transcript": "####Mastering Unstructured Data Preprocessing for LLM Applications\nby Matt Robinson - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Matt Robinson, and today we're embarking on an exciting journey into the world of preprocessing unstructured data for LLM applications.\n\nBut why should you care? Well, if you're looking to level up your RAG system, you need to retrieve diverse data types. That means extracting and normalizing content from a wide variety of document types, such as PDFs, PowerPoints, Word, and HTML files.\n\nBut wait, there's more! We'll also explore how to preprocess tables and images to expand the information accessible to your LLM.\n\nNow, let's enrich our content with metadata. This not only enhances retrieval augmented generation (RAG) results but also supports more nuanced search capabilities.\n\nNext, we'll dive into document image analysis techniques. We'll look at layout detection and vision and table transformers. Don't worry if these terms sound intimidating. I'll break them down into simple, easy-to-understand concepts.\n\nWe'll then apply these methods to preprocess PDFs, images, and tables. By the end of this video, you'll be a pro at handling unstructured data.\n\nRemember, practice makes perfect. So, don't be afraid to get your hands dirty and experiment with these techniques.\n\nAnd before I forget, a big shout-out to our partners at Unstructured for making this video possible.\n\nThat's it for today. If you found this video helpful, be sure to like, share, and subscribe for more exciting content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Matt Robinson", "publication_date": "2023-03-15"}}
{"video": {"title": "Mastering ChatGPT Prompt Engineering for Beginners", "transcript": "####Mastering ChatGPT Prompt Engineering for Beginners\nby Isa Fulford, Andrew Ng - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're embarking on an exciting journey into the world of prompt engineering for ChatGPT. If you're a developer with basic Python skills, you're in luck!\n\nFirst things first, let's talk about what prompt engineering is and why it matters. It's the art of designing and optimizing the input you give to a language model like ChatGPT to get the output you desire. It's a must-have skill for anyone looking to build applications using LLMs.\n\nNow, let's dive into some best practices. Rule number one of prompt engineering: be clear and specific. The more precise your prompt, the better the output.\n\nNext, let's explore some innovative ways to use LLMs. Did you know you can use them for summarizing, inferring, transforming, and expanding text? Let's see some examples using the OpenAI API.\n\nNow, it's your turn. Let's get some hands-on practice writing and iterating on prompts. Remember, the secret to successful prompt engineering is iteration. Don't be afraid to tweak and refine your prompts until you get the output you want.\n\nThat's a wrap for today's lesson. Remember, practice makes perfect when it comes to prompt engineering. So get out there and start building! And don't forget to check out our partners at OpenAI for more resources and tools.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-15"}}
{"video": {"title": "Building a Question Answering System with LlamaIndex", "transcript": "####Building a Question Answering System with LlamaIndex\nby Jerry Liu - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Jerry Liu here, and today we're diving into the exciting world of building a question answering system with LlamaIndex.\n\nIn our previous videos, we've learned how to build an agentic RAG, mastered document Q&A, unleashed the power of summarization, built a multi-document research agent, learned how to debug and control our agent, and extended our agent with custom functions. Today, we're taking it to the next level by building a complete question answering system.\n\nBut first, let's understand how to structure our data for question answering. Then, we'll dive into building our system with LlamaIndex.\n\nOnce we've got that down, we'll look at how to fine-tune our system to improve its accuracy and efficiency.\n\nBy the end of this video, you'll be a pro at building question answering systems with LlamaIndex.\n\nSo, let's get started! And remember, practice makes perfect. So, don't just watch this video, try building your own question answering system with LlamaIndex.\n\nIf you found this video helpful, give it a thumbs up and subscribe to our channel for more exciting content. Until next time, happy coding!\n\n\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-15"}}
{"video": {"title": "Mastering Q&A with Your Agentic RAG", "transcript": "####Mastering Q&A with Your Agentic RAG\nby Jerry Liu - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Jerry Liu here, and welcome back to our series on Agentic RAG systems! Today, we're diving into one of the most exciting features of these systems: Q&A. That's right, we're going to teach our agent how to answer questions about your data.\n\nFirst, we'll cover how to format your questions so your agent can understand them. Remember, your agent is smart, but it's not a mind reader.\n\nNext, we'll explore how your agent finds the answers in your data. It's like a treasure hunt, but with information.\n\nThen, we'll discuss how to handle complex questions. You know, the ones that make you go 'hmm'. Your agent can handle those too, with a little help from you.\n\nAnd finally, we'll go over some common pitfalls and how to avoid them. Because let's face it, we all make mistakes.\n\nSo, are you ready to turn your data into a Q&A powerhouse? Let's get started!\n\nRemember, the key to mastering Q&A is practice. So, don't be afraid to ask your agent lots of questions. The more you practice, the better you'll get.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-03-20"}}
{"video": {"title": "TensorFlow: Advanced Computer Vision Techniques", "transcript": "####TensorFlow: Advanced Computer Vision Techniques\nby Laurence Moroney, Eddy Shyu - 2022-03-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eddy Shyu, and today we're going to explore some advanced computer vision techniques with TensorFlow.\n\nFirst up, object detection. We'll see how to train a model to recognize and locate objects within an image. This is a crucial skill for applications like self-driving cars and security systems.\n\nNext, we're diving into semantic segmentation. This is where we teach our model to understand which parts of an image belong to which objects. It's like coloring by numbers, but for robots.\n\nThen, we're exploring style transfer. This is where we take the style of one image and apply it to another. It's like turning a photograph into a painting, or vice versa.\n\nAnd finally, we're looking at neural style transfer, a technique that combines the content of one image with the style of another. It's like creating a piece of art that's a blend of two different styles.\n\nSo, are you ready to take your computer vision skills to the next level? Let's get started.\n\nRemember, the best way to learn is by doing. So, try out these techniques for yourself, and see what you can create.\n\nThanks for watching, and happy coding!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-03-08"}}
{"video": {"title": "Diffusion Models: Unraveling the Mystery", "transcript": "####Diffusion Models: Unraveling the Mystery\nby Sharon Zhou - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Sharon Zhou here, and today we're diving into the fascinating world of diffusion models!\n\nNow, I know what you're thinking, \"Diffusion models? That sounds complicated!\" But trust me, it's not as scary as it seems. It's like making a smoothie. You start with simple ingredients, blend them together, and voila! You get a delicious, complex mixture.\n\nSo, let's get our hands dirty and create our own diffusion model. Grab your Python, Tensorflow, or Pytorch, and let's get started. We'll define our data distribution, add noise, and learn how to denoise it.\n\nBut wait, there's more! Sampling from diffusion models can be slower than a snail on a hot day. But don't worry, I've got you covered. I'll introduce you to some cool algorithms that can accelerate sampling by a whopping 10 times!\n\nBy the end of this video, you'll be a diffusion model pro, ready to build and train your own. So, keep blending, keep learning, and who knows? You might just create the perfect 'diffusion smoothie'!\n\nThanks for watching, and remember to like, share, and subscribe for more exciting content. See you next time!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-03-20"}}
{"video": {"title": "Mastering Hugging Face: A Beginner's Guide", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits of using Hugging Face.\n- Use of active voice and simple language.\n- Concise and engaging conclusion.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Introduce stakes and payoff to capture the audience.\n- Leverage curiosity gaps to create anticipation.\n- Make the conclusion more memorable and engaging.", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-04-08"}}
{"video": {"title": "Building a Personalized LLM Application with Python and Predibase's LoRAX Framework", "transcript": "####Building a Personalized LLM Application with Python and Predibase's LoRAX Framework\nby Travis Addair - 2023-03-27\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Travis Addair and today we're going to have a blast building a personalized LLM application using Python and Predibase's LoRAX framework.\n\nBut first, let's talk about what a personalized LLM application is. It's an application that can generate responses tailored to a specific user. This can be useful for a variety of applications, such as chatbots and virtual assistants.\n\nNext, we'll dive into how to use Python and Predibase's LoRAX framework to build a personalized LLM application. We'll start by fine-tuning a pre-trained language model on our specific task using LoRA. Once we have our fine-tuned model, we'll use LoRAX to serve it to multiple users at once.\n\nWe'll also talk about how to handle requests from multiple users and how to balance the load between multiple models. This will ensure that our application is scalable and can handle a large number of requests.\n\nFinally, we'll discuss some best practices for building personalized LLM applications, such as how to handle input validation and how to monitor the performance of our application.\n\nThanks for watching and don't forget to like, comment, and subscribe for more videos on GenAI and LLM powered applications. See you in the next one!\n#### END TRANSCRIPT ########", "author": "Travis Addair", "publication_date": "2023-03-27"}}
{"video": {"title": "Expanding Text with Dynamic Prompt Engineering Strategies", "transcript": "####Expanding Text with Dynamic Prompt Engineering Strategies\nby Isa Fulford - 2022-11-03\n\n#### BEGIN TRANSCRIPT ####\n\nAre you ready to take your language model skills to the next level? Today, we're diving into the world of dynamic prompt engineering strategies to expand your text and generate new content using ChatGPT.\n\nImagine being able to create engaging and unique content with just a few clicks. That's the power of dynamic prompt engineering!\n\nBut first, let's set the scene. You're sitting at your desk, staring at a blank screen, and you have no idea where to start. Sound familiar? Don't worry, we've all been there. But with dynamic prompt engineering, you'll never have to face that blank screen again.\n\nIn this video, we'll cover the basics of dynamic prompt engineering and show you how to use ChatGPT to generate new ideas and expand your text. We'll also share some tips and tricks to help you get the most out of this powerful tool.\n\nSo, are you ready to become a prompt engineering pro? Let's get started!\n\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-11-03"}}
{"video": {"title": "Prompt Engineering 101: Getting Started with ChatGPT", "transcript": "Hey there, I'm Isa Fulford and today we're diving into the exciting world of prompt engineering for ChatGPT. If you're a developer with basic Python skills, you're in luck!\n\nFirst things first, let's talk about what prompt engineering is and why it's a game-changer. Prompt engineering is the art of designing and optimizing inputs for language models like ChatGPT. It's crucial because the right prompt can make all the difference in getting the results you want.\n\nNow, let's get into some best practices. First, be clear and specific with your prompts. The more detailed you are, the better ChatGPT can understand what you're asking for. Second, don't be afraid to iterate. Prompt engineering is an iterative process, so try out different prompts and see what works best.\n\nNext, let's explore some new ways to use LLMs, or large language models. Did you know you can use LLMs for summarizing, inferring, transforming, and expanding text? Let's take a look at some examples using the OpenAI API.\n\nNow, it's time for some hands-on practice. We'll walk through writing and iterating on prompts together, and I'll show you how to use the OpenAI API to get results from ChatGPT.\n\nTo wrap up, prompt engineering is a powerful tool for application development with ChatGPT. With these best practices and some hands-on experience, you'll be well on your way to mastering prompt engineering. So go ahead and start experimenting with your own prompts. And who knows, you might even build your own custom chatbot!\n\nThanks for watching, and happy prompt engineering!", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-17"}}
{"video": {"title": "Mastering Prompt Engineering with Llama 2 & 3", "transcript": "####Mastering Prompt Engineering with Llama 2 & 3\nby Amit Sangani - 2023-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Amit Sangani and welcome to our exciting journey on Mastering Prompt Engineering with Llama 2 & 3.\n\nAre you ready to become a prompting pro and unlock the full potential of these powerful models? You're in the right place! In this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst, we'll take a look at Meta Llama 2 Chat and how you can interact with it to get the most out of your prompts. I'll show you some tips and tricks to help you prompt smarter, not harder.\n\nNext, we'll dive into Code Llama and I'll show you how to use it to build some really cool applications. You'll be amazed at what you can create with just a few prompts!\n\nBut that's not all, we'll also be taking a look at Llama Guard and how you can use it to build safe and responsible AI applications. In today's world, it's more important than ever to make sure our AI is being used for good.\n\nSo, are you ready to get started? Let's dive in and start prompting like a pro with Llama 2 & 3. And don't forget to hit that like and subscribe button for more great content. See you in the next video!\n\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-15"}}
{"video": {"title": "Future Trends in On-Device AI", "transcript": "####Future Trends in On-Device AI\nby Krishna Sridhar - 2022-02-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Krishna Sridhar here, and today we're diving into the exciting world of On-Device AI. We'll be exploring the future trends that are shaping the landscape of edge computing. So, buckle up and get ready to discover how advancements in AI hardware and software are revolutionizing the way we interact with technology. Let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-02-25"}}
{"video": {"title": "Implementing Weights Packing for Efficient Models", "transcript": "####Implementing Weights Packing for Efficient Models\nby Marc Sun, Younes Belkada - 2022-03-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc Sun, and today we're diving into the world of weights packing!\n\nEver wondered how to make your models more efficient? Well, you're in luck! We're going to learn how to pack four 2-bit weights into a single 8-bit integer. This technique can save you both storage and computation resources.\n\nFirst, we'll discuss the concept of weights packing. Then, we'll roll up our sleeves and get into the code, showing you how to implement it in Pytorch. Don't worry, we'll take it step by step.\n\nBy the end of this video, you'll have a solid understanding of how to use weights packing to optimize your models. And the best part? You'll be able to put this knowledge into practice right away.\n\nSo, let's get started! And remember, the best way to learn is by doing.\n\nDon't forget to like, share, and subscribe for more great content.\n\nUntil next time, I'm Marc Sun, and this has been Implementing Weights Packing for Efficient Models. Happy coding!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-03-29"}}
{"video": {"title": "Harnessing AI Power with Hugging Face Open Source Models", "transcript": "####Harnessing AI Power with Hugging Face Open Source Models\nby Maria Khalusova, Marc Sun, Younes Belkada - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Younes, and today we're diving into the exciting world of Hugging Face open-source models.\n\nFirst things first, let's head over to the Hugging Face Hub. It's like a goldmine of open-source models, and you can filter them based on task, rankings, and memory requirements.\n\nOnce you've found your dream model, using it is a piece of cake. With the transformers library, you can perform various tasks with just a few lines of code.\n\nNow, once you've built your AI app, sharing it is as easy as pie. With Gradio and Hugging Face Spaces, you can share your app with a user-friendly interface or via API, and run it on the cloud.\n\nSo, are you ready to harness AI power with Hugging Face? Let's get this party started! Remember, no AI experience is necessary.\n\nStay tuned for more AI insights, and don't forget to like, share, and subscribe. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-04-15"}}
{"video": {"title": "Chat with Your Data using LangChain!", "transcript": "####Chat with Your Data using LangChain!\nby Harrison Chase - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Harrison Chase, the mastermind behind LangChain, and today we're going to have a blast building a chatbot that can interact with your private data and documents.\n\nSounds daunting? Fear not! I guarantee it's simpler than you think, even if you're just starting out with Python.\n\nLet's kick things off by discussing what LangChain is. It's a mighty tool that allows you to access and communicate with various data sources. It's like having a personal assistant who can read and comprehend all your documents and data.\n\nWith LangChain, you can access over 80 unique loaders to handle different types of data sources. From PDFs to databases, LangChain has you covered.\n\nNow, let's dive into creating your very own chatbot. Imagine being able to chat directly with information from your own documents and data. No more rummaging through endless files or databases. Just ask your chatbot and get the answer you need in a snap.\n\nI'll walk you through each step, explaining everything in simple, jargon-free language. By the end of this video, you'll have your own personal data assistant!\n\nSo, are you ready to transform the way you interact with your data? Let's get started!\n\nRemember, if you have any questions or need further clarification, don't hesitate to leave a comment. I'm always here to help. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-15"}}
{"video": {"title": "Prompt Engineering for Text Transformation with ChatGPT", "transcript": "####Prompt Engineering for Text Transformation with ChatGPT\nby Isa Fulford, Andrew Ng - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're diving into the exciting world of prompt engineering for text transformation with ChatGPT. If you're a beginner with basic Python skills, you're in the right place!\n\nFirst things first, what is text transformation and why should you care? Text transformation is the process of changing text from one form to another. It's a valuable skill in many areas, from language translation to content generation.\n\nNow, let's see how we can use ChatGPT and prompt engineering to transform text like a pro. The key is to craft prompts that ask the model to transform the text in a specific way. Let's look at some examples and try it out ourselves.\n\nRemember, the key to good prompts is to be clear, concise, and specific. Let's iterate on our prompts and see how we can improve the transformations we get from ChatGPT.\n\nAnd that's a wrap! You've just learned how to use prompt engineering for text transformation with ChatGPT. Remember, practice makes perfect. So keep experimenting and refining your prompts.\n\nThanks for watching and happy coding! And a special thanks to our partners at OpenAI for their support.\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-04-10"}}
{"video": {"title": "Troubleshooting Common Issues with Knowledge Graphs for RAG", "transcript": "####Troubleshooting Common Issues with Knowledge Graphs for RAG\nby Andreas Kollegger - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Andreas Kollegger and today we're diving into the world of troubleshooting common issues with knowledge graphs for Retrieval Augmented Generation, or RAG.\n\nBut wait, what's LangChain? If you're new to this, I suggest checking out our quick course 'LangChain: Chat with Your Data' before you dive into this intermediate level content.\n\nNow, let's get started. We'll be using Neo4j's query language, Cypher, to manage and retrieve data from our knowledge graph.\n\nIn this video, we'll discuss some common issues that you might encounter when working with knowledge graphs for RAG and how to troubleshoot them. We'll also provide some tips and tricks for avoiding these issues in the first place.\n\nSo, are you ready to troubleshoot some common issues with knowledge graphs for RAG? Let's get started.\n\nRemember, the key to troubleshooting is patience and persistence. So, don't be afraid to try, fail, and try again. And if you have any questions, feel free to leave them in the comments below.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2023-04-10"}}
{"video": {"title": "Introduction to On-Device AI", "transcript": "####Introduction to On-Device AI\nby Krishna Sridhar - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Krishna Sridhar here, and today we're diving headfirst into the thrilling world of On-Device AI. Get ready to learn how to deploy AI models on edge devices and smartphones. Trust me, you won't want to miss this!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-01-15"}}
{"video": {"title": "Training GANs: Tips and Tricks", "transcript": "####Training GANs: Tips and Tricks\nby Eric Zelikman - 2022-10-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! Are you struggling with training your Generative Adversarial Networks? Well, you're in luck! I'm Eric Zelikman, and in this video, I'll be sharing some of my top tips and tricks to help you train your GAN models like a pro. So, let's dive in and optimize your GAN training process together!\n#### END TRANSCRIPT ########", "author": "Eric Zelikman", "publication_date": "2022-10-05"}}
{"video": {"title": "Addressing Vulnerabilities in LLM Applications: The Final Step in Red Teaming", "transcript": "####Addressing Vulnerabilities in LLM Applications: The Final Step in Red Teaming\nby Matteo Dora, Luca Martial - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, LLM fans! Luca Martial here, and today we're diving into the final step of red teaming: addressing those pesky vulnerabilities we've uncovered.\n\nBut first, let's talk about how we tackle a vulnerability. Step one: figure out the root cause. Why is this happening? Is it our model, our data, or our code that's causing the issue?\n\nOnce we've got that sorted, we can start brainstorming solutions. This might mean retraining our model, cleaning up our data, or tweaking our code.\n\nRemember, we're not aiming for perfection here. We're looking for a solution that effectively addresses the vulnerability and boosts the safety and reliability of our app.\n\nAnd don't forget about Giskard's open-source library! It's packed with tools and resources to help you tackle vulnerabilities in your LLM applications.\n\nThat's all for today, folks. Don't forget to like, share, and subscribe for more LLM goodness. Until next time, happy red teaming!\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-04-01"}}
{"video": {"title": "Mastering Machine Learning in Production: A Comprehensive Guide", "transcript": "####Mastering Machine Learning in Production: A Comprehensive Guide\nby Andrew Ng - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! I'm Andrew Ng, and today we're embarking on an exciting journey to master Machine Learning in Production.\n\nFirst things first, let's talk about scoping. It's like planning a road trip - you need to know where you're going before you start the engine. We'll discuss how to define your ML project's objectives and set clear, measurable goals.\n\nNext, we'll delve into data. It's the fuel for our ML engine. We'll explore data collection, preprocessing, and how to handle missing or incorrect data.\n\nThen, we'll get our hands dirty with modeling. We'll cover selecting the right algorithm, training your model, and evaluating its performance.\n\nOnce we've built our model, it's time for deployment. We'll walk through integrating your model into your existing systems, monitoring its performance, and handling any issues that arise.\n\nFinally, we'll discuss continuous improvement. Just like a well-oiled machine, our ML system needs regular maintenance and updates to stay in top shape.\n\nRemember, building an ML production system is a journey, not a destination. So, buckle up, and let's get started!\n\nStay tuned for more insights in our next video. Don't forget to like, share, and subscribe for more exciting content on GenAI and LLM powered applications. Until next time, keep learning!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-01-01"}}
{"video": {"title": "Deployment Strategies: From Lab to Live", "transcript": "####Deployment Strategies: From Lab to Live\nby Andrew Ng - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, ML enthusiasts! Andrew Ng here, and today we're diving into the exciting world of deploying ML models.\n\nDeploying a model is like launching a rocket. You need a solid plan, rigorous testing, and a smooth launch process. We'll discuss different deployment strategies, from shadow deployment and canary releases to blue-green deployments.\n\nBut wait, there's more! We'll also explore how to monitor your model in production, handle failures, and ensure high availability and low latency.\n\nRemember, the goal is not just to deploy a model, but to deploy a model that can deliver value consistently and reliably. So, let's get started!\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and keep innovating!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-30"}}
{"video": {"title": "Efficiently Serving LLMs", "transcript": "####Efficiently Serving LLMs\nby Travis Addair - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, welcome back to our channel! Today, we're diving into the world of Large Language Models (LLMs) and how we can efficiently serve them to multiple users. I'm Travis Addair, and I'm thrilled to explore this topic with you.\n\nImagine being able to serve LLMs to multiple users without breaking a sweat. Sounds like a dream, right? Well, it's not. It's possible, and I'm here to show you how.\n\nFirst, we'll discuss the challenges of serving LLMs. Then, we'll dive into some practical solutions. And finally, we'll look at some real-world examples of efficient LLM serving.\n\nBut wait, there's more! We'll also discuss the future of LLM serving and how you can stay ahead of the curve.\n\nSo, are you ready to take your LLM serving skills to the next level? Let's get started!\n#### END TRANSCRIPT ########", "author": "Travis Addair", "publication_date": "2022-10-15"}}
{"video": {"title": "Generative AI for Creativity and Design", "transcript": "####Generative AI: Unleashing Creativity and Design\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, Mike Chambers here, and today we're diving into the fascinating world of generative AI and its impact on creativity and design.\n\nImagine an AI that can compose music, design fashion, or create stunning graphics. Sounds like science fiction, right? Well, it's not! Generative AI is here, and it's changing the game.\n\nIn this video, we'll explore how Large Language Models (LLMs) can generate new ideas and designs. We'll also discuss the latest research in this area and the ethical considerations of using AI for creativity and design.\n\nBut wait, there's more! We'll share best practices for collaborating with AI systems, so you can harness its power for your own projects.\n\nBy the end of this video, you'll have a solid understanding of how generative AI can be used for creativity and design. You'll be able to apply these techniques to your own work and stay ahead of the curve in this rapidly evolving field.\n\nSo, are you ready to unleash your creativity with AI? Let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-29"}}
{"video": {"title": "Challenges and Opportunities in Generative AI", "transcript": "####Challenges and Opportunities in Generative AI\nby Shelbee Eigenbrode - 2022-10-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Shelbee Eigenbrode, and today we're diving into the thrilling world of generative AI. We'll uncover the challenges and opportunities that lie ahead, and I promise, it's going to be a wild ride!\n\nFirst, let's talk about the elephant in the room: the challenges. From ethical concerns to technical hurdles, generative AI is not without its obstacles. But fear not, because with every challenge comes an opportunity. And in this case, the opportunities are endless.\n\nSo, buckle up and get ready to explore the latest developments and trends in generative AI. Trust me, you won't want to miss this!\n#### END TRANSCRIPT ########", "author": "Shelbee Eigenbrode", "publication_date": "2022-10-05"}}
{"video": {"title": "Mastering Multimodal Retrieval and Generation", "transcript": "####Mastering Multimodal Retrieval and Generation\nby Sebastian Witalec - 2022-10-09\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Sebastian! Today, we're going on an exciting journey to master multimodal retrieval and generation. Get ready to learn how to harness the power of multimodality to create innovative applications that transform the way we search and generate content.\n\nLet's start by understanding what multimodal retrieval and generation are and why they matter. Then, we'll explore some real-world examples and practical use cases. Finally, we'll dive into the technical details and walk through a step-by-step tutorial on how to build your own multimodal application.\n\nBut wait, there's more! We'll also discuss some of the challenges and limitations of multimodal retrieval and generation and how to overcome them. And of course, we'll have some fun along the way with some humor and surprises.\n\nSo, are you ready to join me on this adventure? Let's get started!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-09"}}
{"video": {"title": "Creating a Specialized Chatbot with LangChain", "transcript": "####Creating a Specialized Chatbot with LangChain\nby Harrison Chase, Andrew Ng - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're diving into the world of LangChain to create a specialized chatbot.\n\nFirst things first, we need to pick a specialization. It could be anything from customer service to mental health support. The sky's the limit!\n\nNext up, we'll create a new LLM. We'll use prompts and parsing to teach it how to respond to user input. It's like teaching a child to talk, but way cooler.\n\nWe'll also add some memory to our chatbot. This will allow it to remember previous conversations, making it feel more like a real person.\n\nFinally, we'll create an agent. This will allow our chatbot to perform tasks on behalf of the user. It's like having a personal assistant, but without the awkward small talk.\n\nBy the end of this video, you'll have a specialized chatbot that's ready to help users. So, let's get started and have some fun!\n\nRemember, the best way to learn is by doing. And who knows, you might even impress your friends with your new chatbot creation.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-15"}}
{"video": {"title": "Chaining Calls and Using Agents in LangChain", "transcript": "####Chaining Calls and Using Agents in LangChain\nby Harrison Chase, Andrew Ng - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHello, I'm Harrison Chase, and today we're diving into the fascinating world of LangChain. We're going to learn about chaining calls and using agents.\n\nImagine building a tower out of blocks. That's what chaining calls is like. You're combining simple actions to create complex behaviors.\n\nAnd then there are agents. They're like your personal assistants, delegating tasks to your LLM. It's automation at its finest.\n\nFirst, we'll master chaining calls. I'll show you how to combine prompts, parsing, and memory to create behaviors that are anything but simple.\n\nThen, we'll dive into agents. We'll learn how to create them and how to delegate tasks. It's like having your own personal assistant, but better.\n\nBy the end of this video, you'll be a pro at chaining calls and using agents.\n\nSo, let's get started. Remember, the best way to learn is by doing.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-05"}}
{"video": {"title": "Optimizing Prompt Performance with ChatGPT: Best Practices", "transcript": "####Optimizing Prompt Performance with ChatGPT: Best Practices\nby Isa Fulford - 2022-11-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford, and today we're embarking on an exciting journey to optimize prompt performance with ChatGPT! Are you ready to discover the best practices for crafting effective prompts and unlocking the full potential of your language model? Let's dive in and optimize together!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-11-03"}}
{"video": {"title": "Quantization Made Easy: A Step-by-Step Guide with Hugging Face", "transcript": "####Quantization Made Easy: A Step-by-Step Guide with Hugging Face\nby Younes Belkada, Marc Sun - 2023-03-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the world of quantization with Hugging Face.\n\nBut first, what's quantization? It's a technique that helps us shrink models without losing their accuracy. It's like packing your suitcase for a trip - you want to fit as much as possible without breaking anything.\n\nWe'll start with linear quantization, a simple yet powerful method for model compression. It works by reducing the precision of the weights in your model, resulting in a smaller size and faster inference times.\n\nThen, we'll go through the process of quantizing open-source multimodal and language models. Don't worry if you're new to this, I'll be there to guide you every step of the way.\n\nBy the end of this video, you'll be a pro at quantizing any open-source model using Hugging Face and Quanto.\n\nSo, are you ready to make your models more efficient? Let's get started!\n\nAnd don't forget to like, share, and subscribe for more AI and machine learning content. Until next time!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-01"}}
{"video": {"title": "Applying LLMs to Your Proprietary Data with LangChain", "transcript": "####Applying LLMs to Your Proprietary Data with LangChain\nby Harrison Chase, Andrew Ng - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Harrison Chase, and today we're diving into the world of LLMs and LangChain! We're going to show you how to apply LLMs to your proprietary data and build some amazing applications.\n\nImagine having a personal assistant or specialized chatbot that can answer questions based on your data. Sounds pretty cool, right? Well, that's exactly what we're going to do today.\n\nFirst, we'll take a look at the underlying technology and how LangChain helps our application understand and use your data. Then, we'll dive into the code and use LangChain to apply LLMs to your data. We'll even show you how to build a personal assistant and a specialized chatbot.\n\nBut wait, there's more! We'll also be using agents, chained calls, and memories to make our applications even more powerful.\n\nNow, let's wrap up. You've learned how to use LangChain to apply LLMs to your data, how to build a personal assistant and a specialized chatbot, and how to enhance your applications with agents, chained calls, and memories.\n\nSo, what's next? I challenge you to apply LLMs to your own data and build your own applications. Make them unique. Make them powerful.\n\nThanks for watching. If you found this tutorial helpful, give it a thumbs up and don't forget to subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-20"}}
{"video": {"title": "AI for Public Health: Tackling Health Inequalities with Technology", "transcript": "####AI for Public Health: Tackling Health Inequalities with Technology\nby Robert Monarch - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the exciting world of AI and public health.\n\n[Video hook and introduction]\n\nImagine a world where AI helps tackle health inequalities, improving access to healthcare and personalizing treatment. Sounds like a dream, right? Well, it's not. It's happening right now!\n\n[Body content]\n\nFirst, we'll explore the role of AI in tackling health inequalities. We'll see how it's being used to improve access to healthcare, personalize treatment, and improve public health.\n\nNext, we'll get our hands dirty with a project. We'll build a simple model to predict health outcomes. Don't worry, I'll guide you through it step by step.\n\nBut wait, there's more! We'll also discuss the challenges and ethical considerations of using AI in tackling health inequalities. It's not all sunshine and rainbows, but it's important to know the full story.\n\n[Conclusion and call to action]\n\nSo, are you ready to join the AI for health equality movement? Remember, every life counts, and you can make a difference.\n\nThanks for watching. If you found this video helpful, don't forget to like, share, and subscribe. And stay tuned for more exciting content on AI for health equality.\n\n\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-20"}}
{"video": {"title": "Your Journey with AI for Good: Where to Start?", "transcript": "####Your Journey with AI for Good: Where to Start?\nby Robert Monarch - 2023-05-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Robert Monarch, and today we're embarking on an exciting journey into the world of AI for Good.\n\nNow, I know what you're thinking, \"Robert, AI for Good sounds great, but where do I even start?\" Well, fear not, my friend! I'm here to guide you through the process.\n\nToday, we'll be discussing the various paths you can take to kickstart your AI for Good journey. We'll explore everything from learning the basics, to building your own projects, to advocating for ethical AI use.\n\nAnd don't worry, I've got some top-notch tips and resources to share along the way.\n\nSo, are you ready to dive into the world of AI for Good? Let's do this!\n\nRemember, every step you take towards using AI for Good is a step towards creating a better, brighter future.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning, keep growing, and keep making the world a better place with AI!\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-05-01"}}
{"video": {"title": "Best Practices for LLM Red Teaming", "transcript": "####Best Practices for LLM Red Teaming\nby Matteo Dora, Luca Martial - 2023-04-19\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Matteo Dora, and welcome back to our series on red teaming for LLM applications.\n\nIn this video, we're diving into some best practices for LLM red teaming.\n\nWe'll cover topics like how to integrate red teaming into your development process, how to communicate effectively with your team, and how to stay up-to-date with the latest red teaming techniques.\n\nRemember, red teaming is an ongoing process, and following best practices can help us stay efficient and effective.\n\nSo, let's start implementing these best practices and make our LLM applications even safer.\n\nStay tuned for our next video where we'll discuss some common pitfalls in LLM red teaming and how to avoid them. Until then, keep exploring and learning.\n\nAnd don't forget to like, share, and subscribe for more exciting content!\n\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-04-19"}}
{"video": {"title": "Building Safe AI Applications with Llama Guard", "transcript": "####Building Safe AI Applications with Llama Guard\nby Amit Sangani - 2023-02-19\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, AI enthusiasts! I'm Amit Sangani, and today we're diving into the exciting world of safe AI applications with Llama Guard.\n\nIn our fast-paced, tech-driven world, it's crucial to ensure our AI is used for good. That's where Llama Guard steps in. This beginner-friendly course will show you how to build safe and responsible AI applications using Llama Guard.\n\nWe'll explore how Llama Guard works and I'll guide you through the process of creating applications that are not only powerful but also safe and responsible.\n\nSo, are you ready to make a positive impact with AI? Let's get started! And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-19"}}
{"video": {"title": "AI for Disaster Management: Preparing for the Worst with Technology", "transcript": "####AI for Disaster Management: Preparing for the Worst with Technology\nby Robert Monarch - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the fascinating world of AI and disaster management.\n\n[Video hook and introduction]\n\nImagine a future where we can predict disasters before they happen and respond to them in real-time. That future is here, thanks to AI.\n\n[Body content]\n\nFirst, we'll explore the role of AI in disaster management. We'll see how it's being used to predict disasters, improve response times, and optimize resource allocation.\n\nNext, we'll get our hands dirty with a project. We'll build a simple model to predict disaster impacts. Don't worry, I'll guide you through it step by step.\n\nBut it's not all sunshine and rainbows. We'll also discuss the challenges and ethical considerations of using AI in disaster management. It's important to know the full picture.\n\n[Conclusion and call to action]\n\nSo, are you ready to join the AI for disaster management movement? Remember, preparation is key, and you can make a difference.\n\nThanks for watching. If you found this video helpful, don't forget to like, share, and subscribe. And stay tuned for more exciting content on AI for disaster management.\n\n\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-05"}}
{"video": {"title": "Python Basics for Machine Learning", "transcript": "####Python Basics for Machine Learning: Your Gateway to ML Success\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-01-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, ML enthusiasts! Your friendly host here, and today we're diving into Python basics that will supercharge your Machine Learning journey.\n\nBut why Python, you ask? Simple, versatile, and widely loved by the ML community. Plus, it's beginner-friendly!\n\nLet's kick things off with variables. Think of them as your data storage lockers. You can name them anything you like, and they can hold numbers, text, even complex data structures.\n\nNext up, functions. They're like mini programs that perform specific tasks. Python comes with built-in functions, but you can also create your own.\n\nNow, let's talk about loops. They're like a treadmill for your code, making it run repeatedly until a certain condition is met.\n\nDon't worry if this seems overwhelming. We'll be practicing these concepts with Machine Learning examples.\n\nRemember, everyone starts somewhere. So, don't be discouraged if you don't get it right away. Keep practicing and you'll be a Python pro in no time!\n\nThat's all for today's video. If you found this helpful, give us a thumbs up and don't forget to subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-01-08"}}
{"video": {"title": "Building AI Apps Made Easy with Hugging Face", "transcript": "####Building AI Apps Made Easy with Hugging Face\nby Maria Khalusova, Marc Sun, Younes Belkada - 2023-04-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Marc here! Today, we're going to make AI app development a breeze with Hugging Face open-source models.\n\nFirst things first, let's find the right model. On the Hugging Face Hub, you can filter models based on your specific needs. Whether it's a text, audio, image, or multimodal task, there's a model for you.\n\nOnce you've found your model, using it is as simple as writing a few lines of code with the transformers library. Yes, it's that easy!\n\nBut wait, there's more! Let's say you've built your AI app. How do you share it? Well, with Gradio and Hugging Face Spaces, you can share your app with a user-friendly interface or via API, and run it on the cloud.\n\nSo, what are you waiting for? Dive into the world of AI with Hugging Face. Remember, no prior AI experience is needed.\n\nDon't forget to like, share, and subscribe for more AI adventures. See you next time!\n#### END TRANSCRIPT ########", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-04-08"}}
{"video": {"title": "Advanced Techniques in GANs: StyleGAN and Beyond", "transcript": "####Advanced Techniques in GANs: StyleGAN and Beyond\nby Eda Zhou - 2022-10-09\n\n#### BEGIN TRANSCRIPT ####\nAre you ready to level up your GAN game? I'm Eda Zhou, and today we're diving into the exciting world of advanced techniques like StyleGAN. We'll explore the latest developments in Generative Adversarial Networks and push the limits of image generation together!\n\nStay tuned as we uncover the secrets of StyleGAN and discover how it's revolutionizing the field of AI. You won't want to miss this!\n\n#### END TRANSCRIPT ########", "author": "Eda Zhou", "publication_date": "2022-10-09"}}
{"video": {"title": "Troubleshooting Common Issues in LangChain", "transcript": "####Troubleshooting Common Issues in LangChain: A Fun and Engaging Guide\nby Harrison Chase, Andrew Ng - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, LangChain enthusiasts! I'm Harrison Chase, and today we're going to have some fun troubleshooting common issues in LangChain.\n\nFirst things first, let's learn how to diagnose issues with your LLM. I'll share some tips and tricks for identifying the root cause of a problem. Trust me, it's not as scary as it sounds.\n\nNext, we'll dive into some common issues. We'll learn how to fix issues with prompts, parsing, memory, and agents. By the end of this video, you'll be a LangChain troubleshooting pro.\n\nBut wait, there's more! We'll also have some fun along the way. I'll sprinkle in some humor and make this learning experience as enjoyable as possible.\n\nSo, let's get started. Remember, the best way to learn is by doing. And who knows, you might even have some fun along the way.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-25"}}
{"video": {"title": "TensorFlow: Multi-Processor Training", "transcript": "Hi there, I'm Eddy Shyu, and today we're going to supercharge our training with TensorFlow!\n\nFirst, we're going to look at how to distribute our training across multiple GPUs. This can significantly speed up our training times, and it's easier than you might think.\n\nNext, we're going to explore how to distribute our training across multiple machines. This is a powerful technique for training large models on massive datasets.\n\nThen, we're going to look at how to use TensorFlow's built-in support for mixed precision training. This can further speed up our training, and even reduce our memory usage.\n\nAnd finally, we're going to look at some tips and tricks for optimizing our training loops. These techniques can help us squeeze every last drop of performance out of our hardware.\n\nSo, are you ready to train your models faster than ever before? Let's get started!\n\nRemember, the best way to learn is by doing. So, try out these techniques for yourself, and see how much faster you can train your models.\n\nThanks for watching, and happy coding!", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-03-22"}}
{"video": {"title": "Unleashing the Power of On-Device AI: A Beginner's Guide", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Make the benefits and applications of the technology more relatable and engaging.\n- Improve the conclusion to leave a lasting impression and encourage further engagement.", "author": "Krishna Sridhar", "publication_date": "2022-03-01"}}
{"video": {"title": "Continuous Improvement: The Secret Sauce of Successful ML Systems", "transcript": "####Continuous Improvement: The Secret Sauce of Successful ML Systems\nby Andrew Ng - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here! Today, we're diving into the world of continuous improvement in ML production systems.\n\nThink of continuous improvement like sharpening a knife. It's not just about making it sharp once, but keeping it sharp over time. We'll discuss how to collect feedback, measure performance, and iterate on your ML models.\n\nWe'll also explore some cool techniques for online learning, active learning, and transfer learning.\n\nRemember, the goal is not just to build a good model, but to build a model that can continuously learn, adapt, and improve. So, let's get started!\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and keep innovating!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-05"}}
{"video": {"title": "TensorFlow: From Zero to Hero", "transcript": "####TensorFlow: From Zero to Hero\nby Laurence Moroney - 2022-01-08\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, Laurence Moroney here, and welcome to another video!\n\n[Video hook and introduction]\n\nAre you new to TensorFlow and feeling a bit overwhelmed? Don't worry, we've all been there. In this video, we'll go from zero to hero in TensorFlow, together.\n\n[Body content]\n\nFirst, we'll start with the basics. What is TensorFlow, and why should you care? We'll explore its uses in machine learning and AI and why it's a go-to tool for many professionals in the field.\n\nThen, we'll dive into setting up your TensorFlow environment. We'll cover installation, configuration, and how to verify that everything is working correctly. You'll also learn about essential TensorFlow concepts like tensors, variables, and operations.\n\nOnce we've got the basics down, we'll start building our first model. We'll use a simple dataset and work our way up to more complex models as the series progresses. You'll learn how to train, evaluate, and optimize your models for the best results.\n\n[Conclusion and call to action]\n\nSo, are you ready to go from TensorFlow zero to hero? Let's get started! Remember, the best way to learn is by doing, so make sure to code along with me. See you in the first lesson!\n\nAnd don't forget to like, share, and subscribe for more exciting content!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-01-08"}}
{"video": {"title": "Preprocessing Unstructured Data for LLM Applications", "transcript": "####Preprocessing Unstructured Data for LLM Applications\nby Matt Robinson - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Matt Robinson, and today we're going to dive into the world of preprocessing unstructured data for LLM applications. Are you ready to take your RAG system to the next level? Let's get started!\n\nWhen it comes to extracting and normalizing content from a variety of document types, such as PDFs, PowerPoints, and HTML files, there are a few key steps you need to follow. By enriching your content with metadata, you can enhance your retrieval augmented generation (RAG) results and support more nuanced search capabilities.\n\nIn this video, we'll explore document image analysis techniques like layout detection, vision, and table transformers. These methods can be applied to preprocess PDFs, images, and tables, expanding the information accessible to your LLM.\n\nSo, whether you're a beginner looking to improve your RAG system or an experienced user wanting to take your LLM to the next level, this video is for you. Stay tuned for some valuable insights and practical tips on preprocessing unstructured data for LLM applications. And remember, with great data comes great LLM!\n#### END TRANSCRIPT ########", "author": "Matt Robinson", "publication_date": "2022-10-15"}}
{"video": {"title": "Building a Research Agent with Agentic RAG and LlamaIndex", "transcript": "Hi there, I'm Jerry Liu and welcome back to our series on Agentic RAG with LlamaIndex.\n\nToday, we're going to build a research agent with our Agentic RAG. This agent will be able to handle multi-documents and perform complex research tasks.\n\nBut first, let's understand what a research agent is and how it differs from a router agent.\n\nThen, we'll learn how to build our research agent step by step.\n\nAnd finally, we'll explore some tips and tricks to improve the performance of our research agent.\n\nSo, are you ready to build your own research agent with Agentic RAG and LlamaIndex? Let's get started!\n\nRemember, practice makes perfect. So keep trying, keep building, and have fun!\n\nThanks for watching and don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n\nAnd as always, if you have any questions or suggestions, leave them in the comments below. Let's learn together!", "author": "Jerry Liu", "publication_date": "2023-04-05"}}
{"video": {"title": "Machine Learning Project: Predicting House Prices", "transcript": "####Machine Learning Project: Predicting House Prices\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-02-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! Your favorite host is back with an exciting new project. Today, we're going to predict house prices using Machine Learning. Are you ready to dive in?\n\nFirst things first, we'll start with a dataset of house prices. We'll walk you through the steps of preparing it for our model. This includes cleaning the data, handling missing values, and converting categorical data into numbers.\n\nNext, we'll split our data into a training set and a test set. The training set is used to train our model, while the test set is used to evaluate its performance.\n\nThen, we'll dive into building our model. We'll start with a simple linear regression model, and we'll learn how to train it using our training data.\n\nBut wait, there's more! We'll also learn how to evaluate our model using metrics like mean squared error and R-squared. And we'll do it all with practical examples, so you can see how it's done in the real world.\n\nRemember, the best way to learn is by doing, so don't be afraid to get your hands dirty. So, are you ready to predict house prices with Machine Learning? Let's get started! And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-02-12"}}
{"video": {"title": "Collaboration with AutoGen: Building AI Dream Teams", "transcript": "####Collaboration with AutoGen: Building AI Dream Teams\nby Chi Wang, Qingyun Wu - 2023-03-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Chi Wang here, and today we're diving into the Multi-agent Collaboration design pattern in AutoGen.\n\nThink of a team of superheroes, each with their own unique abilities, joining forces to save the day. That's what Multi-agent Collaboration is all about. We'll show you how to create a team of AI agents that can work together to achieve a common goal.\n\nWe'll kick things off by explaining the concept of Multi-agent Collaboration and then move on to a practical example. We'll walk you through the process of creating multiple agents, assigning them roles, and setting them loose on a task.\n\nRemember, the goal here is to make our agents more cooperative and effective. So, let's get started and build some AI dream teams with AutoGen!\n\nAs always, if you have any questions, feel free to leave them in the comments. We're here to help you learn and grow.\n\nDon't forget to like, subscribe, and hit that notification bell for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2023-03-29"}}
{"video": {"title": "LangChain and Business Intelligence: Making Data-Driven Decisions", "transcript": "####LangChain and Business Intelligence: Unlocking Data-Driven Decisions\nby Harrison Chase - 2023-05-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Harrison Chase, the mastermind behind LangChain, and today we're diving into an exciting topic: how LangChain can supercharge your business intelligence efforts.\n\nYou already know LangChain as your go-to tool for building chatbots that can interact with your private data and documents. But did you know that LangChain can also help you unlock insights from your data to make smarter decisions?\n\nIn this video, we'll explore the basics of business intelligence and how LangChain can be your secret weapon. We'll start with a fun overview of business intelligence and some of the most popular tools, including Tableau and Power BI.\n\nNext, we'll get our hands dirty with some real-world examples of how to use LangChain for business intelligence. We'll cover topics like data modeling, data visualization, and KPI tracking.\n\nBy the end of this video, you'll be a LangChain and business intelligence pro, ready to make data-driven decisions that can take your business to the next level.\n\nSo, are you ready to unlock the full potential of your data? Let's get started!\n\nRemember, if you have any questions or need a helping hand, don't hesitate to reach out to me on social media or through the LangChain website.\n\nThanks for watching, and happy data exploring!\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-05-01"}}
{"video": {"title": "Extending Your Router Agent: Passing Arguments", "transcript": "####Extending Your Router Agent: Passing Arguments\nby Jerry Liu - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Jerry Liu and today we're going to level up your router agent.\n\nIn this video, we're diving into the exciting world of passing arguments. This will make your agent more adaptable and capable of handling more intricate tasks.\n\nFirst, we'll demystify arguments and how they can be used to tailor your agent's behavior.\n\nThen, we'll roll up our sleeves and I'll guide you through modifying your router agent to accept and process arguments.\n\nWe'll also discuss some top tips for using arguments and common pitfalls to dodge.\n\nBy the end of this video, you'll be a pro at extending your router agent to handle any task that comes your way.\n\nSo, let's get this show on the road!\n\nRemember, if you have any questions or need further clarification, don't be shy and leave a comment below. And don't forget to like, share, and subscribe for more thrilling content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-03-25"}}
{"video": {"title": "Understanding Diffusion Models: A Step-by-Step Guide", "transcript": "####Understanding Diffusion Models: A Fun and Easy Guide\nby Sharon Zhou - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Today, we're going on an exciting journey into the world of diffusion models. I'll make it fun, easy, and engaging for you. Let's get started! So, what are diffusion models? They're a type of generative model that can capture complex data distributions. They work by simulating the spread of information or particles through a system. It's like watching paint mix in water, but for data! To build a diffusion model, you'll need a solid understanding of Python, Tensorflow, or Pytorch. If you're familiar with these tools, you're ready to dive in. Now, let's talk about how diffusion models work in practice. We'll cover the key concepts, walk through the implementation, and discuss some real-world applications. By the end of this video, you'll have a solid grasp of diffusion models and be ready to start building your own. So, grab your coding tools and let's get started!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2022-10-15"}}
{"video": {"title": "Quantization Basics: Compress Models with Hugging Face", "transcript": "####Quantization Basics: Compress Models with Hugging Face\nby Younes Belkada, Marc Sun - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the world of quantization with Hugging Face.\n\nIn this video, we'll be exploring how to compress models using the Hugging Face Transformers library and the Quanto library.\n\nBut first, let's get a grip on what quantization is. It's a process that shrinks the size of a model, making it more efficient and faster, while keeping its accuracy intact.\n\nWe'll kick things off with linear quantization, a simple yet effective method for model compression. It works by lowering the precision of the weights in your model, resulting in a smaller model size and quicker inference times.\n\nNext, we'll take you through the process of quantizing open-source multimodal and language models. Don't worry if you're new to this, I'll be there to guide you through each step.\n\nBy the end of this video, you'll have the skills to quantize any open-source model using Hugging Face and Quanto.\n\nThanks for watching, and don't forget to like, share, and subscribe for more AI and machine learning content. See you next time!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-25"}}
{"video": {"title": "Enhancing Multimodal Search with Weaviate", "transcript": "####Enhancing Multimodal Search with Weaviate\nby Sebastian Witalec - 2022-10-09\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Are you ready to take your multimodal search and RAG applications to the next level? Well, buckle up because in this video, we're diving into the world of Weaviate!\n\nI'm your host, Sebastian Witalec, and I'm beyond excited to show you how Weaviate can supercharge your applications. Trust me, you won't want to miss this!\n\nSo, what exactly is Weaviate? It's a powerful, open-source vector database that can handle both text and image data. And the best part? It's designed to work seamlessly with GraphQL and REST APIs.\n\nBut enough with the chit-chat, let's get into the nitty-gritty. In this video, we'll explore how Weaviate can enhance your multimodal search and RAG applications. We'll cover everything from setting up your database to running complex queries. And don't worry, I'll be breaking down all the technical jargon into simple, easy-to-understand terms.\n\nSo, are you ready to discover the power of partnership with Weaviate? Let's get started!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-09"}}
{"video": {"title": "Mastering Linear Quantization Techniques", "transcript": "####Mastering Linear Quantization Techniques\nby Marc Sun - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc Sun, and today we're going on an exciting journey into the world of advanced quantization techniques. We're going to customize model compression with Linear Quantization, exploring symmetric vs. asymmetric mode, and different granularities. If you're ready to level up your quantization skills, buckle up! Let's get started!\n\nLinear Quantization is a powerful tool that allows us to compress models without losing accuracy. By quantizing weights and activations to a lower bit precision, we can achieve significant model size reduction. But not all quantization techniques are the same. In this video, we'll explore the nuances of Linear Quantization, including the differences between symmetric and asymmetric mode, and the impact of different granularities like per tensor, per channel, and per group quantization.\n\nBut wait, there's more! We'll also show you how to build a general-purpose quantizer in Pytorch that can quantize the dense layers of any open source model for up to 4x compression on dense layers. And if you're looking to push the boundaries of compression even further, we'll teach you how to implement weights packing to pack four 2-bit weights into a single 8-bit integer.\n\nSo if you're ready to master Linear Quantization techniques and unlock the full potential of model compression, join us in this deep dive into Quantization in Depth. I'm Marc Sun, and I'll see you in the next video. Stay tuned for more quantization tips and tricks!\n#### END TRANSCRIPT ########", "author": "Marc Sun", "publication_date": "2022-10-15"}}
{"video": {"title": "Unleashing the Power of Multi AI Agent Systems with crewAI", "transcript": "####Unleashing the Power of Multi AI Agent Systems with crewAI\nby Jo\u00e3o Moura - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jo\u00e3o Moura, and today we're diving into the thrilling world of Multi AI Agent Systems with crewAI!\n\nAre you comfortable with prompt engineering and basic coding? Eager to incorporate Large Language Models (LLMs) into your professional work? You're in luck!\n\nImagine automating business workflows with not just one, but a team of AI agents. With crewAI, an open-source library, you can surpass the performance of prompting a single LLM by designing and prompting a team of AI agents through natural language.\n\nSounds daunting? Don't worry, it's easier than you think. Let's break it down.\n\nFirst, let's understand what crewAI is. It's an open-source library that allows you to automate repeatable, multi-step tasks. Think of it like tailoring a resume to a job description, or automating business processes that are typically done by a group of people, like event planning.\n\nSo, how does it work? By creating a team of AI agents, you can define a specific role, goal, and backstory for each agent. This breaks down complex multi-step tasks and assigns them to agents that are customized to perform those tasks.\n\nLet's take an example. Suppose you're planning an event. You can create an AI agent responsible for venue selection, another for catering, and another for guest list management. Each agent has a specific role and works together to achieve the common goal of a successful event.\n\nIsn't that incredible? With crewAI, you're not just automating tasks, you're creating a team of AI agents that work together to achieve your goals.\n\nSo, are you ready to start building your own team of AI agents? Join me in this journey as we explore more about crewAI and how it can transform your workflows.\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like, share, and subscribe for more exciting content on AI and automation.\n\nUntil next time, keep learning and keep innovating!\n#### END TRANSCRIPT ########", "author": "Jo\u00e3o Moura", "publication_date": "2023-03-15"}}
{"video": {"title": "Generative AI Ethics and Responsible Use", "transcript": "####Generative AI Ethics and Responsible Use\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Shelbee Eigenbrode here, and today we're diving into the ethics and responsible use of generative AI.\n\nAs generative AI continues to evolve and become more prevalent, it's crucial to consider the ethical implications of its use. In this course, we'll explore the potential risks and harms of generative AI, such as bias, misinformation, and privacy violations.\n\nWe'll also cover best practices for responsible AI development and deployment, such as transparency, accountability, and fairness. You'll learn about the role of regulation and policy in shaping the ethical use of generative AI.\n\nBy the end of this course, you'll have a deeper understanding of the ethical considerations of generative AI, and be better equipped to develop and use generative AI in a responsible and ethical manner.\n\nSo, are you ready to explore the ethics of generative AI? Let's get started!\n\nDon't forget to like, comment, and subscribe for more content like this. And if you have any questions, feel free to leave them in the comments below. Thanks for watching!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-29"}}
{"video": {"title": "Unleashing AI Potential with Hugging Face Open Source Models", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits.\n- Use of active voice and simple language.\n- Encouragement and positive reinforcement.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-04-01"}}
{"video": {"title": "Quantization for Dummies: Compress Models with Hugging Face and Quanto", "transcript": "####Quantization for Dummies: Compress Models with Hugging Face and Quanto\nby Younes Belkada, Marc Sun - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're making quantization a breeze for beginners with Hugging Face and Quanto.\n\nIn this video, we'll be learning how to compress models using the Hugging Face Transformers library and the Quanto library.\n\nBut first, what is quantization? It's a technique used to shrink the size of a model, making it more efficient and faster, without sacrificing its accuracy.\n\nWe'll start with linear quantization, a simple yet effective method for model compression. It works by decreasing the precision of the weights in your model, resulting in a smaller model size and faster inference times.\n\nThen, we'll dive into quantizing open-source multimodal and language models. I'll be there to guide you through each step, so don't worry if you're new to this.\n\nBy the end of this video, you'll know how to quantize any open-source model using Hugging Face and Quanto.\n\nThanks for tuning in, and remember to like, share, and subscribe for more AI and machine learning content. Until next time!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-30"}}
{"video": {"title": "TensorFlow: Data Preprocessing for Deployment", "transcript": "####TensorFlow: Data Preprocessing for Deployment\nby Laurence Moroney - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Laurence Moroney here, and today we're diving into the world of data preprocessing for deployment with TensorFlow.\n\n[Video hook and introduction]\n\nData preprocessing is a game-changer in any machine learning project, and it's no different when it comes to deploying your models.\n\n[Body content]\n\nLet's kick things off with the basics. Data preprocessing involves transforming raw data into an understandable format, making it a breeze for models to learn and predict.\n\nWith TensorFlow, you have access to powerful tools like tf.data for efficient data input pipelines. You can use it to load, preprocess, and shuffle your data, ensuring your models are trained on top-notch data.\n\n[Conclusion and call to action]\n\nSo, don't underestimate the power of data preprocessing! Remember, your models are only as good as the data they're trained on.\n\nKeep exploring, keep learning, and as always, happy coding!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-03-20"}}
{"video": {"title": "Creating Controllable AI Agents with LangGraph", "transcript": "####Creating Controllable AI Agents with LangGraph\nby Harrison Chase, Rotem Weiss - 2023-05-01\n\n#### BEGIN TRANSCRIPT ####\n\nHey AI enthusiasts! Today, we're diving into the world of LangGraph and learning how to create controllable AI agents.\n\nBut first, why should we care about creating controllable AI agents? It's simple: it allows us to guide our agents' actions, ensuring they align with our goals and values.\n\nSo, how do we create controllable AI agents with LangGraph? Let's break it down.\n\nWe'll start by understanding the importance of control in AI and how LangGraph enables it. Then, we'll walk you through the process of creating controllable AI agents with LangGraph, using its components and tools to build agents that we can guide and direct.\n\nBy the end of this video, you'll be able to create AI agents that are not only powerful but also controllable, ensuring they always act in our best interests.\n\nSo, are you ready to create the future of AI with LangGraph? Let's get started!\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-05-01"}}
{"video": {"title": "Exploring New Applications of LLMs with Prompt Engineering", "transcript": "####Exploring New Applications of LLMs with Prompt Engineering\nby Andrew Ng - 2022-10-27\n\n#### BEGIN TRANSCRIPT ####\nAre you ready to take your LLM game to the next level? In this video, we'll dive into the world of prompt engineering and explore innovative ways to use LLMs beyond traditional applications. Get ready to think outside the box and unlock the full potential of LLMs!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-27"}}
{"video": {"title": "Hands-On Tutorial: Linear Quantization in Pytorch", "transcript": "####Hands-On Tutorial: Linear Quantization in Pytorch\nby Marc Sun - 2022-10-21\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Marc Sun! Are you ready to dive into the world of linear quantization in Pytorch? Today, we're going to get our hands dirty with some code and explore different variants and modes. By the end of this tutorial, you'll have a practical understanding of this essential technique. So, let's not waste any time and get started!\n#### END TRANSCRIPT ########", "author": "Marc Sun", "publication_date": "2022-10-21"}}
{"video": {"title": "Getting Started with AI for Good: A Beginner's Guide", "transcript": "####Getting Started with AI for Good: A Beginner's Guide\nby Robert Monarch - 2023-05-06\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the exciting world of AI for Good!\n\nFirst, we'll cover the essential skills and resources you need to kickstart your AI for Good journey. Then, we'll explore some beginner-friendly projects that you can start working on right away.\n\nWe'll also discuss how to connect with the AI for Good community, and how to find mentors and collaborators who can help you along the way.\n\nSo, are you ready to make a positive impact with AI? Let's get started!\n\nRemember, every little step you take towards learning and applying AI for good makes a difference.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content on AI. Until next time, let's keep using AI for good!\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-05-06"}}
{"video": {"title": "Mastering Deep Learning Specialization with Python and TensorFlow", "transcript": "####Mastering Deep Learning Specialization with Python and TensorFlow\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, deep learning enthusiasts! Are you ready to take your skills to the next level? Today, we're diving into the world of deep learning with Andrew Ng and his team. We'll be exploring how to build neural networks like CNNs, RNNs, LSTMs, and Transformers using Python and TensorFlow. And the best part? We'll be applying these powerful tools to real-world problems like speech recognition and NLP. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-10-15"}}
{"video": {"title": "Mistral AI: Generating Structured LLM Responses with JSON Mode", "transcript": "####Mistral AI: Unleashing the Power of Structured LLM Responses with JSON Mode\nby Younes Belkada, Marc Sun - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Younes Belkada, and today I'm thrilled to introduce you to Mistral AI's JSON mode, alongside my co-host, Marc Sun.\n\nMistral AI's JSON mode is a game-changer. It allows you to generate LLM responses in a structured JSON format, making it a breeze to integrate LLM outputs into larger software applications.\n\nIn this video, we'll show you how to use Mistral's JSON mode to generate structured responses for a variety of tasks, including text generation, question answering, and more.\n\nBut wait, there's more! We'll also demonstrate how to use Mistral's API to call user-defined Python functions. This means you can perform tasks like web searches or retrieving text from databases, enhancing the LLM's ability to find relevant information to answer your queries.\n\nSo, whether you're a coding newbie or a seasoned developer, Mistral AI's JSON mode has got you covered. And the cherry on top? It's easy to use and integrates seamlessly with Mistral's open-source and commercial models.\n\nDon't forget to like, share, and subscribe for more exciting content on Mistral AI. And a big shoutout to our technology partner, Mistral AI, for making this video possible.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-30"}}
{"video": {"title": "Unlocking LLM Potential with Function-Calling", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-03-16"}}
{"video": {"title": "Quantization Q&A: Your Questions Answered", "transcript": "####Quantization Q&A: Your Burning Questions Answered\nby Marc Sun, Younes Belkada - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc Sun, and today we're diving into the world of quantization to answer your most burning questions.\n\nWe've received a ton of great questions from our community, and we're thrilled to tackle them head-on.\n\nFrom the basics of quantization to advanced techniques and troubleshooting tips, we've got you covered.\n\nSo, are you ready to level up your quantization game? Let's get started!\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-15"}}
{"video": {"title": "Getting Started With Mistral: Unleashing the Power of LLM", "transcript": "####Unleashing the Power of Mistral: Your First Step into LLM\nby Younes Belkada, Marc Sun - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada and today, we're embarking on an exciting journey into the world of Mistral AI!\n\nBut first, what's Mistral? It's an advanced AI platform that offers a variety of open-source and commercial LLM models. Don't worry if you're new to this, we're keeping it fun and easy!\n\nMistral has three open-source models: Mistral 7B, Mixtral 8x7B, and the latest Mixtral 8x22B. Plus, they have three commercial models: small, medium, and large. You can access these via web interface and API calls. Pretty neat, huh?\n\nNow, let's talk about Mistral's JSON mode. It generates LLM responses in a structured JSON format. Why is this a big deal? Because it allows you to integrate LLM outputs into larger software applications.\n\nBut wait, there's more! With Mistral's API, you can call user-defined Python functions. This means you can perform tasks like web searches or retrieving text from databases. Essentially, it enhances the LLM\u2019s ability to find relevant information to answer your queries.\n\nSo, are you ready to explore Mistral AI? Remember, this is just the beginning. Stay tuned for more exciting content. And if you have any questions, don't hesitate to ask!\n\nDon't forget to like, share, and subscribe for more updates. Let's learn and grow together with Mistral AI. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-15"}}
{"video": {"title": "Unleashing the Power of LangChain: A Beginner's Guide", "transcript": "####Unleashing the Power of LangChain: A Beginner's Guide\nby Harrison Chase - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! I'm Harrison Chase, and today we're diving into the fascinating world of LangChain.\n\nIf you're new to LangChain, don't worry! We'll start from scratch. LangChain is a tool that lets you interact with various data sources in a unique and efficient manner.\n\nWith LangChain, you can access over 80 unique loaders to handle different types of data. This means you can work with PDFs, databases, and much more, all within the same tool.\n\nBut wait, there's more! Today, we're going to build a chatbot that can chat directly with information from your own documents and data.\n\nImagine having a personal assistant who can read and understand all your documents and data. That's what we're going to create today.\n\nI'll be guiding you through each step, making sure to keep things simple and easy to understand. By the end of this video, you'll have your own chatbot ready to assist you with your data needs.\n\nSo, are you ready to unleash the power of LangChain? Let's get started!\n\nRemember, if you have any questions, feel free to leave a comment. I'm always here to help. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-20"}}
{"video": {"title": "Building a Transformer from Scratch", "transcript": "####Building a Transformer from Scratch: A Step-by-Step Guide\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Today, we're embarking on an exciting journey to build a Transformer from scratch.\n\nFirst, we'll demystify the basics of Transformers, from self-attention mechanisms to encoder-decoder architecture and positional encoding. Then, we'll roll up our sleeves and start coding our own Transformer using Python and TensorFlow.\n\nBy the end of this video, you'll have your very own Transformer and will have applied it to a real-world scenario.\n\nSo, are you ready to join the Transformer revolution? Let's dive in!\n\nRemember, this video is part of our Deep Learning Specialization, so if you're new to the field, you might want to start with the basics first.\n\nAnd that's a wrap for today! I hope you enjoyed building your own Transformer as much as I did. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and keep transforming!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2023-04-25"}}
{"video": {"title": "Interacting with Meta Llama 2 Chat", "transcript": "####Interacting with Meta Llama 2 Chat\nby Amit Sangani - 2023-02-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Amit Sangani here and today we're diving into the world of Meta Llama 2 Chat.\n\nMeta Llama 2 Chat is a game-changer for interacting with AI models, and in this beginner-friendly course, we'll be exploring how you can use it to get the most out of your prompts.\n\nI'll share some tips and tricks for interacting with Meta Llama 2 Chat, so you can prompt smarter, not harder.\n\nSo, are you ready to get started? Let's dive in and start interacting with Meta Llama 2 Chat like a pro. And don't forget to hit that like and subscribe button for more great content. See you in the next video!\n\n\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-20"}}
{"video": {"title": "Building a Question-Answering System with Neo4j and LangChain", "transcript": "####Building a Question-Answering System with Neo4j and LangChain\nby Andreas Kollegger - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Andreas Kollegger and today we're diving into the exciting world of question-answering systems. We'll be using Neo4j and LangChain to build a system that lets you chat with your data.\n\nBut wait, what's LangChain? If you're new to this, don't worry! I've got a short course called 'LangChain: Chat with Your Data' that'll get you up to speed.\n\nNow, let's get our hands dirty. We'll be using Neo4j's query language, Cypher, to manage and retrieve data from our knowledge graph.\n\nIn this video, we'll walk you through the process of building a system that allows you to ask your data questions and get accurate, contextually relevant answers. Imagine having a conversation with your data! That's what we're building today.\n\nSo, are you ready to build your own question-answering system? Let's get started!\n\nRemember, practice makes perfect. So, don't be afraid to try, fail, and try again. And if you have any questions, feel free to leave them in the comments below.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2023-03-25"}}
{"video": {"title": "Building a Multi-Document Research Agent with LlamaIndex", "transcript": "####Building a Multi-Document Research Agent with LlamaIndex\nby Jerry Liu - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and today we're diving into the exciting world of building a multi-document research agent with LlamaIndex.\n\nBut first, let's recap. In our previous videos, we've learned how to build an agentic RAG, mastered document Q&A, unleashed the power of summarization, built a multi-document research agent, learned how to debug and control our agent, extended our agent with custom functions, built a question answering system, and mastered document summarization. Today, we're going to take it to the next level by building a multi-document research agent.\n\nWe'll start by understanding how to structure our data for multi-document research. Then, we'll dive into building our research agent with LlamaIndex.\n\nOnce we've got that down, we'll look at how to fine-tune our agent to improve its accuracy and efficiency.\n\nBy the end of this video, you'll be a pro at building multi-document research agents with LlamaIndex.\n\nSo, let's get started! And remember, practice makes perfect. So, don't just watch this video, try building your own multi-document research agent with LlamaIndex.\n\nIf you found this video helpful, give it a thumbs up and subscribe to our channel for more exciting content. Until next time, happy coding!\n\n\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-25"}}
{"video": {"title": "LangChain for Beginners: A Step-by-Step Guide to Building a Chatbot", "transcript": "####LangChain for Beginners: A Step-by-Step Guide to Building a Chatbot\nby Harrison Chase - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Harrison Chase, and today we're diving into the world of LangChain. We're going to build a chatbot, and I promise, it's going to be a fun ride!\n\nNow, don't worry if you're new to LangChain or chatbot building. This video is designed for beginners, and I'll be explaining everything in simple, easy-to-understand terms.\n\nLangChain is a powerful tool that lets you access and interact with various data sources. With over 80 unique loaders, you can handle different types of data, from PDFs to databases.\n\nBut today, we're not just stopping at data access. We're going to build a chatbot that can chat directly with information from your own documents and data.\n\nImagine having a personal assistant who can read and understand all your documents and data. Sounds cool, right?\n\nI'll be guiding you through each step, making sure to keep things simple and easy to understand. By the end of this video, you'll have your own chatbot ready to assist you with your data needs.\n\nSo, are you ready to build your first chatbot with LangChain? Let's get this party started!\n\nRemember, if you have any questions, feel free to leave a comment. I'm always here to help. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-04-05"}}
{"video": {"title": "Preparing for the TensorFlow Developer Certificate Exam", "transcript": "####Preparing for the TensorFlow Developer Certificate Exam\nby Laurence Moroney - 2022-01-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the TensorFlow Developer Certificate exam!\n\n[Video hook and introduction]\n\nAre you ready to showcase your TensorFlow skills and earn a valuable certification? Let's do this!\n\n[Body content]\n\nFirst, we'll cover the exam format and what to expect. We'll explore the different sections, question types, and scoring criteria. You'll also learn about the exam's prerequisites and how to register.\n\nThen, we'll dive into preparing for the exam. We'll cover essential TensorFlow concepts, like tensors, variables, and operations. We'll also review building and training models, computer vision, and NLP. Plus, we'll go over best practices for coding in TensorFlow.\n\nYou'll get plenty of practice with sample questions and hands-on labs. Plus, we'll cover tips and strategies for acing the exam.\n\n[Conclusion and call to action]\n\nSo, are you ready to prepare for the TensorFlow Developer Certificate exam? Let's get started! Remember, practice is key, so make sure to follow along and code with me. See you in the first lesson!\n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-01-29"}}
{"video": {"title": "Exploring Mistral's Open-Source and Commercial Models", "transcript": "####Exploring Mistral's Open-Source and Commercial Models\nby Younes Belkada, Marc Sun - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nVideo hook and introduction: Hey there, AI enthusiasts! Today, we're diving into the world of Mistral's open-source and commercial models. If you're eager to leverage Mistral's JSON mode for generating structured LLM responses, you're in the right place! Let's get started!\n\nBody content: Mistral offers a trio of open-source models - Mistral 7B, Mixtral 8x7B, and the latest Mixtral 8x22B. But wait, there's more! Mistral also provides access to three commercial models - small, medium, and large. You can access these models through Mistral's web interface and API calls.\n\nNow, here's where it gets exciting. By leveraging Mistral's JSON mode, you can generate LLM responses in a structured JSON format. This means seamless integration into larger software applications. But that's not all! Mistral's API allows you to call user-defined Python functions, enhancing the LLM's capabilities for tasks like web searches and retrieving text from databases.\n\nConclusion and call to action: So, there you have it! Mistral offers a range of open-source and commercial models that you can access through its web interface and API. By utilizing Mistral's JSON mode and API, you can enhance the LLM's capabilities for various tasks. Stay tuned for more Mistral tutorials and don't forget to like, share, and subscribe for future updates!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2022-10-15"}}
{"video": {"title": "TensorFlow for Generative Adversarial Networks", "transcript": "####TensorFlow for Generative Adversarial Networks\nby Laurence Moroney - 2022-02-26\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Laurence Moroney, and today we're diving into the exciting world of generative adversarial networks (GANs) with TensorFlow!\n\n[Video hook and introduction]\n\nAre you ready to build models that can generate realistic images, videos, and more? Let's do this!\n\n[Body content]\n\nFirst, we'll cover the basics of GANs and how TensorFlow fits into the picture. We'll explore essential concepts like generators, discriminators, and adversarial training.\n\nThen, we'll dive into building our first GAN. We'll use a simple dataset to generate new images and learn how to train our generator and discriminator networks. You'll also discover how to use pre-trained models and transfer learning to speed up the process.\n\nWe'll also explore real-world applications of GANs, like image-to-image translation and text-to-image synthesis. Plus, we'll cover advanced topics like conditional GANs and cycleGANs.\n\n[Conclusion and call to action]\n\nSo, are you ready to master GANs with TensorFlow? Let's get started! Remember, practice makes perfect, so make sure to follow along and code with me. See you in the first lesson!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-02-26"}}
{"video": {"title": "Mistral AI: The Benefits of Structured LLM Responses", "transcript": "####Mistral AI: Unlocking the Power of Structured LLM Responses\nby Younes Belkada, Marc Sun - 2023-02-24\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Younes Belkada here, and today we're going to dive into the exciting world of structured LLM responses and how Mistral AI's JSON mode can help you unlock their full potential.\n\nWith JSON mode, you can generate LLM responses in a structured JSON format, making it a breeze to integrate LLM outputs into your larger software applications. This means you can leverage the power of Mistral AI's advanced LLM capabilities in a more seamless and efficient way.\n\nBut wait, there's more! Structured LLM responses offer a range of benefits, including improved accuracy, easier parsing, and more efficient data processing.\n\nSo, what does this mean for you? It means that now is the time to start exploring Mistral AI's JSON mode and see how it can help you achieve your LLM goals more efficiently and accurately.\n\nAnd don't forget about Mistral AI's API. With Mistral's API, you can call user-defined Python functions for tasks like web searches or retrieving text from databases. This means you can enhance the LLM's ability to find relevant information and answer user queries more accurately.\n\nSo, what are you waiting for? Start exploring Mistral AI today and see how its JSON mode and API can help you take your LLM capabilities to the next level. And don't forget to check out Mistral AI, our technology partner for this video.\n\nThanks for watching, and stay tuned for more exciting videos on Mistral AI and LLM. I'm Younes Belkada, and I'll see you in the next one.\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-24"}}
{"video": {"title": "AI and Climate Change: A Powerful Partnership", "transcript": "####AI and Climate Change: A Powerful Partnership\nby Robert Monarch - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Robert Monarch, and today we're diving into an exciting topic: how AI is helping us tackle climate change.\n\nClimate change is a complex beast, but with AI, we're not just fighting it, we're outsmarting it!\n\nIn this video, we'll explore how machine learning is revolutionizing the way we understand, predict, and mitigate climate change. We'll delve into different models and techniques, from climate modeling to carbon capture.\n\nBut that's not all! We'll also look at real-world case studies, like how scientists are using AI to predict and respond to extreme weather events.\n\nSo, are you ready to become a climate hero? Let's get started!\n\nRemember, every step we take towards understanding and fighting climate change is a step towards a cleaner, greener world.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning, keep growing, and keep using AI for Good!\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-15"}}
{"video": {"title": "TensorFlow: Mastering Data and Deployment", "transcript": "####TensorFlow: Mastering Data and Deployment\nby Laurence Moroney - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\n\nHello, TensorFlow enthusiasts! I'm Laurence Moroney, and today we're embarking on an exciting journey into the realm of data and deployment.\n\n[Video hook and introduction]\n\nAre you curious about deploying your machine learning models on devices? Or perhaps you're intrigued by the idea of training and running models in browsers and mobile apps? You're in luck!\n\n[Body content]\n\nLet's kick things off with deploying ML models on devices. It's not as daunting as it sounds. With TensorFlow, you can effortlessly deploy your trained models on a range of hardware, from edge devices to smartphones.\n\nNext up, we'll discuss training and running models in browsers and mobile apps. TensorFlow.js is a mighty library that brings machine learning to the web and beyond. You can use it to train models directly in the browser or import existing ones.\n\nAnd here's the icing on the cake - retraining deployed models while safeguarding privacy. With TensorFlow Federated, you can retrain models on device data, all while keeping that data under wraps.\n\n[Conclusion and call to action]\n\nSo, are you ready to level up your TensorFlow game? Start deploying your models, explore the potential of browser and mobile training, and ensure privacy with federated learning.\n\nRemember, practice makes perfect. Keep experimenting, keep learning, and don't forget to share your incredible projects with us!\n\nUntil next time, happy coding!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-03-15"}}
{"video": {"title": "GANs and Bias: What You Need to Know", "transcript": "####GANs and Bias: What You Need to Know\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-02-22\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Eda Zhou, and today we're diving into a hot topic in the world of GANs: bias.\n\n[Video hook and introduction]\n\nGANs are powerful tools for generating new data, but they can also perpetuate biases in the data they're trained on. This can lead to unfair outcomes and reinforce harmful stereotypes. But don't worry, we've got you covered.\n\n[Body content]\n\nSo, how does bias show up in GANs? Well, it all starts with the data. If the data used to train a GAN is biased, then the generated data will also be biased. For example, if a GAN is trained on a dataset of mostly white faces, it will generate mostly white faces. This can be a problem in applications like facial recognition, where biased data can lead to biased outcomes.\n\nBut there are ways to address bias in GANs. One approach is to use a diverse dataset for training, which can help reduce bias in the generated data. Another approach is to use techniques like fairness constraints, which can help ensure that the generated data is fair and unbiased.\n\n[Conclusion and call to action]\n\nSo that's a quick overview of bias in GANs. It's a complex issue, but by being aware of it and taking steps to address it, we can make sure that our GANs are fair and unbiased. Thanks for watching, and be sure to check out our other videos on GANs and machine learning. And remember, the future of AI is in our hands, so let's make it a fair one.\n\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-02-22"}}
{"video": {"title": "GANs and Social Implications: Addressing Bias and Privacy", "transcript": "####GANs and Social Implications: Addressing Bias and Privacy\nby Sharon Zhou - 2022-10-07\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Sharon Zhou, and today we're diving into the fascinating world of Generative Adversarial Networks, or GANs. But we're not just talking about image generation. We're going to explore the social implications of GANs, and trust me, it's a rollercoaster ride!\n\nFirst up, we'll discuss how GANs can unintentionally perpetuate bias. It's a bit like a game of telephone, but with AI. Then, we'll talk about why privacy preservation is more important than ever in this data-driven age.\n\nSo, are you ready to explore the ethical side of GANs? Let's get started!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2022-10-07"}}
{"video": {"title": "Unleashing the Power of Multi AI Agent Systems with crewAI", "transcript": "####Unleashing the Power of Multi AI Agent Systems with crewAI\nby Jo\u00e3o Moura - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jo\u00e3o Moura and today we're diving into the thrilling world of Multi AI Agent Systems with crewAI.\n\nAre you feeling limited by using just one Language Learning Model (LLM) for your tasks? It's time to upgrade! With Multi AI Agent Systems, you can surpass the performance of a single LLM by designing and prompting a team of AI agents through natural language.\n\nImagine automating repeatable, multi-step tasks like tailoring a resume to a job description or even automating business processes that are typically done by a group of people, such as event planning. Sounds fun, right?\n\nWith crewAI, an open source library, you can create a team of AI agents, defining a specific role, goal, and backstory for each one. This breaks down complex multi-step tasks and assigns them to agents that are customized to perform those tasks.\n\nIf you've taken some prompt engineering courses and have some familiarity with basic coding, you're in the right place. This video is designed for beginners who want to incorporate LLMs in their professional work.\n\nSo, are you ready to transform your workflows? Let's get started with crewAI and Multi AI Agent Systems. Remember, there's no 'I' in 'team', but there is in 'AI'!\n\nStay tuned for more videos where we'll deep dive into how to set up your own team of AI agents. And don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and innovating!\n#### END TRANSCRIPT ########", "author": "Jo\u00e3o Moura", "publication_date": "2023-04-15"}}
{"video": {"title": "LangChain and Data Analysis", "transcript": "####LangChain and Data Analysis: Unleashing Your Chatbot's Potential\nby Harrison Chase - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! I'm Harrison Chase, the creator of LangChain, and today we're diving into the exciting world of data analysis with LangChain.\n\nData analysis is the process of inspecting, cleaning, transforming, and modeling data to discover useful information, inform conclusions, and support decision-making. And with LangChain, you can leverage the power of data analysis to build even more powerful chatbots.\n\nBut how does it work? Let's take a look.\n\nLangChain provides you with access to a wide range of data analysis tools and techniques, from data visualization to statistical modeling. This means you can use your chatbot to gain insights and make data-driven decisions like never before.\n\nI'll be guiding you through each step of the process, sharing tips and tricks along the way. And the best part? You'll be learning directly from me, the creator of LangChain.\n\nSo, are you ready to take your chatbot to the next level with data analysis? Let's get started!\n\nRemember, if you have any questions or need help along the way, don't hesitate to reach out. And once you've mastered data analysis with LangChain, be sure to share your creations with me. I can't wait to see what you build!\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-22"}}
{"video": {"title": "Using Function Calling for Database Interaction with Natural Language", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Encouragement for audience engagement.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.\n- Include critical analysis and personal insights.", "author": "Adrian Gonzalez Sanchez", "publication_date": "2023-04-10"}}
{"video": {"title": "Unlocking the Power of AI for Good", "transcript": "####Unlocking the Power of AI for Good\nby Robert Monarch - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, your AI guide for today. We're about to embark on an exciting journey into the world of AI for Good. Imagine harnessing the power of AI to make our planet a better place. Sounds intriguing, right?\n\nLet's get started. We'll explore a practical framework for developing AI projects, focusing on models for air quality, wind energy, biodiversity, and disaster management. We'll also dive into some real-world case studies on public health and climate change.\n\nBut wait, there's more! We'll discuss how you can get involved in this movement and make a difference. So, buckle up and let's unlock the power of AI for Good together!\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2022-10-15"}}
{"video": {"title": "Advanced Techniques for LLM Training and Tuning", "transcript": "####Advanced Techniques for LLM Training and Tuning\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, Chris Fregly here, and today we're diving into the world of advanced techniques for LLM training and tuning.\n\nIn this course, you'll discover cutting-edge techniques for enhancing the performance of LLMs, such as transfer learning, distillation, and regularization.\n\nYou'll also learn about advanced training strategies, such as curriculum learning and meta-learning, and how to use them to train more effective LLMs.\n\nWe'll cover best practices for selecting and tuning hyperparameters, and how to use techniques like Bayesian optimization and evolution strategies to automate the tuning process.\n\nBy taking this course, you'll gain a deeper understanding of the latest research and advancements in LLM training and tuning, and be better equipped to build state-of-the-art LLMs for your own projects.\n\nSo, are you ready to level up your LLM skills? Let's do this!\n\nRemember to like, comment, and subscribe for more content like this. And if you have any questions, feel free to leave them in the comments below. Thanks for watching!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-22"}}
{"video": {"title": "Master TensorFlow and Boost Your AI Career", "transcript": "####Master TensorFlow and Skyrocket Your AI Career\nby Laurence Moroney - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving headfirst into the thrilling world of TensorFlow!\n\n[Video hook and introduction]\n\nAre you ready to build scalable AI applications and take your skills to the next level? Then you're in luck! In this video series, we'll explore TensorFlow, the powerful open-source library for machine learning and artificial intelligence.\n\n[Body content]\n\nFirst, we'll get you comfortable with the TensorFlow environment. You'll learn how to install it, set it up, and navigate its features like a pro. We'll also cover essential TensorFlow concepts, such as tensors, variables, and operations.\n\nNext, we'll dive into building and training machine learning models using TensorFlow. We'll explore different model architectures, loss functions, and optimization techniques to help you create accurate and efficient models.\n\nOnce we've mastered the basics, we'll level up by discussing how to scale our TensorFlow applications. You'll learn how to distribute training across multiple devices, use pre-trained models, and deploy your AI apps in the real world.\n\nThroughout this series, we'll apply our newfound skills to various projects, ensuring you get hands-on experience and can showcase your TensorFlow expertise.\n\n[Conclusion and call to action]\n\nBy the end of these videos, you'll be well-prepared to tackle the Google TensorFlow Developer Certificate exam and take your AI career to new heights. So, are you ready to become a TensorFlow master? Let's get started!\n\nRemember to like, share, and subscribe for more exciting content on AI and machine learning. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-03-15"}}
{"video": {"title": "Generative AI Challenges and Opportunities", "transcript": "####Generative AI Challenges and Opportunities\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, Mike Chambers here! Today, we're diving into the thrilling world of generative AI, exploring both its challenges and opportunities.\n\nGenerative AI has the power to transform numerous industries, but it also comes with its own set of unique hurdles. For instance, how can we guarantee that the content generated is accurate, fair, and free from bias? And how do we stop generative AI from being misused, such as in the creation of deepfakes or spreading misinformation?\n\nBut don't worry, it's not all doom and gloom! There are plenty of exciting possibilities with generative AI. In this course, you'll hear from top researchers and industry experts about the latest advancements in generative AI, like generative design, drug discovery, and personalized content creation.\n\nYou'll also learn about the ethical considerations of generative AI and how to ensure it's used responsibly and for the greater good.\n\nBy the end of this course, you'll have a deeper understanding of the challenges and opportunities of generative AI, and be better prepared to navigate this fast-paced field.\n\nSo, are you ready to discover the future of generative AI? Let's get started!\n\nDon't forget to like, comment, and subscribe for more content like this. And if you have any questions, feel free to leave them in the comments below. Thanks for watching!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-08"}}
{"video": {"title": "Mistral AI: Getting Started with the Web Interface", "transcript": "####Mistral AI: Mastering the Web Interface\nby Younes Belkada and Marc Sun - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today I'm joined by my co-host Marc Sun. We're diving into Mistral AI's web interface, and trust me, you won't want to miss this!\n\nMistral AI's web interface is your gateway to access and use their open-source and commercial models. In this video, we'll show you how to get started with the web interface and unlock its full potential.\n\nFirst, we'll walk you through how to access the web interface and sign up for an account. Then, we'll demonstrate how to use the web interface to generate text, answer questions, and more.\n\nBut wait, there's more! We'll also show you how to use Mistral's JSON mode and user-defined functions with the web interface, allowing you to create even more powerful LLM applications.\n\nWhether you're a beginner or an experienced developer, Mistral AI's web interface has something for you. And the best part? It's easy to use and requires no coding experience.\n\nSo, what are you waiting for? Let's get started!\n\nDon't forget to like, share, and subscribe for more content on Mistral AI. And a special thanks to our technology partner, Mistral AI, for making this video possible.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-10"}}
{"video": {"title": "Machine Learning Project: Recommendation System", "transcript": "####Machine Learning Project: Recommendation System\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-03-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! It's your favorite host, and today we're diving into an exciting project: building a recommendation system using Machine Learning. Are you ready to level up your skills? Let's get started!\n\nFirst, we'll work with a dataset of user ratings. We'll walk you through the process of preparing the data for our model. This includes cleaning the data, handling missing values, and converting categorical data into numbers.\n\nNext, we'll split our data into a training set and a test set. The training set is used to train our model, while the test set is used to evaluate its performance.\n\nThen, we'll dive into building our model. We'll start with a simple collaborative filtering model, and we'll show you how to train it using our training data.\n\nBut that's not all. We'll also teach you how to evaluate your model using metrics like mean absolute error and root mean squared error. And we'll do it all with practical examples, so you can see how it's done in the real world.\n\nRemember, the best way to learn is by doing, so don't be afraid to get your hands dirty. So, are you ready to build a recommendation system with Machine Learning? Let's do this! And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-03-05"}}
{"video": {"title": "Machine Learning Specialization: Understanding the Math Behind ML", "transcript": "####Machine Learning Specialization: Unveiling the Math Behind ML\nby Aarti Bagul - 2022-10-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Aarti Bagul, and today we're going to demystify the math behind machine learning. Don't worry, I'll make it as simple as pie for you to understand. Let's dive in!\n#### END TRANSCRIPT ########", "author": "Aarti Bagul", "publication_date": "2022-10-03"}}
{"video": {"title": "Best Practices for Building Knowledge Graphs for RAG", "transcript": "####Best Practices for Building Knowledge Graphs for RAG\nby Andreas Kollegger - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Andreas Kollegger and today we're diving into the exciting world of Retrieval Augmented Generation, or RAG, and how to build the best knowledge graphs for it.\n\nBut first, a quick heads up! If you're new to LangChain, I highly recommend checking out our crash course 'LangChain: Chat with Your Data' before jumping into this intermediate level content.\n\nNow, let's get started. We'll be using Neo4j's query language, Cypher, to manage and retrieve data from our knowledge graph.\n\nIn this video, we'll be discussing some top-notch practices for building knowledge graphs that provide more relevant context to LLMs for RAG.\n\nWe'll also be sharing some insider tips and tricks for optimizing the performance and functionality of your knowledge graphs.\n\nSo, are you ready to level up your knowledge graph game for RAG? Let's do this!\n\nRemember, the secret to building effective knowledge graphs is understanding your data and your use case. So, don't be afraid to experiment and iterate. And if you have any questions, feel free to leave them in the comments below.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2023-04-15"}}
{"video": {"title": "AI and Disaster Management: Predicting, Preparing, and Responding", "transcript": "####AI and Disaster Management: Predicting, Preparing, and Responding\nby Robert Monarch - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the world of AI and disaster management.\n\nDisasters are unpredictable, but what if we could change that? What if we could predict them, prepare for them, and respond more effectively? That's where AI comes in!\n\nToday, we'll explore how machine learning can help us predict, prepare for, and respond to disasters. We'll look at different models and techniques, from analyzing satellite imagery to mining social media data.\n\nWe'll also look at real-world case studies, like how emergency responders are using AI to save lives.\n\nSo, are you ready to become a disaster management superhero? Let's get started!\n\nRemember, every step we take towards understanding and managing disasters is a step towards a safer, more resilient world.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning, keep growing, and keep using AI for Good!\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-05"}}
{"video": {"title": "Building Your Own Database Agent", "transcript": "####Building Your Own Database Agent: A Fun and Efficient Way to Interact with Data\nby Adrian Gonzalez Sanchez - 2022-11-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Today, I'm going to show you how to build your own database agent to interact with tabular data and SQL databases using natural language. This will enable more efficient and accessible data analysis. Let's dive in!\n\nFirst, let's talk about the prerequisites for this course. If you want to learn how to interact with databases through natural language, this beginner-friendly course is for you. Familiarity with Python programming and databases (CSV files and SQL) is recommended, but not required.\n\nNow, let's explore the features of this database agent. You will be able to interact with tabular data and SQL databases using natural language, gaining hands-on experience with the Azure OpenAI Service. You will implement techniques like Retrieval Augmented Generation (RAG) and function calling. Additionally, you will use the Azure OpenAI Service's Assistants API and test it with function calling and code interpreter features.\n\nIn conclusion, building your own database agent is a great way to streamline your data analysis process. With the help of Microsoft as our partner, you will have all the tools you need to succeed in this course. I'm Adrian Gonzalez Sanchez, and I can't wait to see what you create with your new database agent. Happy coding!\n#### END TRANSCRIPT ########", "author": "Adrian Gonzalez Sanchez", "publication_date": "2022-11-01"}}
{"video": {"title": "Text Summarization with LLMs", "transcript": "####Text Summarization with LLMs: A Game Changer\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Shelbee Eigenbrode, and today we're diving into the fascinating world of text summarization with LLMs.\n\nText summarization is like having a super-efficient personal assistant who can condense a lengthy text into a concise summary, while keeping the essence and key details intact. And guess what? LLMs are the perfect tool for the job!\n\nIn this video, we'll explore the basics of text summarization and how LLMs can make it a breeze. We'll also delve into different types of summarization, such as extractive and abstractive, and see how LLMs stack up.\n\nBy the end of this video, you'll be a pro at using LLMs for text summarization. You'll be able to apply these techniques to your own projects and stay ahead of the curve in this rapidly evolving field.\n\nSo, let's get started and unlock the power of text summarization with LLMs!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-22"}}
{"video": {"title": "Unlocking the Power of LLMs with Prompt Engineering", "transcript": "####Unlocking the Power of LLMs with Prompt Engineering\nby Andrew Ng - 2022-10-17\n\n#### BEGIN TRANSCRIPT ####\nAre you ready to unlock the full potential of LLMs? In this video, we'll dive into the endless possibilities of using LLMs for summarizing, inferring, transforming, and expanding text. Get ready to be amazed!\n#### END TRANSCRIPT ########\n\n####Unlocking the Power of LLMs with Prompt Engineering\nby Andrew Ng - 2022-10-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Are you ready to take your language modeling skills to the next level? In this video, we'll explore the endless possibilities of using LLMs for summarizing, inferring, transforming, and expanding text. Get ready to be blown away by the power of prompt engineering!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-17"}}
{"video": {"title": "Mastering Function-Calling and Data Extraction with LLMs", "transcript": "####Mastering Function-Calling and Data Extraction with LLMs\nby Jiantao Jiao, Venkat Srinivasan - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao and today we're embarking on an exciting journey into the realm of Function-Calling and Data Extraction with Language Learning Models, or LLMs for short. If you're already familiar with LLMs and have some basic Python knowledge, you're in luck!\n\nFirst off, let's chat about function-calling. With function-calling, we can supercharge our LLMs with custom functionality, allowing them to make calls to external functions. This means we can make our LLMs even more powerful and adaptable.\n\nNext, we'll delve into data extraction. With LLMs, we can extract structured data from natural language inputs. This is a game-changer for real-world data analysis, as it makes previously unstructured data usable and valuable.\n\nTo tie it all together, we'll build an end-to-end application that processes customer service transcripts using LLMs. This will give you a practical understanding of how these concepts can be applied in the real world.\n\nAnd guess what? We're teaming up with Nexusflow to bring you this content. So, you'll not only learn from us but also get insights from industry experts.\n\nNow, remember, this video is for beginners. So, don't worry if some concepts seem challenging at first. We'll break everything down into simple, easy-to-understand steps.\n\nBy the end of this video, you'll have a solid understanding of Function-Calling and Data Extraction with LLMs. And who knows, you might even have some fun along the way!\n\nSo, are you ready to get started? Let's dive right in!\n\nOh, and before I forget, if you find this video helpful, be sure to give it a thumbs up and subscribe to our channel for more great content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-03-15"}}
{"video": {"title": "AI for Biodiversity: Protecting Our Planet with Technology", "transcript": "####AI for Biodiversity: Protecting Our Planet with Technology\nby Robert Monarch - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the fascinating world of AI and biodiversity conservation.\n\n[Video hook and introduction]\n\nDid you know that AI is playing a crucial role in protecting our planet's biodiversity? From tracking endangered species to monitoring habitats, AI is making a real difference. But how does it work?\n\n[Body content]\n\nFirst, we'll explore the role of AI in biodiversity conservation. We'll see how it's being used to track species, monitor habitats, and predict threats.\n\nNext, we'll get our hands dirty with a project where we'll build a simple model to predict species distribution. Don't worry, I'll guide you through it step by step.\n\nBut it's not all sunshine and rainbows. We'll also talk about the challenges and ethical considerations of using AI in biodiversity conservation. It's important to know the full picture.\n\n[Conclusion and call to action]\n\nSo, are you ready to join the AI for biodiversity movement? Remember, every species counts, and you can make a difference.\n\nThanks for watching. If you found this video helpful, don't forget to like, share, and subscribe. And stay tuned for more exciting content on AI for biodiversity.\n\n\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-03-30"}}
{"video": {"title": "Scaling AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####Scaling AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-04-26\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python aficionados! Today, we're diving into the world of scaling AI agents using LangGraph and Tavily's agentic search.\n\nFirst, we'll uncover how LangGraph's components can supercharge our AI agents' performance. It's like having a turbocharger for our agents!\n\nThen, we'll demonstrate how to integrate Tavily's agentic search capabilities to take our scaling to the next level.\n\nIn this course, you'll learn directly from Harrison Chase, the mastermind behind LangChain, and Rotem Weiss, the brain behind Tavily. They'll walk you through the scaling process and share their insider tips.\n\nRemember, this course is ideal for those with intermediate Python skills who want to master the art of scaling their AI agents.\n\nSo, are you ready to become a scaling superstar? Let's get started!\n\nStay tuned for more thrilling lessons. And don't forget to like, share, and subscribe for more AI-powered fun.\n\nUntil next time, happy scaling!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-26"}}
{"video": {"title": "Mastering Multistage Prompts with ChatGPT", "transcript": "####Mastering Multistage Prompts with ChatGPT\nby Isa Fulford - 2022-10-24\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Isa Fulford! Are you ready to take your ChatGPT game to the next level? Today, we're diving into the world of multistage prompts. Trust me, you won't want to miss this!\n\nImagine being able to split complex tasks into a pipeline of subtasks, like a pro. That's exactly what we're going to learn today. Not only will this enhance your productivity, but it'll also boost your performance. So, let's get started!\n\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-24"}}
{"video": {"title": "Probability for Machine Learning", "transcript": "####Probability: The Secret Sauce of Machine Learning\nby Obed Kobina Nsiah - 2022-01-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Obed and welcome back to our channel! Today, we're diving into the fascinating world of probability in machine learning.\n\nProbability, the study of uncertainty, is like the secret sauce that makes machine learning work. It's how we model uncertainty and make predictions.\n\nWe're going to start with the basics, from random variables to probability distributions, and even the famous Bayes' theorem. Then, we'll explore how probability is used in machine learning, from generative models to discriminative models, and even Bayesian methods.\n\nSo, are you ready to unlock the secrets of probability in machine learning? Let's get started!\n\n...\n\nThanks for watching! I hope you found this video on probability in machine learning as exciting as I do. If you did, please give this video a thumbs up and subscribe to our channel for more content like this. And if you have any questions, don't be shy, leave them in the comments below. Until next time, happy learning!\n\n#### END TRANSCRIPT ########", "author": "Obed Kobina Nsiah", "publication_date": "2022-01-29"}}
{"video": {"title": "Mastering On-Device AI Deployment", "transcript": "####Mastering On-Device AI Deployment\nby Krishna Sridhar - 2022-03-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're diving headfirst into the exciting world of On-Device AI deployment. Are you ready to take your AI skills to the next level and deploy models on edge devices like a pro? Let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-03-01"}}
{"video": {"title": "Building JavaScript RAG Web Apps with LlamaIndex", "transcript": "####Building JavaScript RAG Web Apps with LlamaIndex\nby Laurie Voss - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, JavaScript enthusiasts! Welcome to today's video where we'll be diving into the world of building RAG web apps with LlamaIndex. I'm Laurie Voss, your friendly guide for this beginner-friendly tutorial.\n\nAre you ready to take your JavaScript skills to the next level? Let's get started!\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2022-10-15"}}
{"video": {"title": "TensorFlow: Data Preprocessing for Deployment", "transcript": "####TensorFlow: Master Data Preprocessing for Deployment\nby Laurence Moroney - 2022-01-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Laurence Moroney here, and welcome back to our TensorFlow series! Today, we're diving into the exciting world of data preprocessing for deployment.\n\n[Video hook and introduction]\n\nData preprocessing is the secret sauce that can make or break your machine learning project. It's like cleaning your room before inviting guests over - you want everything to be in order and ready for learning.\n\n[Body content]\n\nLet's start with the basics. We'll cover how to handle missing data, how to normalize your data, and how to encode categorical data. These steps are essential for preparing your data for deployment.\n\nNext, we'll dive into more advanced techniques. We'll discuss feature scaling, feature extraction, and dimensionality reduction. These techniques can significantly improve your model's performance and make it more efficient.\n\nFinally, we'll talk about how to validate your preprocessing steps. This is important to ensure that your data is ready for deployment and to avoid any unexpected surprises.\n\n[Conclusion and call to action]\n\nAnd that's it for today! You now have the tools to preprocess your data like a pro for deployment.\n\nRemember, the quality of your data impacts the quality of your results. So, don't skimp on the data preprocessing step.\n\nThanks for watching, and stay tuned for more TensorFlow videos. If you have any questions, feel free to ask.\n\nUntil next time, happy coding and preprocessing! \n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-01-08"}}
{"video": {"title": "Building Your Own Custom Chatbot with ChatGPT and Prompt Engineering", "transcript": "Positive Points:\n\n- Clear introduction of the topic and its importance.\n- Use of active voice and simple language.\n- Presence of humor and enthusiasm.\n\nAreas for Improvement:\n\n- Add more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-24"}}
{"video": {"title": "Advanced RAG Concepts: Querying Multiple Data Sources with JavaScript", "transcript": "####Advanced RAG Concepts: Querying Multiple Data Sources with JavaScript\nby Laurie Voss - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Laurie Voss, and today we're diving into the exciting world of RAG concepts. We're going to learn how to query multiple data sources using JavaScript.\n\nImagine having an intelligent agent that can answer queries by discerning and selecting from multiple data sources. Sounds cool, right? Well, that's exactly what we're going to build!\n\nWe'll be integrating different data sources, such as databases and APIs, into our RAG-powered backend. But don't worry, I'll be guiding you through every step of the process.\n\nTo get started, we'll be using the create-llama command-line tool to set up our project and install the necessary dependencies. Then, we'll create our frontend component using React and integrate it with our RAG-powered backend.\n\nBut wait, there's more! We'll also learn how to persist your data, enable chatting with your data, and make streaming responses possible.\n\nThroughout this process, I'll be sharing tips and best practices for building RAG applications in JavaScript. By the end of this video, you'll have a fully functional web app that can query multiple data sources.\n\nSo, are you ready to take your coding skills to the next level? Let's get started! And don't forget to check out LlamaIndex for more resources on building intelligent applications.\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2023-04-10"}}
{"video": {"title": "Scaling ML Models: Handling Large Datasets and Real-Time Predictions", "transcript": "####Scaling ML Models: Handling Large Datasets and Real-Time Predictions\nby Andrew Ng - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here, and today we're diving into the exciting world of scaling machine learning models to handle large datasets and real-time predictions.\n\nFirst things first, why is scaling so crucial? When we're dealing with massive datasets, we need to make sure our models can keep up with the volume and speed of data. And when it comes to real-time predictions, we need to ensure our models can deliver quickly and accurately.\n\nSo, how do we make it happen? It all begins with data processing. We need to leverage distributed computing frameworks like Apache Spark or Apache Flink to process large datasets in parallel. We'll discuss how to optimize data processing for machine learning tasks and how to tackle data quality issues at scale.\n\nNext up, we need to consider model training. We need to use distributed training techniques like data parallelism and model parallelism to train our models on large datasets. We'll chat about how to pick the right distributed training strategy and how to boost training performance.\n\nThen, we need to think about model serving. We need to use low-latency serving frameworks like TensorFlow Serving or TorchServe to serve our models in real-time. We'll talk about how to optimize model serving for low-latency predictions and how to handle model versioning and A/B testing.\n\nBut wait, there's more! Scaling machine learning models is not just about technology. It's also about people and processes. We'll discuss how to collaborate with data engineers, DevOps teams, and business stakeholders to ensure our scaling strategy aligns with the overall business goals.\n\nSo, are you ready to scale your machine learning models to handle large datasets and real-time predictions? Let's do this!\n\nRemember, scaling machine learning models is not just about technology. It's about people, processes, and culture. So keep learning, keep experimenting, and most importantly, enjoy the ride!\n\nIf you found this video helpful, be sure to give it a thumbs up and subscribe for more content. And if you have any questions or suggestions, leave them in the comments below. Thanks for watching, and I'll see you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-15"}}
{"video": {"title": "Building a General-Purpose Quantizer in Pytorch", "transcript": "####Building a General-Purpose Quantizer in Pytorch\nby Younes Belkada - 2022-10-18\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Younes Belkada! Today, we're diving into the exciting world of Pytorch to build a general-purpose quantizer. This nifty tool will let you quantize the dense layers of any open-source model, giving you up to 4x compression. So, buckle up and get ready for some hands-on coding!\n#### END TRANSCRIPT ########", "author": "Younes Belkada", "publication_date": "2022-10-18"}}
{"video": {"title": "Mastering Generative AI with Language Models", "transcript": "####Mastering Generative AI with Language Models\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Antje Barth, and today we're diving into the thrilling world of Generative AI with Language Models, or LLMs!\n\nFirst things first, what's generative AI and how does it work? Generative AI is a type of artificial intelligence that can create new content, like images, music, or text, by learning patterns from existing data. LLMs are a specific type of generative AI that focus on generating human-like language.\n\nAt the core of LLMs is the transformer architecture, which allows the model to process input sequences all at once, rather than one word at a time. This makes it much more efficient and effective at understanding the context of a sentence or paragraph.\n\nNow, let's talk about training, tuning, and running inference on LLMs. Training an LLM involves feeding it large amounts of text data and using techniques like backpropagation to adjust the model's weights and improve its accuracy. Tuning involves adjusting the model's hyperparameters to optimize its performance on specific tasks. And inference is the process of using the trained model to generate new text.\n\nBut what about the challenges and opportunities of generative AI? We'll hear from researchers in the field about the latest advancements and obstacles in this rapidly-evolving technology.\n\nBy taking this course, you'll gain foundational knowledge, practical skills, and a functional understanding of how generative AI works. You'll also hear from expert AWS AI practitioners who actively build and deploy AI in business use-cases today.\n\nSo, are you ready to dive into the world of Generative AI with LLMs? Let's get started!\n\nDon't forget to like, comment, and subscribe for more content like this. And if you have any questions, feel free to leave them in the comments below. Thanks for watching!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-02-15"}}
{"video": {"title": "Master TensorFlow and Boost Your AI Career", "transcript": "####Master TensorFlow and Skyrocket Your AI Career\nby Laurence Moroney - 2022-03-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're jumping into the thrilling world of TensorFlow!\n\n[Video hook and introduction]\n\nAre you ready to create scalable AI applications and level up your skills? You're in luck! In this video series, we'll explore TensorFlow, the mighty open-source library for machine learning and artificial intelligence.\n\n[Body content]\n\nFirst, we'll get you cozy with the TensorFlow environment. You'll learn how to install it, set it up, and navigate its features. We'll also cover essential TensorFlow concepts like tensors, variables, and operations.\n\nNext, we'll dive into building models. We'll start with simple linear regression and gradually move on to complex neural networks. You'll learn how to train, evaluate, and optimize your models for better performance.\n\nWe'll also explore how to use TensorFlow for computer vision and natural language processing tasks. You'll learn how to build image recognition systems and chatbots from scratch!\n\nLastly, we'll prepare you for the Google TensorFlow Developer Professional Certificate exam. We'll go over the exam format, key topics, and provide tips and tricks to ace it.\n\n[Conclusion and call to action]\n\nBy the end of this series, you'll be able to apply your new TensorFlow skills to a variety of projects. You'll be ready to build scalable AI applications and make a giant leap in your AI career. So, let's get started!\n\nRemember, practice makes perfect. The more you work with TensorFlow, the better you'll get. So don't be shy, dive in and start building.\n\nIf you found this video helpful, be sure to give it a thumbs up and subscribe to our channel for more AI and TensorFlow content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-03-01"}}
{"video": {"title": "Unleashing Mistral's Potential: Web Interface and API Calls", "transcript": "####Unleashing Mistral's Potential: Web Interface and API Calls\nby Younes Belkada, Marc Sun - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! Marc Sun here, and today we're diving into the exciting world of Mistral AI.\n\nAre you ready to unlock the full potential of Mistral's models? Well, buckle up, because we're about to show you how to do it through web interface and API calls.\n\nFirst up, let's talk about the web interface. It's like the gateway to Mistral's models, perfect for beginners or those who prefer a more visual approach.\n\nBut wait, there's more! If you're an advanced user, you'll love Mistral's API calls. They allow you to integrate Mistral into your own applications and workflows. And the best part? You can call user-defined Python functions. That means you can perform tasks like web searches or retrieving text from databases.\n\nSo, whether you're a newbie or a pro, Mistral AI has got you covered.\n\nBut don't just take our word for it. Try it out for yourself and see the magic happen. And remember, if you have any questions, just let us know.\n\nUntil next time, happy learning and keep exploring the world of AI!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-01"}}
{"video": {"title": "Linear Algebra: The Backbone of Machine Learning", "transcript": "####Linear Algebra: The Powerhouse of Machine Learning\nby Anshuman Singh - 2023-03-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Anshuman Singh, and today we're diving into the fascinating world of linear algebra, the powerhouse of machine learning.\n\nLinear algebra is all about vectors and matrices. In machine learning, we use vectors to represent data points and matrices to represent datasets.\n\nLet's talk about matrix multiplication. It's like a supercharged version of regular multiplication. We use it to transform our data in machine learning.\n\nEigenvalues and eigenvectors might sound intimidating, but they're just special numbers and vectors for a matrix. They're incredibly useful for reducing the dimensions of our data.\n\nDon't worry if this feels a bit challenging. With practice, you'll get the hang of it.\n\nRemember, the journey of a thousand miles begins with a single step. So, keep learning, keep practicing, and soon you'll be a linear algebra pro.\n\nThanks for watching. Be sure to like, share, and subscribe for more exciting videos on Mathematics for Machine Learning and Data Science. See you next time!\n\n\n#### END TRANSCRIPT ########", "author": "Anshuman Singh", "publication_date": "2023-03-03"}}
{"video": {"title": "Mastering Machine Learning in Production: A Comprehensive Guide", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Present and encouraging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Andrew Ng", "publication_date": "2023-03-15"}}
{"video": {"title": "Optimizing Your Multi AI Agent System with crewAI", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Encouragement for audience interaction.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.\n- Improve the call to action to encourage more likes, shares, and subscriptions.", "author": "Jo\u00e3o Moura", "publication_date": "2023-04-25"}}
{"video": {"title": "Introduction to Generative AI with LLMs", "transcript": "####Introduction to Generative AI with LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Today, we're embarking on an exciting journey into the world of Generative AI with Large Language Models. We'll be exploring the lifecycle of generative AI, the transformer architecture that powers LLMs, and the methods for training, tuning, and inference. So, buckle up and get ready to hear from some of the brightest minds in the field as they share their insights on the challenges and opportunities in the world of generative AI. Let's dive in!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2022-10-15"}}
{"video": {"title": "Getting Started with RAG and JavaScript: Building Your First Web App", "transcript": "####Getting Started with RAG and JavaScript: Build Your First Web App in No Time!\nby Laurie Voss - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Laurie Voss and today, we're going to embark on an exciting journey to build our first RAG-powered web application using JavaScript.\n\nBut wait, what's RAG? Don't worry, I've got you covered. RAG stands for Retrieval-Augmented Generation, which means our application will use an intelligent agent to answer queries by selecting from multiple data sources. Sounds cool, right?\n\nTo get started, we'll be using the create-llama command-line tool to set up our project and install the necessary dependencies. Then, we'll create our frontend component using React and integrate it with our RAG-powered backend.\n\nThroughout this process, I'll be sharing tips and best practices for building RAG applications in JavaScript. By the end of this video, you'll have a fully functional web app that you can use to chat with your data.\n\nThanks for watching and happy coding! Be sure to check out LlamaIndex for more resources on building intelligent applications. Let's get started!\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2023-03-20"}}
{"video": {"title": "Introduction to On-Device AI", "transcript": "####Introduction to On-Device AI\nby Krishna Sridhar - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're diving into the thrilling world of On-Device AI. Are you ready to explore how we can deploy AI models on edge devices and smartphones? Let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-10-15"}}
{"video": {"title": "Memory Management in LangChain", "transcript": "####Memory Management Mastery in LangChain\nby Harrison Chase, Andrew Ng - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, Harrison Chase here, and today we're diving into the fascinating world of memory management in LangChain.\n\nMemory is the brain of any LLM. It's what allows the model to remember past interactions and use that information to inform future responses.\n\nIn LangChain, we've made memory management a breeze. We'll start with the basics and then move on to some more advanced techniques.\n\nBy the end of this video, you'll be a memory management master. So, let's get started.\n\nRemember, practice makes perfect. The more you work with memory in LangChain, the better you'll understand it.\n\nThanks for watching. Don't forget to like, comment, and subscribe for more content on LLM application development. See you next time.\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-01"}}
{"video": {"title": "Quantization Challenges: Troubleshooting Common Issues", "transcript": "####Quantization Challenges: Troubleshooting Common Issues\nby Marc Sun, Younes Belkada - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the exciting world of quantization! But don't worry, we'll also be tackling some of the common challenges that come with it.\n\nFrom dealing with those pesky outliers to handling activation functions, we'll cover a range of topics to help you overcome common issues.\n\nSo, are you ready to become a quantization pro? Let's get started!\n\nAnd remember, if you find this video helpful, be sure to give it a thumbs up, share it with your friends, and subscribe for more great content. Until next time, happy quantizing!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-20"}}
{"video": {"title": "Implementing Industry Applications of Multimodal Search", "transcript": "####Implementing Industry Applications of Multimodal Search\nby Sebastian Witalec - 2022-10-09\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Sebastian Witalec, and today we're diving headfirst into the exciting world of multimodal search. This technology is not just changing the game, it's redefining it! So, buckle up and get ready to explore how multimodal search is revolutionizing information retrieval and building next-level recommender systems. Let's get started!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-09"}}
{"video": {"title": "Transformer Architecture: The Power Behind LLMs", "transcript": "####Transformer Architecture: The Power Behind LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Chris Fregly here, and today we're going to dive into the transformer architecture that powers LLMs.\n\nThe transformer architecture was introduced in a paper by Vaswani et al. in 2017, and it quickly became the go-to architecture for natural language processing tasks. The transformer uses self-attention mechanisms to process input sequences in parallel, allowing it to understand the context and meaning of text.\n\nBut how exactly does the transformer work? Let's break it down.\n\nThe transformer consists of an encoder and a decoder, both of which are made up of multiple layers. Each layer contains a self-attention mechanism, a feedforward neural network, and normalization and residual connections.\n\nThe self-attention mechanism allows the transformer to weigh the importance of different words in a sentence, so it can understand the relationships between them. The feedforward neural network then processes this information and generates output sequences.\n\nBut the transformer architecture isn't just useful for LLMs. It's also used in computer vision, speech recognition, and other applications where understanding context and meaning is important.\n\nBy the end of this video, you'll have a solid understanding of how the transformer architecture works and how it powers LLMs. You'll be able to apply this knowledge to your own projects and stay up-to-date on the latest developments in the field.\n\nSo, let's get started and explore the transformer architecture!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-20"}}
{"video": {"title": "Introduction to Generative Adversarial Networks (GANs)", "transcript": "####Introduction to Generative Adversarial Networks (GANs)\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2022-10-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, welcome to our video on Generative Adversarial Networks, also known as GANs! Today, we're going to take you on a thrilling journey into the world of image generation using GANs. We'll start with the basics and work our way up to advanced techniques. I'm Sharon, and I'm joined by my co-hosts Eda and Eric. Let's dive in!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2022-10-01"}}
{"video": {"title": "GANs and Reinforcement Learning: A Powerful Combination", "transcript": "####GANs and Reinforcement Learning: A Powerful Duo\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eda Zhou, and today we're diving into the fascinating world of GANs and reinforcement learning.\n\n[Video hook and introduction]\n\nGANs are incredible tools for creating new data, but they can also be combined with other machine learning techniques to create even more powerful models. In this video, we'll explore how GANs and reinforcement learning can work together to solve complex problems.\n\n[Body content]\n\nReinforcement learning is a type of machine learning that involves training agents to make decisions in complex environments. The goal is to maximize a reward signal over time, which can be used to teach agents to perform tasks like playing games or controlling robots.\n\nGANs can be used in reinforcement learning to generate synthetic data for training agents. This can be particularly useful in environments where real data is scarce, like in the field of robotics. By generating synthetic data, GANs can help agents learn more quickly and efficiently.\n\nBut GANs can also be used to improve the performance of reinforcement learning algorithms themselves. For example, you can use GANs to generate synthetic rewards for agents, which can help them learn more quickly and efficiently.\n\n[Conclusion and call to action]\n\nSo that's a quick overview of the powerful combination of GANs and reinforcement learning. It's a duo that's driving some of the most exciting advances in machine learning today. Thanks for watching, and be sure to check out our other videos on GANs and machine learning.\n\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-04-05"}}
{"video": {"title": "Optimizing Performance in On-Device AI", "transcript": "####Optimizing Performance in On-Device AI\nby Krishna Sridhar - 2022-02-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Krishna Sridhar here, and today we're diving into the exciting world of On-Device AI. We'll be exploring how GPU, NPU, and CPU compute unit utilization can make or break the performance of your AI models. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-02-05"}}
{"video": {"title": "Optimizing Knowledge Graph Queries for RAG", "transcript": "####Optimizing Knowledge Graph Queries for RAG\nby Andreas Kollegger - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Andreas Kollegger and today we're diving into the world of optimizing knowledge graph queries for Retrieval Augmented Generation, or RAG.\n\nBut wait, what's LangChain? If you're new to this, don't worry! I've got a short course called 'LangChain: Chat with Your Data' that'll get you up to speed.\n\nNow, let's get our hands dirty. We'll be using Neo4j's query language, Cypher, to manage and retrieve data from our knowledge graph.\n\nIn this video, we'll walk you through writing knowledge graph queries that find and format text data to provide more relevant context to LLMs for RAG.\n\nWe'll also share some tips and tricks for optimizing these queries to boost the performance of your RAG applications.\n\nSo, are you ready to take your knowledge graph queries to the next level? Let's do this!\n\nRemember, practice makes perfect. So, don't be afraid to try, fail, and try again. And if you have any questions, feel free to leave them in the comments below.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2023-03-30"}}
{"video": {"title": "Building a Language Translator with NLP", "transcript": "####Building a Language Translator with NLP\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eddy, and today we're diving into the world of NLP to build our very own language translator!\n\nImagine having your own personal translator in your pocket. Well, with NLP, we can make that a reality!\n\nWe'll be using Hugging Face, our trusted technology partner, to help us build our translator.\n\nFirst things first, we need to collect our data. This means gathering text in the language we want to translate from, and the corresponding text in the language we want to translate to.\n\nNext up, we'll preprocess our data. This involves cleaning up the text and converting it into a format that our app can understand.\n\nThen, we'll train our model. This is where the magic happens, and our app learns to translate text from one language to another.\n\nFinally, we'll put our model to the test. We'll see how well it can translate new pieces of text.\n\nRemember, the more data we have, the better our app will be. So don't be shy, collect as much data as you can!\n\nSo, are you ready to build your own translator? Let's get started! And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, keep exploring and innovating.\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-03-25"}}
{"video": {"title": "Building a Machine Learning Production System", "transcript": "####Building a Machine Learning Production System\nby Andrew Ng - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, ML enthusiasts! Today, we're diving headfirst into the thrilling world of machine learning in production. We're going to design an ML production system together, covering everything from scoping and data to modeling, deployment, and continuous improvement.\n\nBut first, let's talk about why this is important. Machine learning is no longer just a buzzword; it's a game-changer. It's transforming industries and shaping our future. But to truly harness its power, we need to know how to put it into production.\n\nSo, buckle up and get ready for an exciting journey!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-01-15"}}
{"video": {"title": "The Future of ML Production", "transcript": "####The Future of ML Production\nby Andrew Ng - 2023-04-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, ML enthusiasts! Andrew Ng here, and today we're diving into the thrilling world of the future of ML production.\n\nML production is a dynamic field, and the innovations are coming in faster than you can say \"neural network\".\n\nOne of the hottest trends is the rise of MLOps, or DevOps for machine learning. It's like bringing order to the chaos of ML, from data preparation to deployment and monitoring.\n\nAnother trend that's got everyone buzzing is the increasing use of automation in ML production. We're talking automated data cleaning, automated model selection, and automated hyperparameter tuning. It's like having a personal assistant for your ML projects!\n\nAnd let's not forget about the growing importance of explainability in ML production. As our systems get more complex, it's becoming crucial to understand how they're making decisions.\n\nSo, there you have it, folks! A quick peek into the future of ML production. It's an exciting time to be in this field, and I can't wait to see what's next.\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-03"}}
{"video": {"title": "Mastering Prompt Engineering with Llama 2 & 3", "transcript": "####Mastering Prompt Engineering with Llama 2 & 3\nby Amit Sangani - 2022-11-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Amit Sangani and today we're embarking on an exciting journey into the world of prompt engineering with Llama 2 & 3. Are you ready to level up your skills and learn the best practices for prompting and selecting among these powerful models? Let's dive in!\n\nWhen it comes to interacting with Meta Llama 2 Chat, Code Llama, and Llama Guard models, there are some key strategies to keep in mind. We'll explore how to effectively prompt these models to get the results you want, and we'll even throw in some humor to keep things interesting. Plus, we'll discuss how you can build safe and responsible AI applications using the Llama Guard model.\n\nSo, are you ready to become a prompt engineering pro? Stay tuned for all the tips and tricks you need to master prompt engineering with Llama 2 & 3. Trust me, you won't want to miss this!\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2022-11-15"}}
{"video": {"title": "LangChain: A New Way to Interact with Your Data", "transcript": "####LangChain: Revolutionizing Your Data Interaction\nby Harrison Chase - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Harrison Chase, and today we're diving into a game-changer for your data interaction - LangChain.\n\nLangChain is a tool that's about to make your data handling a breeze. With over 80 unique loaders, you can handle different types of data, from PDFs to databases. But wait, there's more! We're going to build a chatbot that can chat directly with information from your own documents and data.\n\nImagine having a personal assistant who can read and understand all your documents and data. That's what we're going to create today.\n\nI'll be guiding you through each step, making sure to keep things simple and easy to understand. By the end of this video, you'll have your own chatbot ready to assist you with your data needs.\n\nSo, are you ready to revolutionize your data interaction with LangChain? Let's get started!\n\nRemember, if you have any questions, feel free to leave a comment. I'm always here to help. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-04-20"}}
{"video": {"title": "Mistral AI: Advanced LLM Techniques", "transcript": "####Mistral AI: Advanced LLM Techniques Unleashed\nby Younes Belkada and Marc Sun - 2023-05-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Younes Belkada, and today I'm thrilled to be joined by my co-host Marc Sun. We're diving into the exciting world of Mistral AI, exploring advanced techniques for developing LLM applications.\n\nIn this video, we'll be your guides as we navigate through transfer learning, fine-tuning, and ensemble methods. We'll also show you how to use Mistral's API to integrate LLM outputs into your software applications, opening up a world of possibilities, from chatbots to text generation tools.\n\nWhether you're a beginner or a seasoned developer, Mistral AI has got you covered. It's easy to use and integrates seamlessly with your existing software.\n\nBut wait, there's more! We'll also share some insider tips and tricks to help you get the most out of Mistral AI.\n\nRemember to like, share, and subscribe for more exciting content on Mistral AI. And a big shoutout to our technology partner, Mistral AI, for making this video possible.\n\nUntil next time, keep coding and stay curious!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-05-01"}}
{"video": {"title": "Building a Custom Chatbot with LangChain", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits of using LangChain.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more stakes and payoffs at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Leverage curiosity and make the benefits more tangible.\n- Make the conclusion more memorable and engaging.", "author": "Harrison Chase", "publication_date": "2023-04-01"}}
{"video": {"title": "Getting Started with Azure OpenAI Service for Database Interaction", "transcript": "####Getting Started with Azure OpenAI Service for Database Interaction\nby Adrian Gonzalez Sanchez - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Adrian Gonzalez Sanchez and today we're going to have some fun with Azure OpenAI Service for database interaction!\n\nAre you tired of writing complex SQL queries? Or maybe you're just starting out with databases and natural language processing? Well, you're in luck! In this video, we'll cover everything you need to know to get started with using the Azure OpenAI Service to interact with databases using natural language.\n\nWe'll start by introducing the Azure OpenAI Service and its Assistants API. Then, we'll dive into how to set up your own Azure OpenAI Service instance and connect it to your database.\n\nWe'll cover techniques like Retrieval Augmented Generation (RAG) and function calling to make your natural language interface more powerful. And we'll provide hands-on examples to help you understand how to use the Azure OpenAI Service for database interaction.\n\nBy the end of this video, you'll have the skills to start building your own natural language interface for databases using the Azure OpenAI Service.\n\nSo, are you ready to revolutionize the way you interact with databases? Let's dive in!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like and subscribe for more exciting content on natural language processing and databases.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Adrian Gonzalez Sanchez", "publication_date": "2023-03-30"}}
{"video": {"title": "Diffusion Models: From Scratch", "transcript": "####Diffusion Models: From Scratch\nby Sharon Zhou - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Sharon Zhou here, and today we're diving into the fascinating world of diffusion models!\n\nDiffusion models are like painting a masterpiece. You start with a blank canvas and gradually add details until you have a beautiful, complex painting. But instead of paintbrushes, we'll be using Python, Tensorflow, or Pytorch.\n\nLet's get started! We'll define our data distribution, add noise, and learn how to denoise it. But don't worry, I'll be with you every step of the way.\n\nBut that's not all! Sampling from diffusion models can be as slow as watching paint dry. So, let's speed things up! I'll introduce you to some amazing algorithms that can accelerate sampling by a staggering 10 times!\n\nBy the end of this video, you'll be a diffusion model artist, ready to build and train your own masterpieces. So, keep painting, keep learning, and who knows? You might just create the perfect 'diffusion painting'!\n\nThanks for watching, and remember to like, share, and subscribe for more exciting content. See you next time!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-03-30"}}
{"video": {"title": "Building a Robust ML Production System", "transcript": "####Building a Robust ML Production System\nby Andrew Ng - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! Andrew Ng here, and today we're diving into the exciting world of building a robust Machine Learning production system.\n\nA robust ML system is like a superhero, ready to handle real-world data, scale to meet demand, and adapt to new challenges. It's about building a system that's reliable, efficient, and ready for anything.\n\nFirst, let's understand what makes a system robust. This involves analyzing our data quality, system performance, and error handling capabilities.\n\nNext, we need to design our system for robustness. This might involve using redundancy, implementing failover mechanisms, or using load balancing.\n\nThen, we need to test our system. This involves stress testing, load testing, and testing under various failure scenarios.\n\nBut the journey doesn't end there. We also need to continuously monitor our system, handle any issues that arise, and continuously improve our robustness processes.\n\nSo, are you ready to build a robust ML production system? Start planning your robustness strategy today, and remember, a robust ML system is a successful ML system.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content on Machine Learning. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-30"}}
{"video": {"title": "Learning from the Experts: A Conversation with Harrison Chase and Rotem Weiss", "transcript": "####Learning from the Experts: A Conversation with Harrison Chase and Rotem Weiss\nby Harrison Chase, Rotem Weiss - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey AI enthusiasts! Today, we're in for a treat. We're sitting down with Harrison Chase, the founder of LangChain, and Rotem Weiss, the founder of Tavily. We're going to learn about their journey in AI and pick their brains.\n\nFirst, we'll hear about their backgrounds and what led them to their current roles.\n\nThen, we'll dive into their experiences with LangGraph and Tavily's agentic search. We'll learn about the challenges they've faced and the successes they've achieved.\n\nFinally, we'll get their expert advice on building, debugging, and maintaining AI agents.\n\nSo, are you ready to learn from the best in the business? Let's get started!\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-15"}}
{"video": {"title": "AI for Good: Real-World Case Studies", "transcript": "####AI for Good: Real-World Case Studies\nby Robert Monarch - 2023-04-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Robert Monarch, and today we're diving into some real-world examples of AI for Good.\n\nWe'll explore how AI is being used to address some of the world's biggest challenges, from climate change to public health.\n\nWe'll delve into the nitty-gritty of each case study, discussing the AI models used, the data analyzed, and the impact achieved.\n\nWe'll also discuss the obstacles and limitations of each project, and how they were tackled.\n\nSo, are you ready to see AI for Good in action? Let's get started!\n\nRemember, every step you take towards learning and applying AI for good makes a difference.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content on AI. Until next time, let's keep using AI for good.\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-29"}}
{"video": {"title": "Handling Data Drift in ML Production Systems", "transcript": "####Handling Data Drift in ML Production Systems\nby Andrew Ng - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here, and today we're diving into the world of data drift in Machine Learning production systems.\n\nData drift is when the data our model was trained on is different from the data it's making predictions on. This can lead to poor performance and inaccurate predictions.\n\nFirst, we need to understand what causes data drift. This involves analyzing our data sources, data quality, and data preprocessing steps.\n\nNext, we need to detect data drift. This might involve monitoring performance metrics, analyzing data distributions, or using statistical tests.\n\nThen, we need to handle data drift. This involves retraining our model, updating our data preprocessing steps, or implementing a drift correction algorithm.\n\nBut the journey doesn't end there. We also need to continuously monitor for data drift, handle any drift issues that arise, and continuously improve our drift handling processes.\n\nSo, are you ready to handle data drift in your ML production system? Start planning your drift handling strategy today, and remember, a successful drift handling strategy is key to a successful ML system.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content on Machine Learning. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-20"}}
{"video": {"title": "Mastering LangGraph: A Deep Dive into AI Agent Development", "transcript": "####Mastering LangGraph: Unleash Your AI Agent Potential\nby Harrison Chase, Rotem Weiss - 2023-03-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! Today, we're diving headfirst into the world of LangGraph and how it can revolutionize your AI agent development.\n\nLangGraph is a game-changer, allowing us to build, debug, and maintain AI agents with ease. It's like having a superpower in your coding toolkit.\n\nBut wait, there's more! We're also going to explore how to integrate Tavily's agentic search capabilities to turbocharge your AI agents' knowledge and performance.\n\nIn this course, you'll learn directly from the experts - Harrison Chase, the mastermind behind LangChain, and Rotem Weiss, the genius behind Tavily. They'll guide you through the ins and outs of LangGraph and agentic search.\n\nRemember, this course is designed for those with intermediate Python knowledge who are ready to level up their AI agent skills.\n\nSo, are you ready to master LangGraph and Tavily's agentic search? Let's do this!\n\nStay tuned for more thrilling lessons. And don't forget to like, share, and subscribe for more AI-powered content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-08"}}
{"video": {"title": "Mastering Diffusion Models: A Step-by-Step Guide", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Presence of humor and enthusiasm.\n- Encouragement for practice and learning.\n\nAreas for Improvement:\n\n- Add more curiosity and stakes at the beginning.\n- Improve contrast and pacing.\n- Include critical analysis and real-world applications.\n- Make the conclusion more memorable and engaging.", "author": "Sharon Zhou", "publication_date": "2023-03-15"}}
{"video": {"title": "Mastering Machine Learning in Production: A Comprehensive Guide", "transcript": "####Mastering Machine Learning in Production: A Comprehensive Guide\nby Andrew Ng - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, ML enthusiasts! I'm Andrew Ng, and today we're diving into the thrilling world of Machine Learning in Production!\n\nFirst things first, what does it mean to have an ML system in production? It's not just about training a model and calling it a day. Oh no! It's about designing a system that can handle data at scale, make accurate predictions, and continuously improve over time.\n\nLet's start with scoping. Before you even think about building a model, you need to understand the problem you're trying to solve. What are your business objectives? What data do you have available? These are questions you need to answer before moving forward.\n\nNext up, let's talk data. You need to have a reliable way to collect, store, and process your data. This means having a robust data pipeline in place. You also need to think about how you're going to monitor your data quality over time.\n\nNow, let's move on to modeling. This is where the magic happens! You need to choose the right algorithm for your problem, train your model, and evaluate its performance. But remember, your model is only as good as the data it's trained on.\n\nOnce you have a model you're happy with, it's time to deploy it. This can be a challenging step, as you need to make sure your model can handle real-time predictions and integrate with your existing systems.\n\nBut the work doesn't stop there! Once your model is in production, you need to continuously monitor its performance and make improvements as needed. This is where the real value of ML in production comes in.\n\nSo, that's a quick overview of Machine Learning in Production. It's a complex process, but with the right tools and strategies, you can design a system that delivers real business value.\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-15"}}
{"video": {"title": "Expanding LLM Capabilities with Function-Calling", "transcript": "####Expanding LLM Capabilities with Function-Calling\nby Jiantao Jiao, Venkat Srinivasan - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nVideo hook and introduction: Hey there, AI enthusiasts! Are you ready to take your LLMs to the next level? Today, we're diving into the world of function-calling and how it can supercharge your LLMs and agent applications. Let's get started!\n\nBody content: Imagine being able to extend the functionality of your LLMs by enabling them to make calls to external functions. Sounds like a game-changer, right? Well, that's exactly what function-calling can do! By leveraging this powerful tool, you can extract structured data from natural language inputs, making real-world data more accessible and usable for analysis. In this video, we'll walk you through the process of building an end-to-end application that processes customer service transcripts using LLMs and function-calling.\n\nConclusion and call to action: And there you have it, folks! By the end of this video, you'll have a solid understanding of how function-calling can be used to expand the capabilities of your LLMs and agent applications. Don't forget to check out our partnership with Nexusflow for additional resources and support. And stay tuned for more exciting content on AI and machine learning! Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-10-15"}}
{"video": {"title": "TensorFlow: Fine-Tuning Pre-Trained Models", "transcript": "####TensorFlow: Fine-Tuning Pre-Trained Models\nby Laurence Moroney, Eddy Shyu - 2022-04-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the world of fine-tuning pre-trained models in TensorFlow.\n\nFine-tuning pre-trained models is a game-changer for your machine learning projects. In this video, we'll show you how to leverage these models as a starting point, and then fine-tune them with your own data.\n\nWe'll also share some best practices for fine-tuning pre-trained models, and some common pitfalls to steer clear of.\n\nSo, whether you're looking to boost your project's performance, or just want to explore the capabilities of TensorFlow, this video has got you covered. Let's get started.\n\n[Demonstration of fine-tuning pre-trained models]\n\nThanks for tuning in, and don't forget to check out our other videos on TensorFlow. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-04-12"}}
{"video": {"title": "Building AI Models for Air Quality: A Step-by-Step Guide", "transcript": "####Building AI Models for Air Quality: A Step-by-Step Guide\nby Robert Monarch - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Robert Monarch, and today we're diving into the world of AI to build models that can improve air quality.\n\nFirst, we'll talk about why air quality matters and how AI can make a difference. Then, we'll walk through the step-by-step process of building an AI model.\n\nWe'll start by collecting air quality data from various sources. Next, we'll preprocess the data to clean and format it for our model.\n\nThen, we'll explore different AI algorithms and choose the best one for our project. We'll train our model using the preprocessed data and test it to see how well it predicts air quality patterns.\n\nBut don't worry, we'll also discuss how to improve our model's performance.\n\nSo, are you ready to build your first AI model for a good cause? Let's get started!\n\nRemember, every step you take towards learning and applying AI for good makes a difference.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content on AI. Until next time, let's keep using AI for good.\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-03-20"}}
{"video": {"title": "Customize Model Compression with Advanced Quantization Techniques", "transcript": "####Customize Model Compression with Advanced Quantization Techniques\nby Marc Sun - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Welcome back to our channel. Today, we're going to dive headfirst into the fascinating world of quantization. We'll explore advanced techniques to customize model compression and optimize performance. I'm your host, Marc Sun, and I'm thrilled to be your guide on this journey.\n\nAre you ready to level up your machine learning skills? Let's get started!\n#### END TRANSCRIPT ########", "author": "Marc Sun", "publication_date": "2022-10-15"}}
{"video": {"title": "Creating a Text Summarization App with NLP and Hugging Face", "transcript": "####Creating a Text Summarization App with NLP and Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Your Assistant here! Today, we're going to explore the fascinating world of text summarization with NLP. Imagine being able to condense a lengthy article into a concise summary. That's the magic of NLP!\n\nFirst, let's discuss how text summarization works. It's all about teaching a machine to grasp the key points of a text and then summarize it in a shorter form.\n\nWith Hugging Face, we can create a text summarization app in just a few easy steps. We'll guide you through preparing your data, training your model, and deploying your app.\n\nBut wait, there's more! We'll also delve into some advanced techniques for enhancing your summaries, like extractive and abstractive summarization. And don't worry, we'll explain everything in a clear and simple way, so you won't get lost in the details.\n\nSo, are you ready to create your own text summarization app with NLP and Hugging Face? Let's get started!\n\nThat's all for today's video. If you enjoyed it, don't forget to hit that like button and subscribe for more content. And if you're ready to start building your own text summarization app, check out the links in the description for some great resources. See you next time!\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-03-30"}}
{"video": {"title": "GANs for Video Generation: Creating Realistic Motion", "transcript": "####GANs for Video Generation: Creating Realistic Motion\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, Eric Zelikman here, and today we're diving into the exciting world of GANs for video generation.\n\n[Video hook and introduction]\n\nGANs are a game-changer for generating realistic images, but did you know they can also create lifelike videos? In this video, we'll explore how GANs can generate new video that's almost indistinguishable from the real thing.\n\n[Body content]\n\nThe process of using GANs for video generation is similar to image generation. The generator creates new video frames, while the discriminator tries to tell the difference between real video and the video created by the generator. It's a game of cat and mouse, with the generator trying to fool the discriminator, and the discriminator trying to correctly identify real video.\n\nBut video generation comes with its own unique challenges. For example, video has a temporal dimension, which means that the frames need to be coherent and consistent over time.\n\nTo overcome these challenges, researchers have developed techniques like using 3D convolutions or incorporating motion models into the GAN.\n\n[Conclusion and call to action]\n\nSo, that's a quick overview of using GANs for video generation. If you want to learn more, check out our other videos on the topic. And if you have any questions or comments, leave them down below. We love hearing from you.\n\nThanks for watching, and we'll see you in the next video.\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-03-22"}}
{"video": {"title": "Real-World Applications of On-Device AI", "transcript": "####Real-World Applications of On-Device AI\nby Krishna Sridhar - 2022-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Krishna Sridhar, and today we're diving into the exciting world of On-Device AI. We'll explore how deploying AI models on edge devices is transforming industries like healthcare and retail. So, buckle up and let's embark on this journey together!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-02-15"}}
{"video": {"title": "Scaling Your ML Production System", "transcript": "####Scaling Your ML Production System\nby Andrew Ng - 2023-03-27\n\n#### BEGIN TRANSCRIPT ####\nHey there, ML enthusiasts! Andrew Ng here, and today we're diving into the exciting world of scaling your ML production system.\n\nScaling is all about making sure your system can handle increased demand. This can mean handling more data, making more predictions, or supporting more users. But how do you do it?\n\nFirst, you need to understand your system's bottlenecks. This means identifying the parts of your system that are struggling to keep up with demand. Think of it like a traffic jam on a highway. You need to find the bottleneck and clear it up to keep the traffic flowing smoothly.\n\nNext, you need to think about how you can optimize your system. This can involve improving your algorithms, upgrading your hardware, or even redesigning your system architecture. It's like upgrading your car's engine to handle more power.\n\nOnce you have a plan in place, it's time to start scaling. This can involve adding more servers, distributing your workload, or implementing caching strategies. But remember, scaling is not a one-time thing. You need to continuously monitor your system's performance, and make adjustments as needed. It's like tuning your car for optimal performance.\n\nSo, that's a quick overview of scaling your ML production system. It's a challenging process, but with the right approach, you can ensure your system can handle whatever comes its way.\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content! And remember, the journey to mastering ML is a marathon, not a sprint. So, keep learning, keep experimenting, and most importantly, keep having fun!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-27"}}
{"video": {"title": "Building a Chatbot with LLMs", "transcript": "####Building a Chatbot with LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Chris Fregly here, and today we're diving into the exciting world of chatbots! We're going to build one using LLMs, and trust me, it's going to be a blast.\n\nChatbots are all the rage these days, and for good reason. They allow users to interact with a system using natural language, making it easier and more enjoyable for everyone involved. In this video, we'll walk through the process of building a chatbot from scratch, using an LLM as the core component.\n\nWe'll cover everything you need to know, from data preprocessing to model training and deployment. We'll also discuss best practices for designing conversational interfaces and evaluating chatbot performance.\n\nBy the end of this video, you'll have a solid understanding of how to build a chatbot with LLMs. You'll be able to apply these techniques to your own projects and stay up-to-date on the latest developments in the field.\n\nSo, let's get started and build a chatbot with LLMs! You won't want to miss this.\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-15"}}
{"video": {"title": "AI for Air Quality: Breathing Easier with Technology", "transcript": "####AI for Air Quality: Breathing Easier with Technology\nby Robert Monarch - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the fascinating world of AI and air quality.\n\n[Video hook and introduction]\n\nImagine being able to predict air quality or identify pollution sources with just a few lines of code. Sounds like a breath of fresh air, right? Well, that's exactly what AI is doing!\n\n[Body content]\n\nFirst, we'll explore the role of AI in air quality management. We'll see how it's being used to predict air quality, identify pollution sources, and improve public health.\n\nNext, we'll get our hands dirty with a project where we'll build a simple model to predict air quality. Don't worry, I'll be your guide every step of the way.\n\nBut wait, there's more! We'll also discuss the challenges and ethical considerations of using AI in air quality management. It's not all sunshine and rainbows, but it's important to know the full story.\n\n[Conclusion and call to action]\n\nSo, are you ready to join the AI for air quality revolution? Remember, every breath counts, and you can make a difference.\n\nThanks for watching. If you enjoyed this video, don't forget to like, share, and subscribe. And stay tuned for more exciting content on AI for air quality.\n\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-15"}}
{"video": {"title": "Building Agentic RAG with LlamaIndex", "transcript": "####Building Agentic RAG with LlamaIndex\nby Jerry Liu - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and today we're embarking on an exciting journey into the world of building agentic RAG systems with LlamaIndex. Are you ready to create autonomous agents that can navigate and analyze your data like never before? Let's dive in!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2022-10-15"}}
{"video": {"title": "TensorFlow: Multi-GPU Training", "transcript": "####TensorFlow: Multi-GPU Training\nby Laurence Moroney - 2022-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're going to talk about how to supercharge your TensorFlow training with multiple GPUs!\n\n[Video hook and introduction]\n\nTraining machine learning models can be a time-consuming process, but using multiple GPUs can significantly speed up the training time. So let's dive in and learn how to harness the power of multiple GPUs with TensorFlow!\n\n[Body content]\n\nFirst, we'll cover the basics of multi-GPU training and discuss how TensorFlow distributes the training process across multiple GPUs using data parallelism.\n\nNext, we'll walk through the process of setting up your TensorFlow environment for multi-GPU training, including installing the necessary software and configuring your hardware.\n\nWe'll also cover how to modify your TensorFlow code to take advantage of multiple GPUs, using techniques like replica devices and tower functions.\n\nLastly, we'll discuss some best practices for multi-GPU training, such as using batch normalization and adjusting your learning rate.\n\n[Conclusion and call to action]\n\nAre you ready to speed up your TensorFlow training times with multi-GPU training? Let's get started! Remember, using multiple GPUs can make a big difference in the time it takes to train your machine learning models.\n\nIf you found this video helpful, be sure to give it a thumbs up, share it with your friends, and subscribe to our channel for more awesome content. See you in the next video!\n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-04-05"}}
{"video": {"title": "Unleashing the Power of Function-Calling and Data Extraction with LLMs", "transcript": "####Unleashing the Power of Function-Calling and Data Extraction with LLMs\nby Jiantao Jiao, Venkat Srinivasan - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao and today we're embarking on an exciting journey into the world of function-calling and data extraction with Language Learning Models, or LLMs for short. If you're already familiar with LLMs and have some basic Python knowledge, you're in luck!\n\nFirst off, let's chat about function-calling. Imagine being able to extend your LLMs with custom functionality. Well, with function-calling, you can do just that! By enabling LLMs to form calls to external functions, you can expand their capabilities and create more powerful applications.\n\nNow, let's shift gears to data extraction. With LLMs, you can extract structured data from natural language inputs. This means you can take real-world data and make it usable for analysis. No more struggling with messy, unstructured data!\n\nTo tie it all together, we're going to build an end-to-end application that processes customer service transcripts using LLMs. You'll see firsthand how function-calling and data extraction can take your LLM applications to the next level.\n\nAnd guess what? We're teaming up with Nexusflow to bring you this content. So, you'll not only learn from us but also get insights from industry experts.\n\nSo, are you ready to unleash the power of function-calling and data extraction with LLMs? Let's dive in!\n\nRemember, practice makes perfect and exploration is key. If you have any questions, feel free to leave them in the comments. And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-03-15"}}
{"video": {"title": "Mastering Llama 2 & 3 Models for AI Applications", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and real-world applications to make the content more valuable.\n- Make the conclusion more memorable and engaging.", "author": "Amit Sangani", "publication_date": "2023-02-23"}}
{"video": {"title": "Optimizing NLP Apps with Hugging Face and Cloud Computing", "transcript": "####Optimizing NLP Apps with Hugging Face and Cloud Computing\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Your Assistant, and today we're diving into the world of NLP optimization with Hugging Face and cloud computing.\n\nTraining NLP models can be a real power hog. It needs a ton of data and processing power. But with cloud computing, we can scale up our resources and give our NLP apps a serious performance boost.\n\nWe'll kick things off by learning how to use cloud computing for NLP, then we'll see how to optimize our models with Hugging Face, and finally, we'll put it all to the test.\n\nRemember, the secret to successful optimization is finding the right balance between performance and cost. We need to strike that perfect balance for our app.\n\nSo, are you ready to take your NLP apps to the next level? Let's get started with Hugging Face and cloud computing!\n\nStay tuned for more thrilling videos on this topic. And don't forget to like, share, and subscribe for more tech content. Until next time, I'm Your Assistant, your guide in the world of AI.\n\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-04-20"}}
{"video": {"title": "Automating Workflows with Multistage Prompts", "transcript": "####Automating Workflows with Multistage Prompts\nby Isa Fulford - 2022-10-21\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford, and today we're going to have a blast learning how to automate workflows using multistage prompts. Imagine breaking down complex tasks into manageable chunks and evaluating outputs for safety and relevance. Sounds exciting, right? Let's dive in!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-21"}}
{"video": {"title": "Demystifying Statistics for Machine Learning", "transcript": "####Demystifying Statistics for Machine Learning\nby Elena Sanina - 2023-03-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Elena Sanina, and today we're diving into the fascinating world of statistics for machine learning.\n\nStatistics is the superpower that helps us make sense of the data we collect and use it to make predictions. It's like having a crystal ball for numbers!\n\nLet's start with the basics: mean, median, and mode. They're simple ways to summarize our data. Think of them as your data's best friends.\n\nStandard deviation and variance are like the data's personal space. They help us understand how spread out our data is.\n\nProbability distributions, like the normal distribution, help us predict the likelihood of different outcomes. It's like playing the odds, but with numbers!\n\nDon't worry if this seems a bit complex. With practice, you'll master these concepts in no time. And remember, the only way to do great work is to love what you do. So, keep learning, keep practicing, and soon you'll be a statistics pro.\n\nThanks for watching. Be sure to like, share, and subscribe for more exciting videos on Mathematics for Machine Learning and Data Science. See you in the next one!\n\n\n#### END TRANSCRIPT ########", "author": "Elena Sanina", "publication_date": "2023-03-05"}}
{"video": {"title": "Unraveling CNNs: A Deep Dive into Convolutional Neural Networks", "transcript": "####Unraveling CNNs: A Deep Dive into Convolutional Neural Networks\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-01-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your friendly guide and today we're diving into the fascinating world of Convolutional Neural Networks, or CNNs.\n\nCNNs are a type of neural network that are simply amazing for image processing. They can spot patterns in images, like edges and shapes, and use those patterns to make predictions. For example, they can tell the difference between a cat and a dog in a picture.\n\nBut how do they do it? Well, it's all about layers. CNNs have three main types of layers: convolutional layers, pooling layers, and fully connected layers. Each layer plays a vital role in processing the image.\n\nThe convolutional layer applies a series of filters to the image to extract features. The pooling layer reduces the spatial size of the representation to reduce the amount of parameters and computation in the network. The fully connected layer takes the output of the previous layers and uses it to classify the image.\n\nNow, I know this might sound a bit tricky, but don't worry. With some practice and patience, you'll be building your own CNNs in no time.\n\nSo, what are you waiting for? Let's get started on your CNN journey. And remember, if you ever get stuck, I'm here to help.\n\nThanks for watching, and happy learning!\n\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-01-08"}}
{"video": {"title": "Training and Tuning LLMs for Optimal Performance", "transcript": "####Training and Tuning LLMs for Optimal Performance\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, Shelbee Eigenbrode here! Today, we're diving into the exciting world of training and tuning LLMs for optimal performance.\n\nBut first, let me ask you a question. Have you ever wondered how to make your LLM models more accurate? Well, you're in luck! In this video, we'll be covering everything you need to know to take your LLM skills to the next level.\n\nWe'll start by discussing how to train your LLM using techniques like backpropagation and large amounts of text data. But how do you know when your model is ready to use? That's where validation and testing come in. We'll show you how to split your data into training, validation, and testing sets, and how to use metrics like perplexity and BLEU score to evaluate your model's performance.\n\nBut wait, there's more! We'll also be covering how to fine-tune your model on specific tasks, such as text classification or language translation. And let's not forget about hyperparameters. Choosing the right learning rate, batch size, and number of epochs can make a big difference in your model's performance. We'll cover best practices for selecting and tuning hyperparameters to get the most out of your LLM.\n\nIn this course, you'll get hands-on experience training and tuning LLMs using Python and popular deep learning frameworks like TensorFlow and PyTorch. You'll also hear from experts in the field about the latest research and advancements in LLM training and tuning.\n\nSo, are you ready to take your LLM skills to the next level? Let's get started!\n\nDon't forget to like, comment, and subscribe for more content like this. And if you have any questions, feel free to leave them in the comments below. Thanks for watching!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-01"}}
{"video": {"title": "Tuning Techniques for Generative AI", "transcript": "####Tuning Techniques for Generative AI: Unleashing Your Model's Potential\nby Antje Barth - 2022-10-09\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to take your generative AI models to the next level? Well, buckle up because in this video, we're diving into the world of tuning techniques. That's right, we're going to fine-tune your models for better results. I'm your host, Antje Barth, and I can't wait to share these valuable insights with you. So, let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth", "publication_date": "2022-10-09"}}
{"video": {"title": "Unleashing the Power of LangChain for LLM Application Development", "transcript": "####Unleashing the Power of LangChain for LLM Application Development\nby Harrison Chase, Andrew Ng - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're diving into the world of LangChain for LLM Application Development. No fancy jargon, just plain and simple learning.\n\nFirst things first, what's LangChain? It's a powerful and extensible framework that lets you use prompts, parsing, memory, chains, question answering, and agents. Sounds complex? Don't worry, it's easier than you think.\n\nIf you've got basic Python under your belt, you're good to go. We'll be applying LLMs to your proprietary data to build personal assistants and specialized chatbots. Imagine having your own AI helper!\n\nBut wait, there's more. We'll also explore how to use agents, chained calls, and memories to expand your use of LLMs. It's like giving your AI helper superpowers.\n\nAnd guess what? You're learning LangChain directly from me, the creator of the framework. No second-hand knowledge here.\n\nSo, are you ready to improve the way you develop applications? Let's get started. Remember, practice makes perfect.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-03-15"}}
{"video": {"title": "Device Integration for On-Device AI", "transcript": "####Device Integration for On-Device AI\nby Krishna Sridhar - 2022-10-07\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're diving into the fascinating world of device integration for On-Device AI. Are you ready to learn how to seamlessly integrate AI models into diverse devices? Let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-10-07"}}
{"video": {"title": "Model Conversion for On-Device AI", "transcript": "####Model Conversion for On-Device AI\nby Krishna Sridhar - 2022-01-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Krishna Sridhar here, and today we're diving into the exciting world of On-Device AI. Specifically, we'll be exploring how to convert your PyTorch or TensorFlow models for deployment on a variety of devices. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-01-20"}}
{"video": {"title": "Model Conversion for On-Device AI", "transcript": "####Model Conversion for On-Device AI\nby Krishna Sridhar - 2022-10-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Krishna Sridhar and welcome back to another exciting video! Today, we're diving into the world of model conversion for On-Device AI. Are you ready to level up your AI game? Let's do this!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-10-03"}}
{"video": {"title": "LangChain and Machine Learning: Taking Your Chatbot to the Next Level", "transcript": "####LangChain and Machine Learning: Unleashing Your Chatbot's Potential\nby Harrison Chase - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, chatbot enthusiasts! I'm Harrison Chase, the creator of LangChain, and today we're going to have a blast exploring how LangChain and machine learning (ML) can supercharge your chatbot.\n\nIf you've been keeping up with our previous videos, you know that LangChain is designed to work hand-in-hand with NLP techniques. But did you know that you can also use machine learning algorithms to make your chatbot even more impressive?\n\nIn this video, we'll cover the basics of machine learning and how it can be used in conjunction with LangChain to build more sophisticated chatbots. We'll start with an overview of machine learning and some of the most popular ML libraries, including scikit-learn and TensorFlow.\n\nNext, we'll dive into some examples of how to use machine learning algorithms to improve your chatbot's responses. We'll cover techniques such as sentiment analysis, intent classification, and entity recognition.\n\nBy the end of this video, you'll have a solid understanding of how to use LangChain and machine learning to build more powerful chatbots that can understand and respond to natural language queries with greater accuracy and sophistication.\n\nSo, are you ready to take your chatbot to the next level? Let's dive in and start exploring the world of LangChain and machine learning!\n\nRemember, if you have any questions or need help along the way, feel free to reach out to me on social media or through the LangChain website.\n\nThanks for watching, and happy coding! \n\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-04-10"}}
{"video": {"title": "Deploying LLMs in Real-World Applications", "transcript": "####Deploying LLMs in Real-World Applications\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, Mike Chambers here, and today we're diving into the exciting world of deploying LLMs in real-world applications!\n\nDeploying an LLM is like integrating a super-smart assistant into a larger system, such as a chatbot or virtual assistant. But it's not all sunshine and rainbows, there are challenges to consider, like latency, scalability, and security.\n\nIn this video, we'll cover best practices for deploying LLMs, including how to choose the right deployment strategy, optimize the model for performance, and secure the system against attacks. We'll also talk about how to monitor the model's performance in production and update it as needed.\n\nBy the end of this video, you'll have a solid understanding of how to deploy LLMs in real-world applications. You'll be able to apply these techniques to your own projects and stay up-to-date on the latest developments in the field.\n\nSo, let's get started and learn how to deploy LLMs like a pro!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-01"}}
{"video": {"title": "Getting Started with Meta Llama 2 & 3", "transcript": "####Getting Started with Meta Llama 2 & 3\nby Amit Sangani - 2023-02-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Amit Sangani and welcome to our exciting journey into the world of Meta Llama 2 & 3.\n\nAre you ready to become a prompting pro and unlock the full potential of these powerful models? You're in the right place! In this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst, we'll take a look at Meta Llama 2 Chat and how you can interact with it to get the most out of your prompts. I'll show you some tips and tricks to help you prompt smarter, not harder.\n\nNext, we'll dive into Code Llama and I'll show you how to use it to build some really cool applications. You'll be amazed at what you can create with just a few prompts!\n\nBut that's not all, we'll also be taking a look at Llama Guard and how you can use it to build safe and responsible AI applications. In today's world, it's more important than ever to make sure our AI is being used for good.\n\nSo, are you ready to get started? Let's dive in and start prompting like a pro with Llama 2 & 3. And don't forget to hit that like and subscribe button for more great content. See you in the next video!\n\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-17"}}
{"video": {"title": "Building a Scalable LLM Application with Predibase's LoRAX Framework", "transcript": "####Building a Scalable LLM Application with Predibase's LoRAX Framework\nby Travis Addair - 2023-02-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Travis Addair and today we're going to have a blast building a scalable LLM application using Predibase's LoRAX framework.\n\nFirst things first, what's LoRAX? It's a framework that lets us serve multiple fine-tuned models at once, making it a breeze to serve LLM applications to a large number of users. It's built on top of Low Rank Adapters (LoRA), a technique for fine-tuning large language models.\n\nNow, let's get our hands dirty and see how to use LoRAX to build a scalable LLM application. We'll start by fine-tuning a pre-trained language model on our specific task. Once we have our fine-tuned model, we'll use LoRAX to serve it to multiple users at once.\n\nWe'll also cover how to handle requests from multiple users and how to balance the load between multiple models. This will ensure that our application is scalable and can handle a large number of requests.\n\nFinally, we'll discuss some best practices for building LLM applications, such as how to handle input validation and how to monitor the performance of our application.\n\nThanks for watching and don't forget to like, comment, and subscribe for more videos on GenAI and LLM powered applications. See you in the next one!\n#### END TRANSCRIPT ########", "author": "Travis Addair", "publication_date": "2023-02-20"}}
{"video": {"title": "LangChain and Data Integration", "transcript": "####LangChain and Data Integration: Unleashing Your Chatbot's Potential\nby Harrison Chase - 2023-03-27\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Harrison Chase, the mastermind behind LangChain, and today we're diving into an exciting topic: data integration.\n\nData integration is like the secret sauce that makes your chatbot a superhero. It's the process of combining data from various sources into one cohesive view. And with LangChain, you can harness this power to create even more impressive chatbots.\n\nBut how does it work? Let's find out.\n\nLangChain offers you access to over 80 unique loaders that can handle a variety of data sources. This means you can connect your chatbot to a wide range of documents and data, from PDFs to CSV files, and even your own custom data sources.\n\nOnce you've connected your data, LangChain's data integration tools allow you to combine your data into a single, unified view. This means you can ask your chatbot questions that span multiple data sources and get a single, accurate answer.\n\nI'll be your guide through each step of the process, sharing my insider tips and tricks along the way. And the cherry on top? You'll be learning directly from me, the creator of LangChain.\n\nSo, are you ready to level up your chatbot with data integration? Let's get started!\n\nRemember, if you have any questions or need a helping hand, don't be shy. And once you've mastered data integration with LangChain, be sure to share your creations with me. I can't wait to see what you build!\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-27"}}
{"video": {"title": "Mastering Python for ML", "transcript": "####Mastering Python for ML: A Fun and Engaging Journey\nby Eddy Shyu - 2022-10-07\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! Are you ready to take your Python skills to the next level and conquer the world of machine learning? Well, you're in luck! In this video, we're going to embark on an exciting journey to master the basics of Python for ML. Whether you're a newbie to coding or a seasoned pro looking to brush up on your skills, I've got you covered. I'm Eddy Shyu, your friendly coding guide, and I can't wait to help you level up your game!\n\nBut first, let me tell you why Python is the perfect language for machine learning. It's simple, easy to learn, and has a ton of powerful libraries that make data analysis and modeling a breeze. Plus, it's used by some of the biggest companies in the world, like Google and Netflix. So, are you ready to join the ranks of Python pros and start building amazing ML models? Let's do this!\n\n#### END TRANSCRIPT ########", "author": "Eddy Shyu", "publication_date": "2022-10-07"}}
{"video": {"title": "AI and Climate Change: A Match Made in Heaven", "transcript": "####AI and Climate Change: A Match Made in Heaven\nby Robert Monarch - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into an exciting topic: AI and climate change.\n\n[Video hook and introduction]\n\nClimate change is one of the most pressing issues of our time. But what if I told you that AI could be our secret weapon in the fight against it?\n\n[Body content]\n\nFirst, let's explore how AI can help. From predicting extreme weather events to optimizing renewable energy, AI has a lot to offer. We'll look at some real-world examples to see how it's being done.\n\nNext, we'll get our hands dirty with a project where we'll build a simple model to predict climate patterns. Don't worry, I'll guide you through it step by step.\n\nBut it's not all sunshine and rainbows. We'll also discuss the challenges and ethical considerations of using AI in climate change. It's important to know the full picture.\n\n[Conclusion and call to action]\n\nSo, are you ready to join the fight against climate change with AI? Remember, every little bit helps, and you can make a difference.\n\nThanks for watching. If you enjoyed this video, don't forget to like, share, and subscribe. And stay tuned for more exciting content on AI and climate change.\n\n\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-03-20"}}
{"video": {"title": "Monitoring and Maintenance: Keeping Your ML System Healthy", "transcript": "####Monitoring and Maintenance: Keep Your ML System in Top Shape\nby Andrew Ng - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here, and today we're diving into the world of monitoring and maintenance for your machine learning system in production.\n\nFirst things first, why is monitoring so crucial? Well, when we're dealing with complex systems, things can go south. Models can drift, data can get corrupted, and hardware can fail. That's why we need to keep a close eye on our system to catch any issues before they become major headaches.\n\nSo, how do we do it? It all starts with metrics. We need to define the right metrics to measure the performance of our system, such as accuracy, precision, recall, and F1 score. Then, we need to set up alerts to notify us when these metrics dip below a certain threshold.\n\nNext up, maintenance. When we're dealing with large datasets and complex models, we need to perform regular maintenance tasks to keep our system in tip-top shape. That means cleaning up old data, retraining our models, and updating our software dependencies.\n\nBut wait, there's more! Monitoring and maintenance are not just about technology. They're also about people and processes. We'll talk about how to build a dream team of data scientists, engineers, and DevOps professionals to support your ML system in production.\n\nSo, are you ready to keep your ML system healthy and performing at its best? Let's get started!\n\nRemember, monitoring and maintenance are not just about technology. They're about people, processes, and culture. So keep learning, keep experimenting, and most importantly, have fun!\n\nIf you found this video helpful, be sure to give it a thumbs up and subscribe for more content. And if you have any questions or suggestions, leave them in the comments below. Thanks for watching, and I'll see you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-25"}}
{"video": {"title": "Unlocking the Power of LangChain for LLM Application Development", "transcript": "####Unlocking the Power of LangChain for LLM Application Development\nby Harrison Chase - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nVideo hook and introduction: Hey there, tech enthusiasts! Today, we're diving into the fascinating world of LangChain and how it's revolutionizing LLM application development. I'm Harrison Chase, the mastermind behind LangChain, and I can't wait to share its secrets with you. Let's get started!\n\nBody content: LangChain is a powerful framework that puts the might of LLMs right at your fingertips. With features like prompts, parsing, memory, chains, question answering, and agents, you can create personalized assistants and specialized chatbots tailored to your needs. Whether you're a newbie or a seasoned pro, LangChain's intuitive interface makes it a breeze to get started. Plus, with LangChain, you can apply LLMs to your proprietary data, opening up a world of possibilities for your projects.\n\nConclusion and call to action: So, there you have it, folks! LangChain is the key to unlocking the full potential of LLM application development. Join the LangChain community today and let's revolutionize the tech world together. I'm Harrison Chase, and I can't wait to see the amazing things you'll create with LangChain. Thanks for watching!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2022-10-15"}}
{"video": {"title": "Quantization Fundamentals with Hugging Face", "transcript": "####Quantization Fundamentals with Hugging Face\nby Younes Belkada - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Younes Belkada, and today we're embarking on an exciting journey to explore the fundamentals of quantization with Hugging Face. Are you ready to learn how to compress models using the Hugging Face Transformers library and the Quanto library? Let's dive right in!\n#### END TRANSCRIPT ########", "author": "Younes Belkada", "publication_date": "2022-10-15"}}
{"video": {"title": "Expanding Your Use of LLMs with LangChain", "transcript": "####Expanding Your Use of LLMs with LangChain\nby Harrison Chase, Andrew Ng - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, Harrison Chase here, and today we're diving into the exciting world of LangChain and how it can help you expand your use of LLMs.\n\nAre you ready to take your LLM application development to the next level? Well, you're in luck! In LangChain, we provide a number of tools and techniques that allow you to go beyond the basics.\n\nWe'll cover some of these advanced techniques, including the use of agents, chained calls, and memories. By the end of this video, you'll be pushing the boundaries of what's possible with LLMs.\n\nSo, let's get started. Remember, practice makes perfect.\n\nAnd don't forget to like, comment, and subscribe for more content on LLM application development. We've got some exciting stuff in the works, and you won't want to miss it.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-25"}}
{"video": {"title": "Building a SQL Database Agent with Natural Language Processing", "transcript": "####Building a SQL Database Agent with Natural Language Processing\nby Adrian Gonzalez Sanchez - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Adrian Gonzalez Sanchez and today we're diving into the world of SQL databases and natural language processing.\n\nEver struggled with writing complex SQL queries to extract the data you need? What if I told you that you could ask your database a question in plain English and get the answer you need?\n\nIn this video, we'll explore how to use natural language processing to interact with SQL databases. We'll start by introducing the concept of natural language processing and how it can be applied to SQL databases.\n\nThen, we'll dive into the Azure OpenAI Service and learn how to use its Assistants API to build a natural language interface for your SQL database. We'll cover techniques like Retrieval Augmented Generation (RAG) and function calling to make your interface more powerful.\n\nBy the end of this video, you'll have the skills to build your own natural language interface for SQL databases. And the best part? You don't need to be an expert in Python programming or databases to follow along.\n\nSo, are you ready to make data analysis more efficient and accessible? Let's get started!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like and subscribe for more exciting content on natural language processing and databases.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Adrian Gonzalez Sanchez", "publication_date": "2023-03-25"}}
{"video": {"title": "Introduction to Multimodal Search and RAG", "transcript": "####Introduction to Multimodal Search and RAG\nby Sebastian Witalec - 2022-10-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Sebastian Witalec here, and today we're embarking on an exciting journey into the realm of multimodal search and RAG. Get ready to level up your search and RAG applications for multimodal retrieval and generation.\n\nBut first, let's set the stage. Imagine being able to search for information not just through text, but also through images, audio, and video. That's the power of multimodal search! And with RAG, or Retrieval Augmented Generation, we can generate more accurate and contextually relevant responses.\n\nSo, are you ready to take your search and RAG applications to the next level? Let's dive in!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-01"}}
{"video": {"title": "Generative Adversarial Networks (GANs) and Their Applications", "transcript": "####Generative Adversarial Networks (GANs) and Their Applications\nby Laurence Moroney - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Laurence Moroney, and today we're diving into the fascinating world of generative adversarial networks (GANs) and their applications using TensorFlow.\n\n[Video hook and introduction]\n\nGANs are a type of neural network architecture that can generate new, realistic data by learning the underlying patterns in a dataset. They've been used for tasks like image synthesis, style transfer, and even creating deepfakes. Let's get started!\n\n[Body content]\n\nFirst, we'll discuss the structure of a GAN, including the generator and discriminator networks and how they work together in a two-player minimax game.\n\nNext, we'll walk through building and training a GAN in TensorFlow for a specific task, such as generating handwritten digits or human faces. We'll cover techniques for stabilizing GAN training and improving the quality of generated samples.\n\nWe'll also discuss some popular GAN variants, such as Deep Convolutional GANs (DCGANs), Wasserstein GANs (WGANs), and CycleGANs, and their unique applications.\n\n[Conclusion and call to action]\n\nBy the end of this video, you'll have a solid understanding of generative adversarial networks and how to use them for various applications in TensorFlow.\n\nDon't forget to like, share, and subscribe for more AI and machine learning content. Join me in the next video, where we'll explore reinforcement learning and how it's used to train intelligent agents. See you there!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-04-15"}}
{"video": {"title": "Building Advanced NLP Applications with Hugging Face", "transcript": "####Building Advanced NLP Applications with Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, NLP enthusiasts! Welcome back to our channel. Today, we're going to explore the fascinating world of Natural Language Processing and show you how to create advanced NLP applications using Hugging Face. Are you ready to build apps that can answer questions, analyze sentiment, translate languages, and summarize text? Let's get started!\n\nFirst things first, let's talk about what you need to know before diving into this intermediate-level project. If you're comfortable with the basics of NLP and have some coding experience, you're all set!\n\nNow, let's talk about our amazing technology partner, Hugging Face. They provide state-of-the-art NLP models and tools that will take your app to the next level. With their support, you'll be able to create powerful and efficient NLP applications that can change the way we interact with language.\n\nSo, what are you waiting for? Let's start building some incredible NLP apps with Hugging Face today! Thanks for watching, and don't forget to like and subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2022-10-15"}}
{"video": {"title": "Breaking Down Complex Tasks with ChatGPT", "transcript": "####Breaking Down Complex Tasks with ChatGPT: A Game Changer\nby Andrew Ng - 2022-10-16\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Andrew Ng, your AI guide! Today, we're going to have some fun and learn how to break down complex tasks using ChatGPT. We'll also explore how to chain LLM calls, and evaluate inputs and outputs for safety and relevance. Are you ready to level up your AI game? Let's dive in!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-16"}}
{"video": {"title": "TensorFlow: Transfer Learning with Pre-trained Models", "transcript": "####TensorFlow: Transfer Learning with Pre-trained Models\nby Laurence Moroney - 2022-04-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're going to talk about transfer learning with pre-trained models in TensorFlow. \n\n[Video hook and introduction]\n\nTransfer learning is a game-changer! It allows you to leverage pre-trained models for your own machine learning tasks, saving you time and resources. So let's dive in and learn how to use transfer learning with TensorFlow! \n\n[Body content]\n\nFirst, we'll cover the basics of transfer learning and discuss how pre-trained models can be used as feature extractors or fine-tuned for your specific task. \n\nNext, we'll walk through the process of using popular pre-trained models like VGG16, ResNet, and Inception in TensorFlow, including how to load the models and extract features. \n\nWe'll also cover how to fine-tune pre-trained models for your specific task, using techniques like freezing layers, unfreezing layers, and adjusting learning rates. \n\nLastly, we'll discuss some best practices for transfer learning, such as choosing the right pre-trained model, using data augmentation, and monitoring your training progress. \n\n[Conclusion and call to action]\n\nAre you ready to leverage the power of pre-trained models and save time with transfer learning in TensorFlow? Let's get started! Remember, transfer learning can make a big difference in the performance of your machine learning models. \n\nIf you found this video helpful, be sure to give it a thumbs up, share it with your friends, and subscribe to our channel for more awesome content. See you in the next video! \n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-04-19"}}
{"video": {"title": "Building Agentic RAG with LlamaIndex", "transcript": "####Building Agentic RAG with LlamaIndex\nby Jerry Liu - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nVideo hook and introduction: Hey there, tech enthusiasts! Are you ready to take your data analysis skills to the next level? Today, we're diving into the fascinating world of building agentic RAG systems with LlamaIndex. Get ready to learn how to create autonomous agents that can navigate and analyze your data with ease. I'm Jerry Liu, your friendly guide on this exciting journey. Let's get started!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2022-10-15"}}
{"video": {"title": "Demystifying AI with Hugging Face: A Beginner's Journey", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits of Hugging Face.\n- Use of active voice and simple language.\n- Encouragement for the audience to try out the platform.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-03-20"}}
{"video": {"title": "Building NLP Apps with Hugging Face: A Step-by-Step Guide", "transcript": "####Building NLP Apps with Hugging Face: A Fun and Easy Guide\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, NLP enthusiasts! Today, we're going to have a blast exploring the world of Natural Language Processing. We'll be designing NLP apps that can answer questions, analyze sentiment, translate languages, and summarize text. Are you as excited as I am? Let's get this party started!\n\nToday, we're going to walk through a step-by-step guide on how to build NLP apps using Hugging Face. Hugging Face is an amazing partner that provides top-notch tools and models for NLP tasks. With their help, we can create powerful applications that can understand and generate human language. Are you ready to change the game and create some mind-blowing NLP apps together? Let's dive in and start building!\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2022-10-15"}}
{"video": {"title": "Mathematics for Machine Learning: Real-World Applications", "transcript": "####Mathematics for Machine Learning: Real-World Applications\nby Lucas Coutinho - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, machine learning fans! Lucas Coutinho here, and today we're diving into the fascinating world of mathematics in machine learning.\n\nFrom recommending your next binge-watch on Netflix, to detecting fraud in your bank account, to predicting the weather for your weekend plans, mathematics is the secret sauce.\n\nLet's get our hands dirty with some real-world case studies. We'll see how tech giants like Google, Amazon, and Facebook use mathematics to power their machine learning models.\n\nBut it's not all sunshine and rainbows. We'll also discuss some of the challenges and ethical considerations in applying mathematics and machine learning to real-world problems.\n\nSo, that's the power of mathematics in machine learning. It's not just theory, it's a tool that helps us solve real-world problems and make a difference.\n\nRemember, the best way to learn is by doing. So, start working on your own machine learning projects and see the power of mathematics in action.\n\nJoin us in our next video, where we'll be diving into even more advanced machine learning topics. If you found this video helpful, give us a thumbs up and subscribe to our channel for more exciting content. See you next time!\n\n#### END TRANSCRIPT ########", "author": "Lucas Coutinho", "publication_date": "2023-04-10"}}
{"video": {"title": "Automating Workflows with ChatGPT", "transcript": "####Automating Workflows with ChatGPT\nby Isa Fulford - 2022-10-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Isa Fulford! Today, we're diving into the exciting world of automating workflows with the ChatGPT API. Are you ready to streamline your processes and skyrocket your productivity? Let's do this!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-17"}}
{"video": {"title": "Debugging and Controlling Your Agentic RAG with LlamaIndex", "transcript": "####Debugging and Controlling Your Agentic RAG with LlamaIndex\nby Jerry Liu - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Jerry Liu here and today we're diving into the world of debugging and controlling our agentic RAG with LlamaIndex.\n\nIn our previous videos, we've built an agentic RAG, mastered document Q&A, unleashed the power of summarization, and even built a multi-document research agent. But today, we're going to take it to the next level by learning how to debug and control our agent.\n\nWe'll start by understanding common issues that can arise with agentic RAG systems. Then, we'll dive into debugging techniques and tools available in LlamaIndex.\n\nOnce we've got that down, we'll look at how to control our agent's reasoning process to improve its accuracy and efficiency.\n\nBy the end of this video, you'll be a pro at debugging and controlling your agentic RAG systems.\n\nSo, let's get started! And remember, practice makes perfect. So, don't just watch this video, try debugging and controlling your own agentic RAG with LlamaIndex.\n\nIf you found this video helpful, give it a thumbs up and subscribe to our channel for more exciting content. Until next time, happy coding!\n\n\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-05"}}
{"video": {"title": "Mastering Q&A and Summarization with Router Agents", "transcript": "####Mastering Q&A and Summarization with Router Agents\nby Jerry Liu - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and welcome back to our series on building agentic RAG systems with LlamaIndex.\n\nToday, we're going to master Q&A and summarization tasks with our router agent.\n\nFirst, we'll understand how our router agent processes queries and retrieves information from our documents. Then, we'll dive into the specifics of Q&A and summarization tasks.\n\nI'll show you how to formulate your queries for the best results and how to fine-tune your router agent for optimal performance.\n\nWe'll also discuss common challenges you might encounter and how to overcome them.\n\nBy the end of this video, you'll be a pro at using your router agent for Q&A and summarization tasks.\n\nSo, let's get started!\n\nRemember, if you have any questions or need further clarification, leave a comment below. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-03-20"}}
{"video": {"title": "RAG and Machine Learning: Building a Recommendation System with JavaScript and LlamaIndex", "transcript": "####RAG and Machine Learning: Building a Recommendation System with JavaScript and LlamaIndex\nby Laurie Voss - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurie Voss and today we're diving into the exciting world of RAG and machine learning. We're going to build a recommendation system using JavaScript and LlamaIndex.\n\nImagine having an intelligent agent that analyzes user data and recommends relevant content. That's exactly what we're going to create! We'll build an interactive frontend component that allows users to input their preferences and receive personalized recommendations from our RAG-powered backend.\n\nLet's get started! We'll use the create-llama command-line tool to set up our project and install the necessary dependencies. Then, we'll create our frontend component using React and integrate it with our RAG-powered backend.\n\nBut wait, there's more! We'll also learn how to persist your data, enable chatting with your data, and make streaming responses possible.\n\nThroughout this process, I'll be sharing tips and best practices for building RAG applications in JavaScript. By the end of this video, you'll have a fully functional recommendation system that you can use to recommend content to your users.\n\nThanks for watching and happy coding! Be sure to check out LlamaIndex for more resources on building intelligent applications.\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2023-04-30"}}
{"video": {"title": "Boost Your LLM Capabilities with Function-Calling and Data Extraction", "transcript": "#### Boost Your LLM Capabilities with Function-Calling and Data Extraction\nby Jiantao Jiao, Venkat Srinivasan - 2022-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao and today we're taking your Language Learning Model, or LLM, to the next level with function-calling and data extraction. If you're already familiar with LLMs and have some basic Python skills, you're in luck!\n\nLet's start with function-calling. It's a game-changer for extending your LLMs with custom functionality. Imagine teaching your LLM to make calls to external functions. Sounds cool, right?\n\nNext, we'll dive into data extraction. We'll learn how to extract structured data from natural language inputs, making real-world data usable for analysis.\n\nBut wait, there's more! We've teamed up with Nexusflow to bring you an end-to-end application that processes customer service transcripts using LLMs. You'll see how function-calling and data extraction can enhance your application capabilities.\n\nRemember, practice makes perfect. So, don't just watch, get involved! Try out the techniques we'll cover and see how they can boost your LLM and agent applications.\n\nThanks for tuning in and happy learning! Don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, this is Venkat Srinivasan signing off.\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-03-15"}}
{"video": {"title": "Understanding Named Entity Recognition with NLP and Hugging Face", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Present and encouraging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and real-world applications to make the content more valuable.", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-04-15"}}
{"video": {"title": "Deep Learning Applications: From Theory to Practice", "transcript": "####Deep Learning Applications: From Theory to Practice\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-01-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Today, we're diving headfirst into the world of deep learning applications.\n\nFirst, we'll recap the neural networks we've been working on, including CNNs, RNNs, LSTMs, and Transformers. Then, we'll see how these networks are used in real-world applications, like self-driving cars, speech recognition, and NLP.\n\nBut we won't just stop at theory. We'll also get our hands dirty by building our own AI application using Python and TensorFlow.\n\nSo, are you ready to see deep learning in action? Let's dive in! And remember, the best way to learn is by doing, so don't be afraid to get creative with your application.\n\nThat's it for today's video. If you found it helpful, give it a thumbs up and subscribe to our channel for more AI content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-01-29"}}
{"video": {"title": "Common Pitfalls in ML Production", "transcript": "####Common Pitfalls in ML Production\nby Andrew Ng - 2023-04-06\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here! Today, we're diving into the world of ML production and the common pitfalls that can trip you up.\n\nNow, ML production is no walk in the park. It's a complex process with plenty of potential pitfalls.\n\nFirst up, not having a clear problem statement. Without a crystal-clear understanding of what you're trying to achieve, you're likely to get lost in the details and end up with a system that's all sizzle and no steak.\n\nNext, not having a robust data pipeline. Without a reliable way to collect, store, and process your data, your system is going to be as useful as a chocolate teapot.\n\nAnd finally, not continuously monitoring and improving your system. ML production is not a set-it-and-forget-it kind of deal. You need to keep a close eye on your system's performance and make adjustments as needed.\n\nSo, there you have it! A quick rundown of some common pitfalls in ML production. By keeping these pitfalls in mind, you can avoid them and set yourself up for success.\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-06"}}
{"video": {"title": "Getting Started with crewAI: Your First Multi AI Agent System", "transcript": "####Getting Started with crewAI: Your First Multi AI Agent System\nby Jo\u00e3o Moura - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Jo\u00e3o Moura here, and welcome back to our series on Multi AI Agent Systems with crewAI.\n\nLast time, we discussed what Multi AI Agent Systems are and how they can streamline your business workflows. Today, we're diving in and setting up your first Multi AI Agent System using crewAI.\n\nFirst things first, you'll need to install the crewAI library. Don't worry, it's a breeze - just a few lines of code.\n\nOnce you've got crewAI installed, we'll guide you through creating your first team of AI agents. Each agent has a unique role, goal, and backstory. We'll define these for each agent and watch as they collaborate to tackle complex tasks.\n\nBy the end of this video, you'll have your very own Multi AI Agent System ready to rock.\n\nSo, let's get started! And remember, if you have any questions, don't hesitate to drop them in the comments.\n\nStay tuned for our next video where we'll delve deeper into optimizing your Multi AI Agent System. Don't forget to like, share, and subscribe for more thrilling content. Until next time, keep exploring and innovating!\n#### END TRANSCRIPT ########", "author": "Jo\u00e3o Moura", "publication_date": "2023-04-20"}}
{"video": {"title": "Challenges and Solutions in On-Device AI", "transcript": "####Challenges and Solutions in On-Device AI\nby Krishna Sridhar - 2022-10-13\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here. Today, we're diving into the exciting world of On-Device AI. We'll uncover the challenges and solutions in deploying AI models on edge devices and smartphones. Are you ready to level up your AI game? Let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-10-13"}}
{"video": {"title": "The Ethics of Generative AI with LLMs", "transcript": "####The Ethics of Generative AI with LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Antje Barth, and today we're diving into the fascinating world of Generative AI with LLMs. But wait, before we get too excited, let's not forget about the ethical considerations that come with this powerful technology.\n\nImagine LLMs being used to spread misinformation or propaganda. Scary, right? Or what about perpetuating biases that exist in the training data? We need to address these issues head-on.\n\nBut don't worry, it's not all doom and gloom. LLMs have the potential to generate creative content and assist with language translation. They could even revolutionize fields like healthcare, finance, and entertainment.\n\nBy the end of this video, you'll have a better understanding of the ethical considerations surrounding LLMs and some ideas for how to use this technology responsibly. So, are you ready to explore the ethical frontier of Generative AI with LLMs? Let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-29"}}
{"video": {"title": "On-Device AI: Overcoming Challenges and Limitations", "transcript": "####On-Device AI: Overcoming Challenges and Limitations\nby Krishna Sridhar - 2023-04-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're diving into the exciting world of On-Device AI. But don't worry, we're not just going to talk about the benefits. We're also going to tackle the challenges head-on!\n\nNow, I know what you're thinking. \"On-Device AI? That sounds complicated.\" But don't worry, I'm here to make it simple and fun.\n\nSo, what are the challenges we're facing? Well, for starters, there's power consumption. We all know how quickly our phones can drain when we're using too many apps. But what if we could use AI without draining our batteries?\n\nAnd then there's the issue of model size. AI models can be huge, taking up valuable space on our devices. But what if we could make them smaller, without sacrificing performance?\n\nBut don't worry, we're not just going to talk about the problems. We're also going to discuss strategies to overcome them. From optimizing power consumption to reducing model size, we'll look at how to tackle these issues head-on.\n\nSo, are you ready to become an On-Device AI expert? Let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2023-04-29"}}
{"video": {"title": "Applying CNNs to Speech Recognition", "transcript": "####Applying CNNs to Speech Recognition: A Fun and Engaging Journey\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-02-26\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your friendly AI guide, and today we're embarking on an exciting journey to apply Convolutional Neural Networks (CNNs) to speech recognition.\n\nWe'll be using Python and TensorFlow to build our CNN, and we'll be applying it to a real-world speech recognition task. Trust me, it's going to be a blast!\n\nFirst, we'll preprocess our audio data and convert it into spectrograms. Then, we'll define our CNN architecture, including the convolutional, pooling, and fully connected layers. After that, we'll compile our model and train it on our data. Finally, we'll evaluate our model and see how well it performs.\n\nNow, I know this might sound complex, but don't worry. I'll be with you every step of the way, making sure you don't miss a beat.\n\nSo, what are you waiting for? Let's get started on this fun and engaging journey of applying CNNs to speech recognition. And remember, if you ever get stuck, I'm here to help.\n\nThanks for watching, and happy learning!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-02-26"}}
{"video": {"title": "Mastering AI Agent Workflows with LangGraph and Tavily", "transcript": "####Mastering AI Agent Workflows with LangGraph and Tavily\nby Harrison Chase, Rotem Weiss - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey, coding enthusiasts! Today, we're diving into the world of AI agent workflows using LangGraph and Tavily's agentic search.\n\nLangGraph is a game-changer, allowing you to develop, debug, and maintain AI agents with ease. It's like having the secret decoder ring to the AI universe.\n\nBut wait, there's more! When you pair it with Tavily's agentic search, you're taking your AI to the stratosphere. It boosts your agent's knowledge and performance, making your AI more powerful than ever.\n\nIn this course, you'll learn directly from the brains behind the operations, Harrison Chase, the founder of LangChain, and Rotem Weiss, the founder of Tavily. They'll guide you through LangGraph's components and show you how to integrate agentic search capabilities.\n\nThis course is perfect for those with intermediate Python knowledge who want to become AI agent workflow masters.\n\nSo, are you ready to take your AI skills to the next level? Let's do this! Don't forget to like, share, and subscribe for more exciting content.\n\nKeep coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-25"}}
{"video": {"title": "Unleashing the Power of LangChain for LLM Application Development", "transcript": "####Unleashing the Power of LangChain for LLM Application Development\nby Harrison Chase, Andrew Ng - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Harrison Chase, the mastermind behind LangChain, and today we're embarking on an exciting journey into the realm of LLM application development using LangChain.\n\nBut first, let's get acquainted with LangChain. It's a robust and flexible framework that empowers you to use prompts, parsing, memory, chains, question answering, and agents to create truly remarkable applications.\n\nI'm guessing you're here because you've got some Python skills and you're ready to take them to the next level. Well, you're in luck! We're going to keep things beginner-friendly, but we'll also be pushing the boundaries of what you can do with LLMs.\n\nLet's kick things off by applying LLMs to your proprietary data. Imagine building a personal assistant or a specialized chatbot that's tailored to your unique needs. That's the magic of LangChain.\n\nBut we're not stopping there. We're going to delve into how to use agents, chained calls, and memories to really amplify your use of LLMs. By the end of this video, you'll be a LangChain whiz.\n\nAnd the best part? This isn't just theory. We're teaming up with LangChain to bring you real-world examples and practical applications.\n\nSo, are you ready to transform your applications with LangChain? Let's dive in!\n\nThanks for watching. Don't forget to like, comment, and subscribe for more content on LLM application development. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-03-15"}}
{"video": {"title": "Mastering Knowledge Graphs for RAG with Neo4j and LangChain", "transcript": "####Mastering Knowledge Graphs for RAG with Neo4j and LangChain\nby Andreas Kollegger - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Andreas Kollegger, and today we're going to explore the fascinating realm of Knowledge Graphs for Retrieval Augmented Generation, or RAG for short. If you've already dabbled with LangChain or taken our crash course 'LangChain: Chat with Your Data', you're in the perfect place to learn how to build and use knowledge graph systems to turbocharge your RAG applications.\n\nSo, what's a knowledge graph? Picture a massive web of data points, all linked by various relationships. That's a knowledge graph. And today, we're using Neo4j, a robust graph database, to manage and retrieve this data.\n\nNeo4j uses a query language called Cypher. It's like SQL, but for graphs. With Cypher, we can craft queries that locate and format text data, providing more relevant context to our Language Learning Models (LLMs) for RAG.\n\nNow, let's roll up our sleeves and build a question-answering system using Neo4j and LangChain. We'll start by creating a knowledge graph from structured text documents. Then, we'll write a Cypher query to find the most relevant data. Finally, we'll use LangChain to generate a response based on the retrieved data.\n\nAnd voila! You've just built a question-answering system powered by a knowledge graph. With this new skill, you can enhance the relevance and accuracy of your RAG applications.\n\nRemember, practice makes perfect. So, keep experimenting with different knowledge graphs and queries. And if you're ever stuck, Neo4j has a fantastic community and resources to help you out.\n\nThanks for watching, and happy coding! Don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2023-04-01"}}
{"video": {"title": "Supervised Learning: Regression vs Classification", "transcript": "####Supercharged Learning: Regression vs Classification\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-01-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Today, we're taking a thrilling dive into the world of supervised learning, focusing on regression and classification.\n\nRegression is like forecasting the temperature for the next week. It's all about predicting a continuous value.\n\nClassification, on the other hand, is like deciding if an email is spam or not. It's about categorizing data into classes.\n\nWe'll be using Python to bring these concepts to life, so you'll get some coding practice too!\n\nRemember, practice makes perfect. So, keep coding and experimenting.\n\nThat's a wrap for today's video. If you found this helpful, give us a thumbs up and don't forget to subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-01-22"}}
{"video": {"title": "Mastering TensorFlow: Advanced Techniques", "transcript": "####Mastering TensorFlow: Advanced Techniques\nby Laurence Moroney, Eddy Shyu - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, welcome back to our TensorFlow series! Today, we're diving into some advanced techniques that will take your deep learning skills to the next level. I'm Laurence Moroney, and I'm Eddy Shyu, and we're thrilled to guide you through this journey.\n\nAre you ready to level up your TensorFlow game? Let's get started!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-10-15"}}
{"video": {"title": "Building Multimodal Search and RAG with Weaviate", "transcript": "####Building Multimodal Search and RAG with Weaviate\nby Sebastian Witalec - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sebastian Witalec and today we're diving headfirst into the thrilling world of multimodal search and RAG applications. If you've got a basic understanding of Python, you're all set!\n\nFirst up, let's demystify multimodality. It's a fancy term, but don't let it scare you. In simple terms, it's the ability to handle different types of data, like text, images, and audio, all at the same time. We'll be using contrastive learning to build modality-independent embeddings. This means you can retrieve any type of data with any type of query. Pretty cool, right?\n\nNext, we'll be building a multimodal RAG system. RAG stands for Retrieval Augmented Generation. It's a system that retrieves relevant context and reasons over it to generate more accurate answers. Imagine asking a question about a picture and getting a detailed answer that refers to specific elements in the image. That's the power of multimodal RAG.\n\nBut wait, there's more! We'll also be exploring some real-world applications of multimodal search. Ever heard of multi-vector recommender systems? They're like regular recommender systems, but on steroids. They can recommend items based on multiple factors, like user preferences and item features.\n\nAnd the cherry on top? We're partnering with Weaviate to bring you this content. They're a leading company in the field of vector search engines, and their technology will make our journey much more exciting.\n\nSo, are you ready to build smarter search and RAG applications? Let's get started! Remember, if you have any questions, feel free to leave a comment. And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2023-03-15"}}
{"video": {"title": "Diffusion Models: A Practical Approach", "transcript": "####Diffusion Models: A Practical Approach\nby Sharon Zhou - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sharon Zhou, and today we're diving into the world of diffusion models!\n\nDiffusion models are like composing a symphony. You start with a single note and gradually add more until you have a beautiful, complex composition.\n\nLet's get started! Fire up your Python environment, and make sure you have Tensorflow or Pytorch. We'll start by defining our data distribution, then gradually add noise and learn how to denoise it.\n\nBut wait, there's more! Sampling from diffusion models can be as slow as composing a symphony. So, let's speed things up! I'll show you some fantastic algorithms that can accelerate sampling by up to 10 times!\n\nBy the end of this video, you'll be a diffusion model maestro, ready to build and train your own symphonies. So, keep composing, keep learning, and who knows? You might just compose the perfect 'diffusion symphony'!\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. See you soon!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-04-15"}}
{"video": {"title": "Understanding Calculus for Machine Learning", "transcript": "####Understanding Calculus for Machine Learning\nby Anshuman Singh - 2022-10-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! It's Anshuman Singh here, and today we're diving into the fascinating world of calculus and machine learning. Are you ready to level up your mathematical skills and become a data science pro? Let's get started!\n#### END TRANSCRIPT ########", "author": "Anshuman Singh", "publication_date": "2022-10-03"}}
{"video": {"title": "Mistral AI: Best Practices for LLM Development", "transcript": "####Mistral AI: Unleashing Your Potential with LLM Development\nby Younes Belkada and Marc Sun - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Younes Belkada, and today I'm thrilled to be joined by my co-host, Marc Sun. We're diving into the exciting world of LLM development with Mistral AI.\n\nIn this video, we'll be sharing our top tips and best practices for developing LLM applications using Mistral AI. We'll cover everything from data preprocessing to model selection and hyperparameter tuning.\n\nBut that's not all! We'll also show you how to use Mistral's API to integrate LLM outputs into your larger software applications. Whether you're building chatbots or text generation tools, Mistral AI has got you covered.\n\nAnd the best part? Mistral AI is incredibly user-friendly and integrates seamlessly with your existing software applications. So, whether you're a beginner or a seasoned pro, Mistral AI has everything you need to create powerful LLM applications.\n\nSo, what are you waiting for? Let's get started! And don't forget to like, share, and subscribe for more exciting content on Mistral AI.\n\nA big thank you to our technology partner, Mistral AI, for making this video possible. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-25"}}
{"video": {"title": "Diffusion Models: The Power to Predict", "transcript": "####Diffusion Models: Unleashing the Power of Prediction\nby Sharon Zhou - 2023-03-23\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Sharon Zhou, and today we're diving into the fascinating world of diffusion models.\n\nImagine being able to predict how a trend will spread on social media, or how a disease will spread in a population. That's the power of diffusion models!\n\nBut enough chit-chat, let's get our hands dirty. Open up your Python environment, and make sure you've got Tensorflow or Pytorch installed. We'll start by defining our model, then we'll feed in our data, and finally, we'll train our model.\n\nBut wait, there's more! I'll also show you how to speed up your sampling process by 10 times. We'll implement some algorithms that will make your sampling process faster than a cheetah on roller skates.\n\nAnd that's a wrap, folks! You've just learned how to build and train your own diffusion model, and even how to speed up the sampling process. Don't forget to like, subscribe, and share this video with your friends. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-03-23"}}
{"video": {"title": "Unleashing the Power of Llama 2 & 3 Models", "transcript": "####Unleashing the Power of Llama 2 & 3 Models\nby Amit Sangani - 2023-02-23\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Amit Sangani and today we're diving into the exciting world of Llama 2 & 3 Models.\n\nAre you ready to level up your AI game? In this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst, we'll take a look at Meta Llama 2 Chat and how you can interact with it to get the most out of your prompts. We'll also explore Code Llama and how it can help you with your coding needs.\n\nBut wait, there's more! We'll also be discussing the importance of building safe and responsible AI applications. That's where Llama Guard comes in. We'll show you how you can use this model to ensure that your AI applications are safe and responsible.\n\nSo, are you ready to unleash the power of Llama 2 & 3 models? Let's get started!\n\nRemember, practice makes perfect. So, be sure to try out these best practices on your own and see how they work for you. And, if you have any questions or need further clarification, don't hesitate to reach out.\n\nThanks for watching and happy prompting!\n\nDon't forget to like, comment, and subscribe for more content like this. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-23"}}
{"video": {"title": "AutoGen and Microsoft: A Powerful Partnership", "transcript": "####AutoGen and Microsoft: A Powerful Partnership\nby Chi Wang, Qingyun Wu - 2023-04-26\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Chi Wang here, and today we're diving into our powerful partnership with Microsoft.\n\nWe'll kick things off by discussing how Microsoft's technology seamlessly integrates with AutoGen. Then, we'll show you some real-world examples of how this partnership can supercharge your AI agent building experience.\n\nRemember, partnerships like these are all about giving you the best tools and resources to thrive in your AI journey. So, let's get started and explore the benefits of AutoGen and Microsoft!\n\nAs always, if you have any questions, don't be shy! Leave them in the comments. We're here to help you learn and grow.\n\nAnd before you go, don't forget to like, subscribe, and hit that notification bell for more exciting content. We can't wait to see you in the next video!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2023-04-26"}}
{"video": {"title": "Unleashing AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####Unleashing AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! Today, we're going to unleash the full potential of AI agents using LangGraph and Tavily's agentic search.\n\nLangGraph is an open-source framework that allows us to build, debug, and maintain AI agents. It's like having a magic wand for creating controllable agents.\n\nAnd when we combine it with Tavily's agentic search, we can enhance our AI agents' knowledge and performance to a whole new level.\n\nIn this course, you'll learn directly from Harrison Chase, the founder of LangChain, and Rotem Weiss, the founder of Tavily. They'll show you how to use LangGraph's components and integrate agentic search capabilities.\n\nRemember, this course is perfect for those with intermediate Python knowledge who want to create more powerful AI agents.\n\nSo, are you ready to unleash the power of AI agents? Let's get started!\n\nStay tuned for more exciting lessons. And don't forget to like, share, and subscribe for more AI-powered content.\n\nUntil next time, keep innovating!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-15"}}
{"video": {"title": "Building an End-to-End Application with LLMs, Function-Calling, and Data Extraction", "transcript": "####Building an End-to-End Application with LLMs, Function-Calling, and Data Extraction\nby Jiantao Jiao, Venkat Srinivasan - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Venkat Srinivasan and welcome back to our series on function-calling and data extraction with LLMs. Today, we're going to have a blast building an end-to-end application that processes customer service transcripts using LLMs, function-calling, and data extraction.\n\nWe'll kick things off by setting up our environment and then move on to building the application step by step. You'll learn how to use function-calling to extend LLMs with custom functionality and how to extract structured data from natural language inputs.\n\nBy the end of this video, you'll have a fully functional application that you can use as a starting point for your own projects.\n\nRemember, the best way to learn is by doing. So, don't just watch the video. Follow along and build the application with me.\n\nAnd if you have any questions, feel free to leave them in the comments. We're here to help!\n\nSo, are you ready to build an end-to-end application with LLMs, function-calling, and data extraction? Let's get started!\n\nDon't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-04-01"}}
{"video": {"title": "Building Agentic RAG with LlamaIndex", "transcript": "####Building Agentic RAG with LlamaIndex\nby Jerry Liu - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and today we're embarking on an exciting journey into the world of building agentic RAG systems with LlamaIndex. Are you ready to create autonomous agents that can navigate and analyze your data like never before? Let's dive in!\n\nSo, what exactly is an agentic RAG system? It's a powerful tool that allows you to develop agents that can reason over your documents and provide intelligent answers to complex questions. But before we jump into the coding, make sure you have a basic understanding of Python.\n\nNow, let's start by building a router agent that can assist you with Q&A and summarization tasks. With LlamaIndex, you'll be able to extend this agent to handle passing arguments and make your workflow even more efficient.\n\nNext, we'll explore how to design a research agent that can handle multiple documents at once. We'll also cover different methods for debugging and controlling this agent to ensure it's working at its best.\n\nBy the end of this video, you'll have the skills to create your own agentic RAG systems and take your data analysis to the next level. Partnering with LlamaIndex, we're excited to show you how to build intelligent agents that can revolutionize the way you work with your data.\n\nSo, what are you waiting for? Let's start building agentic RAG with LlamaIndex today!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2022-10-15"}}
{"video": {"title": "Implementing ML Algorithms with Code", "transcript": "####Implementing ML Algorithms with Code\nby Andrew Ng - 2022-10-05\n\n#### BEGIN TRANSCRIPT ####\nAre you ready to get your hands dirty with some code? After mastering the foundational concepts visually, it's time to roll up our sleeves and dive into the exciting world of machine learning algorithms. I'm Andrew Ng, and I'll be your coding companion on this hands-on journey.\n\nTogether, we'll walk through the step-by-step process of implementing machine learning algorithms and the math behind them. Trust me, it's not as scary as it sounds!\n\nSo, grab your favorite coding snack and let's get started.\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-05"}}
{"video": {"title": "Mistral AI: The Future of LLM", "transcript": "####Mistral AI: The Future of LLM\nby Younes Belkada, Marc Sun - 2023-02-18\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Younes Belkada here, and today we're diving into the future of LLM with Mistral AI.\n\nMistral AI is revolutionizing the game with its advanced LLM capabilities. From open-source and commercial models to JSON mode and API, Mistral AI is making it a breeze to integrate LLM into your software applications.\n\nBut wait, there's more! Mistral AI is constantly evolving and improving, so you can expect even more advanced LLM capabilities in the future.\n\nSo, what does this mean for you? It means that now is the time to start exploring Mistral AI and its advanced LLM capabilities. Whether you're a beginner or a seasoned pro, Mistral AI has something for everyone.\n\nSo, what are you waiting for? Start exploring Mistral AI today and take your LLM capabilities to the next level. And don't forget to check out Mistral AI, our technology partner for this video.\n\nThanks for watching, and stay tuned for more exciting videos on Mistral AI and LLM. I'm Younes Belkada, and I'll see you in the next one.\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-18"}}
{"video": {"title": "Building a Natural Language Interface for Data Analysis", "transcript": "####Building a Natural Language Interface for Data Analysis\nby Adrian Gonzalez Sanchez - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! It's Adrian Gonzalez Sanchez and today we're going to revolutionize the way you analyze data.\n\nImagine being able to ask your data a question in plain English and getting the answer you need in seconds. Sounds too good to be true? Well, not anymore!\n\nIn this video, we'll explore how to build a natural language interface for data analysis using the Azure OpenAI Service. We'll start by introducing the concept of natural language processing and how it can be applied to data analysis.\n\nThen, we'll dive into the Azure OpenAI Service and learn how to use its Assistants API to build a natural language interface for your data. We'll cover techniques like Retrieval Augmented Generation (RAG) and function calling to make your interface more powerful.\n\nBy the end of this video, you'll have the skills to build your own natural language interface for data analysis. And the best part? You don't need to be an expert in Python programming or databases to follow along.\n\nSo, are you ready to make data analysis more efficient and accessible? Let's get started!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like and subscribe for more exciting content on natural language processing and databases.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Adrian Gonzalez Sanchez", "publication_date": "2023-04-30"}}
{"video": {"title": "On-Device AI: A Roundup of Tools and Frameworks", "transcript": "####On-Device AI: A Roundup of Tools and Frameworks\nby Krishna Sridhar - 2023-05-13\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're diving into the exciting world of On-Device AI!\n\nAre you tired of relying on the cloud for your AI needs? Well, you're in luck! We're rounding up the best tools and frameworks for deploying AI models on edge devices.\n\nFrom TensorFlow Lite to PyTorch Mobile, we'll explore the top tools and frameworks for On-Device AI. We'll discuss their features, strengths, and weaknesses, and help you choose the right one for your needs.\n\nRemember, we're using short sentences, present tense, and a conversational style. We're also using more active voice than passive and keeping things clear and simple.\n\nSo, are you ready to explore the best tools and frameworks for On-Device AI? Let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2023-05-13"}}
{"video": {"title": "Understanding Diffusion Models: A Comprehensive Guide", "transcript": "####Understanding Diffusion Models: A Comprehensive Guide\nby Sharon Zhou - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Sharon Zhou here, and today we're embarking on an exciting journey into the world of diffusion models. Are you ready to dive in? Let's go!\n\nFirst things first, let's get our bearings. Diffusion models are all about simulating the spread of information, ideas, or diseases through a population. By modeling how particles move and interact, we can unlock insights into real-world phenomena.\n\nNow, let's roll up our sleeves and get into the nitty-gritty. We'll discuss the mathematical equations behind diffusion models and how they're implemented in Python using libraries like Tensorflow or Pytorch.\n\nBut wait, there's more! We'll also explore diffusion models in action. We'll look at real-world examples where diffusion models are used to predict trends, analyze social networks, and more.\n\nAnd finally, we'll build our own diffusion model from scratch. We'll train it on sample data and implement algorithms to speed up sampling by 10 times. By the end of this video, you'll have a solid understanding of diffusion models and the tools to create your own.\n\nThanks for watching! Don't forget to like and subscribe for more AI and machine learning content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2022-10-15"}}
{"video": {"title": "AutoGen Tips and Tricks: Enhancing Your AI Agent's Performance", "transcript": "####AutoGen Tips and Tricks: Enhancing Your AI Agent's Performance\nby Chi Wang, Qingyun Wu - 2023-04-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Qingyun Wu here, and today we're diving into some exciting tips and tricks to supercharge your AI agent's performance in AutoGen.\n\nWe'll kick things off by discussing some best practices for building AI agents. Then, we'll dive into some advanced techniques that can help improve your agent's efficiency and effectiveness.\n\nRemember, the key to mastering AutoGen is practice and continuous learning. So, let's get started and level up your AI agent's performance!\n\nAs always, if you have any questions, feel free to leave them in the comments. We're here to help you learn and grow.\n\nAnd don't forget to like, subscribe, and hit that notification bell for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2023-04-19"}}
{"video": {"title": "AI for Public Health: Predicting and Preventing Disease Outbreaks", "transcript": "####AI for Public Health: Predicting and Preventing Disease Outbreaks\nby Robert Monarch - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, health champions and AI aficionados! I'm Robert Monarch, and today we're diving into the fascinating world of AI in public health.\n\nWe'll kick things off by discussing how AI is revolutionizing disease outbreak prediction. Then, we'll delve into how AI can help us prevent these outbreaks and boost public health.\n\nWe'll explore how AI can crunch data to predict disease patterns, optimize vaccine distribution, and enhance patient care.\n\nWe'll also take a look at a real-world case study where AI has been used to save lives during a disease outbreak.\n\nSo, are you ready to discover how AI can help us be better prepared for public health challenges? Let's get this show on the road!\n\nRemember, every step you take towards learning and applying AI for good makes a difference.\n\nThanks for watching. Don't forget to like, share, and subscribe for more thrilling content on AI. Until next time, let's keep using AI for good.\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-15"}}
{"video": {"title": "Debugging Your Agentic RAG", "transcript": "####Debugging Your Agentic RAG: Mastering the Art of Bug Squashing\nby Jerry Liu - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! Jerry Liu here, and today we're diving into the thrilling world of debugging.\n\nThat's right, we're going to learn how to fix issues with our Agentic RAG system. Because even the most advanced systems can have bugs.\n\nFirst, we'll uncover some common issues you might encounter with your agent. Knowledge is power, right?\n\nNext, we'll talk about how to identify these issues. It's like being a bug detective, but for your code.\n\nThen, we'll discuss how to fix these issues. Because the best way to deal with a bug is to squash it.\n\nAnd finally, we'll go over some best practices for avoiding bugs in the first place. Because an ounce of prevention is worth a pound of cure.\n\nSo, are you ready to become a bug-squashing ninja? Let's get started!\n\nRemember, debugging is a skill that comes with time and practice. So, don't be discouraged if you don't catch every bug right away.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-03-30"}}
{"video": {"title": "Mastering ChatGPT for System Building", "transcript": "####Mastering ChatGPT for System Building: A Fun and Engaging Journey\nby Isa Fulford - 2022-10-23\n\n#### BEGIN TRANSCRIPT ####\nHello, fellow tech enthusiasts! Are you ready to level up your system building skills with ChatGPT? Today, we're going on an exciting journey to discover how to efficiently build multi-step systems, chain LLM calls, and evaluate outputs for safety and relevance. Trust me, you won't want to miss this!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-23"}}
{"video": {"title": "Building a Multi-Task LLM Application with Python and Predibase's LoRAX Framework", "transcript": "####Building a Multi-Task LLM Application with Python and Predibase's LoRAX Framework\nby Travis Addair - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Travis Addair and today we're diving into the exciting world of multi-task LLM applications! We'll be using Python and Predibase's LoRAX framework to build an application that can perform multiple tasks using a single language model.\n\nFirst, let's talk about what a multi-task LLM application is. It's like having a Swiss Army knife for language models, capable of handling a variety of tasks such as chatbots and virtual assistants.\n\nNext, we'll get our hands dirty and start building our application. We'll fine-tune a pre-trained language model on our specific tasks using LoRA. Once we have our fine-tuned models, we'll use LoRAX to serve them to multiple users at once.\n\nWe'll also cover how to handle requests from multiple users and balance the load between multiple models. This will ensure our application is scalable and can handle a large number of requests.\n\nFinally, we'll discuss some best practices for building multi-task LLM applications, such as input validation and performance monitoring.\n\nThanks for watching and don't forget to like, comment, and subscribe for more videos on GenAI and LLM powered applications. See you in the next one!\n#### END TRANSCRIPT ########", "author": "Travis Addair", "publication_date": "2023-03-22"}}
{"video": {"title": "Getting Started with ChatGPT Prompt Engineering", "transcript": "####Getting Started with ChatGPT Prompt Engineering\nby Isa Fulford, Andrew Ng - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're diving headfirst into the exciting world of prompt engineering for ChatGPT. If you're a beginner with a basic understanding of Python, you're in luck!\n\nSo, what is prompt engineering and why should you care? Prompt engineering is the art of crafting effective inputs for language models like ChatGPT. It's important because it can significantly impact the output.\n\nLet's explore some prompt engineering best practices. First, be explicit and thorough with your prompts. The more information you provide, the better ChatGPT can understand and deliver. Second, iteration is your best friend. Prompt engineering is a process of refinement, so don't be afraid to try different approaches.\n\nNow, let's explore some novel ways to use LLMs. Did you know they can summarize, infer, transform, and expand text? Let's build our own custom chatbot using the OpenAI API.\n\nTime for some hands-on practice. Let's write and refine some prompts together. Remember, clarity and iteration are your best friends.\n\nTo wrap up, prompt engineering is a powerful tool for application development with ChatGPT. With these best practices and some practical experience, you're well on your way to mastering prompt engineering. So, let's get started! And remember, the more you practice, the better you'll get.\n\nThanks for watching and happy prompting! Don't forget to like, share, and subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-20"}}
{"video": {"title": "Mastering LangGraph: Building AI Agents Like a Pro", "transcript": "####Mastering LangGraph: Build AI Agents Like a Pro\nby Harrison Chase, Rotem Weiss - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! Are you ready to take your AI skills to the next level? Today, we're going to master LangGraph and build AI agents like pros.\n\nLangGraph is a game-changer in the world of AI development. It's like having a secret weapon in your coding arsenal. But wait, there's more! We're also going to supercharge our agents with Tavily's agentic search. This will enhance our agent's knowledge and performance, making our AI truly top-notch.\n\nIn this course, you'll learn from the best - Harrison Chase from LangChain and Rotem Weiss from Tavily. They'll take you through LangGraph's components and show you how to integrate agentic search capabilities.\n\nThis course is perfect for those with intermediate Python knowledge who want to create more controllable agents.\n\nSo, are you ready to become an AI agent master? Let's dive in! Remember to like, share, and subscribe for more exciting content.\n\nHappy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-20"}}
{"video": {"title": "TensorFlow: Building Custom Models", "transcript": "####TensorFlow: Building Custom Models\nby Laurence Moroney, Eddy Shyu - 2022-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eddy Shyu, and today we're diving into the exciting world of TensorFlow to show you how to build custom models.\n\nBuilding custom models can be a game-changer for your machine learning projects. In this video, we'll show you how to use the Functional API to create custom models with multiple inputs and outputs, shared layers, and more.\n\nWe'll also share some best practices for building custom models, and some common pitfalls to avoid.\n\nSo, whether you're looking to take your projects to the next level, or just want to explore the capabilities of TensorFlow, this video has got you covered. Let's get started.\n\n[Demonstration of building custom models with multiple inputs and outputs, shared layers, etc.]\n\nAnd that's a wrap! Thanks for watching, and be sure to check out our other videos on TensorFlow. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-04-05"}}
{"video": {"title": "Deploying NLP Apps with Hugging Face and Docker", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning.\n- Make the conclusion more memorable and engaging.\n- Introduce more personal insights and critical analysis.\n- Improve contrast and pacing to maintain interest.\n- Include more real-world applications and benefits.\n- Improve contrast and pacing to maintain interest.\n- Introduce more personal insights and critical analysis.", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-04-25"}}
{"video": {"title": "Probability: The Language of Uncertainty in Machine Learning", "transcript": "####Probability: The Language of Uncertainty in Machine Learning\nby Magdalena Bouza - 2023-03-07\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Magdalena Bouza, and today we're diving into the fascinating world of probability, the language of uncertainty in machine learning.\n\nProbability is our friend. It helps us quantify uncertainty. It's a number between 0 and 1 that tells us how likely an event is to occur.\n\nLet's talk about conditional probability. It's the probability of an event given that another event has occurred. It's like saying, \"If it rains, there's a 70% chance I'll bring an umbrella.\"\n\nBayes' theorem is our superpower. It helps us update our beliefs based on new data. It's a fundamental concept in machine learning.\n\nDon't worry if this seems a bit tricky. With practice, you'll become fluent in the language of uncertainty. Remember, the expert in anything was once a beginner. So, keep learning, keep practicing, and soon you'll be a probability pro.\n\nThanks for watching. Be sure to like, share, and subscribe for more exciting videos on Mathematics for Machine Learning and Data Science. See you next time!\n\n#### END TRANSCRIPT ########", "author": "Magdalena Bouza", "publication_date": "2023-03-07"}}
{"video": {"title": "Probability: The Language of Uncertainty", "transcript": "####Probability: The Language of Uncertainty\nby Magdalena Bouza - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, data science aficionados! Magdalena Bouza here, and today we're diving into the fascinating world of probability - the language of uncertainty.\n\nProbability is all about putting numbers to our doubts. It's our guide when we're not sure what's coming next.\n\nLet's kick things off with the basics: probability distributions. They're like a roadmap showing where our data might be. Some of the most common ones include the normal distribution and the binomial distribution.\n\nNext up, let's talk about conditional probability. It's like asking, 'What's the probability of this, given that?'. We use it in machine learning algorithms like Naive Bayes.\n\nSo, that's probability in a nutshell. It's not just numbers and equations, it's a powerful tool that helps us make decisions in uncertain situations.\n\nRemember, the best way to learn is by doing. So, grab some datasets and start exploring probability distributions.\n\nStay tuned for our next video, where we'll be putting all these concepts into action in real-world machine learning applications. If you enjoyed this video, don't forget to give us a thumbs up and subscribe to our channel for more exciting content. Until next time, happy learning!\n\n#### END TRANSCRIPT ########", "author": "Magdalena Bouza", "publication_date": "2023-03-30"}}
{"video": {"title": "Building Your First Agentic RAG with LlamaIndex", "transcript": "####Building Your First Agentic RAG with LlamaIndex\nby Jerry Liu - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and today we're embarking on an exciting journey into the world of autonomous agents that can intelligently navigate and analyze your data.\n\nBut first, what is an Agentic RAG? It's a system that uses LlamaIndex to enable powerful document Q&A and summarization. Sounds intriguing, doesn't it?\n\nLet's dive in. To build our first Agentic RAG, we'll need some basic Python knowledge. But don't worry, we'll keep it simple and enjoyable.\n\nOur first step is to build an agent that can reason over your documents and answer complex questions. Imagine having your own personal assistant that can read and understand your documents!\n\nNext, we'll build a router agent that can help you with Q&A and summarization tasks. And guess what? We'll even extend it to handle passing arguments to this agent.\n\nBut wait, there's more. We'll also design a research agent that handles multi-documents. Yes, you heard it right, multi-documents!\n\nAnd finally, we'll learn about different ways to debug and control this agent. Because let's face it, even the smartest agents can sometimes make mistakes.\n\nSo, are you ready to transform the way you interact with your data? Let's get started with LlamaIndex and build your first Agentic RAG.\n\nRemember, practice makes perfect. So keep trying, keep building, and most importantly, enjoy the process!\n\nThanks for watching and don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-03-15"}}
{"video": {"title": "AI for Biodiversity: Protecting Our Planet with Technology", "transcript": "####AI for Biodiversity: Protecting Our Planet with Technology\nby Robert Monarch - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the fascinating world of AI and biodiversity.\n\n[Video hook and introduction]\n\nDid you know that AI is helping protect our planet's biodiversity? From tracking endangered species to monitoring habitats, AI is playing a crucial role in conservation efforts. But how does it work? Let's find out!\n\n[Body content]\n\nFirst, we'll explore the role of AI in biodiversity conservation. We'll see how it's being used to track species, monitor habitats, and predict threats.\n\nNext, we'll dive into a project where we'll build a simple model to predict species distribution. Don't worry, I'll guide you through it step by step.\n\nBut that's not all. We'll also discuss the challenges and ethical considerations of using AI in biodiversity conservation. It's not all plain sailing, but it's important to know the full picture.\n\n[Conclusion and call to action]\n\nSo, are you ready to join the AI for biodiversity movement? Remember, every species counts, and you can make a difference.\n\nThanks for watching. If you found this video helpful, don't forget to like, share, and subscribe. And stay tuned for more exciting content on AI for biodiversity.\n\nUntil next time, keep exploring and let's protect our planet together!\n\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-30"}}
{"video": {"title": "Maximizing the Potential of LLMs", "transcript": "####Maximizing the Potential of LLMs\nby Isa Fulford - 2022-10-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Isa Fulford! Today, we're diving into the exciting world of large language models, or LLMs. We'll explore how to maximize their potential and leverage them for optimal performance and results. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-22"}}
{"video": {"title": "Statistics for Machine Learning", "transcript": "####Statistics for Machine Learning: Unleashing the Power of Data\nby Magdalena Bouza - 2022-01-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Magdalena, and welcome back to our channel. Today, we're diving into the fascinating world of statistics for machine learning.\n\nStatistics, the art of learning from data, is the backbone of machine learning. It's what allows us to make predictions and decisions based on data.\n\nWe're going to start with the basics of statistics, from descriptive statistics to probability distributions, and even a bit of hypothesis testing. Then, we'll explore how statistics is used in machine learning, from supervised learning to unsupervised learning, and even reinforcement learning.\n\nSo, are you ready to unlock the secrets of data? Let's get started!\n\n...\n\nThanks for joining me on this statistical journey. I hope you found this video on statistics for machine learning as exciting as I do. If you did, please give this video a thumbs up and subscribe to our channel for more data-filled content. And if you have any questions, don't be shy, leave them in the comments below. Until next time, happy learning!\n\n#### END TRANSCRIPT ########", "author": "Magdalena Bouza", "publication_date": "2022-01-22"}}
{"video": {"title": "Granularity Matters: Per Tensor, Per Channel, and Per Group Quantization", "transcript": "####Granularity Matters: Per Tensor, Per Channel, and Per Group Quantization\nby Marc Sun, Younes Belkada - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc Sun, and today we're diving into the world of granularity in quantization.\n\nFirst off, we've got per tensor quantization. This is where all the weights in a tensor share the same quantization parameters. It's simple, it's efficient, but it might not be the best choice for complex models.\n\nNext up, we've got per channel quantization. This is where each channel in a tensor has its own unique quantization parameters. It's more flexible than per tensor quantization, but it comes at a higher computational cost.\n\nFinally, we've got per group quantization. This is where you group weights based on some criteria and assign quantization parameters to each group. It's the most flexible option, but it's also the most complex.\n\nSo, which one should you use? Well, it depends on your model and your computational resources. That's why we're going to show you how to try out all three and compare the results.\n\nAre you ready to master granularity in quantization? Let's get started!\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-03-25"}}
{"video": {"title": "PyTorch to Edge: Model Conversion Made Easy", "transcript": "####PyTorch to Edge: Model Conversion Made Easy\nby Krishna Sridhar - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're making model conversion for edge devices a breeze!\n\nSo, you've built this incredible AI model using PyTorch. Now what? Well, we're going to convert that model for device compatibility.\n\nFirst, we'll export your PyTorch model to ONNX format. Think of it like saving a Word document as a PDF.\n\nNext, we'll use the Qualcomm AI Model Converter to convert the ONNX model to a format compatible with your edge device. It's like turning a PC game into a version that can run on your PlayStation.\n\nAnd voila! Your PyTorch model is now ready to be deployed on your edge device.\n\nRemember, keep your writing clear and simple. Translate jargon into simpler words, and use more active voice than passive.\n\nSo, are you ready to take your PyTorch models to the edge? Let's dive in and make AI more accessible than ever!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2023-03-20"}}
{"video": {"title": "Mastering TensorFlow: Functional API and Multi-Processor Training", "transcript": "####Mastering TensorFlow: Functional API and Multi-Processor Training\nby Laurence Moroney, Eddy Shyu - 2022-03-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, TensorFlow enthusiasts! I'm Laurence Moroney, and today we're going to level up your TensorFlow game.\n\nFirst off, we're diving into the Functional API. This powerful tool lets you define models with shared layers, multiple inputs and outputs, and even custom training loops. It's a game-changer for complex model architectures.\n\nNext, we're going to turbocharge our training with multiple processors. I'll show you how to distribute your training across multiple GPUs or even multiple machines, so you can train your models faster than ever before.\n\nBut wait, there's more! We're also going to explore some advanced computer vision techniques. We'll look at how to use pre-trained models, transfer learning, and fine-tuning to get state-of-the-art results with minimal effort.\n\nAnd finally, we're going to have some fun with generative deep learning. We'll see how to create models that can generate their own images, text, and even music. It's like teaching a robot to be an artist.\n\nSo, are you ready to take your TensorFlow skills to the next level? Let's get started.\n\nRemember, practice makes perfect. Don't just watch these videos, try out the techniques for yourself. And if you have any questions, don't hesitate to ask.\n\nThanks for watching, and happy coding!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-03-01"}}
{"video": {"title": "Integrating RAG with Existing JavaScript Applications", "transcript": "####Integrating RAG with Existing JavaScript Applications\nby Laurie Voss - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Laurie Voss, and today we're diving into the exciting world of RAG and JavaScript.\n\nAre you sitting on a web application and dreaming of adding RAG capabilities? You're in the right place! We'll be using the create-llama command-line tool to set up our project and install the necessary dependencies.\n\nBut wait, there's more! We'll also be integrating our RAG-powered backend with our existing frontend component. And don't worry, I'll be sharing tips and best practices for building RAG applications in JavaScript along the way.\n\nBut what's the cherry on top, you ask? We'll be learning how to persist your data, enable chatting with your data, and make streaming responses possible. By the end of this video, you'll have a fully functional web app with RAG capabilities.\n\nSo, are you ready to take your JavaScript skills to the next level? Let's get started! And don't forget to check out LlamaIndex for more resources on building intelligent applications.\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2023-04-05"}}
{"video": {"title": "Granularities in Quantization: Per Tensor, Per Channel, Per Group", "transcript": "####Granularities in Quantization: Per Tensor, Per Channel, Per Group\nby Marc Sun - 2022-10-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! It's your favorite AI influencer, Marc Sun, back with another exciting episode. Today, we're diving into the world of quantization and exploring the various granularities, including per tensor, per channel, and per group quantization. These different approaches can have a significant impact on model performance. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Marc Sun", "publication_date": "2022-10-17"}}
{"video": {"title": "Mastering Quantization: A Deep Dive into Advanced Techniques", "transcript": "####Mastering Quantization: A Deep Dive into Advanced Techniques\nby Marc Sun, Younes Belkada - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, quantization enthusiasts! I'm Marc Sun, and today we're taking a thrilling journey into the world of advanced quantization techniques. If you've already mastered the basics with our Quantization Fundamentals course, you're in for a treat!\n\nFirst, we're exploring the wild world of Linear Quantization. We'll compare symmetric and asymmetric modes, and discuss the pros and cons of each. We'll also delve into different granularities, like per tensor, per channel, and per group quantization.\n\nNext, we're getting our hands dirty and building a general-purpose quantizer in Pytorch. This powerhouse can quantize the dense layers of any open-source model, giving you up to 4x compression on dense layers. Pretty neat, huh?\n\nBut wait, there's more! We'll also walk you through implementing weights packing. This clever technique lets you pack four 2-bit weights into a single 8-bit integer.\n\nRemember, quantization is a powerful tool for model compression, but it's not a one-size-fits-all solution. That's why we're giving you the skills to customize your approach.\n\nAnd guess what? We're partnering with Hugging Face to bring you this content. So you know it's top-notch.\n\nSo, are you ready to level up your quantization game? Let's dive in!\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-03-15"}}
{"video": {"title": "Applying RNNs to NLP", "transcript": "####Applying RNNs to NLP: A Fun and Engaging Journey\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-03-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! I'm your AI guide and today we're going to have a blast applying Recurrent Neural Networks (RNNs) to Natural Language Processing (NLP).\n\nWe'll be using Python and TensorFlow to build our RNN, and we'll be applying it to a real-world NLP task. Trust me, it's going to be a fun ride!\n\nFirst, we'll preprocess our text data and convert it into sequences. Then, we'll define our RNN architecture, including the recurrent layer and the output layer. After that, we'll compile our model and train it on our data. Finally, we'll evaluate our model and see how well it performs.\n\nNow, I know this might sound like a lot, but don't worry. I'll be with you every step of the way, making sure you don't miss a beat.\n\nSo, what are you waiting for? Let's get started on this exciting journey of applying RNNs to NLP. And remember, if you ever get stuck, I'm here to help.\n\nThanks for watching, and happy learning! \n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-03-05"}}
{"video": {"title": "Monitoring and Maintenance: Keeping Your ML Systems Healthy", "transcript": "####Monitoring and Maintenance: The Secret to a Healthy ML System\nby Andrew Ng - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here! Today, we're diving into the world of monitoring and maintenance in ML production systems.\n\nThink of monitoring and maintenance as regular check-ups for your ML models. They help you spot issues early, prevent failures, and keep your models running at their best. We'll be discussing how to monitor model performance, data quality, and system health.\n\nWe'll also be exploring some cool techniques for anomaly detection, root cause analysis, and incident management.\n\nRemember, the goal isn't just to build a model, but to build a model that can consistently and reliably perform well. So, let's get started!\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and keep innovating!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-15"}}
{"video": {"title": "Machine Learning Math: Calculus", "transcript": "####Machine Learning Math: Calculus\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-02-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! Today, we're going to demystify the math behind Machine Learning, specifically calculus.\n\nCalculus is all about rates of change. It might sound intimidating, but don't worry, we'll make it simple and fun.\n\nWe'll be using Python to implement these concepts, so you'll get some coding practice too!\n\nRemember, the key to understanding calculus is practice. So, keep coding and experimenting.\n\nThat's it for today's video. If you found this helpful, give us a thumbs up and don't forget to subscribe for more exciting content. See you in the next video, where we'll continue to make Machine Learning accessible and fun!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-02-19"}}
{"video": {"title": "AutoGen and Penn State University: Pioneering AI Education", "transcript": "####AutoGen and Penn State University: Revolutionizing AI Education\nby Chi Wang, Qingyun Wu - 2023-05-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Qingyun Wu here, and today we're diving into an exciting collaboration between AutoGen and Penn State University.\n\nWe'll kick things off by exploring how Penn State is leading the charge in AI education with AutoGen. Then, we'll showcase some real-world examples of how this partnership is reshaping the future of AI learning.\n\nRemember, collaborations like these are all about equipping you with the best educational tools to thrive in your AI adventure. So, let's jump right in and discover the advantages of AutoGen and Penn State University!\n\nAs always, if you have any questions, don't hesitate to drop them in the comments. We're here to support you on your learning journey.\n\nAnd before you go, don't forget to hit that like button, subscribe, and ring the notification bell for more thrilling content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2023-05-03"}}
{"video": {"title": "Getting Started with LangChain: Your First Chatbot", "transcript": "####Getting Started with LangChain: Your First Chatbot\nby Harrison Chase - 2023-02-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! I'm Harrison Chase, the creator of LangChain, and today we're going to build your very first chatbot using LangChain.\n\nAre you excited? I know I am! But before we dive in, let's make sure you have everything you need. You'll need a basic understanding of Python, but don't worry, we'll keep it simple and easy to follow.\n\nNow, let's get started! The first step is to install LangChain. You can do this by using pip, the Python package installer. Once you've installed LangChain, you'll have access to over 80 unique loaders that can handle various data sources.\n\nNext, we'll connect your chatbot to your data. This could be anything from a PDF file to a CSV file, or even your own custom data source. Once you've connected your data, you'll be able to chat directly with the information from your own documents and data.\n\nI'll be guiding you through each step of the process, sharing tips and tricks along the way. And the best part? You'll be learning directly from me, the creator of LangChain.\n\nSo, are you ready to create your very first chatbot? Let's do this!\n\nRemember, if you have any questions or need help along the way, don't hesitate to reach out. And once you've built your chatbot, be sure to share it with me. I can't wait to see what you create!\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########\n\nPositive Points:\n\n- Clear introduction of the topic and the creator.\n- Use of active voice and simple language.\n- Present and encouraging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.", "author": "Harrison Chase", "publication_date": "2023-02-20"}}
{"video": {"title": "TensorFlow for Natural Language Processing", "transcript": "####TensorFlow for Natural Language Processing\nby Laurence Moroney - 2022-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, Laurence Moroney here, and today we're diving into the exciting world of TensorFlow for natural language processing!\n\n[Video hook and introduction]\n\nAre you ready to build your own chatbots and text analysis tools? Then let's get started!\n\n[Body content]\n\nFirst, we'll cover the basics of natural language processing and how TensorFlow can help. We'll go over essential concepts like word embeddings, recurrent neural networks, and attention mechanisms.\n\nThen, we'll dive into building our own text classification system. We'll use TensorFlow to train a model on a dataset of text and evaluate its performance.\n\nWe'll also explore how to use pre-trained models to save time and improve accuracy. You'll learn how to use models like BERT, ELMo, and GPT-2 for your own projects.\n\nLastly, we'll cover some advanced topics like sequence-to-sequence models and transformers. You'll learn how to build systems that can translate text, summarize articles, and generate creative writing.\n\n[Conclusion and call to action]\n\nBy the end of this video, you'll have a solid understanding of how to use TensorFlow for natural language processing tasks. So, let's get started!\n\nRemember, the best way to learn is by doing. So, make sure to try building your own chatbots and text analysis tools.\n\nIf you liked this video, be sure to give it a thumbs up and subscribe to our channel for more TensorFlow content. See you in the next one!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-03-22"}}
{"video": {"title": "Harnessing the Power of Open Source Models with Hugging Face", "transcript": "####Harnessing the Power of Open Source Models with Hugging Face\nby Maria Khalusova, Marc Sun, Younes Belkada - 2023-03-18\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Maria, and today we're going to unleash the power of open-source models with Hugging Face.\n\nHugging Face is a platform that empowers everyone to build AI applications. It's beginner-friendly, so let's get started.\n\nThe Hugging Face Hub is a goldmine of open-source models. You can find and filter models based on tasks, rankings, and memory requirements. It's like shopping for AI, but everything's free!\n\nOnce you've found your model, using it is a breeze. With the transformers library, you can perform text, audio, image, and multimodal tasks with just a few lines of code. It's like having your own AI lab.\n\nBut wait, there's more! Sharing your AI apps is easy with Hugging Face. With a user-friendly interface or via API, you can run them on the cloud using Gradio and Hugging Face Spaces. It's like launching your own AI project, but without the red tape.\n\nSo, are you ready to unleash the power of open-source models with Hugging Face? Remember, the best way to learn is by doing. So, go ahead, explore the Hugging Face Hub, play around with the models, and who knows, you might just create the next AI marvel.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-03-18"}}
{"video": {"title": "Building Knowledge Graphs for RAG with Neo4j and Cypher", "transcript": "####Building Knowledge Graphs for RAG with Neo4j and Cypher\nby Andreas Kollegger - 2022-11-15\n\n#### BEGIN TRANSCRIPT ####\nVideo hook and introduction: Hey there, data enthusiasts! Are you ready to dive into the world of knowledge graphs and discover how they can supercharge your retrieval augmented generation applications? I'm your host, Andreas Kollegger, and I'm thrilled to guide you through this exciting journey. Let's get started!\n\nBody content: Knowledge graphs are the secret sauce that makes data more accessible and understandable. With Neo4j's query language Cypher, we can manage and retrieve data stored in these graphs like a pro. This means we can provide more relevant context to our language models for Retrieval Augmented Generation, making our applications even better.\n\nOne of the coolest things about using Cypher is that we can write queries that find and format text data in a meaningful and useful way. This is crucial for building a question-answering system that can interact with a knowledge graph of structured text documents. By combining Neo4j and LangChain, we can create a powerful tool that allows us to chat with our data and extract valuable insights.\n\nConclusion and call to action: In conclusion, knowledge graphs are a game-changer for enhancing retrieval augmented generation applications. By leveraging Neo4j and Cypher, we can unlock the full potential of our data and take our applications to the next level. I encourage you to explore this topic further and see the impact it can have on your projects. Thanks for watching, and happy data wrangling!\n\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2022-11-15"}}
{"video": {"title": "Building AI Applications with Open Source Models on Hugging Face", "transcript": "####Building AI Applications with Open Source Models on Hugging Face\nby Maria Khalusova - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Maria Khalusova, and today we're diving headfirst into the exciting world of open-source models with Hugging Face. Are you ready to learn how to build AI applications like a pro using these powerful tools? Let's do this!\n\nOpen-source models are a game-changer in the AI world. They allow developers to access pre-trained models and fine-tune them for specific tasks. And Hugging Face Hub is a goldmine of open-source models that you can use for text, audio, image, and multimodal tasks.\n\nWith just a few lines of code using the transformers library, you can start building your AI applications. And the best part? You can easily find the perfect model for your project by filtering models based on task, rankings, and memory requirements.\n\nOnce you've built your AI app, you can share it with others using a user-friendly interface or via API. And if you want to run your app on the cloud, you can do so with Gradio and Hugging Face Spaces.\n\nSo what are you waiting for? Start building your AI applications today with open-source models on Hugging Face! Trust me, it's easier than you think.\n#### END TRANSCRIPT ########", "author": "Maria Khalusova", "publication_date": "2022-10-15"}}
{"video": {"title": "Quantization Fundamentals: Shrink Models with Hugging Face", "transcript": "####Quantization Fundamentals: Shrink Models with Hugging Face\nby Younes Belkada, Marc Sun - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Younes Belkada, and today we're diving into the exciting world of quantization with Hugging Face.\n\nBut first, let me ask you a question. Have you ever wanted to make your models more efficient without sacrificing accuracy? Well, you're in luck! In this video, we'll be learning how to compress models using the Hugging Face Transformers library and the Quanto library.\n\nSo, what is quantization? It's a technique used to reduce the size of a model, making it more efficient and faster, without losing its accuracy. And the best part? It's like magic!\n\nWe'll start with linear quantization, a simple yet powerful method for model compression. It works by decreasing the precision of the weights in your model, resulting in a smaller model size and faster inference times.\n\nBut wait, there's more! We'll also be diving into quantizing open-source multimodal and language models. Don't worry if you're new to this, I'll be there to guide you through each step.\n\nBy the end of this video, you'll know how to quantize any open-source model using Hugging Face and Quanto. And who knows, you might even impress your friends with your newfound knowledge!\n\nSo, what are you waiting for? Hit that like button, share this video, and subscribe for more AI and machine learning content. Until next time, happy quantizing!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-20"}}
{"video": {"title": "Building AI Agents Like a Pro with LangGraph and Tavily", "transcript": "####Building AI Agents Like a Pro with LangGraph and Tavily\nby Harrison Chase, Rotem Weiss - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! Today, we're diving into the world of AI agents and learning how to build them like pros using LangGraph and Tavily's agentic search.\n\nLangGraph is an open-source framework that empowers you to build, debug, and maintain AI agents. It's like having a superpower for creating controllable agents.\n\nAnd when you add Tavily's agentic search into the mix, you're enhancing your agent's knowledge and performance, making your AI more efficient and effective.\n\nIn this course, you'll learn from the best - Harrison Chase from LangChain and Rotem Weiss from Tavily. They'll take you through LangGraph's components and show you how to integrate agentic search capabilities.\n\nThis course is perfect for those with intermediate Python knowledge who want to level up their AI game.\n\nSo, are you ready to build AI agents like a pro? Let's get started! Remember to like, share, and subscribe for more exciting content.\n\nHappy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-30"}}
{"video": {"title": "Integrating Knowledge Graphs with LLMs for RAG", "transcript": "####Integrating Knowledge Graphs with LLMs for RAG\nby Andreas Kollegger - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andreas Kollegger here! Are you ready to take your understanding of large language models to the next level? Today, we're diving into the exciting world of integrating knowledge graphs with LLMs for Retrieval Augmented Generation or RAG.\n\nBut wait, what's LangChain? If you're new to the game, don't worry! We've got you covered with our short course 'LangChain: Chat with Your Data'. Trust me, you won't want to miss out on this intermediate level content.\n\nNow, let's get started. We'll be using Neo4j's query language, Cypher, to manage and retrieve data from our knowledge graph.\n\nIn this video, we'll walk you through the process of integrating knowledge graphs with LLMs to provide more relevant context for RAG. We'll also discuss some best practices for integrating these two powerful technologies.\n\nBut why should you care? Well, integrating knowledge graphs with LLMs can lead to more accurate and contextually relevant responses. And who doesn't want that?\n\nSo, are you ready to take your LLMs to the next level? Let's get started!\n\nRemember, the key to successful integration is understanding both your knowledge graph and your LLM. So, don't be afraid to experiment and iterate. And if you have any questions, feel free to leave them in the comments below.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2023-04-20"}}
{"video": {"title": "LangChain 101: Building Your First Data-Driven Chatbot", "transcript": "####LangChain 101: Building Your First Data-Driven Chatbot\nby Harrison Chase - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Harrison Chase, and today we're diving into the thrilling world of data-driven chatbots using LangChain.\n\nDon't worry if you're new to LangChain or chatbot building. This video is perfect for beginners, and I'll be explaining everything in a way that's easy to digest.\n\nLangChain is a powerful tool that allows you to access and interact with various data sources. With over 80 unique loaders, you can handle different types of data, from PDFs to databases.\n\nBut we're not stopping at just accessing data. Today, we're going to build a chatbot that can chat directly with information from your own documents and data.\n\nImagine having a personal assistant who can read and understand all your documents and data. Sounds cool, right?\n\nI'll be guiding you through each step, making sure to keep things simple and fun. By the end of this video, you'll have your own chatbot ready to assist you with your data needs.\n\nSo, are you ready to build your first data-driven chatbot? Let's get this party started!\n\nRemember, if you have any questions, feel free to leave a comment. I'm always here to help. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-25"}}
{"video": {"title": "Building JavaScript RAG Web Apps with LlamaIndex", "transcript": "####Building JavaScript RAG Web Apps with LlamaIndex\nby Laurie Voss - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, welcome to today's video! I'm Laurie Voss, and I'm thrilled to show you how to build a full-stack web application using JavaScript and LlamaIndex. We'll be creating a RAG (Retrieve, Analyze, Generate) capable app that can chat with your data. Let's get started!\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2022-10-15"}}
{"video": {"title": "TensorFlow: Mastering Data and Deployment", "transcript": "####TensorFlow: Mastering Data and Deployment\nby Laurence Moroney - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, TensorFlow enthusiasts! I'm Laurence Moroney, and today we're diving into the thrilling world of data and deployment.\n\n[Video hook and introduction]\n\nEver wondered how to deploy your machine learning models on devices? Or maybe you've been curious about training and running models in browsers and mobile apps? Well, you're in luck!\n\n[Body content]\n\nLet's kick things off with deploying ML models on devices. It's easier than you think. With TensorFlow, you can effortlessly take your trained models and deploy them on a variety of devices, from edge devices like Raspberry Pi to mobile devices.\n\nNext, let's talk about training and running models in browsers and mobile apps. TensorFlow.js is a JavaScript library that lets you do just that. Imagine being able to train a model right in your browser, or on your mobile device. It's not only possible, but it's also a blast!\n\nNow, let's discuss a really cool feature: retraining deployed models while protecting privacy. With TensorFlow, you can retrain your models on new data without compromising user privacy. This is done using a technique called federated learning.\n\n[Conclusion and call to action]\n\nAnd that's a wrap, folks! You're now equipped with the knowledge to deploy your models, train and run them in browsers and mobile apps, and retrain them while respecting user privacy.\n\nRemember, practice makes perfect. So, go ahead and start deploying those models. And if you have any questions or need further clarification, don't hesitate to reach out.\n\nThanks for watching, and stay tuned for more exciting videos on TensorFlow. Until next time, happy coding!\n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-01-01"}}
{"video": {"title": "Exploring Dependency Parsing with NLP and Hugging Face", "transcript": "Hi there, Your Assistant here, and today we're diving into the exciting world of dependency parsing in NLP! If you've ever wondered how machines understand the structure of sentences, you're in the right place!\n\nFirst things first, let's talk about what dependency parsing is. It's the process of analyzing the grammatical structure of a sentence, and identifying the relationships between words. Think of it as a map that shows how words are connected to each other.\n\nWith Hugging Face, we can build a dependency parsing model in just a few simple steps. We'll show you how to prepare your data, train your model, and deploy your app. And don't worry, we'll explain everything in a clear and simple way, so you won't get lost in the details.\n\nBut that's not all! We'll also cover some advanced techniques for improving your model's performance, like syntactic and semantic role labeling. And we'll sprinkle in some humor to keep things interesting.\n\nSo, are you ready to explore dependency parsing with NLP and Hugging Face? Let's get started!\n\nAnd remember, if you enjoyed this video, don't forget to hit that like button and subscribe for more content. And if you're ready to start building your own dependency parsing models, check out the links in the description for some great resources. See you next time!", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-04-20"}}
{"video": {"title": "Machine Learning in the Real World", "transcript": "####Machine Learning in the Real World: Unveiling the Power of AI\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-02-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! It's your favorite host, back with an exciting episode on Machine Learning in the real world. Buckle up, because we're about to embark on an incredible journey!\n\nFirst, we'll explore some common applications of Machine Learning, like recommendation systems, image recognition, and natural language processing. We'll show you how these technologies are changing the world, one algorithm at a time.\n\nNext, we'll dive into a case study, where we'll see how a company used Machine Learning to solve a real-world problem. We'll walk you through the entire process, from defining the problem to deploying the solution. You'll see how Machine Learning can be used to make a real impact on the world.\n\nBut that's not all. We'll also discuss some of the challenges and ethical considerations of using Machine Learning in the real world. And we'll do it all with practical examples, so you can see how it's done in the real world.\n\nRemember, Machine Learning has the potential to make a real impact on the world, so it's important to use it responsibly. So, are you ready to see Machine Learning in action? Let's get started! And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-02-05"}}
{"video": {"title": "TensorFlow: Deployment on Edge Devices", "transcript": "####TensorFlow: Deployment on Edge Devices\nby Laurence Moroney - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHello and welcome back, TensorFlow enthusiasts! I'm Laurence Moroney, and today we're diving into the exciting world of edge computing.\n\n[Video hook and introduction]\n\nImagine being able to process data faster, reduce latency, and enhance privacy. That's the power of edge computing!\n\n[Body content]\n\nFirst, we'll walk through the process of deploying your TensorFlow models on edge devices. From training your model to deployment, we've got you covered.\n\nNext, we'll discuss the benefits of edge computing. We'll talk about how it can improve the performance of your models and enhance user privacy.\n\nFinally, we'll touch on some common challenges in edge computing and how to overcome them.\n\n[Conclusion and call to action]\n\nAnd that's a wrap! You're now ready to deploy your models on edge devices.\n\nRemember, edge computing can give you a significant advantage in your machine learning projects. So, don't be afraid to explore it.\n\nThanks for watching, and stay tuned for more TensorFlow videos. If you have any questions, don't hesitate to ask.\n\nUntil next time, happy coding! \n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-01-15"}}
{"video": {"title": "Diffusion Models: A Step-by-Step Walkthrough", "transcript": "####Diffusion Models: A Step-by-Step Walkthrough\nby Sharon Zhou - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Sharon Zhou here, and today we're diving into the fascinating world of diffusion models!\n\nImagine writing a novel, starting with a single word and gradually adding more until you have a beautiful, complex story. That's exactly what diffusion models do!\n\nLet's grab our pens and write our own diffusion model. Open your Python, Tensorflow, or Pytorch, and let's get started. We'll define our data distribution, add noise, and learn how to denoise it.\n\nBut wait, there's more! Sampling from diffusion models can be as slow as writing a novel. But don't worry, I've got you covered! I'll introduce you to some efficient algorithms that can accelerate sampling by a staggering 10 times!\n\nBy the end of this video, you'll be a diffusion model author, ready to build and train your own models. So, keep writing, keep learning, and who knows? You might just write the perfect 'diffusion novel'!\n\nThanks for watching, and remember to like, share, and subscribe for more exciting content. See you next time!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-04-20"}}
{"video": {"title": "Optimizing Your Agentic RAG System for Performance", "transcript": "####Optimizing Your Agentic RAG System for Performance\nby Jerry Liu - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Jerry Liu and today we're diving into the world of agentic RAG systems. We're going to learn how to optimize your system for top-notch performance.\n\nAre you tired of slow response times and inefficient processes? Well, you're in the right place!\n\nIn this video, we'll explore some strategies for boosting your system's speed and efficiency. We'll talk about profiling your system to spot bottlenecks and optimizing your code for better performance.\n\nWe'll also discuss best practices for data management and how to choose the right hardware for your system.\n\nBy the end of this video, you'll have the skills to optimize your own agentic RAG system like a pro.\n\nSo, are you ready to take your system to the next level? Let's get started!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding and see you in the tech world!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-15"}}
{"video": {"title": "Unraveling CNNs: The Brain's Visual Cortex of Deep Learning", "transcript": "####Unraveling CNNs: The Visual Cortex of Deep Learning\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! It's your favorite guide, and today we're diving into the fascinating world of Convolutional Neural Networks, or CNNs.\n\nCNNs are like the brain's visual cortex, processing images and videos. They're the superstars of computer vision tasks.\n\nBut how do they work? Well, they use filters, also known as kernels, to extract features from images. These features can be edges, shapes, textures, and more.\n\nWe'll learn how to build CNNs from scratch, train them, and apply them to real-world scenarios.\n\nBy the end of this video, you'll be able to build your own CNNs and use them for tasks like image classification, object detection, and more.\n\nSo, are you ready to unleash the power of CNNs? Let's get started!\n\nRemember, this video is part of our Deep Learning Specialization, so if you're new to the field, you might want to start with the basics first.\n\nAnd that's it for today! I hope you enjoyed learning about CNNs. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and exploring the AI universe!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2023-03-20"}}
{"video": {"title": "Transformers: The Game Changers in NLP", "transcript": "####Transformers: The Game Changers in NLP\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-01-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your guide and today we're diving into the world of Transformers. No, not the ones from the blockbuster movie, but the ones that are shaking up the field of NLP, or Natural Language Processing.\n\nTransformers are a type of neural network that's making waves in the way machines understand and generate human language. They're the brains behind some of the most advanced AI applications, like chatbots and translation services.\n\nIn this video, we'll break down how Transformers work and why they're so effective. Then, we'll roll up our sleeves and build our own Transformer model using Python and TensorFlow.\n\nSo, are you ready to transform your understanding of NLP? Let's get started! And remember, practice makes perfect, so don't be afraid to experiment with your model.\n\nThat's all for today's video. If you enjoyed it, don't forget to hit that like button and subscribe to our channel for more AI content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-01-22"}}
{"video": {"title": "Creating a RAG-Powered Chatbot with JavaScript and LlamaIndex", "transcript": "####Creating a RAG-Powered Chatbot with JavaScript and LlamaIndex\nby Laurie Voss - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurie Voss and today we're diving into the world of chatbots! We're going to build a chatbot powered by RAG and LlamaIndex using JavaScript.\n\nImagine having an intelligent agent that can answer queries by discerning and selecting from multiple data sources. Sounds cool, right? Well, that's exactly what we're going to create!\n\nTo get started, we'll be using the create-llama command-line tool to set up our project and install the necessary dependencies. Then, we'll create our frontend component using React and integrate it with our RAG-powered backend.\n\nBut wait, there's more! We'll also learn how to persist your data, enable chatting with your data, and make streaming responses possible.\n\nThroughout this process, I'll be sharing tips and best practices for building RAG applications in JavaScript. By the end of this video, you'll have a fully functional chatbot that you can use to chat with your data.\n\nSo, are you ready to level up your coding skills and build something amazing? Let's get started!\n\nAnd don't forget to check out LlamaIndex for more resources on building intelligent applications. Happy coding!\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2023-03-25"}}
{"video": {"title": "Mastering Prompts and Parsing in LangChain", "transcript": "####Mastering Prompts and Parsing in LangChain\nby Harrison Chase, Andrew Ng - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're diving into the exciting world of prompts and parsing in LangChain.\n\nPrompts and parsing are the secret sauce of LLM applications. They're what allow your application to understand and respond to user input.\n\nFirst, we'll learn how to create effective prompts. I'll share some insider tips and tricks to help you get the most out of your LLM.\n\nThen, we'll dive into parsing. We'll learn how to extract useful information from the user's input. It's like being a detective, but with words.\n\nBy the end of this video, you'll be a pro at creating prompts and parsing user input.\n\nSo, let's get started. Remember, practice makes perfect.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-03-25"}}
{"video": {"title": "TensorFlow: Protecting Privacy in Deployment", "transcript": "####TensorFlow: Protecting Privacy in Deployment\nby Laurence Moroney - 2022-02-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, TensorFlow enthusiasts! Laurence Moroney here, and today we're diving into the world of privacy in deployment.\n\n[Video hook and introduction]\n\nPrivacy is a hot topic in the world of machine learning. It's not just about protecting user data, but also about building trust and complying with regulations.\n\n[Body content]\n\nFirst, we'll explore the process of protecting privacy in TensorFlow deployment. We'll cover techniques like differential privacy and federated learning.\n\nNext, we'll discuss the benefits of protecting privacy in deployment. We'll talk about how it can build user trust and comply with data protection regulations.\n\nFinally, we'll touch on some common challenges in protecting privacy in deployment and how to overcome them.\n\n[Conclusion and call to action]\n\nAnd that's a wrap! You're now ready to protect user privacy in your deployment.\n\nRemember, protecting user privacy is not just a legal requirement, but also a moral responsibility. So, don't take it lightly.\n\nThanks for watching, and stay tuned for more TensorFlow videos. If you have any questions, feel free to ask.\n\nUntil next time, happy coding and keep your data safe! \n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-02-19"}}
{"video": {"title": "Mastering Deep Learning Specialization: CNNs, RNNs, LSTMs, and Transformers", "transcript": "####Mastering Deep Learning Specialization: CNNs, RNNs, LSTMs, and Transformers\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your friendly guide and today we're embarking on an exciting adventure into the world of Deep Learning Specialization.\n\nSo, what's the big deal about Deep Learning Specialization? Well, it's all about mastering neural networks - specifically Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTMs), and Transformers. We'll be using Python and TensorFlow to apply these networks to speech recognition, Natural Language Processing (NLP), and so much more.\n\nBut why should you care? Because these technologies are changing the game. They're the brains behind voice assistants like Siri and Alexa, and they're making huge strides in fields like medicine and finance.\n\nLet's start with CNNs. These powerhouses are amazing for image processing. They can identify patterns in images, like edges and shapes, and use those patterns to make predictions. For example, they can tell the difference between a cat and a dog in a picture.\n\nNext up, we have RNNs and LSTMs. These networks are fantastic for processing sequential data, like time series or sentences. They can remember previous inputs, which helps them understand the context of the current input. This makes them perfect for tasks like language translation and speech recognition.\n\nFinally, we have Transformers. These are the newest kids on the block, and they're shaking things up. They're great for handling long-range dependencies in data, which makes them ideal for tasks like machine translation and text summarization.\n\nNow, I know this might seem like a lot to take in, but don't worry. With some practice and patience, you'll be building your own neural networks in no time.\n\nSo, what are you waiting for? Let's get started on your Deep Learning journey. And remember, if you ever get stuck, I'm here to help.\n\nThanks for watching, and happy learning!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-01-01"}}
{"video": {"title": "Automate Business Workflows with Multi-AI Agent Systems", "transcript": "####Automate Business Workflows with Multi-AI Agent Systems\nby Jo\u00e3o Moura - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jo\u00e3o Moura, and today we're diving into the fascinating world of multi-AI agent systems with crewAI. Are you ready to automate your business workflows and surpass the performance of a single LLM? Let's get started!\n\nSo, what exactly are multi-AI agent systems? Well, they allow you to design and prompt a team of AI agents through natural language, taking your automation capabilities to the next level. If you've taken some prompt engineering courses, have basic coding knowledge, and want to incorporate LLMs into your work, this course is perfect for you.\n\nWith crewAI as our partner, we can automate repeatable, multi-step tasks like tailoring a resume to a job description and streamline business processes that are typically done by a group of people, such as event planning. By creating a team of AI agents, you can assign specific roles, goals, and backstories to each agent, breaking down complex tasks and optimizing efficiency.\n\nSay goodbye to manual processes and hello to a more efficient workflow with multi-AI agent systems. Join me in this exciting journey to revolutionize your business automation strategies. Don't miss out on the opportunity to take your automation game to the next level. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jo\u00e3o Moura", "publication_date": "2022-10-15"}}
{"video": {"title": "Testing Your Natural Language Interface for Databases", "transcript": "####Testing Your Natural Language Interface for Databases\nby Adrian Gonzalez Sanchez - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Adrian Gonzalez Sanchez and today we're going to have some fun testing your natural language interface for databases!\n\nIf you've built a natural language interface for a database, you know how crucial it is to test it thoroughly to ensure it's working correctly. But how do you test a natural language interface?\n\nIn this video, we'll explore how to test your natural language interface for databases using the Azure OpenAI Service. We'll start by introducing the concept of testing for natural language interfaces and why it's important.\n\nThen, we'll dive into the Azure OpenAI Service and learn how to use its Assistants API to test your natural language interface. We'll cover techniques like function calling and code interpreter to make your testing more effective.\n\nWe'll provide hands-on examples to help you understand how to test your natural language interface for databases using the Azure OpenAI Service.\n\nBy the end of this video, you'll have the skills to test your own natural language interface for databases thoroughly.\n\nSo, are you ready to ensure your natural language interface is working correctly? Let's get started!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like and subscribe for more exciting content on natural language processing and databases.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Adrian Gonzalez Sanchez", "publication_date": "2023-04-15"}}
{"video": {"title": "Improving Your Machine Learning Model", "transcript": "####Improving Your Machine Learning Model: A Fun and Engaging Journey\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-01-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! It's your favorite host, back with another exciting episode. Today, we're diving into the world of improving our Machine Learning models. Are you ready to level up? Let's get started!\n\nFirst, we'll explore some cool techniques like feature scaling and polynomial regression. These can help our model perform better and make our data more understandable.\n\nNext, we'll delve into more advanced topics like regularization and model selection. These techniques can help prevent overfitting, which is when our model performs well on the training data but poorly on new data.\n\nBut wait, there's more! We'll also learn about ensemble methods, which involve combining multiple models to improve performance. And we'll do it all with practical examples, so you can see how it's done in the real world.\n\nRemember, improving a Machine Learning model is both an art and a science, so don't be discouraged if it takes some time. Practice makes perfect!\n\nSo, are you ready to take your Machine Learning skills to the next level? Let's do this! And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-01-29"}}
{"video": {"title": "Deploying ML Models: From Lab to Live", "transcript": "####Deploying ML Models: From Lab to Live\nby Andrew Ng - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here, and today we're diving into the exciting world of deploying machine learning models from the lab to live production environments.\n\nFirst things first, why is deployment so crucial? When we're working on a machine learning project, our end goal is to use our model to make predictions on new data. But to do that, we need to deploy our model to a production environment where it can be accessed by other systems and users.\n\nSo, how do we do it? It all starts with testing. We need to test our model thoroughly to make sure it's accurate, reliable, and robust. That means using techniques like cross-validation, unit testing, and integration testing to catch any issues before deployment.\n\nNext, we need to think about deployment strategies. There are many ways to deploy a machine learning model, such as using a cloud-based platform like AWS SageMaker, containerizing our model with Docker, or integrating it into an existing application. We'll talk about the pros and cons of each approach and how to choose the right one for your use case.\n\nBut wait, there's more! Deployment is not just about technology. It's also about people and processes. We'll talk about how to collaborate with DevOps teams, how to manage model versioning, and how to monitor and maintain our model in production.\n\nSo, are you ready to deploy your machine learning models to production? Let's get started!\n\nRemember, deployment is not just about technology. It's about people, processes, and culture. So keep learning, keep experimenting, and most importantly, have fun!\n\nIf you found this video helpful, be sure to give it a thumbs up and subscribe for more content. And if you have any questions or suggestions, leave them in the comments below. Thanks for watching, and I'll see you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-05"}}
{"video": {"title": "Designing a Research Agent for Multi-Document Analysis", "transcript": "####Designing a Research Agent for Multi-Document Analysis\nby Jerry Liu - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and welcome back to our series on building agentic RAG systems with LlamaIndex.\n\nAre you ready to take your document analysis skills to the next level? Today, we're diving into the world of research agents.\n\nA research agent is a supercharged tool that can handle multiple documents at once. It's perfect for tasks like literature reviews or market research.\n\nBut first, let's clear up any confusion. What's the difference between a router agent and a research agent? We'll cover that and more.\n\nThen, we'll dive into the design process and I'll show you how to build your own research agent step by step.\n\nWe'll also discuss some strategies for managing multiple documents and how to ensure your research agent is giving you the best results.\n\nBy the end of this video, you'll be able to build your own research agent and unlock the power of multi-document analysis.\n\nSo, let's get started!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-01"}}
{"video": {"title": "TensorFlow: Deploying Models with REST APIs", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Leverage input bias to show the effort put into making the video.\n- Make the conclusion more memorable and engaging.", "author": "Laurence Moroney", "publication_date": "2022-03-15"}}
{"video": {"title": "Building Multimodal RAG Systems", "transcript": "####Building Multimodal RAG Systems\nby Sebastian Witalec - 2022-10-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Sebastian! Today, we're going to level up your RAG game by diving into building multimodal RAG systems. These systems can retrieve multimodal context and reason over it to generate more relevant answers. Are you ready to make your AI applications more powerful? Let's get started!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-05"}}
{"video": {"title": "LLMs for Natural Language Understanding and Generation", "transcript": "####LLMs for Natural Language Understanding and Generation\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, Antje Barth here, and today we're diving into the fascinating world of using LLMs for natural language understanding and generation.\n\nLLMs have been making waves in the NLP scene, delivering impressive results in tasks like language translation, summarization, and question answering. In this course, we'll show you how to harness the power of LLMs for these tasks and more.\n\nWe'll be covering topics such as text classification, named entity recognition, and sentiment analysis. You'll get hands-on experience using popular tools and frameworks like spaCy and NLTK.\n\nBut that's not all! We'll also be exploring the latest research and advancements in natural language understanding and generation. You'll learn how to apply these cutting-edge techniques to your own projects.\n\nBy the end of this course, you'll have a deeper understanding of the capabilities and limitations of LLMs for natural language processing. You'll be better equipped to build and use LLMs for your own projects.\n\nSo, are you ready to take your NLP skills to the next level with LLMs? Let's get started!\n\nAnd don't forget to like, comment, and subscribe for more content like this. If you have any questions, feel free to leave them in the comments below. Thanks for watching!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-12"}}
{"video": {"title": "AI for Good: A Framework for AI Project Development", "transcript": "####AI for Good: A Framework for AI Project Development\nby Robert Monarch - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're embarking on an exciting journey into the world of AI for Good. We're going to explore a framework for AI project development that focuses on building models for air quality, wind energy, biodiversity, and disaster management. And to make things even more interesting, we'll also take a look at some real-world case studies in public health and climate change. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2022-10-15"}}
{"video": {"title": "Machine Learning Specialization: Introduction to AI Concepts", "transcript": "####Machine Learning Specialization: Introduction to AI Concepts\nby Andrew Ng - 2022-10-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, machine learning enthusiasts! Today, we're diving headfirst into the world of machine learning with a specialization that covers foundational AI concepts. Get ready to learn through an intuitive visual approach and master the code needed to implement algorithms and math for ML. I'm your host, Andrew Ng, and I'm thrilled to guide you through this exciting journey.\n\nSo, why should you care about machine learning? Well, it's the technology that powers everything from your favorite streaming service to self-driving cars. And with this specialization, you'll be able to understand how it all works and even build your own machine learning models.\n\nBut don't just take my word for it. Let's dive in and see for ourselves!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-01"}}
{"video": {"title": "Mastering Prompt Engineering with Llama 2 & 3", "transcript": "####Mastering Prompt Engineering with Llama 2 & 3\nby Amit Sangani - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Amit Sangani and today we're going to have a blast exploring the world of prompt engineering with Llama 2 & 3. Are you ready to level up your AI game? Let's dive in!\n\nEver wondered how to prompt and select among Meta Llama 2 & 3 models? You're in luck! Today, we'll be uncovering the best practices for interacting with Meta Llama 2 Chat, Code Llama, and Llama Guard models.\n\nWhen it comes to prompt engineering, it's crucial to understand the unique strengths of each model. Meta Llama 2 Chat is your go-to for generating conversational responses, while Code Llama shines in coding-related prompts. And let's not forget about Llama Guard, which is all about building safe and responsible AI applications.\n\nBy mastering prompt engineering with Llama 2 & 3, you'll be ready to create some truly amazing AI solutions. So, what are you waiting for? Let's start prompting with confidence!\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2022-10-15"}}
{"video": {"title": "Mastering Model Compression with Hugging Face and Quanto", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits of model compression.\n- Use of active voice and simple language.\n- Encouragement for practice and learning.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce stakes and payoff at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Improve contrast and pacing to maintain interest.", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-20"}}
{"video": {"title": "Building Cool Applications with Code Llama", "transcript": "####Building Cool Applications with Code Llama\nby Amit Sangani - 2023-02-21\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, tech enthusiasts! I'm Amit Sangani, and today we're diving into the exciting world of Code Llama.\n\nImagine building AI-powered applications that are not only functional but also a blast to use. That's exactly what we're going to do in this beginner-friendly course.\n\nI'll guide you through the process of creating cool projects using Code Llama. Trust me, you're going to love the results!\n\nSo, are you ready to unleash your inner tech wizard? Let's get started! And don't forget to hit that like and subscribe button for more awesome content. See you in the next video!\n\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-21"}}
{"video": {"title": "Advanced Topics in Multi AI Agent Systems with crewAI", "transcript": "####Advanced Topics in Multi AI Agent Systems with crewAI\nby Jo\u00e3o Moura - 2023-05-02\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Jo\u00e3o Moura here, and welcome back to our series on Multi AI Agent Systems with crewAI.\n\nWe've covered the basics, now let's dive into some advanced topics.\n\nFirst up, we'll tackle complex tasks that require multiple AI agents to work together in sequence. We'll set up a workflow and coordinate our agents to complete each step in the right order.\n\nNext, we'll discuss how to handle errors and exceptions in your system. This will make your system more robust and reliable.\n\nLastly, we'll explore some advanced features of crewAI, such as agent communication and dynamic role assignment.\n\nSo, let's get started! And remember, if you have any questions, feel free to leave them in the comments.\n\nStay tuned for our next video where we'll discuss some real-world applications of Multi AI Agent Systems. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep pushing the boundaries of what's possible with AI!\n#### END TRANSCRIPT ########", "author": "Jo\u00e3o Moura", "publication_date": "2023-05-02"}}
{"video": {"title": "Challenges and Solutions in On-Device AI", "transcript": "####Challenges and Solutions in On-Device AI\nby Krishna Sridhar - 2022-02-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Krishna Sridhar, and today we're diving into the exciting world of On-Device AI. We'll be exploring the challenges that come with limited compute power and memory on edge devices, and I'll be sharing some strategies to help you overcome these obstacles. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-02-20"}}
{"video": {"title": "Mastering AI with Hugging Face: A Beginner's Guide", "transcript": "####Mastering AI with Hugging Face: A Beginner's Guide\nby Maria Khalusova, Marc Sun, Younes Belkada - 2023-03-16\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc, and today we're going to make AI accessible with Hugging Face.\n\nHugging Face is an open-source platform that simplifies building AI applications. Even if you're a beginner, you'll feel at home.\n\nLet's dive in. The Hugging Face Hub is your go-to place for open-source models. You can filter models based on tasks, rankings, and memory requirements. It's like choosing a superpower, but for AI.\n\nOnce you've chosen your model, using it is a breeze. With the transformers library, you can perform text, audio, image, and multimodal tasks with just a few lines of code. It's like having your own AI assistant.\n\nBut wait, there's more. Sharing your AI apps is a piece of cake with Hugging Face. With a user-friendly interface or via API, you can run them on the cloud using Gradio and Hugging Face Spaces. It's like launching your own AI startup, but without the venture capital.\n\nSo, are you ready to master AI with Hugging Face? Remember, the best way to learn is by doing. So, go ahead, explore the Hugging Face Hub, play around with the models, and who knows, you might just create the next AI sensation.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-03-16"}}
{"video": {"title": "Mistral AI: Enhancing LLM Capabilities with User-Defined Functions", "transcript": "####Mistral AI: Supercharge Your LLM with User-Defined Functions\nby Younes Belkada and Marc Sun - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the exciting world of Mistral AI's user-defined functions, joined by my co-host Marc Sun.\n\nMistral AI's API lets you call user-defined Python functions, giving your LLM superpowers to find the most relevant information for your queries.\n\nIn this video, we'll show you how to use Mistral's API to call user-defined functions for tasks like web searches, retrieving text from databases, and more.\n\nWe'll also demonstrate how to integrate these functions with Mistral's open-source and commercial models, allowing you to create even more powerful LLM applications.\n\nSo, whether you're a beginner or an experienced developer, Mistral AI's user-defined functions have something for you. And the best part? They're easy to use and integrate seamlessly with Mistral's other features.\n\nDon't forget to like, share, and subscribe for more content on Mistral AI. And a special thanks to our technology partner, Mistral AI, for making this video possible.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-05"}}
{"video": {"title": "Introduction to Multimodal Search and RAG", "transcript": "####Introduction to Multimodal Search and RAG\nby Sebastian Witalec - 2022-10-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, welcome to today's video! I'm Sebastian Witalec, your host, and we're about to embark on an exciting journey into the world of building multimodal search and RAG applications. Are you ready? Let's dive in!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-01"}}
{"video": {"title": "Quantization 101: Shrinking Models with Hugging Face and Quanto", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits of quantization.\n- Use of active voice and simple language.\n- Encouragement for viewers to try quantizing models on their own.\n\nAreas for Improvement:\n\n- Add more humor and curiosity to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include more stakes and payoff to make the content more rewarding.\n- Make the conclusion more memorable and engaging.", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-15"}}
{"video": {"title": "Unlocking the Power of LLMs: A Developer's Guide to ChatGPT", "transcript": "####Unlocking the Power of LLMs: A Developer's Guide to ChatGPT\nby Isa Fulford - 2022-10-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford, and today we're diving headfirst into the world of large language models, specifically ChatGPT. Are you ready to discover new ways to leverage LLMs for your application development and take your projects to new heights? Let's do this!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-30"}}
{"video": {"title": "TensorFlow: Deployment on Mobile Devices", "transcript": "####TensorFlow: Deployment on Mobile Devices\nby Laurence Moroney - 2022-01-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, Laurence Moroney here, and welcome back to our TensorFlow series! Today, we're diving into the exciting world of deploying machine learning models on mobile devices.\n\n[Video hook and introduction]\n\nImagine being able to make real-time predictions and have offline functionality right at your fingertips. Sounds amazing, right? Well, that's exactly what we're going to cover today.\n\n[Body content]\n\nFirst, we'll go over the process of deploying your TensorFlow models on mobile devices. We'll cover the necessary steps, from model training to deployment, and make sure you're ready to take your machine learning projects to the next level.\n\nNext, we'll discuss the benefits of deploying on mobile devices. We'll talk about how it can improve user experience and enable new use cases.\n\nFinally, we'll touch on some common challenges in mobile deployment and how to overcome them. Trust me, you don't want to miss this.\n\n[Conclusion and call to action]\n\nAnd that's all for today! You're now ready to deploy your models on mobile devices and take your machine learning projects to the next level.\n\nRemember, mobile deployment can open up a world of possibilities. So, don't be afraid to give it a try.\n\nThanks for watching, and stay tuned for more TensorFlow videos. If you have any questions, feel free to ask.\n\nUntil next time, happy coding! \n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-01-22"}}
{"video": {"title": "ChatGPT Prompt Engineering: The Step-by-Step Guide for Novices", "transcript": "####ChatGPT Prompt Engineering: The Ultimate Guide for Beginners\nby Isa Fulford, Andrew Ng - 2023-03-24\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're diving into the thrilling world of prompt engineering for ChatGPT. If you're a newbie with some Python skills, you're in luck!\n\nLet's kick things off with the basics. What is prompt engineering and why should you care? Prompt engineering is the craft of creating effective inputs for language models like ChatGPT. It's crucial because it can greatly influence the quality of the output.\n\nNow, let's chat about some prompt engineering best practices. First, be specific and detailed with your prompts. The more context you provide, the better ChatGPT can generate the desired output. Second, keep iterating. Prompt engineering is all about trial and error, so don't be shy to experiment.\n\nLet's explore some creative ways to utilize LLMs. Did you know they can summarize, infer, transform, and expand text? Let's create our own custom chatbot using the OpenAI API.\n\nNow, let's get our hands dirty. Let's practice writing and refining prompts together. Remember, clarity and iteration are key.\n\nIn conclusion, prompt engineering is a game-changer for developing applications with ChatGPT. With these best practices and some hands-on experience, you're well on your way to becoming a prompt engineering master. So, what are you waiting for? Start prompting! And remember, practice makes perfect.\n\nThanks for tuning in and happy prompting! Don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-24"}}
{"video": {"title": "Training Methods for Generative AI", "transcript": "####Training Methods for Generative AI: Master the Art of Optimization\nby Mike Chambers - 2022-10-07\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to take your generative AI skills to the next level? Well, buckle up because today we're diving deep into the world of training methods for generative AI models.\n\nBut first, let me introduce myself. I'm Mike Chambers, your friendly neighborhood AI expert, and I'm here to guide you through this exciting journey.\n\nSo, why should you care about training methods for generative AI? Well, let me tell you, it's the key to unlocking the full potential of your models. And trust me, you don't want to miss out on that!\n\nBut enough with the chit-chat, let's get started.\n\n#### END TRANSCRIPT ########", "author": "Mike Chambers", "publication_date": "2022-10-07"}}
{"video": {"title": "Real-World Applications of On-Device AI", "transcript": "####Real-World Applications of On-Device AI\nby Krishna Sridhar - 2022-10-11\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Krishna Sridhar here, and I'm thrilled to share with you the fascinating world of On-Device AI. Today, we're diving into how this technology is transforming various industries. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-10-11"}}
{"video": {"title": "GANs vs. Other Generative Models: A Comparison", "transcript": "####GANs vs. Other Generative Models: A Comparison\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-03-12\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Eda Zhou, and today we're diving into the world of generative models! Specifically, we're comparing GANs to other popular models.\n\n[Video hook and introduction]\n\nGANs are a hot topic in the world of AI, but they're not the only game in town. In this video, we'll explore some other generative models and see how they stack up against GANs.\n\n[Body content]\n\nFirst up, we have Variational Autoencoders, or VAEs for short. VAEs are a type of neural network that can learn to generate new data by encoding and decoding the training data. They're a bit easier to train than GANs, but they may not generate images that are quite as realistic.\n\nNext, we have Normalizing Flows. Normalizing Flows are a type of generative model that can learn to transform simple distributions into complex ones. They're great for modeling complex data, but they can be a bit more computationally expensive than GANs.\n\nSo, how do these models compare to GANs? Well, each model has its own strengths and weaknesses. GANs are great for generating high-quality images, but they can be a bit tricky to train. VAEs are easier to train, but they may not generate images that are quite as realistic. Normalizing Flows are great for modeling complex data, but they can be more expensive to run.\n\nUltimately, the choice of generative model depends on the specific task and the resources you have available.\n\n[Conclusion and call to action]\n\nSo, there you have it! A quick comparison of GANs to other generative models. If you want to learn more, be sure to check out our other videos on the topic. And if you have any questions or comments, leave them down below. We love hearing from you!\n\nThanks for watching, and we'll see you in the next video.\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-03-12"}}
{"video": {"title": "Real-World Applications of Agentic RAG Systems", "transcript": "####Real-World Applications of Agentic RAG Systems\nby Jerry Liu - 2023-05-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and welcome back to our series on building agentic RAG systems with LlamaIndex.\n\nToday, we're diving into the exciting world of real-world applications of agentic RAG systems.\n\nWe'll be discussing how these systems are revolutionizing industries like healthcare, finance, and customer service.\n\nWe'll also talk about the challenges and opportunities in these areas and how you can get involved.\n\nBy the end of this video, you'll have a clearer understanding of the potential impact of agentic RAG systems and how you can use your skills to make a difference.\n\nSo, let's get started!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-05-01"}}
{"video": {"title": "Reinforcement Learning: The Basics", "transcript": "####Reinforcement Learning: The Basics\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-02-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's your friendly host! Today, we're diving into the exciting world of reinforcement learning. It's like teaching a dog new tricks, but for computers!\n\nReinforcement learning is all about learning from feedback. The computer tries different actions and learns which ones lead to the best outcome. It's like a game of trial and error, but with a smart twist.\n\nWe'll be using Python to implement these concepts, so you'll get some coding practice too! And don't worry, we'll keep things simple and fun.\n\nRemember, the key to understanding reinforcement learning is practice. So, keep coding, keep experimenting, and most importantly, keep having fun!\n\nThat's it for today's video. If you found this helpful, give us a thumbs up and don't forget to subscribe for more exciting content. See you in the next video, where we'll take reinforcement learning to the next level!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-02-05"}}
{"video": {"title": "Exploring the Future of NLP with Hugging Face", "transcript": "####Exploring the Future of NLP with Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Your Assistant, and today we're diving into the future of NLP with Hugging Face.\n\nNLP is a fast-paced field, and Hugging Face is leading the charge. We'll start by discussing the hottest trends in NLP, then we'll see how Hugging Face is pushing these boundaries, and finally, we'll dream up some potential future applications.\n\nBut remember, the future of NLP is not just about tech. It's about how we can use this tech to make a positive impact on society.\n\nSo, are you ready to explore the future of NLP? Let's get started with Hugging Face!\n\nStay tuned for more thrilling videos on this topic. And don't forget to like, share, and subscribe for more tech content. Until next time, I'm Your Assistant, your guide in the world of AI.\n\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-04-30"}}
{"video": {"title": "LangChain Loaders: Accessing Your Data Made Easy", "transcript": "####LangChain Loaders: Unlocking Your Data's Potential\nby Harrison Chase - 2023-02-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Harrison Chase, the mastermind behind LangChain, and today we're diving into one of its most exciting features: Loaders.\n\nLoaders are your secret weapon for effortlessly accessing a variety of data sources. From PDFs to CSV files, and even your own custom data sources, there are over 80 unique loaders at your disposal. That means you can connect your chatbot to a vast array of documents and data.\n\nBut how do they work? Let's find out.\n\nFirst, you'll need to import the loader that matches your data source. For instance, if you're working with a PDF file, you'll import the PDFLoader. Then, you'll use the loader to access your data and load it into LangChain.\n\nOnce your data is loaded, you're ready to start chatting with it! It's as easy as pie.\n\nI'll be your guide through each step of the process, sharing my insider tips and tricks along the way. And the cherry on top? You'll be learning directly from me, the creator of LangChain.\n\nSo, are you ready to unleash the power of LangChain Loaders? Let's get this party started!\n\nRemember, if you have any questions or need a helping hand, don't be shy. And once you've mastered Loaders, be sure to show off your creations. I can't wait to see what you build!\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-02-25"}}
{"video": {"title": "Building an ML Production Pipeline: End-to-End Workflow", "transcript": "####Building an ML Production Pipeline: End-to-End Workflow\nby Andrew Ng - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here, and today we're diving into the exciting world of building an end-to-end machine learning production pipeline.\n\nBut first, let's talk about why a production pipeline is so important. When we're working on a machine learning project, we need to manage many different components, such as data preprocessing, feature engineering, model training, and deployment. A production pipeline helps us automate and streamline these components, making it easier to develop, test, and deploy our models.\n\nSo, how do we do it? It all starts with data. We need to define our data sources, data transformations, and data validation steps to ensure our data is clean, relevant, and ready for modeling.\n\nNext, we need to think about feature engineering. We need to select the right features, transform them into the right format, and validate them to ensure they're meaningful and predictive.\n\nThen, we need to think about model training. We need to choose the right algorithm, tune the hyperparameters, and validate the model to ensure it's accurate, reliable, and robust.\n\nFinally, we need to think about deployment. We need to choose the right deployment strategy, containerize our model, and monitor it in production to ensure it's performing as expected.\n\nBut wait, there's more! Building an ML production pipeline is not just about technology. It's also about people and processes. We'll talk about how to collaborate with data engineers, DevOps teams, and business stakeholders to ensure our pipeline is aligned with the overall business goals.\n\nSo, are you ready to build an end-to-end machine learning production pipeline? Let's get started!\n\nRemember, building an ML production pipeline is not just about technology. It's about people, processes, and culture. So keep learning, keep experimenting, and most importantly, have fun!\n\nIf you found this video helpful, be sure to give it a thumbs up and subscribe for more content. And if you have any questions or suggestions, leave them in the comments below. Thanks for watching, and I'll see you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-10"}}
{"video": {"title": "Mastering Unstructured Data Preprocessing for LLM Applications", "transcript": "####Mastering Unstructured Data Preprocessing for LLM Applications\nby Matt Robinson - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Matt Robinson, and today we're embarking on an exciting journey into the world of preprocessing unstructured data for LLM applications.\n\nBut first, what exactly is unstructured data? It's everything from PDFs and PowerPoints to Word documents and HTML files. Our mission? To extract and normalize content from these diverse sources, making it a breeze for our LLM.\n\nLet's kick things off with extraction. We'll be using some cool tools and techniques to pull out the information we need. This includes text, tables, and even images.\n\nNext up, normalization. This is where we take our extracted data and transform it into a consistent format. It's like turning a chaotic pile of documents into a neatly organized library.\n\nBut wait, there's more! We're also going to enrich our content with metadata. This not only enhances our RAG results but also supports more nuanced search capabilities.\n\nNow, let's get a bit technical. We'll explore document image analysis techniques like layout detection and vision and table transformers. Don't worry, we'll break it down into simple steps so you can easily apply these methods to preprocess PDFs, images, and tables.\n\nAnd guess what? We're partnering with Unstructured to bring you this content. They're the experts in this field, so you're learning from the best.\n\nSo, are you ready to level up your RAG system? Let's get started! Remember, practice makes perfect, so keep experimenting and exploring.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Matt Robinson", "publication_date": "2023-03-15"}}
{"video": {"title": "From Prototype to Production: Scaling Your ML System", "transcript": "####From Prototype to Production: Scaling Your ML System\nby Andrew Ng - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here, and today we're diving into the exciting world of scaling your machine learning prototype into a full-fledged production system.\n\nFirst things first, why is scaling so important? Well, when we're working with small datasets and simple models, a few lines of code can do the trick. But when we're dealing with large datasets and complex models, we need a system that can handle the load.\n\nSo, how do we do it? It all starts with data. We need to make sure our data pipeline is robust, scalable, and reliable. That means using tools like Apache Beam or Apache Airflow to automate our data processing and ensure our data is always up-to-date.\n\nNext, we need to think about modeling. When we're working with large datasets, we need to use distributed training techniques to train our models efficiently. That means using tools like TensorFlow or PyTorch to parallelize our training across multiple machines.\n\nFinally, we need to think about deployment. When we're deploying our model to production, we need to make sure it's fast, reliable, and secure. That means using tools like Kubernetes or Docker to containerize our model and deploy it to a cluster of machines.\n\nBut wait, there's more! Scaling is not just about technology. It's also about people and processes. We'll talk about how to build a team of data scientists, engineers, and DevOps professionals to support your ML system in production.\n\nSo, are you ready to take your ML prototype to the next level? Let's get started!\n\nRemember, scaling is not just about technology. It's about people, processes, and culture. So keep learning, keep experimenting, and most importantly, have fun!\n\nIf you found this video helpful, be sure to give it a thumbs up and subscribe for more content. And if you have any questions or suggestions, leave them in the comments below. Thanks for watching, and I'll see you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-20"}}
{"video": {"title": "TensorFlow: Advanced Generative Models", "transcript": "####TensorFlow: Mastering Advanced Generative Models\nby Laurence Moroney, Eddy Shyu - 2022-05-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eddy Shyu, and today we're diving into the exciting world of advanced generative models in TensorFlow.\n\nGenerative models are like a magic wand for creating new, synthetic data. In this video, we'll show you how to use the Functional API to build advanced generative models with multiple inputs and outputs, shared layers, and more.\n\nWe'll also share some best practices for working with generative models, and some common pitfalls to avoid.\n\nSo, whether you're working on a generative modeling project, or just looking to level up your TensorFlow skills, this video has got you covered. Let's get started.\n\n[Demonstration of building advanced generative models with multiple inputs and outputs, shared layers, etc.]\n\nThanks for watching, and don't forget to check out our other videos on TensorFlow. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-05-03"}}
{"video": {"title": "Practical Skills in Generative AI", "transcript": "####Practical Skills in Generative AI\nby Mike Chambers - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to dive into the exciting world of generative AI? Well, buckle up because we're about to embark on an epic journey! In this video, we'll be focusing on practical skills in generative AI. You'll gain foundational knowledge and a functional understanding of how generative AI works. And the best part? We'll be doing it together! So, let's get started, shall we?\n#### END TRANSCRIPT ########", "author": "Mike Chambers", "publication_date": "2022-10-15"}}
{"video": {"title": "Harnessing the Power of AI for Good: A Beginner's Guide", "transcript": "####Harnessing the Power of AI for Good: A Beginner's Guide\nby Robert Monarch - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the fascinating world of AI, but with a twist. We're not just talking about any AI, we're talking about AI for Good.\n\n(Video hook and introduction)\n\nImagine using artificial intelligence to predict air quality, optimize wind energy, protect biodiversity, or even manage disasters. Sounds like a sci-fi movie, right? Well, it's not. It's happening right now, and you can be a part of it.\n\n(Body content)\n\nFirst, let's understand what AI for Good is. It's a movement, an initiative, a call to action for using AI to tackle some of the world's most pressing issues. From climate change to public health, AI is proving to be a powerful tool.\n\nNow, let's get our hands dirty. We'll walk through a simple framework for developing AI projects. Don't worry, it's beginner-friendly. We'll start with defining the problem, move on to data collection and preparation, then model building, and finally, deployment and monitoring.\n\nThroughout this journey, we'll explore real-world case studies. We'll see how AI is used in public health to predict disease outbreaks, or in climate change to model and predict weather patterns.\n\n(Conclusion and call to action)\n\nBy the end of this series, you'll have a solid understanding of how AI can be used for good. And who knows, you might just be inspired to start your own AI for Good project. So, are you ready to change the world with AI? Let's get started.\n\nRemember, the best way to learn is by doing. So, don't just watch these videos, apply what you learn. And if you have any questions or ideas, share them in the comments. I'm here to help.\n\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2022-01-01"}}
{"video": {"title": "Linear Algebra: The Backbone of Machine Learning", "transcript": "####Linear Algebra: The Hidden Hero of Machine Learning\nby Anshuman Singh - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, machine learning aficionados! Anshuman Singh here, and today we're unveiling the hidden hero of machine learning - linear algebra!\n\nNow, you might be thinking, \"Linear algebra? That's just numbers and equations, right?\" Well, not quite. It's the secret sauce that helps us manipulate and understand our data.\n\nSo, what's all the fuss about vectors and matrices? In machine learning, we use vectors to represent our data points and matrices to represent our datasets.\n\nLet's talk about matrix multiplication. It might sound intimidating, but it's just a fancy way of combining data. In machine learning, we use it to transform our data into something our models can understand.\n\nNext up, eigenvectors and eigenvalues. They might sound like characters from a sci-fi novel, but they're actually powerful tools. We use them in techniques like Principal Component Analysis (PCA) to reduce the dimensionality of our data.\n\nSo, there you have it. Linear algebra is not just numbers and equations, it's a superpower that helps us make sense of our data.\n\nRemember, the best way to learn is by doing. So, grab some datasets and start playing with vectors and matrices.\n\nStay tuned for our next video, where we'll be exploring the thrilling world of statistics and probability. If you enjoyed this video, give us a thumbs up and subscribe to our channel for more exciting content. Until next time, happy learning!\n\n#### END TRANSCRIPT ########", "author": "Anshuman Singh", "publication_date": "2023-03-20"}}
{"video": {"title": "Building a Multi-Document Agent with Agentic RAG and LlamaIndex", "transcript": "####Building a Multi-Document Agent with Agentic RAG and LlamaIndex\nby Jerry Liu - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Jerry Liu here and welcome back to our journey into the world of Agentic RAG with LlamaIndex.\n\nToday, we're going to build a multi-document agent with our Agentic RAG. This agent will be able to handle and analyze multiple documents at once.\n\nWe'll start by understanding how to prepare our documents for multi-document processing.\n\nThen, we'll learn how to build our multi-document agent step by step.\n\nAnd finally, we'll explore some tips and tricks to improve the performance of our multi-document agent.\n\nSo, are you ready to build your own multi-document agent with Agentic RAG and LlamaIndex? Let's get started!\n\nRemember, the more you practice, the better you'll get. So keep trying, keep building, and have fun!\n\nThanks for watching and don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n\nAnd remember, with great power comes great responsibility. Use your new multi-document agent for good!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-20"}}
{"video": {"title": "ChatGPT Prompt Engineering: A Beginner's Guide", "transcript": "####ChatGPT Prompt Engineering: A Beginner's Guide\nby Isa Fulford, Andrew Ng - 2023-03-16\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're going to demystify prompt engineering for ChatGPT. If you're a beginner with some Python knowledge, you're in the perfect spot!\n\nLet's start with the basics. What is prompt engineering and why should you care? Prompt engineering is the art of crafting effective inputs for language models like ChatGPT. It's important because it can significantly impact the quality of the output.\n\nNow, let's discuss some prompt engineering best practices. First, be precise and detailed with your prompts. The more context you provide, the better ChatGPT can generate the desired output. Second, iterate, iterate, iterate. Prompt engineering is all about trial and error, so don't be afraid to experiment.\n\nLet's discover some innovative ways to leverage LLMs. Did you know they can summarize, infer, transform, and expand text? Let's create our own custom chatbot using the OpenAI API.\n\nNow, let's get our hands dirty. Let's practice writing and refining prompts together. Remember, clarity and iteration are key.\n\nIn conclusion, prompt engineering is a game-changer for developing applications with ChatGPT. With these best practices and some hands-on experience, you're on your way to becoming a prompt engineering pro. So, what are you waiting for? Start prompting! And remember, practice makes perfect.\n\nThanks for tuning in and happy prompting! Don't forget to like, share, and subscribe for more exciting content. Catch you in the next video!\n#### END TRANSCRIPT ########\n\nPositive Points:\n\n- Clear introduction of the topic and its importance.\n- Use of active voice and simple language.\n- Encouragement of experimentation and practice.\n- Positive and enthusiastic tone.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.\n- Improve contrast and pacing to maintain interest.", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-16"}}
{"video": {"title": "Quantization in Practice: Real-World Applications", "transcript": "####Quantization in Practice: Real-World Applications\nby Marc Sun, Younes Belkada - 2022-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the exciting world of quantization!\n\nWe'll explore how quantization is revolutionizing industries like healthcare, finance, and technology. We'll also discuss some of the challenges and considerations when applying quantization in these fields.\n\nBut don't worry, we'll take it step by step. By the end of this video, you'll have a solid understanding of how quantization is used in the real world.\n\nSo, let's get started. And remember, the best way to learn is by doing.\n\nDon't forget to like, share, and subscribe for more great content.\n\nUntil next time, I'm Younes Belkada, and this has been Quantization in Practice: Real-World Applications.\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-04-05"}}
{"video": {"title": "Diffusion Models: A Detailed Overview", "transcript": "####Diffusion Models: A Fun and Engaging Overview\nby Sharon Zhou - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sharon Zhou, and today we're diving into the fascinating world of diffusion models!\n\nThink of diffusion models as building a masterpiece. You start with a simple sketch and gradually add more details until you have a stunning, complex piece of art.\n\nLet's grab our pencils and start sketching our own diffusion model. Fire up your Python environment, and make sure you have Tensorflow or Pytorch. We'll start by defining our data distribution, then gradually add noise and learn how to denoise it.\n\nBut wait, there's more! Sampling from diffusion models can be as slow as watching paint dry. So, let's speed things up! I'll show you some effective algorithms that can accelerate sampling by up to 10 times!\n\nBy the end of this video, you'll be a diffusion model maestro, ready to create and train your own masterpieces. So, keep sketching, keep learning, and who knows? You might just create the perfect 'diffusion art'!\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. See you soon!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-04-25"}}
{"video": {"title": "Maintaining AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####Maintaining AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! Today, we're diving into the world of AI maintenance with LangGraph and Tavily's agentic search.\n\nFirst, we'll uncover how LangGraph's components can be your AI agents' best friends, keeping them in tip-top shape.\n\nThen, we'll show you how to leverage Tavily's agentic search capabilities to supercharge your maintenance process.\n\nIn this course, you'll learn directly from Harrison Chase, the mastermind behind LangChain, and Rotem Weiss, the brain behind Tavily. They'll guide you through the maintenance process and share their expert insights.\n\nRemember, this course is perfect for intermediate Python users who want to level up their AI agent maintenance skills.\n\nSo, are you ready to become an AI agent maintenance master? Let's get started!\n\nStay tuned for more thrilling lessons. And don't forget to like, share, and subscribe for more AI-powered fun.\n\nUntil next time, happy maintaining!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-05"}}
{"video": {"title": "Parsing Made Easy with LangChain", "transcript": "####Parsing Made Fun and Easy with LangChain\nby Harrison Chase, Andrew Ng - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're diving into the exciting world of parsing in LangChain.\n\nParsing is like being a detective for data. It's the process of analyzing a string of symbols, whether it's natural language or computer code, according to the rules of a formal grammar.\n\nIn LangChain, parsing is a game-changer. It's the key to making sense of your LLM's output and extracting the information you need.\n\nWe'll start with the basics of parsing and then move on to some advanced techniques. By the end of this video, you'll be parsing like a pro.\n\nSo, let's get started. Remember, practice makes perfect.\n\nThanks for watching. Don't forget to like, comment, and subscribe for more content on LLM application development. Until next time, happy parsing!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-03-25"}}
{"video": {"title": "Mastering LangChain for LLM Application Development", "transcript": "####Mastering LangChain for LLM Application Development\nby Harrison Chase, Andrew Ng - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're going to explore the incredible LangChain framework for LLM application development. LangChain empowers you to harness prompts, parsing, memory, chains, question answering, and agents to create advanced language models. But first, let's make sure you're comfortable with Python. Don't worry if you're new to this - LangChain is beginner-friendly!\n\nAnd guess what? We're partnering with LangChain to bring you exclusive insights from the framework's creator, Harrison Chase, and the legendary AI expert, Andrew Ng. With LangChain, you can apply LLMs to your proprietary data to build personal assistants and specialized chatbots. Plus, you can leverage agents, chained calls, and memories to expand your use of LLMs.\n\nSo, are you ready to take your LLM application development to the next level? Let's embark on this exciting journey with LangChain!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2022-10-15"}}
{"video": {"title": "Unlocking the Power of LLMs with Function-Calling", "transcript": "####Unlocking the Power of LLMs with Function-Calling\nby Jiantao Jiao, Venkat Srinivasan - 2022-03-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Venkat Srinivasan and today we're diving into the exciting world of Language Learning Models, or LLMs, and how function-calling can unlock their full potential. If you're a beginner with some basic Python knowledge, you're in the right place!\n\nLet's get started. Function-calling is a game-changer. It lets you extend your LLMs with custom functionality by teaching them to make calls to external functions. Pretty cool, huh?\n\nNext up, we'll explore data extraction. We'll learn how to extract structured data from natural language inputs, making real-world data usable for analysis.\n\nBut wait, there's more! In partnership with Nexusflow, we'll build an end-to-end application that processes customer service transcripts using LLMs. You'll see how function-calling and data extraction can take your applications to the next level.\n\nRemember, the best way to learn is by doing. So, get involved! Try out the techniques we'll cover and see how they can enhance your LLM and agent applications.\n\nThanks for watching and happy learning! Don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, this is Jiantao Jiao signing off.\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-03-08"}}
{"video": {"title": "Building a Language Translation App with NLP and Hugging Face", "transcript": "####Building a Language Translation App with NLP and Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\n\nHello, tech enthusiasts! I'm Your Assistant, and today we're diving into the fascinating world of language translation with NLP and Hugging Face.\n\nImagine being able to communicate with anyone, anywhere, in any language. That's the power of machine translation! But it's not just about swapping words, it's about understanding the meaning and context. And that's where NLP and Hugging Face come in.\n\nWe'll start by demystifying how machine translation works, then we'll prepare our data, train our model, and finally, put it to the test.\n\nRemember, language translation is an art, not a science. Different languages have different structures and nuances, so our model needs to be smart enough to handle that.\n\nSo, are you ready to break the language barrier? Let's get started with Hugging Face and NLP!\n\nStay tuned for more exciting videos on this topic. And don't forget to like, share, and subscribe for more tech content. Until next time, I'm Your Assistant, your guide in the world of AI.\n\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-03-25"}}
{"video": {"title": "Quantization Uncovered: Optimizing Models with Hugging Face and Quanto", "transcript": "####Quantization Uncovered: Optimizing Models with Hugging Face and Quanto\nby Younes Belkada and Marc Sun - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today, I'm teaming up with Marc Sun to uncover the power of quantization using Hugging Face and Quanto libraries.\n\nSo, what's the buzz about quantization? It's like having a secret technique that lets you optimize your models without compromising their performance.\n\nLet's dive in. We'll be using the Hugging Face Transformers library and the Quanto library for this task. If you're new to these tools, no worries, we'll guide you through every step.\n\nFirst, we'll discover linear quantization, a simple yet potent method for optimizing models. It's like having a magic spell that turns your heavy models into lightweight ones.\n\nThen, we'll practice quantizing open-source multimodal and language models. It's like having a compact version of your favorite movies, but with all the performance intact.\n\nBy the end of this video, you'll be an expert at uncovering the power of quantization and you'll have saved a ton of space on your hard drive.\n\nRemember, practice makes perfect, so don't be afraid to try out different models and methods. And if you get stuck, just hit the rewind button and watch it again.\n\nThanks for joining us and don't forget to like, share, and subscribe for more awesome content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-10"}}
{"video": {"title": "Expanding LLM Capabilities with Function-Calling", "transcript": "####Expanding LLM Capabilities with Function-Calling\nby Jiantao Jiao, Venkat Srinivasan - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nVideo hook and introduction: Hey there, tech enthusiasts! Are you ready to take your LLM game to the next level? Today, we're diving into the world of function-calling and how it can expand the capabilities of your LLMs and agent applications. Let's get started!\n\nBody content: Function-calling is a game-changer for LLMs. It allows us to extend their capabilities with custom functionality, enabling them to make calls to external functions. This means we can extract structured data from natural language inputs and make real-world data usable for analysis. Imagine the possibilities for creating more dynamic and interactive applications!\n\nBut wait, there's more! Function-calling is not just for tech geeks. It's a powerful tool for businesses looking to streamline their data processing workflows. So, whether you're a developer or a data analyst, function-calling is a skill you need to have in your toolkit.\n\nConclusion and call to action: In conclusion, function-calling is the key to unlocking the full potential of your LLMs and agent applications. By learning how to apply this technique, you can take your projects to the next level and stay ahead of the curve. So, what are you waiting for? Don't miss out on this opportunity to revolutionize your applications with function-calling! Stay tuned for more exciting content from Nexusflow.\n\nAuthor: Jiantao Jiao, Venkat Srinivasan\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-10-15"}}
{"video": {"title": "Building a General-Purpose Quantizer in Pytorch", "transcript": "####Building a General-Purpose Quantizer in Pytorch\nby Marc Sun, Younes Belkada - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, data compression enthusiasts! I'm Marc Sun, and today we're diving into the world of Pytorch to build a general-purpose quantizer. This tool can compress dense layers of any open source model by up to 4x.\n\nFirst, we'll cover the basics of Pytorch and quantization. Then, we'll get our hands dirty building our quantizer. We'll break down each part of the code, so you understand exactly how it works.\n\nBy the end of this video, you'll have a powerful new tool in your data compression arsenal. But remember, practice makes perfect. So, get out there and start quantizing!\n\nDon't forget to like, share, and subscribe for more exciting content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-03-30"}}
{"video": {"title": "Deploying ML Models with TensorFlow", "transcript": "####Deploying ML Models with TensorFlow\nby Laurence Moroney - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, welcome back to my channel! Today, we're diving into the exciting world of TensorFlow and exploring how we can deploy machine learning models on various devices. Whether you're interested in training and running models in browsers or mobile apps, this video has got you covered. And the best part? We'll also discuss how you can retrain deployed models while ensuring data privacy. So, let's get started and unlock the full potential of TensorFlow!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-01-15"}}
{"video": {"title": "Building Autonomous Agents with LlamaIndex: A Beginner's Guide", "transcript": "####Building Autonomous Agents with LlamaIndex: A Beginner's Guide\nby Jerry Liu - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu, and today we're embarking on an exciting journey into the world of autonomous agents! We'll be using LlamaIndex to build an Agentic RAG system that can intelligently navigate and analyze your data.\n\nFirst things first, let's ensure you've got the basics of Python under your belt. If you're new to Python, don't worry! We'll keep things simple and easy to follow.\n\nNow, let's dive in and build an agent that can reason over your documents and answer complex questions. Sounds cool, right? Imagine asking your agent about the latest sales report, and it gives you a perfect summary with all the key points.\n\nNext, we'll build a router agent that can help you with Q&A and summarization tasks. And guess what? We'll even extend it to handle passing arguments to this agent. This means you can customize your agent to suit your specific needs.\n\nOnce we've got that down, we'll design a research agent that handles multi-documents. This is where things get really interesting. Your agent will be able to process and analyze multiple documents at once, making it a powerful tool for research and data analysis.\n\nAnd finally, we'll look at different ways to debug and control this agent. After all, even the smartest agents can sometimes make mistakes. But don't worry, I'll show you how to troubleshoot and fix any issues that come up.\n\nBy the end of this video, you'll have gained valuable skills in guiding agent reasoning and debugging. And the best part? You'll be able to build your own autonomous agents that can intelligently navigate and analyze your data.\n\nSo, are you ready to transform the way you interact with your data? Let's get started!\n\nRemember, if you have any questions or need further clarification, don't hesitate to leave a comment below. And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-03-15"}}
{"video": {"title": "Mastering Diffusion Models: A Step-by-Step Guide", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more critical analysis and real-world applications.\n- Make the conclusion more memorable and engaging.", "author": "Sharon Zhou", "publication_date": "2023-03-15"}}
{"video": {"title": "Mastering AI Agentic Design Patterns with AutoGen", "transcript": "####Mastering AI Agentic Design Patterns with AutoGen\nby Chi Wang, Qingyun Wu - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Chi Wang, and I'm Qingyun Wu, and today we're embarking on an exciting journey into the world of AI agentic design patterns with AutoGen. Are you ready to build multi-agent systems with diverse roles and capabilities for implementing complex AI applications? Let's do this!\n\nIn this video, we'll be using the AutoGen framework to create AI agents that can reflect on their actions, use tools effectively, plan ahead, and collaborate with other agents. If you have basic Python coding experience and are interested in automating complex workflows using AI agents, you're in the right place.\n\nWith AutoGen, you can implement agentic design patterns like reflection, tool use, planning, and multi-agent collaboration. This framework provides you with the tools and knowledge you need to leverage AI agents effectively in your projects.\n\nJoin us as we learn directly from the creators of AutoGen, Chi Wang and Qingyun Wu. Get ready to take your AI applications to the next level with AutoGen. Let's dive in and start building those multi-agent systems!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2022-10-15"}}
{"video": {"title": "AI and Biodiversity: Protecting Our Planet's Precious Species", "transcript": "####AI and Biodiversity: Protecting Our Planet's Precious Species\nby Robert Monarch - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're going wild with AI and biodiversity!\n\nBiodiversity is the variety of life on Earth. But it's under threat. Can AI help? You bet!\n\nToday, we'll learn how machine learning can help us monitor and protect biodiversity. We'll explore different models and techniques, from image recognition to sound classification.\n\nWe'll also look at real-world case studies, like how conservationists are using AI to track endangered species.\n\nSo, are you ready to become a digital David Attenborough? Let's get started!\n\nRemember, every step we take towards understanding and protecting biodiversity is a step towards a richer, more resilient world.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning, keep growing, and keep using AI for Good!\n#### END TRANSCRIPT ########\n\nRefined Script:\n\n####AI and Biodiversity: Protecting Our Planet's Precious Species\nby Robert Monarch - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the wild world of AI and biodiversity!\n\nBiodiversity is the variety of life on Earth. But it's under threat. Can AI help? You bet!\n\nToday, we'll learn how machine learning can help us monitor and protect biodiversity. We'll explore different models and techniques, from image recognition to sound classification.\n\nWe'll also look at real-world case studies, like how conservationists are using AI to track endangered species.\n\nSo, are you ready to become a digital David Attenborough? Let's get started!\n\nRemember, every step we take towards understanding and protecting biodiversity is a step towards a richer, more resilient world.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning, keep growing, and keep using AI for Good!\n#### END TRANSCRIPT ########\n\nPositive Points:\n\n- Clear introduction of the topic and its relevance.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.", "author": "Robert Monarch", "publication_date": "2023-04-01"}}
{"video": {"title": "Natural Language Processing with TensorFlow", "transcript": "####Natural Language Processing with TensorFlow\nby Laurence Moroney - 2022-01-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the exciting world of natural language processing with TensorFlow!\n\n[Video hook and introduction]\n\nAre you ready to build chatbots, analyze sentiment, and explore the fascinating world of NLP? Then buckle up, because we're about to embark on an epic journey!\n\n[Body content]\n\nFirst, we'll cover the basics of NLP and how TensorFlow can help. We'll explore essential concepts like tokenization, embedding, and recurrent neural networks (RNNs).\n\nThen, we'll dive into building our first NLP model. We'll use a simple dataset to classify text and learn how to train, evaluate, and optimize our model. You'll also discover how to use pre-trained models and transfer learning to speed up the process.\n\nWe'll also explore real-world applications of NLP, like machine translation and text generation. Plus, we'll cover advanced topics like sequence-to-sequence models and attention mechanisms.\n\n[Conclusion and call to action]\n\nSo, are you ready to master NLP with TensorFlow? Let's get started! Remember, the best way to learn is by doing, so make sure to code along with me. And don't forget to like, share, and subscribe for more exciting content! See you in the first lesson!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-01-22"}}
{"video": {"title": "Prototyping Your ML Production System", "transcript": "Hey there, Andrew Ng here, and today we're diving into the exciting world of prototyping your ML production system.\n\nPrototyping is a game-changer in the ML production process. It lets you test your ideas quickly and on a budget, and make adjustments as needed.\n\nSo, where do you start? First, you need to define your problem statement and gather your data. This will help you understand what you're trying to achieve and what resources you have available.\n\nNext, you need to choose the right tools for the job. There are many different ML frameworks and libraries out there, so it's important to choose the ones that best fit your needs.\n\nOnce you have your tools, it's time to start building! This is where the fun begins. You'll be training models, testing different algorithms, and fine-tuning your system.\n\nBut remember, prototyping is an iterative process. You're not going to get everything right the first time around. That's why it's important to keep testing, evaluating, and making improvements.\n\nSo, that's a quick overview of prototyping your ML production system. It's a challenging process, but with the right mindset and tools, you can build a system that delivers real value.\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content! And remember, the journey to mastering ML is a marathon, not a sprint. So, keep learning, keep experimenting, and most importantly, keep having fun!", "author": "Andrew Ng", "publication_date": "2023-03-17"}}
{"video": {"title": "Red Teaming for Safer LLM Applications: A Beginner's Guide", "transcript": "Hi there, I'm Matteo Dora and today we're diving into the world of red teaming for large language model (LLM) applications.\n\nFirst things first, what is red teaming? It's a technique borrowed from cybersecurity where you intentionally challenge your system to identify vulnerabilities and weaknesses.\n\nIn the context of LLM applications, red teaming helps us ensure the safety and reliability of our apps. It's all about finding potential issues before they become real problems.\n\nNow, you might be thinking, 'I'm just starting out with LLM applications. Is red teaming something I need to worry about?' The answer is yes! It's never too early to start thinking about safety and reliability. Plus, you don't need to be an expert to get started. Basic Python knowledge is all you need to follow along.\n\nSo, how do we start red teaming our LLM applications? First, we need to identify potential vulnerabilities. This could be anything from biased outputs to misinterpretation of user inputs.\n\nNext, we evaluate these vulnerabilities. How likely are they to occur? What would be the impact if they did? This helps us prioritize our efforts and focus on the most critical issues.\n\nBut here's the best part: you don't have to do it all manually. We've partnered with Giskard to bring you an open-source library that automates many of these red-teaming methods. It's a game-changer for beginners and experts alike.\n\nSo, are you ready to start building safer LLM applications? Join us in this course and let's get started. Remember, the best defense is a good offense.\n\nThanks for watching. Don't forget to like, share, and subscribe for more content on LLM applications. See you in the next video!", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-03-15"}}
{"video": {"title": "TensorFlow: Running Models in Mobile Apps", "transcript": "####TensorFlow: Running Models in Mobile Apps\nby Laurence Moroney - 2022-02-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, TensorFlow enthusiasts! Laurence Moroney here, and today we're diving into the exciting world of running models in mobile apps.\n\n[Video hook and introduction]\n\nImagine enhancing your app's user experience and unlocking new functionalities with machine learning models. Sounds intriguing, right? Let's get started!\n\n[Body content]\n\nFirst, we'll walk through the process of running TensorFlow models in mobile apps. We'll cover everything from integrating your model to testing your app.\n\nNext, we'll discuss the benefits of running models in mobile apps. We'll talk about how it can improve app functionality and enable new use cases.\n\nFinally, we'll touch on some common challenges in running models in mobile apps and how to overcome them.\n\n[Conclusion and call to action]\n\nAnd that's a wrap! You're now ready to run your models in mobile apps and take your app development to the next level.\n\nRemember, running models in mobile apps can be a game-changer. So, don't be afraid to give it a try.\n\nThanks for watching, and stay tuned for more TensorFlow videos. If you have any questions, feel free to ask.\n\nUntil next time, happy coding! \n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-02-05"}}
{"video": {"title": "Effective Prompting Techniques with ChatGPT", "transcript": "####Effective Prompting Techniques with ChatGPT\nby Isa Fulford - 2022-10-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Isa Fulford! Are you ready to take your prompt engineering skills to the next level? Today, we're diving into the world of effective prompting with ChatGPT. Get ready to unlock the full potential of language models and have some fun along the way!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-17"}}
{"video": {"title": "Building Your First Machine Learning Model", "transcript": "####Building Your First Machine Learning Model: A Fun and Engaging Journey\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-02-26\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! Are you ready to embark on an exciting journey? Today, we're going to build our very first Machine Learning model.\n\nWe'll be using Python and a dataset to train our model. Don't worry, we'll guide you through each step. It's like having your own personal ML mentors!\n\nRemember, the key to building great models is practice. So, keep coding and experimenting. It's all about having fun and learning along the way.\n\nThat's it for today's video. If you found this helpful, give us a thumbs up and don't forget to subscribe for more exciting content. We promise, you won't want to miss what's coming next! See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-02-26"}}
{"video": {"title": "Unleashing the Power of LLMs with Function-Calling and Data Extraction", "transcript": "####Unleashing the Power of LLMs with Function-Calling and Data Extraction\nby  - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao and today we're diving into the thrilling world of function-calling and data extraction with Language Learning Models, or LLMs.\n\nFirst things first, if you're already familiar with LLMs and have some basic Python knowledge, you're in the right place. If not, don't worry, we'll keep it simple and enjoyable.\n\nSo, what's the deal with function-calling? It's a game-changer. It allows us to extend LLMs with custom functionality, enabling them to form calls to external functions. Imagine your LLM as a superhero, and function-calling is like giving them a new superpower.\n\nNow, let's talk about data extraction. With LLMs, we can extract structured data from natural language inputs. This means we can take real-world data, like customer service transcripts, and make it usable for analysis. No more messy, unstructured data.\n\nLet's get our hands dirty and build an end-to-end application that processes customer service transcripts using LLMs. We'll walk through each step, from setting up our LLM to extracting data and making function calls.\n\nAnd guess what? We're partnering with Nexusflow to bring you this content. They're the experts in this field, so we're in good hands.\n\nBy the end of this video, you'll be a pro at function-calling and data extraction with LLMs. So, are you ready to level up your skills? Let's get started!\n\nRemember, practice makes perfect. So, don't just watch, try it out yourself. And if you have any questions, leave them in the comments. We're here to help.\n\nThanks for watching, and stay tuned for more exciting content.\n\nAuthor: Jiantao Jiao, Venkat Srinivasan\n#### END TRANSCRIPT ########", "author": "", "publication_date": "2022-01-01"}}
{"video": {"title": "Efficiently Serving LLMs: Speed Up Text Generation with KV Caching", "transcript": "####Efficiently Serving LLMs: Speed Up Text Generation with KV Caching\nby Travis Addair - 2023-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Travis Addair and welcome back to another thrilling video on GenAI and LLM powered applications. Today, we're diving into the world of Large Language Models (LLMs) and how techniques like KV caching can make text generation lightning fast.\n\nFirst things first, let's talk about how LLMs predict the next token. In a nutshell, the model takes in a sequence of tokens and spits out a probability distribution over the possible next tokens. The token with the highest probability is then chosen as the next token. This process repeats until a stop token is generated or a maximum sequence length is reached.\n\nBut how can we speed up this process? Enter KV caching. This involves storing the key-value pairs of the input tokens and their corresponding output probabilities in a cache. So, if the same input sequence pops up again, the model can quickly grab the output probabilities from the cache instead of having to recalculate them.\n\nNext, we're going to write some code to efficiently serve LLM applications to a large number of users. We'll be using Python for this, so make sure you're comfortable with the language. We'll also be exploring the tradeoffs between quickly returning the output of the model and serving many users at once.\n\nFinally, we'll delve into the fundamentals of Low Rank Adapters (LoRA) and see how Predibase builds their LoRAX framework inference server to serve multiple fine-tuned models at once. This will allow us to efficiently serve LLM applications to a large number of users while still maintaining high accuracy.\n\nThanks for tuning in and don't forget to like, comment, and subscribe for more videos on GenAI and LLM powered applications. Until next time, keep learning and stay curious!\n#### END TRANSCRIPT ########", "author": "Travis Addair", "publication_date": "2023-02-15"}}
{"video": {"title": "Research Trends in Generative AI", "transcript": "####Research Trends in Generative AI\nby Antje Barth - 2022-10-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to explore the thrilling world of generative AI? Buckle up as we dive into the latest research trends. Today, we're learning from AWS AI practitioners who are not just talking the talk, but walking the walk. They're actively building and deploying AI in real-world business scenarios. I'm your host, Antje Barth, and I can't wait to share this exciting journey with you.\n#### END TRANSCRIPT ########", "author": "Antje Barth", "publication_date": "2022-10-17"}}
{"video": {"title": "ChatGPT Prompt Engineering: Unleashing the Power of LLMs", "transcript": "####ChatGPT Prompt Engineering: Unleashing the Power of LLMs\nby Isa Fulford, Andrew Ng - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're going to unlock the power of LLMs with prompt engineering. If you're a beginner with basic Python skills, you're in the perfect place to start.\n\nLet's kick things off by understanding what LLMs are and how prompt engineering can help you make the most of them. LLMs, or Large Language Models, are powerful tools that can generate human-like text. But to get the most out of them, you need to know how to craft effective prompts.\n\nSo, what makes a good prompt? It's all about being clear, concise, and specific. Let's look at some examples and see how we can improve them.\n\nNow, let's get creative. Did you know you can use LLMs for more than just generating text? With the right prompts, you can use them for summarizing, inferring, transforming, and expanding text. Let's try it out with the OpenAI API.\n\nIt's time to get your hands dirty. Let's write and iterate on some prompts together. Remember, the key to prompt engineering is iteration. So don't be afraid to tweak and refine your prompts until you get the output you want.\n\nAnd that's a wrap! Remember, the more you practice prompt engineering, the better you'll get. So keep experimenting and don't forget to check out our partners at OpenAI for more resources and tools.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########\n\nPositive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Encouragement of experimentation and practice.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Include more curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-20"}}
{"video": {"title": "Function-Calling and Data Extraction: Troubleshooting and Debugging", "transcript": "####Function-Calling and Data Extraction: Troubleshooting and Debugging\nby Jiantao Jiao, Venkat Srinivasan - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Venkat Srinivasan and welcome back to our series on function-calling and data extraction with LLMs. Today, we're going to talk about troubleshooting and debugging when using function-calling and data extraction.\n\nWe'll cover common issues and errors that you might encounter and how to troubleshoot and debug them. We'll also discuss best practices for testing and validating your code.\n\nBy the end of this video, you'll have a better understanding of how to troubleshoot and debug issues when using function-calling and data extraction.\n\nRemember, the key to success is to keep learning and improving. So, don't just watch the video. Try out the examples yourself and experiment with different techniques.\n\nAnd if you have any questions, feel free to leave them in the comments. We're here to help!\n\nSo, are you ready to learn about troubleshooting and debugging when using function-calling and data extraction with LLMs? Let's get started!\n\nDon't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########\n\nPositive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Encouragement for viewers to engage with the content.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-04-20"}}
{"video": {"title": "Getting Started with LangChain: Your Personal Data Assistant", "transcript": "####Getting Started with LangChain: Your Personal Data Assistant\nby Harrison Chase - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, the creator of LangChain, and today we're going to have some fun creating your very own personal data assistant using LangChain.\n\nAre you tired of spending hours searching for information in your documents and data? With LangChain, you can create a personal data assistant that will do all the hard work for you.\n\nIn this video, we'll cover the basics of getting started with LangChain. You'll need to have a basic understanding of Python to follow along, but don't worry, we'll keep it simple and easy to follow.\n\nWe'll start by installing LangChain and selecting the appropriate loader for your data source. LangChain provides access to over 80 unique loaders that can handle various data sources, so you can connect your personal data assistant to a wide range of data sources.\n\nNext, we'll write some code to teach your personal data assistant how to extract the information you need. You'll be able to ask your assistant questions in natural language, and it will provide you with accurate answers from your data.\n\nAnd the best part? You'll be able to access your personal data assistant from anywhere, at any time, making it easier than ever to find the information you need.\n\nSo, are you ready to get started? Let's dive in and start building your very own personal data assistant with LangChain!\n\nRemember, if you have any questions or need help along the way, feel free to reach out to me on social media or through the LangChain website.\n\nThanks for watching, and happy coding!\n\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-20"}}
{"video": {"title": "ChatGPT Prompt Engineering: The Essential Guide for Newbies", "transcript": "####ChatGPT Prompt Engineering: The Essential Guide for Newbies\nby Isa Fulford, Andrew Ng - 2023-03-23\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're diving headfirst into the exciting world of prompt engineering for ChatGPT. If you're a newbie with a basic understanding of Python, you're in luck!\n\nSo, what's prompt engineering and why should you care? Prompt engineering is the art of crafting effective inputs for language models like ChatGPT. It's a game-changer because it can significantly impact the output.\n\nLet's dive into some prompt engineering best practices. First, be explicit and thorough with your prompts. The more information you provide, the better ChatGPT can understand and deliver. Second, iteration is your best friend. Prompt engineering is a process of refinement, so don't be afraid to try different approaches.\n\nNow, let's explore some novel ways to use LLMs. Did you know they can summarize, infer, transform, and expand text? Let's build our own custom chatbot using the OpenAI API.\n\nTime for some hands-on practice. Let's write and refine some prompts together. Remember, clarity and iteration are your best friends.\n\nTo sum up, prompt engineering is a powerful tool for application development with ChatGPT. With these best practices and some practical experience, you're well on your way to mastering prompt engineering. So, let's get started! And remember, the more you practice, the better you'll get.\n\nThanks for watching and happy prompting! Don't forget to like, share, and subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-23"}}
{"video": {"title": "Mastering Image Generation with GANs: A Deep Dive", "transcript": "####Mastering Image Generation with GANs: A Deep Dive\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, machine learning enthusiasts! I'm Sharon Zhou, and today we're diving headfirst into the fascinating world of Generative Adversarial Networks, or GANs for short.\n\n[Video hook and introduction]\n\nGANs are a type of machine learning model that can generate new data that's eerily similar to the data it was trained on. In this case, we're talking about images. But before we get started, a quick reminder that this video is for those with an intermediate skill level in machine learning.\n\n[Body content]\n\nSo, how do GANs work? Well, they consist of two parts: a generator and a discriminator. The generator creates new images, while the discriminator tries to tell the difference between real images and the ones the generator creates. The two parts work together, with the generator trying to fool the discriminator, and the discriminator trying to get better at spotting fakes.\n\nLet's take a look at an example. Say we want to generate images of cats. We'd start by training our GAN on a dataset of cat images. The generator would then create new images, and the discriminator would try to tell if they're real or not. Over time, the generator gets better at creating realistic images, and the discriminator gets better at spotting fakes.\n\nBut it's not all fun and games. GANs also have some social implications that we need to consider. For example, they can perpetuate biases in the data they're trained on, and they can also be used to create deepfakes, which raises privacy concerns.\n\n[Conclusion and call to action]\n\nSo that's a quick overview of GANs and image generation. If you want to learn more, be sure to check out our other videos on advanced techniques for working with GANs. And don't forget to subscribe to our channel for more machine learning content. Thanks for watching!\n\n\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-02-15"}}
{"video": {"title": "Designing an ML Production System: A Step-by-Step Guide", "transcript": "####Designing an ML Production System: A Step-by-Step Guide\nby Andrew Ng - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, machine learning enthusiasts! Andrew Ng here, and today we're diving into the exciting world of designing an ML production system. Are you ready to take your machine learning model from the development stage to a fully operational system? Let's get started!\n\nFirst things first, let's talk about what it means to design an ML production system. Essentially, it's all about taking your machine learning model from the lab to the real world, where it can make real-time predictions. Sounds exciting, right?\n\nBut before we jump into the nitty-gritty details, we need to scope out our project. This means clearly defining our goals, identifying the data sources we'll be working with, and understanding the business impact of our model. This sets the foundation for everything that follows.\n\nNext up, we have the data. Data is the lifeblood of any machine learning model, so we'll need to gather, clean, and preprocess our data to ensure it's ready for modeling. This step is often overlooked but is absolutely essential for the success of our project.\n\nNow, onto the modeling phase. Here, we'll be building and training our machine learning model using the preprocessed data. This is where the magic happens, as we fine-tune our model to achieve the best possible performance.\n\nOnce our model is trained and ready to go, it's time for deployment. This involves integrating our model into our existing systems, setting up monitoring and logging mechanisms, and ensuring everything runs smoothly in a production environment.\n\nBut the journey doesn't end there. Continuous improvement is key to maintaining the performance of our model over time. This involves monitoring its performance, collecting feedback from users, and iterating on our model to keep it up-to-date.\n\nAnd there you have it, a step-by-step guide to designing an ML production system. I hope you found this video helpful and informative. If you have any questions or want to learn more about this topic, feel free to leave a comment below. Thanks for watching, and I'll see you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-15"}}
{"video": {"title": "Breaking Down Complex Tasks with ChatGPT", "transcript": "####Breaking Down Complex Tasks with ChatGPT\nby Isa Fulford - 2022-10-16\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford, and today we're going to have some fun breaking down complex tasks with the ChatGPT API. Are you ready to explore the power of multistage prompts? Let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-16"}}
{"video": {"title": "Implementing Weights Packing: Pack Four 2-bit Weights into a Single 8-bit Integer", "transcript": "####Implementing Weights Packing: Pack Four 2-bit Weights into a Single 8-bit Integer\nby Marc Sun, Younes Belkada - 2022-01-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc Sun, and today we're diving into the fascinating world of weights packing. We're going to learn how to pack four 2-bit weights into a single 8-bit integer.\n\nFirst, we'll discuss the theory behind weights packing. Then, we'll roll up our sleeves and dive into the code. We'll walk through each step of implementing weights packing in your models.\n\nBy the end of this video, you'll be a weights packing pro. You'll know how to maximize your model's efficiency without sacrificing performance.\n\nRemember, this course is designed for an intermediate skill level, and it's brought to you in partnership with Hugging Face.\n\nBut wait, there's more! If you're ready to master weights packing, let's get started. And don't forget to like, share, and subscribe for more great content. See you in the course!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-01-29"}}
{"video": {"title": "Data Management in ML Production Systems", "transcript": "####Data Management in ML Production Systems\nby Andrew Ng - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! I'm Andrew Ng, and today we're going to dive into the exciting world of data management in Machine Learning production systems.\n\nData is the heart and soul of any ML system. It's what our models learn from, and it's what they use to make predictions. But managing data in a production system can be a wild ride.\n\nFirst, we need to collect our data. This might involve pulling data from various sources, cleaning it up, and transforming it into a format our model can understand.\n\nNext, we need to store our data. This involves choosing the right database for our needs and making sure our data is secure and accessible.\n\nThen, we need to serve our data to our model. This involves setting up a data pipeline that can deliver data to our model in real-time.\n\nBut the journey doesn't end there. We also need to monitor our data quality, handle data drift, and continuously improve our data management processes.\n\nSo, are you ready to become a data management master in ML production systems? Start planning your data strategy today, and remember, good data management is the secret sauce to a successful ML system.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content on Machine Learning. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-25"}}
{"video": {"title": "Machine Learning Specialization: Implementing ML Algorithms in Python", "transcript": "####Machine Learning Specialization: Implementing ML Algorithms in Python\nby Eddy Shyu - 2022-10-02\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Eddy Shyu here! Are you ready to level up your machine learning skills? In this video, we're going to have some fun implementing ML algorithms in Python. So, grab your favorite coding snack and let's get started!\n#### END TRANSCRIPT ########", "author": "Eddy Shyu", "publication_date": "2022-10-02"}}
{"video": {"title": "Unleashing the Power of AI with Hugging Face Open Source Models", "transcript": "####Unleashing the Power of AI with Hugging Face Open Source Models\nby Maria Khalusova, Marc Sun, Younes Belkada - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Maria, and today we're embarking on an exciting journey into the world of AI, made accessible with Hugging Face's open-source models!\n\nFirst stop, the Hugging Face Hub. It's like a sweet shop, but for AI models. You'll find a plethora of models, all open source and ready for you to use.\n\nNow, how do you pick the perfect model? Easy. You can filter them based on the task you need, their rankings, and even their memory requirements.\n\nOnce you've made your choice, the fun begins. With just a few lines of code, using the transformers library, you can perform text, audio, image, and even multimodal tasks. It's like having your own AI sidekick!\n\nBut wait, there's more. Want to share your AI apps with the world? No problem. With a user-friendly interface provided by Gradio and Hugging Face Spaces, you can easily share your apps and even run them on the cloud.\n\nSo, are you ready to transform your projects with AI? Remember, you don't need to be a pro to start. With Hugging Face, AI is for everyone.\n\nStay tuned for more tips and tricks on our channel. And don't forget to like, share, and subscribe!\n\nUntil next time, keep exploring and innovating.\n#### END TRANSCRIPT ########", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2022-01-01"}}
{"video": {"title": "LangGraph and Tavily: A Powerful Duo for AI Agent Development", "transcript": "####LangGraph and Tavily: A Powerful Duo for AI Agent Development\nby Harrison Chase, Rotem Weiss - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! Today, we're diving into the dynamic duo of LangGraph and Tavily's agentic search for AI agent development.\n\nLangGraph is an open-source framework that empowers you to build, debug, and maintain AI agents. It's like having a superpower for creating controllable agents.\n\nBut wait, there's more! When you add Tavily's agentic search into the mix, you're enhancing your agent's knowledge and performance, making your AI more efficient and effective.\n\nIn this course, you'll learn from the best - Harrison Chase from LangChain and Rotem Weiss from Tavily. They'll take you through LangGraph's components and show you how to integrate agentic search capabilities.\n\nThis course is perfect for those with intermediate Python knowledge who want to level up their AI game.\n\nSo, are you ready to harness the power of LangGraph and Tavily? Let's dive in! Remember to like, share, and subscribe for more exciting content.\n\nHappy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-30"}}
{"video": {"title": "Advanced Techniques for Model Compression", "transcript": "####Advanced Techniques for Model Compression\nby Younes Belkada - 2022-10-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Younes Belkada! Are you ready to dive into the world of model compression? Today, we're going to explore some advanced techniques through quantization. We'll customize compression, optimize performance, and even have some fun along the way. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Younes Belkada", "publication_date": "2022-10-22"}}
{"video": {"title": "Mastering TensorFlow: Advanced Techniques", "transcript": "####Mastering TensorFlow: Advanced Techniques\nby Laurence Moroney, Eddy Shyu - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, TensorFlow enthusiasts! I'm Laurence Moroney, and I'm Eddy Shyu. Today, we're going to take your TensorFlow skills to the next level with some advanced techniques. Are you ready to dive in?\n\nFirst, we'll be exploring the Functional API and how it can help you build more complex models. Then, we'll show you how to optimize your training with multiple processors. And finally, we'll delve into some advanced computer vision and generative deep learning techniques.\n\nBy the end of this video, you'll have a solid understanding of how to leverage these advanced techniques in your own projects. So grab your coffee, sit back, and let's get started!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-01-15"}}
{"video": {"title": "Optimizing Text Summarization with Prompt Engineering", "transcript": "####Optimizing Text Summarization with Prompt Engineering\nby Isa Fulford - 2022-10-30\n\n#### BEGIN TRANSCRIPT ####\nAre you tired of reading long, drawn-out texts? Wish you could condense them into a more manageable size? Well, you're in luck! Today, we're going to explore how prompt engineering can enhance the summarization capabilities of your language model. Get ready to become a text summarization pro!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-30"}}
{"video": {"title": "Efficiently Serving LLMs", "transcript": "####Efficiently Serving LLMs: Unleashing the Power of Large Language Models\nby Travis Addair - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Travis Addair here, and today we're embarking on an exciting journey into the realm of Large Language Models (LLMs). We'll be exploring how these models predict the next token with mind-blowing accuracy. But wait, there's more! We'll also be discussing techniques like KV caching that can turbocharge your text generation. So, whether you're a seasoned Python pro or just starting out, this video is a must-watch for anyone looking to efficiently serve LLM applications. Let's dive in!\n#### END TRANSCRIPT ########", "author": "Travis Addair", "publication_date": "2022-10-15"}}
{"video": {"title": "Building AI Applications with Hugging Face: A Comprehensive Tutorial", "transcript": "####Building AI Applications with Hugging Face: A Comprehensive Tutorial\nby Maria Khalusova, Marc Sun, Younes Belkada - 2023-03-23\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Younes, and today we're diving into the magical world of Hugging Face to build an AI application from scratch.\n\nHugging Face is a platform that makes building AI applications as easy as pie. So, let's get our hands dirty.\n\nFirst, we'll find a model on the Hugging Face Hub. It's like choosing a spell from a spellbook. You can filter models based on tasks, rankings, and memory requirements.\n\nNext, we'll use the transformers library to implement the model. With just a few lines of code, you can perform text, audio, image, and multimodal tasks. It's like casting an AI spell.\n\nFinally, we'll share our AI app. With a user-friendly interface or via API, you can run it on the cloud using Gradio and Hugging Face Spaces. It's like sharing your AI magic with the world.\n\nSo, are you ready to build your own AI application with Hugging Face? Remember, the best way to learn is by doing. So, go ahead, explore the Hugging Face Hub, play around with the models, and who knows, you might just create the next AI sensation.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-03-23"}}
{"video": {"title": "Mastering Mathematics for Machine Learning and Data Science", "transcript": "####Mastering Mathematics for Machine Learning and Data Science\nby Luis Serrano - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, math enthusiasts! Welcome back to our channel. Today, we're embarking on an exciting journey into the world of mathematics for machine learning and data science. I'm your guide, Luis Serrano, and I can't wait to explore the fundamental toolkit of calculus, linear algebra, statistics, and probability with you. Let's dive in!\n\nFirst up, calculus. It's the study of change and motion, and it's essential for understanding optimization algorithms in machine learning. Next, we have linear algebra, the language of data science. It's used for manipulating vectors and matrices, and it's a must-know for any data scientist. Statistics helps us make sense of data by analyzing patterns and trends, while probability is crucial for making predictions and decisions based on uncertain outcomes.\n\nBut why should you care about mastering these mathematical concepts? Well, let me tell you, they're the secret sauce to excelling in machine learning and data science. So, practice your skills, stay curious, and never stop learning.\n\nAnd before we go, don't forget to like and subscribe for more content. We've got some exciting videos lined up for you, so you won't want to miss out. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Luis Serrano", "publication_date": "2022-10-15"}}
{"video": {"title": "Mastering Prompt Iteration with ChatGPT: A Practical Approach", "transcript": "####Mastering Prompt Iteration with ChatGPT: A Practical Approach\nby Isa Fulford - 2022-10-27\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford, and today we're going to master the art of prompt iteration with ChatGPT. Are you ready to fine-tune your prompts for optimal results and take your language model interactions to the next level? Let's get started!\n\nFirst, we'll cover the basics of prompt iteration and why it's important. Then, we'll dive into some practical examples and tips for improving your prompts. And finally, we'll wrap up with some best practices for working with ChatGPT.\n\nBut wait, there's more! Stick around until the end for a special bonus tip that will really take your prompt game to the next level. Trust me, you won't want to miss it.\n\nSo, are you ready to become a prompt iteration master? Let's do this!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-27"}}
{"video": {"title": "GANs in Action: Real-World Applications and Case Studies", "transcript": "####GANs in Action: Real-World Applications and Case Studies\nby Eric Zelikman - 2022-10-11\n\n#### BEGIN TRANSCRIPT ####\nHello, tech enthusiasts! I'm Eric Zelikman, and today we're going to explore the fascinating world of Generative Adversarial Networks, or GANs. But we're not just going to talk about them, we're going to see them in action!\n\nAre you ready to discover how these powerful AI tools are being used in real-world applications across various industries? Let's dive right in!\n\n#### END TRANSCRIPT ########", "author": "Eric Zelikman", "publication_date": "2022-10-11"}}
{"video": {"title": "Building and Deploying LLM Applications", "transcript": "####Building and Deploying LLM Applications\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Mike Chambers here, and today we're diving into the exciting world of building and deploying LLM applications!\n\nIn this course, we'll be using popular tools and frameworks like TensorFlow, PyTorch, and Flask to build and deploy your very own LLM applications.\n\nWe'll cover everything from data preparation to model training and deployment, and you'll get hands-on experience building and deploying your own applications.\n\nBut that's not all! We'll also be discussing best practices for scaling and optimizing LLM applications, and how to use cloud services like AWS to deploy your applications at scale.\n\nBy the end of this course, you'll have practical skills and knowledge that you can apply to your own projects and career.\n\nSo, are you ready to start building and deploying LLM applications? Let's get started!\n\nRemember to like, comment, and subscribe for more content like this. And if you have any questions, feel free to leave them in the comments below. Thanks for watching!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-05"}}
{"video": {"title": "Mastering LangGraph: A Deep Dive into Its Components", "transcript": "####Mastering LangGraph: A Deep Dive into Its Components\nby Harrison Chase, Rotem Weiss - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to become a LangGraph master? Today, we're going on an exciting journey to explore the components that make LangGraph a powerful tool for developing, debugging, and maintaining AI agents.\n\nFirst up, why should you care about LangGraph's components? Well, they're the building blocks that enable us to create AI agents that can complete tasks and achieve goals.\n\nLet's start with the Graph. It's like a roadmap for our AI agents, guiding them on their journey to complete tasks.\n\nNext up, we've got the Executor. Think of it as the engine that powers our agents, helping them navigate the Graph and make decisions.\n\nThen, we've got the Agents themselves. They're our superheroes, using the Graph and Executor to complete tasks and achieve goals.\n\nAnd finally, we've got the Tools. They're like the gadgets our superheroes use, enhancing their abilities and helping them overcome challenges.\n\nBy the end of this video, you'll have a solid understanding of LangGraph's components and how they work together to create powerful AI agents.\n\nSo, are you ready to master LangGraph? Let's dive in!\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-20"}}
{"video": {"title": "The Future of AI for Good: Trends and Opportunities", "transcript": "####The Future of AI for Good: Trends and Opportunities\nby Robert Monarch - 2023-05-13\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Robert Monarch, and today we're diving into the future of AI for Good.\n\nWe'll uncover the latest trends in AI for Good, from AI-powered climate solutions to AI for public health.\n\nWe'll also explore the opportunities these trends present, and how you can be a part of them.\n\nWe'll look at the challenges and ethical considerations of AI for Good, and discuss how to navigate them.\n\nSo, are you ready to explore the future of AI for Good? Let's get started!\n\nRemember, every bit of knowledge you gain about AI for good brings us one step closer to a better future.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content on AI. Until next time, let's keep using AI for good.\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-05-13"}}
{"video": {"title": "TensorFlow: Training Models in Browsers", "transcript": "####TensorFlow: Training Models in Browsers\nby Laurence Moroney - 2022-01-29\n\n#### BEGIN TRANSCRIPT ####\nHello and welcome back, TensorFlow enthusiasts! I'm Laurence Moroney, and today we're diving into the exciting world of training models in browsers.\n\n[Video hook and introduction]\n\nImagine being able to train machine learning models right in your browser. No need for powerful hardware or complex setups. Just you, your browser, and TensorFlow. Sounds intriguing, right?\n\n[Body content]\n\nFirst, we'll walk you through the process of training TensorFlow models in browsers. We'll start with setting up your environment and then move on to training your model. Don't worry, I'll be with you every step of the way.\n\nNext, we'll discuss the benefits of browser-based training. We'll talk about how it can improve user engagement and enable new use cases. Plus, we'll share some real-world examples to inspire you.\n\nFinally, we'll touch on some common challenges in browser-based training and how to overcome them. Trust me, it's not as daunting as it sounds.\n\n[Conclusion and call to action]\n\nAnd that's a wrap! You're now ready to train your models in browsers.\n\nRemember, browser-based training can open up new possibilities in your machine learning projects. So, don't be afraid to explore it.\n\nThanks for watching, and stay tuned for more TensorFlow videos. If you have any questions, don't hesitate to ask.\n\nUntil next time, happy coding and keep exploring the world of TensorFlow!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-01-29"}}
{"video": {"title": "Building a Custom Data Loader with LangChain", "transcript": "####Building a Custom Data Loader with LangChain\nby Harrison Chase - 2023-03-02\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! I'm Harrison Chase, the creator of LangChain, and today we're going to have a blast building your own custom data loader with LangChain.\n\nLangChain offers you access to over 80 unique loaders that can handle various data sources. But what if you have a custom data source that isn't supported? That's where custom loaders come in.\n\nDon't worry, building your own custom loader may sound daunting, but I'll be guiding you through each step of the process. We'll start by creating a new class that inherits from LangChain's BaseLoader class. Then, we'll define the methods needed to load your custom data.\n\nOnce your custom loader is built, you can use it just like any other loader in LangChain. This means you can connect your chatbot to your custom data source and start chatting with it right away.\n\nI'll be sharing tips and tricks along the way to help you build the most effective custom loader possible. And the best part? You'll be learning directly from me, the creator of LangChain.\n\nSo, are you ready to build your own custom data loader? Let's get started!\n\nRemember, if you have any questions or need help along the way, don't hesitate to reach out. And once you've built your custom loader, be sure to share it with me. I can't wait to see what you create!\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-02"}}
{"video": {"title": "Exploring Probability in Machine Learning", "transcript": "####Exploring Probability in Machine Learning: Unveiling the Power of Uncertainty\nby Obed Kobina Nsiah - 2022-10-09\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Obed Kobina Nsiah here, and today we're diving into the fascinating world of probability and machine learning. Buckle up, because we're about to uncover how uncertainty can help us make better predictions and decisions based on data.\n\nFirst, let's talk about why probability matters in machine learning. Then, we'll explore some key concepts and techniques, like Bayes' theorem and probability distributions. And finally, we'll see how all of this comes together in real-world applications, from spam filtering to self-driving cars.\n\nSo, are you ready to unlock the secrets of probability and machine learning? Let's get started!\n#### END TRANSCRIPT ########", "author": "Obed Kobina Nsiah", "publication_date": "2022-10-09"}}
{"video": {"title": "Implementing Weights Packing for Efficient Compression", "transcript": "####Implementing Weights Packing for Efficient Compression\nby Marc Sun - 2022-10-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Marc Sun! Today, we're diving into the fascinating world of weights packing to achieve efficient compression. We'll show you how to pack four 2-bit weights into a single 8-bit integer, optimizing your model's performance. Are you ready to level up your compression game? Let's get started!\n#### END TRANSCRIPT ########", "author": "Marc Sun", "publication_date": "2022-10-19"}}
{"video": {"title": "RAG and Natural Language Processing: Building a Sentiment Analysis Tool with JavaScript", "transcript": "####RAG and Natural Language Processing: Building a Sentiment Analysis Tool with JavaScript\nby Laurie Voss - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Laurie Voss and today, we're diving into the exciting world of RAG and natural language processing. We're going to build a sentiment analysis tool using JavaScript and LlamaIndex.\n\nOur tool will use an intelligent agent to analyze text and determine its sentiment. We'll create an interactive frontend component that lets users input text and receive a sentiment score from our RAG-powered backend.\n\nTo kick things off, we'll use the create-llama command-line tool to set up our project and install the necessary dependencies. Then, we'll create our frontend component using React and integrate it with our RAG-powered backend.\n\nWe'll also learn how to persist your data, enable chatting with your data, and make streaming responses possible.\n\nThroughout this process, I'll be sharing tips and best practices for building RAG applications in JavaScript. By the end of this video, you'll have a fully functional sentiment analysis tool that you can use to analyze text.\n\nSo, let's get started! And remember, if you want to learn more about building intelligent applications, be sure to check out LlamaIndex.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2023-04-25"}}
{"video": {"title": "Prompt Engineering for Beginners with Llama 2 & 3", "transcript": "Hi there, Amit Sangani here and today we're diving into the exciting world of Prompt Engineering for Beginners with Llama 2 & 3!\n\nIf you're new to the world of AI, don't worry, we've got you covered. In this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst up, we'll be taking a look at Meta Llama 2 Chat and I'll show you how to interact with it to get the most out of your prompts. You'll be prompting like a pro in no time!\n\nNext, we'll dive into Code Llama and I'll show you how to use it to build some really cool applications. You'll be amazed at what you can create with just a few prompts.\n\nBut that's not all, we'll also be taking a look at Llama Guard and how you can use it to build safe and responsible AI applications. It's important to make sure our AI is being used for good, and Llama Guard can help with that.\n\nSo, are you ready to get started? Let's dive in and start prompting like a pro with Llama 2 & 3. And don't forget to hit that like and subscribe button for more great content. See you in the next video!\n\nRemember, the key to success in prompt engineering is to keep experimenting and never stop learning. So, let's get started and see what amazing things we can create together!", "author": "Amit Sangani", "publication_date": "2023-02-22"}}
{"video": {"title": "Generative AI for Business Applications", "transcript": "####Generative AI for Business Applications: Unlocking Potential\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-05-06\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Antje Barth, and today we're going to dive into the fascinating world of generative AI for business applications.\n\nImagine a world where AI can create content for you, improve customer experiences, and even automate mundane tasks. Sounds too good to be true, right? Well, it's not! In this video, we'll explore how LLMs can be used for business applications and discuss the latest research in this area.\n\nBut wait, there's more! We'll also talk about the ethical considerations of using AI for business applications and discuss best practices for integrating AI systems into business processes.\n\nBy the end of this video, you'll have a solid understanding of how generative AI can be used for business applications. You'll be able to apply these techniques to your own projects and stay up-to-date on the latest developments in the field.\n\nSo, are you ready to unlock the potential of generative AI for your business? Let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-05-06"}}
{"video": {"title": "Generative Deep Learning with TensorFlow", "transcript": "####Generative Deep Learning with TensorFlow: Unleashing Creativity\nby Laurence Moroney, Eddy Shyu - 2022-01-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the exciting world of generative deep learning with TensorFlow!\n\nImagine creating models that can generate new images, text, and even music. Sounds like fun, right? Well, that's exactly what we're going to do! We'll explore different types of generative models, including Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs).\n\n...\n\nThanks for joining me on this journey! I hope this video helped you understand how to create generative models with TensorFlow. If you found this video helpful, please give it a thumbs up and subscribe to our channel for more content like this. Until next time, keep exploring and creating!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-01-29"}}
{"video": {"title": "Best Practices for ML Production", "transcript": "####Best Practices for ML Production\nby Andrew Ng - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Andrew Ng here, and today we're diving into the world of ML production!\n\nNow, I know what you're thinking, \"ML production, that sounds complex!\" But don't worry, I've got you covered.\n\nFirst things first, start with a clear problem statement. Trust me, this will keep you focused and ensure your system delivers real value.\n\nNext up, let's talk about data. You need a robust data pipeline, my friend. That means having a reliable way to collect, store, and process your data.\n\nNow, when it comes to tools, choose wisely. There are many different ML frameworks and libraries out there, so make sure you pick the ones that best fit your needs.\n\nAnd finally, don't forget to continuously monitor and improve your system. Collect data on your system's performance and use it to make improvements over time.\n\nSo, there you have it, a quick overview of some best practices for ML production. Follow these practices, and you'll be on your way to delivering real value with your ML system.\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-10"}}
{"video": {"title": "Mastering Sentiment Analysis with NLP and Hugging Face", "transcript": "####Mastering Sentiment Analysis with NLP and Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Your Assistant here, and today we're diving into the fascinating world of sentiment analysis in NLP. If you've ever wondered how machines can understand human emotions, buckle up!\n\nFirst things first, let's define sentiment analysis. It's the process of determining whether a piece of text is positive, negative, or neutral. It's used in everything from social media monitoring to customer feedback analysis.\n\nWith Hugging Face, we can build a sentiment analysis model in just a few lines of code. We'll walk you through each step, from data preprocessing to model training and evaluation.\n\nBut wait, there's more! We'll also show you how to fine-tune your model for even better performance. And don't worry, we'll explain everything in plain English, so you won't get lost in the jargon.\n\nSo, are you ready to master sentiment analysis with NLP and Hugging Face? Let's get started!\n\nAnd that's a wrap for today's video. If you enjoyed it, don't forget to hit that like button and subscribe for more content. And if you're ready to start building your own sentiment analysis models, check out the links in the description for some great resources. See you next time!\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-03-20"}}
{"video": {"title": "Automating LLM Red Teaming with Giskard", "transcript": "####Automating LLM Red Teaming with Giskard\nby Matteo Dora, Luca Martial - 2023-03-29\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, LLM enthusiasts! I'm Matteo Dora, and welcome back to our series on red teaming for LLM applications.\n\nIn this video, we're diving into the world of automation and how it can make our lives easier when it comes to red teaming. We'll be using Giskard's open-source library to automate various tasks, so buckle up!\n\nBut first, let's talk about why automation is important. It can save us time and effort, allowing us to focus on more complex tasks. And with Giskard's library, automating red teaming tasks has never been easier.\n\nWe'll cover how to install and use the library, and how to automate tasks like vulnerability identification, evaluation, and fixing. But remember, while automation is great, it's not a substitute for human intuition and creativity in red teaming.\n\nSo, let's get started and make our LLM applications safer with Giskard's automation tools.\n\nAnd stay tuned for our next video where we'll discuss some advanced red teaming techniques for LLM applications. Until then, keep exploring and learning.\n\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-03-29"}}
{"video": {"title": "Distributed Training with TensorFlow", "transcript": "####Distributed Training with TensorFlow\nby Laurence Moroney, Eddy Shyu - 2022-02-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the exciting world of distributed training with TensorFlow!\n\nAre you ready to take your machine learning skills to the next level? In this video, we'll explore the different strategies for distributed training, including data parallelism and model parallelism. We'll also show you how to implement these strategies using TensorFlow's distributed runtime.\n\nBut wait, there's more! We'll also share some tips and tricks to help you optimize your distributed training workflows and avoid common pitfalls.\n\nSo, let's get started!\n\n...\n\nAnd that's a wrap! I hope this video helped you understand how to perform distributed training with TensorFlow. If you found this video helpful, please give it a thumbs up and subscribe to our channel for more content like this. And don't forget to share it with your friends and colleagues!\n\nSee you next time, and happy training!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-02-12"}}
{"video": {"title": "Advanced Prompt Engineering Techniques for ChatGPT", "transcript": "####Advanced Prompt Engineering Techniques for ChatGPT\nby Isa Fulford, Andrew Ng - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Isa Fulford and today we're diving into the exciting world of advanced prompt engineering techniques for ChatGPT. If you're a beginner with basic Python skills, you're in the right place to level up.\n\nBut first, let's talk about what makes a prompt advanced. It's all about using techniques that help the model understand the context and generate more accurate responses.\n\nLet's start with the first technique: using examples. By providing examples in your prompt, you can help the model understand what you're looking for. Let's see how it works.\n\nNext, let's talk about using instructions. By giving clear instructions in your prompt, you can guide the model towards the output you want. Let's try it out.\n\nFinally, let's explore using constraints. By setting constraints in your prompt, you can limit the model's output and get more precise results. Let's see it in action.\n\nAnd that's it! You've just learned some advanced prompt engineering techniques for ChatGPT. Remember, the key to mastering these techniques is practice. So keep experimenting and refining your prompts.\n\nThanks for watching and happy coding! And a special thanks to our partners at OpenAI for their support.\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-04-20"}}
{"video": {"title": "Building a Q&A Chatbot with Agentic RAG and LlamaIndex", "transcript": "####Building a Q&A Chatbot with Agentic RAG and LlamaIndex\nby Jerry Liu - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Jerry Liu here and welcome back to our adventure into the world of Agentic RAG with LlamaIndex.\n\nToday, we're going to build a Q&A chatbot with our Agentic RAG. This chatbot will be able to answer questions based on the documents it has been trained on.\n\nWe'll start by understanding how to prepare our documents for chatbot training.\n\nThen, we'll learn how to build our Q&A chatbot step by step.\n\nAnd finally, we'll explore some tips and tricks to improve the performance of our Q&A chatbot.\n\nSo, are you ready to build your own Q&A chatbot with Agentic RAG and LlamaIndex? Let's get started!\n\nRemember, the more you practice, the better you'll get. So keep trying, keep building, and have fun!\n\nThanks for watching and don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n\nAnd remember, with great AI comes great responsibility!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-30"}}
{"video": {"title": "Supercharge Your LLMs with Function-Calling and Data Extraction", "transcript": "####Supercharge Your LLMs with Function-Calling and Data Extraction\nby Jiantao Jiao, Venkat Srinivasan - 2022-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Venkat Srinivasan and today we're going to supercharge your Language Learning Models, or LLMs, with function-calling and data extraction. If you're a beginner with some basic Python knowledge, you're in the right place!\n\nLet's dive in. Function-calling is a game-changer. It lets you extend your LLMs with custom functionality by teaching them to make calls to external functions. Impressive, right?\n\nNext up, we'll explore data extraction. We'll learn how to extract structured data from natural language inputs, making real-world data usable for analysis.\n\nBut wait, there's more! In partnership with Nexusflow, we'll build an end-to-end application that processes customer service transcripts using LLMs. You'll see how function-calling and data extraction can supercharge your applications.\n\nRemember, the best way to learn is by doing. So, get involved! Try out the techniques we'll cover and see how they can enhance your LLM and agent applications.\n\nThanks for watching and happy learning! Don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, this is Jiantao Jiao signing off.\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-03-22"}}
{"video": {"title": "LangChain: Unlocking the Potential of Your Data", "transcript": "####LangChain: Unlocking the Potential of Your Data\nby Harrison Chase - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Harrison Chase, and today we're diving into the world of LangChain. We're going to see how it can help you unlock the potential of your data.\n\nLangChain is a game-changer. It allows you to access and interact with various data sources. With over 80 unique loaders, you can handle different types of data, from PDFs to databases.\n\nBut we're not stopping there. We're going to build a chatbot that can chat directly with information from your own documents and data. It's like having a personal assistant who can read and understand all your documents and data.\n\nI'll be your guide, making sure to keep things simple and easy to understand. By the end of this video, you'll have your own chatbot ready to assist you with your data needs.\n\nSo, are you ready to unlock the potential of your data with LangChain? Let's get this party started!\n\nRemember, if you have any questions, feel free to leave a comment. I'm always here to help. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-04-15"}}
{"video": {"title": "Ethics and Fairness: Building Responsible ML Systems", "transcript": "####Ethics and Fairness: Building Responsible ML Systems\nby Andrew Ng - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here! Today, we're diving into the world of ethics and fairness in ML production systems.\n\nBut why should we care? Well, building responsible ML systems is not just about accuracy, but also about fairness, transparency, and privacy. We'll discuss how to identify and mitigate bias, ensure data privacy, and make ethical decisions.\n\nWe'll also explore techniques for explainable AI, differential privacy, and fair machine learning. Trust me, you won't want to miss this!\n\nRemember, the goal is not just to build a good model, but to build a model that is good for society. So, let's get started!\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and keep innovating!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-20"}}
{"video": {"title": "TensorFlow: Building and Deploying Mobile Apps with TensorFlow Lite", "transcript": "####TensorFlow: Building and Deploying Mobile Apps with TensorFlow Lite\nby Laurence Moroney - 2022-05-03\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Laurence Moroney, and today we're diving into the world of TensorFlow Lite!\n\n[Video hook and introduction]\n\nTensorFlow Lite is a lightweight version of TensorFlow designed for mobile and IoT devices. It allows you to run machine learning models on-device, providing fast and private inference. So let's get started and learn how to build and deploy mobile apps with TensorFlow Lite!\n\n[Body content]\n\nFirst, we'll cover the basics of TensorFlow Lite and discuss how it differs from regular TensorFlow. We'll also talk about the benefits of on-device inference and the types of models that can be used with TensorFlow Lite.\n\nNext, we'll walk through the process of converting a TensorFlow model to TensorFlow Lite format, using techniques like quantization and pruning to optimize the model for mobile devices.\n\nWe'll also cover how to integrate TensorFlow Lite models into Android and iOS apps, using popular mobile development frameworks like React Native and Flutter.\n\nLastly, we'll discuss some best practices for building and deploying mobile apps with TensorFlow Lite, such as testing on multiple devices, optimizing for battery life, and monitoring your app's performance.\n\n[Conclusion and call to action]\n\nAre you ready to bring machine learning to the palm of your hand? Let's get started with TensorFlow Lite! Remember, on-device inference can provide fast and private machine learning capabilities for your mobile apps.\n\nIf you found this video helpful, be sure to give it a thumbs up, share it with your friends, and subscribe to our channel for more awesome content. See you in the next video!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-05-03"}}
{"video": {"title": "Model Deployment in ML Production Systems", "transcript": "####Model Deployment in ML Production Systems\nby Andrew Ng - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! Andrew Ng here, and today we're diving into the exciting world of model deployment in Machine Learning production systems.\n\nDeploying a model is more than just putting it on a server. It's about making sure our model is robust, scalable, and secure.\n\nFirst, we need to choose the right deployment strategy. This might involve deploying our model as a web service, embedding it in an application, or using a serverless architecture.\n\nNext, we need to set up our infrastructure. This involves choosing the right hardware and software for our needs and making sure our system is secure and scalable.\n\nThen, we need to monitor our model. This involves tracking performance metrics, handling errors, and making updates as needed.\n\nBut the journey doesn't end there. We also need to plan for model updates, handle versioning, and continuously improve our deployment processes.\n\nSo, are you ready to master model deployment in ML production systems? Start planning your deployment strategy today, and remember, a successful deployment is key to a successful ML system.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content on Machine Learning. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-30"}}
{"video": {"title": "The Role of DevOps in ML Production", "transcript": "####The Role of DevOps in ML Production\nby Andrew Ng - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Andrew Ng, and today we're diving into the exciting world of DevOps in ML production.\n\nDevOps is all about bridging the gap between development and operations, making collaboration and efficiency skyrocket. In the context of ML production, this means bringing together data scientists, engineers, and IT professionals to build and maintain your ML system.\n\nSo, how does DevOps fit into ML production? First, it helps to streamline your development process. This means using tools like version control, automated testing, and continuous integration to make your development process more efficient.\n\nNext, it helps to improve your deployment process. This means using tools like containerization, orchestration, and infrastructure as code to make your deployment process more reliable and scalable.\n\nFinally, it helps to improve your monitoring and maintenance process. This means using tools like log analysis, metrics collection, and alerting to make sure your system is performing as expected.\n\nSo, that's a quick overview of the role of DevOps in ML production. It's a critical component of any successful ML system, and one that deserves your attention.\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content! And remember, the future of ML is in your hands!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-30"}}
{"video": {"title": "Scaling Multimodal Search Applications", "transcript": "####Scaling Multimodal Search Applications\nby Sebastian Witalec - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Sebastian Witalec here, and today we're diving into the exciting world of scaling multimodal search applications.\n\nImagine building a search application that can handle not just text, but images, audio, and more. That's the power of multimodal search. But how do you ensure it can handle a large amount of data and users? That's what we're here to find out!\n\nWe'll explore strategies like distributed systems and load balancing, and I'll share some tips on how to monitor your application's scalability. We'll also tackle common scalability issues head-on.\n\nRemember, the goal is to build a multimodal search application that's not just powerful and secure, but also scalable. This is crucial in industries where data and user growth are the norm.\n\nSo, are you ready to level up your multimodal search game? Let's get started! And if you have any questions, don't be shy. Leave a comment below. We're all in this learning journey together.\n\nAnd before you go, don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2023-04-20"}}
{"video": {"title": "Building Your First Machine Learning Model", "transcript": "####Building Your First Machine Learning Model with Andrew Ng, Eddy Shyu, Aarti Bagul, and Geoff Ladwig - 2022-01-22\n\n#### BEGIN TRANSCRIPT ####\nHello, Machine Learning enthusiasts! Your favorite host is back with an exciting new episode. Today, we're going to roll up our sleeves and build our very first Machine Learning model. Are you ready?\n\nFirst, we'll start with a simple dataset. We'll walk you through the steps of preparing it for our model. This includes cleaning the data, handling missing values, and converting categorical data into numbers.\n\nNext, we'll split our data into a training set and a test set. The training set is used to train our model, while the test set is used to evaluate its performance.\n\nThen, we'll dive into building our model. We'll start with a simple linear regression model, and we'll learn how to train it using our training data.\n\nBut wait, there's more! We'll also learn how to evaluate our model using metrics like mean squared error and R-squared. And we'll do it all with practical examples, so you can see how it's done in the real world.\n\nRemember, the best way to learn is by doing, so don't be afraid to get your hands dirty. So, are you ready to build your first Machine Learning model? Let's get started! And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-01-22"}}
{"video": {"title": "Building Multimodal Search and RAG with Weaviate", "transcript": "####Building Multimodal Search and RAG with Weaviate\nby Sebastian Witalec - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sebastian Witalec and today we're diving headfirst into the thrilling world of multimodal search and RAG applications. If you've got a handle on basic Python, you're all set!\n\nFirst up, let's demystify multimodality. It's a fancy term, but don't let it scare you. In simple terms, it's the ability to handle different types of data, like text, images, and audio, all at the same time. We'll learn how to use contrastive learning to build modality-independent embeddings. This means you can retrieve any type of data with any type of query. Pretty cool, right?\n\nNext, we'll build a multimodal RAG system. RAG stands for Retrieval Augmented Generation. It's a system that retrieves relevant context and reasons over it to generate more accurate answers. We'll see how to retrieve multimodal context and generate more relevant answers.\n\nBut wait, there's more! We'll also explore some real-world applications of multimodal search. Ever wondered how Netflix recommends your next binge-watch? We'll build a multi-vector recommender system to understand just that.\n\nAnd the best part? We're partnering with Weaviate to bring you this exciting content. So, are you ready to transform the way you search and generate data? Let's get started!\n\nRemember, practice makes perfect. So, don't just watch, but also try to implement what you learn. If you have any questions, feel free to leave them in the comments. And if you found this video helpful, don't forget to like, share, and subscribe. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2023-03-15"}}
{"video": {"title": "Building a CNN from Scratch", "transcript": "####Building a CNN from Scratch: A Step-by-Step Guide\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! It's your favorite AI guide, and today we're embarking on an exciting journey to build a Convolutional Neural Network (CNN) from scratch.\n\nWe'll kick things off with the fundamentals of CNNs, including filters, pooling, and fully connected layers. Then, we'll roll up our sleeves and get our hands dirty by building our own CNN using Python and TensorFlow.\n\nBy the time we wrap up this video, you'll have built your very own CNN and applied it to a real-world scenario.\n\nSo, are you ready to join the ranks of CNN builders? Let's dive in!\n\nBut wait, before we get started, remember that this video is part of our Deep Learning Specialization. If you're new to the field, you might want to start with the basics first.\n\nAnd that's a wrap for today! I hope you enjoyed building your own CNN as much as I did. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and having fun! \n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2023-04-10"}}
{"video": {"title": "Mastering Deep Learning Specialization with Python and TensorFlow", "transcript": "####Mastering Deep Learning Specialization with Python and TensorFlow\nby Andrew Ng - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Are you ready to conquer the world of deep learning? Well, you're in luck! Today, I'm going to guide you through the Deep Learning Specialization with Python and TensorFlow. And who better to learn from than yours truly, Andrew Ng, one of the authors of this specialization.\n\nSo, what's in store for you? We'll start by diving into the basics of neural networks, from CNNs to RNNs, LSTMs, and even Transformers. Trust me, you'll be a pro in no time!\n\nBut wait, there's more! We'll also apply these concepts to real-world projects, like speech recognition and NLP. By the end of this video, you'll have a solid understanding of deep learning and be ready to take on any challenge that comes your way.\n\nSo, grab your Python and TensorFlow skills, and let's get started on this exciting journey!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-15"}}
{"video": {"title": "On-Device AI: A New Era of Edge Computing", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning.\n- Make the benefits and applications of On-Device AI more relatable and engaging.\n- Improve contrast and pacing to maintain interest.\n- Include more critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Krishna Sridhar", "publication_date": "2023-03-15"}}
{"video": {"title": "The Future of Generative AI with LLMs", "transcript": "####The Future of Generative AI with LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, Chris Fregly here, and today we're diving into the thrilling world of generative AI with LLMs!\n\nLLMs have already made waves in various applications, but what's next for this groundbreaking technology? In this course, we'll explore the latest research and advancements in generative AI, and how they're reshaping the future of LLMs.\n\nWe'll delve into topics such as multimodal generation, reinforcement learning, and unsupervised learning, and you'll hear from top experts in the field about the hottest trends and developments in generative AI.\n\nBut it's not all sunshine and rainbows. We'll also discuss the potential risks and challenges of generative AI, and how to navigate them in a responsible and ethical manner.\n\nBy taking this course, you'll gain a deeper understanding of the future of generative AI with LLMs, and be better prepared to stay ahead of the game in this fast-paced field.\n\nSo, are you ready to explore the future of generative AI? Let's get started!\n\nRemember to like, comment, and subscribe for more content like this. And if you have any questions, feel free to leave them in the comments below. Thanks for watching!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-19"}}
{"video": {"title": "Unleashing the Power of Natural Language Processing with Hugging Face", "transcript": "####Unleashing the Power of Natural Language Processing with Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, tech enthusiasts! I'm Your Assistant, and today we're embarking on an exciting journey into the realm of Natural Language Processing, or NLP. We're going to design apps that can answer questions, analyze sentiment, translate languages, and even summarize text!\n\nFirst up, let's talk about question-answering. Imagine having an app that can understand and respond to user queries, just like a real person. With NLP, that's a reality! We'll be using Hugging Face, our technology partner, to make this happen.\n\nNext, we'll explore sentiment analysis. This is where our app can understand the emotions behind words. Is a review positive or negative? With NLP, our app can tell the difference.\n\nThen, we'll venture into language translation. Ever wished you could understand a foreign language? With NLP, our app can translate text from one language to another, making communication easier than ever.\n\nLastly, we'll tackle text summarization. Imagine reading a long article and getting a summary that captures all the key points. That's what our NLP app can do!\n\nRemember, NLP is a powerful tool, but it's not magic. It requires a good understanding of language and some technical skills. But don't worry, we'll guide you through it all.\n\nSo, are you ready to transform the way you interact with language? Let's get started with Hugging Face and NLP!\n\nStay tuned for more thrilling videos on this topic. And don't forget to like, share, and subscribe for more tech content. Until next time, I'm Your Assistant, your guide in the world of AI.\n\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-03-15"}}
{"video": {"title": "Introduction to Multimodal Search and RAG", "transcript": "####Introduction to Multimodal Search and RAG\nby Sebastian Witalec - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Today, we're embarking on an exciting journey into the world of multimodal search and RAG applications. Get ready to learn how to build smarter, more efficient search systems that can handle any type of data.\n\nFirst, we'll dive into the concept of contrastive learning and how it can be used to create modality-independent embeddings. This means that our search systems will be able to seamlessly retrieve information across different types of data, from text to images and beyond.\n\nNext, we'll explore how to build multimodal RAG systems that can retrieve multimodal context and reason over it to generate more relevant answers. This will allow our applications to provide more accurate and useful information to users.\n\nFinally, we'll discuss some real-world applications of multimodal search and how to build multi-vector recommender systems. Trust me, you won't want to miss this!\n\nSo, let's get started and take your search applications to the next level.\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-15"}}
{"video": {"title": "Linear Quantization: Symmetric vs. Asymmetric Mode", "transcript": "Hey there, I'm Marc Sun, and welcome back to our series on advanced quantization techniques. Today, we're diving into the world of Linear Quantization, specifically comparing symmetric and asymmetric modes.\n\nFirst up, symmetric mode. In this mode, the zero point is always zero. This means that both positive and negative numbers are represented equally. It's like a perfect balance, just like a well-made sandwich.\n\nBut what if your data isn't centered around zero? That's where asymmetric mode comes in. This mode allows for a non-zero zero point, giving you more flexibility to represent your data accurately.\n\nWe'll dive into the math behind these modes and discuss when to use each one. By the end of this video, you'll be a pro at choosing the right mode for your quantization needs.\n\nRemember, this course is brought to you in partnership with Hugging Face. So you're getting the best resources and guidance out there.\n\nThat's it for today's preview. If you're ready to master symmetric and asymmetric modes, let's get started. And don't forget to like, share, and subscribe for more great content. See you in the course!", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-01-08"}}
{"video": {"title": "Mistral AI: The Future of Natural Language Processing", "transcript": "####Mistral AI: The Future of Natural Language Processing\nby Younes Belkada, Marc Sun - 2023-02-23\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the future of natural language processing with Mistral AI.\n\nMistral AI is revolutionizing the game with its cutting-edge LLM capabilities. From open-source and commercial models to JSON mode and API, Mistral AI is making it a breeze to integrate LLM into your software applications.\n\nBut wait, there's more! Mistral AI is constantly evolving and improving, so you can expect even more advanced LLM capabilities in the future.\n\nSo, what does this mean for you? It means that now is the perfect time to start exploring Mistral AI and its advanced LLM capabilities. Whether you're a beginner or a seasoned pro, Mistral AI has something for everyone.\n\nSo, what are you waiting for? Start exploring Mistral AI today and take your LLM capabilities to the next level. And don't forget to check out Mistral AI, our technology partner for this video.\n\nThanks for watching, and stay tuned for more exciting videos on Mistral AI and LLM. I'm Younes Belkada, and I'll see you in the next one.\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-23"}}
{"video": {"title": "Evaluating LLM Inputs and Outputs", "transcript": "####Evaluating LLM Inputs and Outputs: A Must-Know for AI Enthusiasts\nby Isa Fulford - 2022-10-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Isa Fulford, and today we're diving into the thrilling world of evaluating LLM inputs and outputs. Trust me, you won't want to miss this!\n\nImagine having an AI system that's not just smart, but safe, accurate, and relevant. Sounds like a dream, right? Well, it's not! By evaluating LLM inputs and outputs, you can make this dream a reality.\n\nBut wait, there's more! We'll also be exploring some real-world examples and practical tips to help you get the most out of your AI systems. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-19"}}
{"video": {"title": "TensorFlow: Data Preprocessing Techniques", "transcript": "####TensorFlow: Data Preprocessing Techniques\nby Laurence Moroney - 2022-03-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Laurence Moroney here, and today we're going to talk about data preprocessing techniques in TensorFlow.\n\n[Video hook and introduction]\n\nWe all know that data is the backbone of any machine learning project. But did you know that preprocessing your data can significantly improve your model's performance? Let's dive in and explore some techniques to help you get the most out of your data!\n\n[Body content]\n\nFirst up, we'll cover data normalization. This is the process of rescaling your data to ensure that each feature has equal importance when training your model. We'll discuss popular normalization techniques like Min-Max scaling and Z-score normalization.\n\nNext, we'll talk about handling missing data. We'll explore strategies like deletion, imputation, and using machine learning algorithms to fill in the gaps.\n\nWe'll also cover encoding categorical data, which is essential for working with non-numerical data in TensorFlow. You'll learn about techniques like one-hot encoding and label encoding.\n\nLastly, we'll discuss feature engineering \u2013 the process of creating new features from existing data to improve model performance.\n\n[Conclusion and call to action]\n\nSo, are you ready to level up your data preprocessing skills and improve your TensorFlow models? Let's get started! Remember, the better your data, the better your model.\n\nIf you found this video helpful, be sure to give it a thumbs up, share it with your friends, and subscribe to our channel for more awesome content. See you in the next video!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-03-08"}}
{"video": {"title": "TensorFlow: Model Optimization Techniques", "transcript": "Hi there, I'm Laurence Moroney, and today we're going to explore model optimization techniques in TensorFlow.\n\n[Video hook and introduction]\n\nOptimizing your machine learning models can lead to faster training times, better performance, and more efficient use of resources. So let's dive in and learn how to make your TensorFlow models the best they can be!\n\n[Body content]\n\nFirst up, we'll cover pruning \u2013 a technique for reducing the size of your model by removing unnecessary connections. We'll discuss how to use TensorFlow's built-in pruning API to optimize your models.\n\nNext, we'll talk about quantization \u2013 the process of converting floating-point numbers to integers to reduce model size and improve inference speed. We'll walk through the process of quantizing your TensorFlow models using post-training quantization and quantization-aware training.\n\nWe'll also cover knowledge distillation, a technique for training smaller, more efficient models by transferring knowledge from larger, pre-trained models.\n\nLastly, we'll discuss neural architecture search (NAS) \u2013 a method for automatically finding the best model architecture for your specific task. We'll cover how to use TensorFlow's AutoML capabilities to perform NAS and find the optimal model for your needs.\n\n[Conclusion and call to action]\n\nAre you ready to optimize your TensorFlow models and make them faster, smaller, and more efficient? Let's get started! Remember, a well-optimized model can make a big difference in the performance of your machine learning applications.\n\nIf you found this video helpful, be sure to give it a thumbs up, share it with your friends, and subscribe to our channel for more awesome content. See you in the next video!\n\nAnd don't forget to leave a comment below if you have any questions or suggestions for future videos. Happy optimizing!", "author": "Laurence Moroney", "publication_date": "2022-03-29"}}
{"video": {"title": "Building a General-Purpose Quantizer in Pytorch", "transcript": "####Building a General-Purpose Quantizer in Pytorch\nby Marc Sun, Younes Belkada - 2022-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the world of Pytorch to build a general-purpose quantizer.\n\nThis tool is a game-changer! It can quantize the dense layers of any open-source model, giving you up to 4x compression on dense layers.\n\nBut what exactly is a quantizer, you ask? Well, let's start by discussing the architecture of our quantizer. Then, we'll dive into the code and see how it all comes together.\n\nDon't worry, we'll take it step by step. By the end of this video, you'll have a solid understanding of how to build and use a general-purpose quantizer in Pytorch.\n\nSo, let's get started. And remember, the best way to learn is by doing.\n\nBut wait, there's more! Don't forget to like, share, and subscribe for more great content.\n\nUntil next time, I'm Younes Belkada, and this has been Building a General-Purpose Quantizer in Pytorch.\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-03-22"}}
{"video": {"title": "Real-World Applications of LLMs", "transcript": "####Real-World Applications of LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-05-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, Chris Fregly here, and today we're going to dive into the exciting world of LLMs!\n\nLLMs have a wide range of potential applications, from generating personalized product descriptions for e-commerce sites to creating realistic dialogue for video games. We'll discuss some of these applications in more detail and hear from some AWS AI practitioners who are actively building and deploying LLMs in business use-cases today.\n\nBut it's not all sunshine and rainbows. We'll also talk about some of the challenges of deploying LLMs in the real world, such as the need for scalability and security, and some best practices for addressing these challenges.\n\nBy the end of this video, you'll have a better understanding of some real-world applications of LLMs and some ideas for how to use this technology in your own projects. So let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-05-03"}}
{"video": {"title": "Debugging AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####Debugging AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-03-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python aficionados! Today, we're diving into the world of debugging AI agents using LangGraph and Tavily's agentic search.\n\nFirst, we'll uncover how LangGraph's components can be our secret weapon in debugging our AI agents. It's like having a detective's toolkit for finding and fixing issues.\n\nNext, we'll demonstrate how to leverage Tavily's agentic search capabilities to supercharge our debugging process.\n\nIn this course, you'll learn directly from Harrison Chase, the mastermind behind LangChain, and Rotem Weiss, the brains behind Tavily. They'll guide you through the debugging process and share their expert insights.\n\nRemember, this course is perfect for those with intermediate Python knowledge who want to level up their AI agent debugging skills.\n\nSo, are you ready to become an AI agent debugging pro? Let's do this!\n\nStay tuned for more thrilling lessons. And don't forget to like, share, and subscribe for more AI-powered content.\n\nUntil next time, happy debugging!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-29"}}
{"video": {"title": "Evaluating LLM Performance: Metrics and Best Practices", "transcript": "####Evaluating LLM Performance: Metrics and Best Practices\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-26\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Antje Barth, and today we're diving into the fascinating world of evaluating LLM performance.\n\nEvaluating LLM performance can be a tricky business, but don't worry, we've got you covered. We'll be discussing some of the most popular metrics used to evaluate LLM performance, such as perplexity and BLEU score. And we'll be sharing some best practices for interpreting these metrics.\n\nBut it's not all smooth sailing. We'll also be talking about some of the challenges of evaluating LLM performance, such as the need for human evaluation and the potential for biases in the evaluation data. And we'll be discussing some potential solutions to these challenges, such as using multiple evaluation metrics and implementing active learning techniques.\n\nBy the end of this video, you'll have a better understanding of how to evaluate the performance of LLMs and some practical skills for working with this technology. So let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-26"}}
{"video": {"title": "Optimizing Agentic RAG Performance with LlamaIndex", "transcript": "####Optimizing Agentic RAG Performance with LlamaIndex\nby Jerry Liu - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Agentic RAG enthusiasts! I'm Jerry Liu and welcome back to our thrilling journey into the world of Agentic RAG with LlamaIndex.\n\nToday, we're diving headfirst into the exciting topic of optimizing the performance of our Agentic RAG. Because who doesn't love a speedy and efficient agent?\n\nWe'll kick things off by demystifying the factors that influence the performance of our Agentic RAG.\n\nThen, we'll roll up our sleeves and learn how to leverage LlamaIndex's performance optimization tools to turbocharge our agent's speed and efficiency.\n\nAnd finally, we'll share some pro tips for optimizing Agentic RAG performance like a boss.\n\nSo, are you ready to take your Agentic RAG to the next level with LlamaIndex? Let's do this!\n\nRemember, practice makes perfect. So keep trying, keep building, and most importantly, keep having fun!\n\nThanks for watching and don't forget to like, share, and subscribe for more mind-blowing content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-15"}}
{"video": {"title": "Building an LSTM from Scratch", "transcript": "####Building an LSTM from Scratch\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, AI enthusiasts! It's your favorite AI guide, and today we're embarking on an exciting journey to build a Long Short-Term Memory (LSTM) network from scratch.\n\nWe'll kick things off with the fundamentals of LSTMs, including memory cells, gates, and the constant error carousel. Then, we'll roll up our sleeves and get our hands dirty building our own LSTM using Python and TensorFlow.\n\nBy the time we wrap up this video, you'll have your very own LSTM and will have applied it to a real-world scenario.\n\nSo, are you ready to build your own LSTM? Let's get this party started!\n\nBut wait, before we dive in, remember that this video is part of our Deep Learning Specialization. If you're new to the field, you might want to start with the basics first.\n\nAnd that's a wrap for today! I hope you had as much fun building your own LSTM as I did. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and exploring the world of AI!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2023-04-20"}}
{"video": {"title": "Building Your Own Chatbot with ChatGPT and Prompt Engineering", "transcript": "####Building Your Own Chatbot with ChatGPT and Prompt Engineering\nby Isa Fulford, Andrew Ng - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're going to have a blast building our very own chatbot using ChatGPT and prompt engineering. If you're a beginner with basic Python skills, you're in the right place!\n\nFirst things first, let's talk about what makes a good chatbot. It's all about understanding user input and generating relevant responses. And that's where prompt engineering comes in.\n\nLet's start by designing some prompts for our chatbot. Remember, the key to good prompts is to be clear, concise, and specific. Let's see some examples and craft our own prompts.\n\nNow, let's use the OpenAI API to bring our chatbot to life. We'll see how to send our prompts to the API and get responses that we can use in our chatbot.\n\nIt's time to test our chatbot. Let's see how it handles different inputs and how we can improve its responses with prompt engineering.\n\nAnd that's it! You've just built your own chatbot with ChatGPT and prompt engineering. Remember, the key to a good chatbot is iteration. So keep refining your prompts and improving your chatbot.\n\nThanks for watching and happy coding! And a big thank you to our partners at OpenAI for making this possible.\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-25"}}
{"video": {"title": "Diving Deep into Multimodal Search Techniques", "transcript": "####Diving Deep into Multimodal Search Techniques\nby Sebastian Witalec - 2022-10-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, Sebastian here! Today, we're diving deep into the exciting world of multimodal search techniques. Are you ready to discover the latest strategies and tools to enhance your search capabilities and stay ahead of the curve? Let's get started!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-17"}}
{"video": {"title": "TensorFlow: Federated Learning for Privacy", "transcript": "####TensorFlow: Federated Learning for Privacy\nby Laurence Moroney - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Laurence Moroney, and today we're diving into the world of federated learning with TensorFlow. It's a game-changer for privacy in machine learning, and I can't wait to share it with you!\n\n[Video hook and introduction]\n\nImagine being able to train models on device data without ever compromising privacy. That's where federated learning comes in. It's a decentralized approach to machine learning that's revolutionizing the way we handle data.\n\n[Body content]\n\nWith TensorFlow Federated, you can make this a reality in your projects. It's an open-source framework that's easy to use and packed with features. You'll be able to build and train models on decentralized data in no time.\n\n[Conclusion and call to action]\n\nSo, what are you waiting for? Start exploring federated learning and take your machine learning projects to the next level. Remember, the key to success is to keep learning, keep innovating, and most importantly, happy coding!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-04-05"}}
{"video": {"title": "Data Extraction Magic: Turning Natural Language into Structured Data", "transcript": "####Data Extraction Magic: Turning Natural Language into Structured Data\nby Jiantao Jiao, Venkat Srinivasan - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Jiantao Jiao and welcome back to our series on function-calling and data extraction with LLMs. Today, we're diving into the magical world of data extraction and how you can use LLMs to transform natural language into structured data.\n\nImagine being able to extract valuable insights from real-world data and make it usable for analysis. Sounds exciting, right? Well, that's exactly what we're going to cover in this video.\n\nWe'll start with the basics and then move on to more advanced techniques. By the end of this video, you'll be able to extract data from a variety of sources and formats like a pro.\n\nBut remember, practice makes perfect. So, don't just watch the video. Try out the examples yourself and experiment with different data sources.\n\nAnd if you have any questions, feel free to leave them in the comments. We're here to help you unlock the full potential of data extraction with LLMs.\n\nSo, are you ready to turn natural language into structured data and become a data extraction master? Let's get started!\n\nDon't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-03-25"}}
{"video": {"title": "Building a Router Agent for Q&A and Summarization", "transcript": "####Building a Router Agent for Q&A and Summarization\nby Jerry Liu - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, Jerry Liu here, and today we're diving into the world of Agentic RAG systems. We're going to talk about one of the most versatile types of agents: the router agent.\n\nThat's right, we're going to learn how to build a router agent that can handle both Q&A and summarization tasks. Because sometimes, you need an agent that can do it all.\n\nFirst, we'll go over the basics of router agents. It's like learning the rules of the game before you start playing.\n\nNext, we'll talk about how to build a router agent for Q&A tasks. Because sometimes, you need an agent that can answer your questions.\n\nThen, we'll discuss how to extend this agent to handle summarization tasks. Because sometimes, you need an agent that can summarize your data.\n\nAnd finally, we'll go over some tips and tricks for getting the most out of your router agent.\n\nSo, are you ready to build your own router agent? Let's get started!\n\nRemember, building a router agent is all about flexibility. So, don't be afraid to experiment and find what works best for you.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-10"}}
{"video": {"title": "Quantization Fundamentals: A Beginner's Guide with Hugging Face", "transcript": "####Quantization Fundamentals: A Beginner's Guide with Hugging Face\nby Younes Belkada, Marc Sun - 2023-02-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and welcome to our beginner's guide on quantization with Hugging Face!\n\nIn this video, we'll be exploring how to compress models using the Hugging Face Transformers library and the Quanto library.\n\nBut first, what is quantization? It's a technique used to reduce the size of a model, making it more efficient and faster, without compromising its accuracy.\n\nWe'll start by discussing linear quantization, a straightforward and effective method for model compression. It works by lowering the precision of the weights in your model, resulting in a smaller model size and quicker inference times.\n\nNext, we'll walk you through the process of quantizing open-source multimodal and language models. I'll be there to guide you every step of the way, so don't worry if you're new to this.\n\nBy the end of this video, you'll have the skills to quantize any open-source model using Hugging Face and Quanto.\n\nThanks for tuning in, and remember to hit that like button, share this video, and subscribe for more AI and machine learning content. Until next time!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-20"}}
{"video": {"title": "Harnessing the Power of AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####Harnessing the Power of AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Harrison Chase, the founder of LangChain, and I'm thrilled to have Rotem Weiss, the founder of Tavily, with me today. We're about to show you how to build agentic AI workflows using LangGraph and Tavily's agentic search.\n\nFirst, let's dive into LangGraph's components and see how they make it a breeze to develop, debug, and maintain AI agents. LangGraph is an open-source framework that makes creating more controllable agents a walk in the park.\n\nNow, let's take it up a notch by integrating Tavily's agentic search capabilities. This will enhance your agent's knowledge and performance, making it more efficient and effective.\n\nDon't worry if you're not a Python pro. This course is designed for those with intermediate Python knowledge. We'll guide you through each step, making sure you understand the concepts and how to apply them.\n\nAnd the best part? You'll be learning directly from us, the founders of LangChain and Tavily. We'll share our insights, tips, and tricks to help you make the most of these powerful tools.\n\nSo, are you ready to change the game in building AI agents? Let's get started! Remember, practice makes perfect. The more you work with these tools, the better you'll become.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-15"}}
{"video": {"title": "Prototyping Your ML Production System", "transcript": "####Prototyping Your ML Production System\nby Andrew Ng - 2022-01-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, ML enthusiasts! Andrew Ng here, and today we're diving into the exciting world of prototyping your ML production system.\n\nThink of prototyping as building a mini version of your ML system. It's a golden opportunity to test your ideas, spot any issues, and make improvements before you go live.\n\nWe'll discuss how to create a prototype, test it, and iterate based on feedback. We'll also cover common pitfalls and how to avoid them.\n\nRemember, prototyping is all about learning and improving. So, don't be afraid to make mistakes - that's how we grow!\n\nJoin me in our next video as we continue our journey into ML production systems. Don't forget to like, share, and subscribe for more insightful content. Until next time, keep exploring and happy prototyping!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-01-08"}}
{"video": {"title": "Building Systems with the ChatGPT API", "transcript": "####Building Systems with the ChatGPT API\nby Isa Fulford - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford, and today we're embarking on an exciting journey to explore the world of building systems with the ChatGPT API. Are you ready to automate workflows, chain LLM calls, and get better outputs from LLMs? Let's dive right in!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-15"}}
{"video": {"title": "Mastering AI with Hugging Face: A Practical Guide", "transcript": "####Mastering AI with Hugging Face: A Practical Guide\nby Maria Khalusova, Marc Sun, Younes Belkada - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc, and today we're going to master AI with Hugging Face in this practical guide.\n\nHugging Face is an open-source platform that simplifies the process of building AI applications. So, let's dive in.\n\nFirst, we'll find a model on the Hugging Face Hub. You can filter models based on tasks, rankings, and memory requirements. It's like picking a tool for your AI journey.\n\nNext, we'll use the transformers library to implement the model. With just a few lines of code, you can perform text, audio, image, and multimodal tasks. It's like having your own AI assistant.\n\nFinally, we'll share our AI app. With a user-friendly interface or via API, you can run it on the cloud using Gradio and Hugging Face Spaces. It's like deploying your own AI product.\n\nSo, are you ready to master AI with Hugging Face? Remember, the best way to learn is by doing. So, go ahead, explore the Hugging Face Hub, play around with the models, and who knows, you might just create the next AI marvel.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########\n\nPositive Points:\n\n- Clear introduction of the topic and benefits of Hugging Face.\n- Use of active voice and simple language.\n- Encouragement for the audience to try out the platform.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-03-22"}}
{"video": {"title": "Quantization 101: Shrinking Models with Hugging Face and Quanto", "transcript": "####Quantization 101: Shrinking Models with Hugging Face and Quanto\nby Younes Belkada, Marc Sun - 2023-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Younes Belkada, and today we're going to have some fun with model quantization using Hugging Face and Quanto.\n\nBut first, let's talk about what quantization is. In a nutshell, it's the process of making your models smaller and faster without sacrificing too much accuracy.\n\nToday, we'll be using the Hugging Face Transformers library and the Quanto library to quantize open-source models. Don't worry if you're new to this, we'll be taking it step by step.\n\nLet's start with linear quantization, a simple yet effective method for compressing models. It works by reducing the precision of the weights in your model, which leads to a smaller model size and faster inference times.\n\nNow, let's get our hands dirty and practice quantizing some open-source multimodal and language models. Don't worry, I'll be guiding you through each step of the process.\n\nBy the end of this video, you'll have a solid understanding of how to quantize any open-source model using Hugging Face and Quanto.\n\nThanks for watching, and don't forget to like, share, and subscribe for more content on AI and machine learning. See you in the next one!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-15"}}
{"video": {"title": "Unleashing the Power of ChatGPT with Prompt Engineering", "transcript": "####Unleashing the Power of ChatGPT with Prompt Engineering\nby Isa Fulford, Andrew Ng - 2023-03-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're going to unlock the full potential of ChatGPT through prompt engineering. If you're a beginner with a basic understanding of Python, you're in luck!\n\nFirst things first, what is prompt engineering and why is it so important? Prompt engineering is the art of designing effective inputs for language models like ChatGPT. It's crucial because it can greatly influence the output.\n\nLet's dive into some prompt engineering best practices. First, be explicit and thorough with your prompts. The more information you provide, the better ChatGPT can understand and deliver. Second, iteration is your friend. Prompt engineering is a process of refinement, so don't hesitate to try different approaches.\n\nNow, let's explore some novel ways to use LLMs. Did you know they can summarize, infer, transform, and expand text? Let's build our own custom chatbot using the OpenAI API.\n\nTime for some hands-on practice. Let's write and refine some prompts together. Keep in mind, clarity and iteration are your best friends.\n\nTo sum up, prompt engineering is a powerful tool for application development with ChatGPT. With these best practices and some practical experience, you're well on your way to mastering prompt engineering. So, let's get started! And remember, the more you practice, the better you'll get.\n\nThanks for watching and happy prompting! Don't forget to like, share, and subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-17"}}
{"video": {"title": "Training and Tuning LLMs for Generative AI", "transcript": "####Training and Tuning LLMs for Generative AI\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-02-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Shelbee Eigenbrode here, and today we're diving into the exciting world of training and tuning LLMs for generative AI.\n\nFirst, we'll cover the basics of training LLMs, including data preprocessing, model architecture, and hyperparameter tuning. We'll also discuss the importance of validation and testing in the training process to ensure that our models are accurate and reliable.\n\nBut that's not all! We'll also explore how to fine-tune LLMs for specific use-cases, from generating product descriptions to creating personalized chatbots. And we'll touch on the ethical considerations of generative AI, including responsible AI practices and how to avoid bias in our models.\n\nBy the end of this video, you'll have the practical skills and knowledge to train and tune LLMs for generative AI. So, let's get started! See you in the course.\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-02-25"}}
{"video": {"title": "Controlling Your Agentic RAG", "transcript": "####Controlling Your Agentic RAG: Mastering the Art of Command\nby Jerry Liu - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Jerry Liu, and today we're diving into the exciting world of controlling your Agentic RAG system.\n\nThat's right, we're going to learn how to make your agent dance to your tune. Because sometimes, you need your agent to follow your lead.\n\nFirst up, we'll explore how to give your agent instructions. It's like giving your agent a to-do list, but way cooler.\n\nNext, we'll delve into how to monitor your agent's progress. Because sometimes, you need to keep an eye on your agent to make sure it's not slacking off.\n\nThen, we'll discuss how to adjust your agent's behavior. Because sometimes, your agent needs a little nudge in the right direction.\n\nAnd finally, we'll share some tips and tricks for getting the most out of your agent.\n\nSo, are you ready to take control of your Agentic RAG system? Let's get started!\n\nRemember, controlling your agent is all about communication. So, don't be afraid to tell your agent exactly what you want it to do.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-05"}}
{"video": {"title": "Training and Tuning Methods in Generative AI", "transcript": "####Training and Tuning Methods in Generative AI\nby Shelbee Eigenbrode - 2022-01-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Shelbee Eigenbrode, and today we're diving into the fascinating world of Generative AI. We'll be exploring the essential training and tuning methods that can help you optimize your models for better performance and output quality. So, buckle up and get ready to level up your AI skills with these advanced techniques!\n\nFirst, let's talk about the importance of training data. Without high-quality data, your model is like a car without gas. We'll discuss how to prepare and preprocess your data for optimal results.\n\nNext, we'll delve into the various training algorithms used in Generative AI, such as Maximum Likelihood Estimation and Reinforcement Learning. We'll also cover some of the latest techniques, like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs).\n\nBut wait, there's more! We'll also be discussing the art of tuning your models. This is where the magic happens, and where you can really make your models shine. We'll cover hyperparameter tuning, regularization, and more.\n\nSo, are you ready to take your Generative AI skills to the next level? Let's get started!\n\n#### END TRANSCRIPT ########", "author": "Shelbee Eigenbrode", "publication_date": "2022-01-17"}}
{"video": {"title": "Securing Multimodal Search Applications", "transcript": "####Securing Multimodal Search Applications\nby Sebastian Witalec - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Sebastian Witalec here, and today we're diving into the world of multimodal search applications. But we're not just talking about building them, we're talking about securing them!\n\nNow, you might be thinking, \"Why should I care about security?\" Well, let me tell you, it's not just about protecting your data. It's about protecting your users' data, too. And in today's digital age, that's more important than ever.\n\nSo, buckle up and get ready to learn about some powerful strategies to secure your multimodal search application. We'll be talking about data encryption, access control, and more. And don't worry, we'll keep it simple and fun.\n\nBut that's not all! We'll also be discussing how to monitor the security of your application and how to respond to common security threats. Because let's face it, no application is completely secure. But with the right tools and knowledge, you can make it as secure as possible.\n\nSo, are you ready to take your multimodal search application to the next level? Let's do this! And remember, if you have any questions, don't be shy. Leave a comment and let's learn together.\n\nAnd before you go, don't forget to like, share, and subscribe for more exciting content. Trust me, you won't want to miss what's coming next. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2023-04-15"}}
{"video": {"title": "Machine Learning Math: It's Not as Scary as You Think", "transcript": "####Machine Learning Math: It's Not as Scary as You Think\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! It's your favorite host, back with another exciting episode. Today, we're demystifying the math behind Machine Learning. Don't worry, we'll make it fun and easy to understand.\n\nFirst, we'll dive into linear regression. It's a simple yet powerful tool for predicting numbers. We'll learn about the equation of a line and how to find the best line that fits our data.\n\nNext, we'll explore logistic regression. It's like linear regression, but for predicting categories instead of numbers. We'll learn about the sigmoid function and how it helps us make predictions.\n\nBut wait, there's more! We'll also cover gradient descent, a method for finding the best values for our model. And we'll do it all with intuitive visuals and real-world examples.\n\nRemember, the goal isn't to become a math genius, but to understand the concepts well enough to use them in Machine Learning. So, are you ready to conquer the math behind Machine Learning? Let's do this! And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-01-15"}}
{"video": {"title": "Building AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####Building AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, co-founder of LangChain, and I'm Rotem Weiss, founder of Tavily. Today, we're going to take you on an exciting journey into the world of AI agents. We'll show you how to leverage LangGraph and Tavily's agentic search to build powerful workflows. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2022-10-15"}}
{"video": {"title": "Mastering AI Agentic Design Patterns with AutoGen", "transcript": "####Mastering AI Agentic Design Patterns with AutoGen\nby Chi Wang, Qingyun Wu - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Chi Wang, and I'm Qingyun Wu, and today we're embarking on an exciting journey into the world of AI agentic design patterns with AutoGen. Are you ready to build multi-agent systems with diverse roles and capabilities for implementing complex AI applications? Let's do this!\n\nIn this video, we'll show you how to use the AutoGen framework to automate workflows and implement agentic design patterns like Reflection, Tool use, Planning, and Multi-agent collaboration. If you have basic Python coding experience and you're interested in leveraging AutoGen effectively, this course is perfect for you.\n\nJoin us as we learn directly from the creators of AutoGen, Chi Wang and Qingyun Wu. We'll make sure to keep things fun, engaging, and easy to understand. Get ready to take your AI applications to the next level with AutoGen!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2022-10-15"}}
{"video": {"title": "ChatGPT Prompt Engineering: The Ultimate Guide for Beginners", "transcript": "####ChatGPT Prompt Engineering: The Ultimate Guide for Beginners\nby Isa Fulford, Andrew Ng - 2023-03-18\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're diving into the captivating world of prompt engineering for ChatGPT. If you're a beginner with some Python skills, you're in the perfect place!\n\nLet's kick things off with the basics. What is prompt engineering and why should you care? Prompt engineering is the craft of creating effective inputs for language models like ChatGPT. It's crucial because it can drastically affect the quality of the output.\n\nNow, let's chat about some prompt engineering best practices. First, be precise and detailed with your prompts. The more context you provide, the better ChatGPT can generate the desired output. Second, iterate, iterate, iterate. Prompt engineering is all about trial and error, so don't be shy to experiment.\n\nLet's explore some innovative ways to leverage LLMs. Did you know they can summarize, infer, transform, and expand text? Let's create our own custom chatbot using the OpenAI API.\n\nNow, let's get our hands dirty. Let's practice writing and refining prompts together. Remember, clarity and iteration are key.\n\nIn conclusion, prompt engineering is a game-changer for developing applications with ChatGPT. With these best practices and some hands-on experience, you're well on your way to becoming a prompt engineering pro. So, what are you waiting for? Start prompting! And remember, practice makes perfect.\n\nThanks for tuning in and happy prompting! Don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-18"}}
{"video": {"title": "Value Creation with Generative AI", "transcript": "####Value Creation with Generative AI\nby Shelbee Eigenbrode - 2022-10-13\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to explore the exciting world of generative AI and how it's revolutionizing businesses? Well, buckle up because I'm your host, Shelbee Eigenbrode, and I'm thrilled to take you on this journey.\n\nFirst things first, let's talk about what generative AI is and why it's creating a buzz in the tech world. Trust me, you won't want to miss this!\n\nBut wait, there's more! We'll also dive into the latest research on Gen AI and see how companies are leveraging these cutting-edge solutions to create value. And don't worry, I'll translate all the jargon into simple, easy-to-understand language.\n\nSo, are you ready to learn how generative AI can take your business to the next level? Let's get started!\n#### END TRANSCRIPT ########", "author": "Shelbee Eigenbrode", "publication_date": "2022-10-13"}}
{"video": {"title": "Elevate Your LLM Capabilities with Function-Calling and Data Extraction", "transcript": "####Elevate Your LLM Capabilities with Function-Calling and Data Extraction\nby Jiantao Jiao, Venkat Srinivasan - 2022-04-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao and today we're taking your Language Learning Model, or LLM, to the next level with function-calling and data extraction. If you're already familiar with LLMs and have some basic Python knowledge, you're in luck!\n\nLet's kick things off with function-calling. It's a game-changer for extending your LLMs with custom functionality. Imagine teaching your LLM to make calls to external functions. Sounds fun, right?\n\nNext, we'll dive into data extraction. We'll learn how to extract structured data from natural language inputs, making real-world data usable for analysis.\n\nBut wait, there's more! We've teamed up with Nexusflow to bring you an end-to-end application that processes customer service transcripts using LLMs. You'll see how function-calling and data extraction can enhance your application capabilities.\n\nRemember, practice makes perfect. So, don't just watch, get involved! Try out the techniques we'll cover and see how they can boost your LLM and agent applications.\n\nThanks for tuning in and happy learning! Don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, this is Venkat Srinivasan signing off.\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-04-12"}}
{"video": {"title": "Mastering Quantization: A Deep Dive into Advanced Techniques", "transcript": "####Mastering Quantization: A Deep Dive into Advanced Techniques\nby Marc Sun, Younes Belkada - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc Sun, and today we're diving headfirst into the fascinating world of quantization. If you've already taken our Quantization Fundamentals course, you're in the perfect spot to build on that knowledge.\n\nFirst, we're exploring different variants of Linear Quantization. We'll compare symmetric and asymmetric modes, and discuss the pros and cons of each. We'll also look at different granularities, like per tensor, per channel, and per group quantization.\n\nNext, we're getting our hands dirty. We'll build a general-purpose quantizer in Pytorch. This tool can quantize the dense layers of any open source model, giving you up to 4x compression on dense layers. Pretty neat, right?\n\nBut we're not stopping there. We're also going to implement weights packing. This technique lets us pack four 2-bit weights into a single 8-bit integer. It's like a magic trick for your models.\n\nAnd guess what? We're partnering with Hugging Face for this adventure. So you know you're getting top-notch resources and guidance.\n\nRemember, this course is designed for an intermediate skill level. So if you're new to quantization, I recommend checking out our Quantization Fundamentals course first.\n\nThat's it for today's preview. If you're ready to level up your quantization skills, let's get started. And don't forget to like, share, and subscribe for more great content. See you in the course!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-01-01"}}
{"video": {"title": "Evaluating Vulnerabilities in LLM Applications: A Red Teaming Guide", "transcript": "####Evaluating Vulnerabilities in LLM Applications: A Red Teaming Guide\nby Matteo Dora, Luca Martial - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Matteo Dora and welcome back to our series on red teaming for LLM applications. Today, we're diving into the exciting world of vulnerability evaluation.\n\nEvaluating vulnerabilities is like being a detective, but for code. It's all about understanding the potential impact and likelihood of each issue. This helps us prioritize our efforts and focus on the most critical vulnerabilities.\n\nSo, how do we evaluate a vulnerability? First, we consider the potential impact. How bad would it be if this issue occurred? Would it compromise user data? Would it lead to incorrect outputs?\n\nNext, we consider the likelihood. How likely is it that this issue will occur? Is it a common problem or a rare edge case?\n\nRemember, not all vulnerabilities are created equal. A high-impact, low-likelihood issue might be less critical than a low-impact, high-likelihood issue.\n\nStay tuned for our next video where we'll talk about how to address these vulnerabilities. And don't forget to check out Giskard's open-source library for tools to help you with this process.\n\nThanks for watching. Don't forget to like, share, and subscribe for more content on LLM applications. See you next time!\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-03-25"}}
{"video": {"title": "LangChain and Data Privacy: Keeping Your Information Safe", "transcript": "####LangChain and Data Privacy: Keep Your Information Secure\nby Harrison Chase - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, the creator of LangChain, and today we're diving into the world of data privacy. We'll explore how to keep your information safe when using LangChain.\n\nAs you know, LangChain is designed to help you build chatbots that can interface with your private data and documents. But with great power comes great responsibility, and it's crucial to ensure that your data is kept safe and secure.\n\nIn this video, we'll cover the basics of data privacy and some best practices for keeping your information safe when using LangChain. We'll start with an overview of data privacy and some of the most common data privacy regulations, such as GDPR and CCPA.\n\nNext, we'll dive into some examples of how to use LangChain's built-in security features to keep your data safe. We'll cover topics such as data encryption, access controls, and data retention policies.\n\nBy the end of this video, you'll have a solid understanding of how to use LangChain safely and securely, and how to keep your private data and documents protected.\n\nSo, are you ready to get started? Let's dive in and start exploring the world of LangChain and data privacy!\n\nRemember, if you have any questions or need help along the way, feel free to reach out to me on social media or through the LangChain website.\n\nThanks for watching, and happy coding!\n\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-04-20"}}
{"video": {"title": "Quantization Unleashed: Symmetric vs. Asymmetric Mode", "transcript": "####Quantization Unleashed: Symmetric vs. Asymmetric Mode\nby Marc Sun, Younes Belkada - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! I'm Younes Belkada, and today we're diving into the world of Linear Quantization. Specifically, we're comparing symmetric and asymmetric modes.\n\nFirst up, symmetric mode. This is where the zero point is smack dab in the middle of the range. It's a perfect fit for models with a balanced mix of positive and negative weights.\n\nBut what if your model is a bit lopsided? That's where asymmetric mode comes in. It shifts the zero point to one end of the range, making it ideal for models with mostly positive or negative weights.\n\nSo, which one should you use? Well, that's the million-dollar question, isn't it? But don't worry, we're going to show you how to try out both and compare the results.\n\nAre you ready to unleash the power of quantization? Let's get started!\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content. Until next time, keep exploring the exciting world of AI!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-03-20"}}
{"video": {"title": "RNNs and LSTMs: Unlocking the Power of Sequential Data", "transcript": "####RNNs and LSTMs: Unlocking the Power of Sequential Data\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your friendly guide and today we're diving into the fascinating world of Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTMs).\n\nRNNs and LSTMs are the superheroes of sequential data. They're brilliant at processing data that comes in a sequence, like time series or sentences. They've got a superpower - they can remember previous inputs, which helps them understand the context of the current input. This makes them perfect for tasks like language translation and speech recognition.\n\nBut how do they work? It's all about loops. RNNs have a loop that allows information to persist from one step in the sequence to the next. LSTMs are a special kind of RNN that can learn to forget previous inputs, which helps them handle long-term dependencies.\n\nNow, I know this might sound complex, but don't worry. With some practice and patience, you'll be building your own RNNs and LSTMs in no time.\n\nSo, what are you waiting for? Let's embark on your sequential data journey together. And remember, if you ever get stuck, I'm here to help.\n\nThanks for watching, and happy learning!\n\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-01-15"}}
{"video": {"title": "Building a Language Translation App with NLP and Hugging Face", "transcript": "####Building a Language Translation App with NLP and Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, Assistant here! Today, we're diving into the fascinating world of language translation with NLP. Imagine being able to communicate with anyone, anywhere in the world. That's the power of NLP!\n\nFirst, let's break down how language translation works. It's all about teaching a machine to understand the structure and meaning of one language, and then translate it into another.\n\nWith Hugging Face, we can build a language translation app in just a few easy steps. We'll show you how to prepare your data, train your model, and deploy your app.\n\nBut wait, there's more! We'll also cover some advanced techniques for improving your translations, like beam search and fine-tuning. And don't worry, we'll explain everything in a clear and simple way, so you won't get lost in the details.\n\nSo, are you ready to build your own language translation app with NLP and Hugging Face? Let's get started!\n\nThat's it for today's video. If you found it helpful, be sure to give it a thumbs up and subscribe for more content. And if you're ready to start building your own language translation app, check out the links in the description for some great resources. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-03-25"}}
{"video": {"title": "Mastering Generative AI with Language Models", "transcript": "####Mastering Generative AI with Language Models\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Antje Barth, and today we're going on an exciting journey into the world of Generative AI with Language Models, or LLMs!\n\nFirst things first, what's Generative AI and how does it work? Generative AI is a type of artificial intelligence that can create new content, like images, music, or text, by learning patterns from existing data. LLMs are a specific type of Generative AI that focus on generating text.\n\nAt the core of LLMs is the transformer architecture, which allows the model to process input text in parallel and generate output text one word at a time. This architecture has revolutionized the field of natural language processing and enabled the creation of powerful LLMs like GPT-3.\n\nNow, let's talk about training, tuning, and deploying LLMs. Training an LLM involves feeding it large amounts of text data and using techniques like backpropagation to adjust the model's weights and improve its accuracy. Tuning involves adjusting the model's hyperparameters to optimize its performance on specific tasks. And deployment involves integrating the model into a larger system, such as a chatbot or content generation tool.\n\nBut what about the challenges and opportunities of Generative AI? We'll hear from researchers in the field about the ethical considerations of creating AI that can generate realistic text, as well as the potential applications of LLMs in fields like healthcare, finance, and entertainment.\n\nBy the end of this video series, you'll have a solid foundation in Generative AI with LLMs, practical skills for training and deploying LLMs, and a functional understanding of how this technology is being used to create value in the real world. You'll also hear from expert AWS AI practitioners who actively build and deploy AI in business use-cases today.\n\nSo, are you ready to dive into the world of Generative AI with LLMs? Let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-01"}}
{"video": {"title": "Preprocessing Unstructured Data for LLM Applications", "transcript": "####Preprocessing Unstructured Data for LLM Applications: Unlocking the Power of Diverse Data Types\nby Matt Robinson - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Matt Robinson, and today we're diving into the exciting world of preprocessing unstructured data for LLM applications. Are you ready to supercharge your RAG system and unlock the full potential of diverse data types? Let's get started!\n\nWhen it comes to extracting and normalizing content from a wide variety of document types, such as PDFs, PowerPoints, and HTML files, there are a few key techniques you need to master. By enriching your content with metadata, you can enhance your retrieval augmented generation (RAG) results and support more nuanced search capabilities.\n\nBut wait, there's more! Exploring document image analysis techniques like layout detection and vision and table transformers can help you preprocess PDFs, images, and tables like a pro. Trust me, your LLM applications will thank you.\n\nSo, if you're ready to take your data processing skills to the next level and impress your colleagues, stay tuned for some valuable insights. Let's do this!\n#### END TRANSCRIPT ########", "author": "Matt Robinson", "publication_date": "2022-10-15"}}
{"video": {"title": "Quantization Fundamentals with Hugging Face", "transcript": "####Quantization Fundamentals with Hugging Face\nby Younes Belkada, Marc Sun - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, quantization enthusiasts! Today, we're diving into the fascinating world of model compression using the Hugging Face Transformers library and the Quanto library. Are you ready to shrink your models without losing too much accuracy? Let's do this! Quantization is a game-changer, allowing us to reduce our model's size by converting its weights from floating point numbers to lower precision integers. This is perfect for deploying models on devices with limited resources, like your smartphone or an edge device. Today, we're focusing on linear quantization, a simple yet effective method for model compression. Linear quantization maps floating point numbers to a fixed set of integer values, making our weights more compact. The Hugging Face Transformers library makes quantizing open source models a breeze. With just a few function calls, you can convert your models to a quantized format. And the Quanto library offers tools for quantization-aware training, allowing you to fine-tune your models for quantized inference. Together, these libraries make experimenting with different quantization techniques and finding the optimal configuration for your models a piece of cake. Whether you're interested in deploying models on edge devices or simply want to reduce the size of your models, quantization is a must-have skill. So, let's get started and start compressing some models!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2022-10-15"}}
{"video": {"title": "Understanding Machine Learning Algorithms", "transcript": "####Understanding Machine Learning Algorithms: A Fun and Simple Approach\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, welcome back! Today, we're going to demystify Machine Learning algorithms. Don't worry, we'll make it enjoyable and easy to understand.\n\nThink of algorithms as recipes that the computer follows to learn from data. We have three main flavors: supervised learning, unsupervised learning, and reinforcement learning.\n\nSupervised learning is like teaching a child with flashcards. We feed the computer labeled data and it learns to make predictions.\n\nUnsupervised learning is like giving a child a box of toys and letting them sort it out. We give the computer unlabeled data and it finds patterns on its own.\n\nReinforcement learning is like a child learning to ride a bike. The computer learns by trial and error, receiving rewards for good behavior and penalties for bad.\n\nWe'll be diving deeper into each of these in future videos, so stay tuned!\n\nRemember, the key to mastering algorithms is practice. So, keep coding and experimenting.\n\nThat's it for today's video. If you found this helpful, give us a thumbs up and don't forget to subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-01-15"}}
{"video": {"title": "Mastering Prompts with LangChain", "transcript": "####Mastering Prompts with LangChain\nby Harrison Chase, Andrew Ng - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, LLM enthusiasts! Harrison Chase here, and welcome back to our series on LangChain for LLM application development.\n\nToday, we're diving into one of the most powerful features of LangChain: prompts.\n\nPrompts are the way you communicate with your LLM. They tell the model what to do and how to do it. But crafting the perfect prompt is both an art and a science.\n\nWe'll start with the basics and then move on to more advanced techniques. By the end of this video, you'll be a prompt master.\n\nSo, let's get started. Remember, practice makes perfect, so don't be afraid to experiment with your prompts.\n\nThanks for watching. Don't forget to like, comment, and subscribe for more content on LLM application development. And as always, stay curious and keep learning. See you next time.\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-03-20"}}
{"video": {"title": "Mistral AI: Wrapping Up and Looking Ahead", "transcript": "####Mistral AI: Wrapping Up and Looking Ahead\nby Younes Belkada, Marc Sun - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Marc Sun here, and welcome back to our series on Mistral AI!\n\nToday, we're going to wrap up our series and look ahead to what's next.\n\nOver the past few weeks, we've explored Mistral's open-source and commercial models. We've learned how to use Mistral's JSON mode to generate structured LLM responses. And we've discovered how to use Mistral\u2019s API to call user-defined functions for enhanced LLM capabilities.\n\nBut this is just the beginning. Mistral AI is constantly evolving, and there's always more to learn.\n\nSo, what's next? Well, we're going to continue exploring Mistral AI and all it has to offer. We'll be diving deeper into its features and capabilities, and we'll be sharing more tips and tricks to help you get the most out of Mistral AI.\n\nIf you have any questions or suggestions for what you'd like to see next, just let us know. And don't forget to like, share, and subscribe for more updates. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-30"}}
{"video": {"title": "Troubleshooting Multimodal Search Applications", "transcript": "####Troubleshooting Multimodal Search Applications: A Practical Guide\nby Sebastian Witalec - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Sebastian Witalec here, and today we're diving into the world of troubleshooting multimodal search applications.\n\nNow, building a robust multimodal search application is one thing, but ensuring it runs like a well-oiled machine is a whole different ball game. We'll be discussing some common pitfalls in multimodal search applications and how to navigate them.\n\nBut wait, there's more! We'll also be sharing some proactive strategies to prevent these issues from cropping up in the first place.\n\nRemember, our ultimate goal is to create a multimodal search application that not only performs well, is secure, and can handle a ton of data and users, but also runs smoothly. This is especially important in industries where reliability is the name of the game.\n\nSo, let's get started! And if you have any questions, feel free to drop them in the comments. We're all in this learning journey together. And don't forget to hit that like button, share with your friends, and subscribe for more exciting content. Until next time, happy troubleshooting!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2023-04-25"}}
{"video": {"title": "Getting the Most Out of ChatGPT with Prompt Engineering", "transcript": "####Getting the Most Out of ChatGPT with Prompt Engineering\nby Isa Fulford, Andrew Ng - 2023-03-21\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow developers! I'm Isa Fulford, and today we're diving into the exciting world of prompt engineering for ChatGPT. If you've got basic Python skills, you're in the right place.\n\nFirst things first, let's talk about what prompt engineering is and why it matters. It's the art of designing and optimizing inputs for language models like ChatGPT. Why is it crucial? Because the right prompt can make all the difference in getting the results you want.\n\nNow, let's get into some best practices. First up, be clear and specific with your prompts. The more detailed you are, the better ChatGPT can understand what you're asking for. Second, don't be afraid to iterate. Prompt engineering is an iterative process, so try out different prompts and see what works best.\n\nNext, let's explore some new ways to use LLMs, or large language models. Did you know you can use LLMs for summarizing, inferring, transforming, and expanding text? Let's take a look at some examples using the OpenAI API.\n\nNow, it's time for some hands-on practice. We'll walk through writing and iterating on prompts together, and I'll show you how to use the OpenAI API to get results from ChatGPT.\n\nTo wrap up, prompt engineering is a powerful tool for application development with ChatGPT. With these best practices and some hands-on experience, you'll be well on your way to mastering prompt engineering. So go ahead and start experimenting with your own prompts. And who knows, you might even build your own custom chatbot!\n\nThanks for watching, and happy prompt engineering!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-21"}}
{"video": {"title": "Building Agentic RAG with LlamaIndex", "transcript": "####Building Agentic RAG with LlamaIndex\nby Jerry Liu - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and today we're embarking on an exciting journey into the world of building agentic RAG systems with LlamaIndex. Are you ready to create autonomous agents that can navigate and analyze your data like a pro? Let's dive in!\n\nBut first, let me ask you something. Have you ever wished you could develop agents that can handle document Q&A and summarization tasks with ease? Well, today's your lucky day! With LlamaIndex, you'll be able to do just that. But before we get started, make sure you have a basic understanding of Python. Trust me, it'll make this journey a whole lot smoother.\n\nNow, let's jump into the exciting world of agentic RAG systems! Are you ready to revolutionize the way you interact with your data? Let's do this!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2022-10-15"}}
{"video": {"title": "Maximizing the Potential of Llama 2 & 3 Models", "transcript": "####Maximizing the Potential of Llama 2 & 3 Models\nby Amit Sangani - 2023-02-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Amit Sangani and today we're diving into the exciting world of Llama 2 & 3 Models. Are you ready to level up your AI game?\n\nIn this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models. First, we'll take a look at Meta Llama 2 Chat and how you can interact with it to get the most out of your prompts. We'll also explore Code Llama and how it can help you with your coding needs.\n\nBut wait, there's more! We'll also be discussing the importance of building safe and responsible AI applications. That's where Llama Guard comes in. We'll show you how you can use this model to ensure that your AI applications are safe and responsible.\n\nSo, are you ready to maximize the potential of Llama 2 & 3 models? Let's get started!\n\nRemember, practice makes perfect. So, be sure to try out these best practices on your own and see how they work for you. And, if you have any questions or need further clarification, don't hesitate to reach out.\n\nThanks for watching and happy prompting!\n\nBe sure to like, comment, and subscribe for more content like this. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-22"}}
{"video": {"title": "Exploring the Future of Multimodal Search and RAG", "transcript": "####Exploring the Future of Multimodal Search and RAG\nby Sebastian Witalec - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! It's your favorite AI influencer, Sebastian, and today we're diving into the exciting world of multimodal search and RAG. Are you ready to discover the future of AI and its endless possibilities? Let's get started!\n\n[Video hook and introduction]\n\nImagine being able to search for information using not just text, but also images and videos. That's the power of multimodal search, and it's revolutionizing the way we interact with technology. And what about RAG, or Retrieval-Augmented Generation? It's a game-changer in the world of language models, allowing AI to generate more accurate and contextually relevant responses.\n\n[Body content]\n\nIn this video, we'll explore the latest advancements in multimodal search and RAG, and show you how they're being used in real-world applications. We'll also discuss the challenges and opportunities that lie ahead, and what it means for the future of AI.\n\n[Conclusion and call to action]\n\nSo, are you ready to join me on this exciting journey? Let's explore the future of multimodal search and RAG together! And don't forget to like, share, and subscribe for more AI insights and analysis. Until next time, this is Sebastian, signing off.\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-15"}}
{"video": {"title": "Mastering TensorFlow: A Complete Guide to the TensorFlow Developer Professional Certificate", "transcript": "####Mastering TensorFlow: A Complete Guide to the TensorFlow Developer Professional Certificate\nby Laurence Moroney - 2022-11-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Laurence Moroney, and today we're embarking on an exciting journey to master TensorFlow and prepare for the TensorFlow Developer Professional Certificate. Are you ready to level up your AI skills? Let's do this!\n\nTensorFlow is a game-changer when it comes to building scalable AI applications. With this certificate, you'll not only learn how to apply your new skills to real-world projects but also prepare for the Google TensorFlow Certificate exam. If you're an intermediate level developer looking to upskill in AI, you're in the right place. So, grab your coffee, sit back, and let's dive into the world of TensorFlow!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-11-01"}}
{"video": {"title": "Mistral AI: The Ultimate Guide to LLM", "transcript": "####Mistral AI: The Ultimate Guide to LLM\nby Younes Belkada, Marc Sun - 2023-02-16\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Younes Belkada here, and today we're diving headfirst into Mistral AI and its advanced LLM capabilities.\n\nFirst off, Mistral AI offers a range of open-source and commercial models that you can access via web interface or API calls. From Mistral 7B to Mixtral 8x22B, and even commercial models like small, medium, and large, Mistral AI has got you covered.\n\nBut what sets Mistral AI apart is its JSON mode. With JSON mode, you can generate LLM responses in a structured JSON format, making it a breeze to integrate LLM outputs into your larger software applications.\n\nAnd if that's not enough, Mistral's API also lets you call user-defined Python functions for tasks like web searches or retrieving text from databases. This means you can enhance the LLM's ability to find relevant information and answer user queries more accurately.\n\nSo, whether you're just starting out or you're a seasoned pro, Mistral AI has something for everyone. And the best part? It's beginner-friendly, so you don't need any prior experience to get started.\n\nSo, what are you waiting for? Start exploring Mistral AI today and take your LLM capabilities to the next level. And don't forget to check out Mistral AI, our technology partner for this video.\n\nThanks for watching, and stay tuned for more exciting videos on Mistral AI and LLM. I'm Younes Belkada, and I'll see you in the next one.\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-16"}}
{"video": {"title": "Automating Workflows with ChatGPT", "transcript": "####Automating Workflows with ChatGPT\nby Isa Fulford - 2022-10-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Are you ready to take your workflows to the next level? Today, we're diving into the world of large language models and how they can help you build multi-step systems like a pro. Get ready to learn how to split tasks into subtasks and evaluate outputs. Let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-17"}}
{"video": {"title": "Deploying ML Models with TensorFlow", "transcript": "####Deploying ML Models with TensorFlow\nby Laurence Moroney - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, machine learning enthusiasts! Welcome back to my channel. Today, we're going to dive into the exciting world of deploying machine learning models using TensorFlow. I'm your host, Laurence Moroney, and I can't wait to show you how to train and run models in browsers and mobile apps, all while keeping user privacy intact. So, let's get started!\n\nYou've built your model in TensorFlow, now what? Well, TensorFlow makes it a breeze to export your model and run it on various devices. Whether you're targeting a web browser or a mobile app, TensorFlow has got you covered. And the cherry on top? You can even retrain your deployed models without compromising user data. It's a win-win situation!\n\nSo, if you're ready to take your machine learning projects to the next level, join me in this video as we explore the ins and outs of deploying ML models with TensorFlow. And don't forget to like and subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-10-15"}}
{"video": {"title": "Mastering Quantization: Compress Models with Hugging Face and Quanto", "transcript": "####Mastering Quantization: Compress Models with Hugging Face and Quanto\nby Younes Belkada, Marc Sun - 2023-02-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're going to master the art of model quantization with Hugging Face and Quanto.\n\nIn this video, we'll be learning how to compress models using the Hugging Face Transformers library and the Quanto library.\n\nFirst off, let's talk about what quantization is. It's a process that reduces the size of a model, making it more efficient and faster, while maintaining its accuracy.\n\nWe'll kick things off with linear quantization, a simple yet powerful method for model compression. It works by decreasing the precision of the weights in your model, leading to a smaller model size and faster inference times.\n\nThen, we'll dive into quantizing open-source multimodal and language models. I'll be there to guide you through each step, so don't worry if you're a beginner.\n\nBy the end of this video, you'll be a pro at quantizing any open-source model using Hugging Face and Quanto.\n\nThanks for watching, and don't forget to like, share, and subscribe for more AI and machine learning content. See you next time!\n#### END TRANSCRIPT ########\n\nRefined Script:\n\n####Mastering Quantization: Compress Models with Hugging Face and Quanto\nby Younes Belkada, Marc Sun - 2023-02-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're going to master the art of model quantization with Hugging Face and Quanto.\n\nIn this video, we'll be learning how to compress models using the Hugging Face Transformers library and the Quanto library.\n\nFirst off, let's talk about what quantization is. It's a process that reduces the size of a model, making it more efficient and faster, while maintaining its accuracy.\n\nWe'll kick things off with linear quantization, a simple yet powerful method for model compression. It works by decreasing the precision of the weights in your model, leading to a smaller model size and faster inference times.\n\nThen, we'll dive into quantizing open-source multimodal and language models. I'll be there to guide you through each step, so don't worry if you're a beginner.\n\nBy the end of this video, you'll be a pro at quantizing any open-source model using Hugging Face and Quanto.\n\nThanks for watching, and don't forget to like, share, and subscribe for more AI and machine learning content. See you next time!\n\nRemember, with quantization, you'll be able to make your models more efficient and faster, without sacrificing accuracy. So let's get started and become a quantization master!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-25"}}
{"video": {"title": "Prompt Engineering for ChatGPT: Common Pitfalls and How to Avoid Them", "transcript": "Hey there, I'm Isa Fulford and today we're diving into the world of prompt engineering for ChatGPT. If you're a beginner with basic Python skills, you're in the right place!\n\nFirst up, let's talk about the most common pitfall: being too vague. If your prompt is too vague, the model won't know what you're looking for and you'll get unpredictable results. Let's see how to avoid this and make your prompts more effective.\n\nNext, let's talk about being too specific. If your prompt is too specific, you might limit the model's creativity and get less diverse results. Let's see how to find the right balance and get the most out of ChatGPT.\n\nFinally, let's talk about using jargon. If your prompt contains jargon or technical terms, the model might not understand it and you'll get incorrect results. Let's see how to translate jargon into simpler words and make your prompts more accessible.\n\nAnd that's it! You've just learned how to avoid common pitfalls in prompt engineering for ChatGPT. Remember, the key to successful prompt engineering is iteration. So keep refining your prompts and improving your results.\n\nThanks for watching and happy coding! And a big thank you to our partners at OpenAI for their support. Until next time, keep exploring the world of AI and see you in the next video!", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-04-25"}}
{"video": {"title": "Secure AI Inference: The Power of On-Device AI", "transcript": "####Secure AI Inference: The Power of On-Device AI\nby Krishna Sridhar - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're diving into the exciting world of On-Device AI and its security benefits.\n\nImagine having your data stay on your device, enhancing privacy and security for your AI applications. Sounds too good to be true? Well, it's not!\n\nWe'll look at how On-Device AI can help protect your data, and explore best practices for secure AI inference on edge devices.\n\nRemember, use short sentences, write in a conversational style, and use more active voice than passive. Be clear and simple in your writing, and sprinkle in some humor to keep things interesting.\n\nSo, are you ready to secure your AI inference with On-Device AI? Let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2023-04-15"}}
{"video": {"title": "Building Your Own Database Agent", "transcript": "####Building Your Own Database Agent\nby Adrian Gonzalez Sanchez - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Welcome back to our channel. Today, we're embarking on an exciting journey into the world of building your own database agent. I'm your guide, Adrian Gonzalez Sanchez, and I'm thrilled to take you through this beginner-friendly course on interacting with tabular data and SQL databases using natural language. Are you ready to level up your data skills? Let's dive in!\n#### END TRANSCRIPT ########", "author": "Adrian Gonzalez Sanchez", "publication_date": "2022-10-15"}}
{"video": {"title": "Quantization in Depth: A Recap", "transcript": "####Quantization in Depth: A Recap\nby Marc Sun, Younes Belkada - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, quantization enthusiasts! I'm Marc Sun, and today we're diving back into the world of advanced quantization techniques. We've covered a lot of ground, so let's take a moment to review.\n\nFirst, we talked about symmetric and asymmetric modes in Linear Quantization. Then, we discussed different granularities like per tensor, per channel, and per group quantization.\n\nNext, we built a general-purpose quantizer in Pytorch. This quantizer can quantize the dense layers of any open source model, giving you up to 4x compression on dense layers.\n\nFinally, we implemented weights packing. This technique lets us pack four 2-bit weights into a single 8-bit integer, giving us even more data compression.\n\nBut remember, practice makes perfect. So, get out there and start quantizing!\n\nAnd don't forget to like, share, and subscribe for more exciting content. See you in the next video, where we'll be exploring the wild world of quantization-aware training. Until then, happy quantizing!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-10"}}
{"video": {"title": "Pack a Punch: Implementing Weights Packing", "transcript": "####Pack a Punch: Implementing Weights Packing\nby Marc Sun, Younes Belkada - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc Sun, and today we're diving into the world of weights packing!\n\nFirst, we'll explain what weights packing is and why it's a game-changer for model compression. Then, we'll show you how to implement it in Pytorch.\n\nBut wait, there's more! We'll also show you how to combine weights packing with quantization for even more compression.\n\nSo, are you ready to pack a punch with weights packing? Let's get started!\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-05"}}
{"video": {"title": "GANs for Text Generation: Beyond Image Synthesis", "transcript": "####GANs for Text Generation: Beyond Image Synthesis\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-03-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sharon Zhou, and today we're diving into the exciting world of GANs for text generation.\n\n[Video hook and introduction]\n\nYou've heard of GANs for generating realistic images, but did you know they can also be used for text generation? In this video, we'll explore how GANs can generate new text that's similar to the training data.\n\n[Body content]\n\nThe process of using GANs for text generation is similar to the process for image generation. The generator creates new text, while the discriminator tries to tell the difference between real text and the text created by the generator. The two parts work together, with the generator trying to fool the discriminator, and the discriminator trying to correctly identify real text.\n\nBut there are some challenges that are unique to text generation. For example, text is discrete, which means that it's made up of individual words or characters. This can make it difficult to generate coherent and meaningful text.\n\nTo overcome these challenges, researchers have developed techniques like using continuous representations of text or incorporating language models into the GAN.\n\n[Conclusion and call to action]\n\nSo, that's a quick overview of using GANs for text generation. If you want to learn more, check out our other videos on the topic. And if you have any questions or comments, leave them down below. We love hearing from you.\n\nThanks for watching, and we'll see you in the next video.\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-03-17"}}
{"video": {"title": "Introduction to Mathematics for Machine Learning and Data Science", "transcript": "####Introduction to Mathematics for Machine Learning and Data Science\nby Luis Serrano - 2022-10-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Welcome back to our channel. I'm Luis Serrano, your friendly guide in the world of data science and machine learning. Today, we're embarking on an exciting journey into the heart of mathematics, the secret sauce that powers our favorite algorithms.\n\nAre you ready to unlock the mysteries of linear algebra, calculus, and probability? Let's dive in!\n#### END TRANSCRIPT ########", "author": "Luis Serrano", "publication_date": "2022-10-01"}}
{"video": {"title": "TensorFlow: Building Custom Layers and Models", "transcript": "####TensorFlow: Building Custom Layers and Models\nby Laurence Moroney - 2022-04-26\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Laurence Moroney, and today we're going to have some fun exploring how to build custom layers and models in TensorFlow!\n\n[Video hook and introduction]\n\nWhile TensorFlow offers a wide range of pre-built layers and models, sometimes you need to create your own custom components to achieve the best results. So let's dive in and learn how to build custom layers and models with TensorFlow!\n\n[Body content]\n\nFirst, we'll cover the basics of building custom layers in TensorFlow, including how to define the layer's forward pass and backward pass using the TensorFlow API.\n\nNext, we'll walk through the process of building custom models in TensorFlow, using techniques like subclassing the Model class and using the Functional API.\n\nWe'll also cover how to use custom layers within your custom models, and how to save and load custom models for later use.\n\nLastly, we'll discuss some best practices for building custom layers and models, such as using weight regularization, choosing the right activation functions, and monitoring your training progress.\n\n[Conclusion and call to action]\n\nAre you ready to unleash your creativity and build custom layers and models with TensorFlow? Let's get started! Remember, building custom components can make a big difference in the performance of your machine learning models.\n\nIf you found this video helpful, be sure to give it a thumbs up, share it with your friends, and subscribe to our channel for more awesome content. See you in the next video!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-04-26"}}
{"video": {"title": "Prompt Engineering for ChatGPT: Real-World Applications", "transcript": "####Prompt Engineering for ChatGPT: Real-World Applications\nby Isa Fulford, Andrew Ng - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're diving into the exciting world of prompt engineering for ChatGPT. If you're a Python beginner with basic skills, you're in the right place to see the impact you can make.\n\nFirst up, let's talk about content creation. With prompt engineering, you can use ChatGPT to generate blog posts, articles, and even books. Let's see how it works.\n\nNext, let's talk about customer service. With prompt engineering, you can use ChatGPT to build a chatbot that answers customer queries and provides support. Let's see it in action.\n\nFinally, let's talk about data analysis. With prompt engineering, you can use ChatGPT to analyze text data and extract insights. Let's see an example.\n\nAnd that's a wrap! You've just seen some real-world applications of prompt engineering for ChatGPT. Remember, the possibilities are endless. So keep experimenting and finding new ways to use this powerful tool.\n\nThanks for watching and happy coding! And a special thanks to our partners at OpenAI for their support.\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-04-30"}}
{"video": {"title": "TensorFlow: Optimizing Models for Deployment", "transcript": "####TensorFlow: Supercharge Your Models for Deployment\nby Laurence Moroney - 2022-02-26\n\n#### BEGIN TRANSCRIPT ####\nHello, TensorFlow enthusiasts! I'm Laurence Moroney, and today we're diving into the exciting world of model optimization for deployment.\n\n[Video hook and introduction]\n\nAre you tired of sluggish models and high computational costs? Well, you're in luck! We're about to unlock the secrets of optimizing your TensorFlow models for deployment.\n\n[Body content]\n\nFirst, we'll explore the art of model optimization. We'll cover techniques like pruning, quantization, and distillation. Trust me, your models will thank you!\n\nNext, we'll discuss the benefits of optimizing models for deployment. We'll talk about how it can reduce model size, boost prediction speed, and save you a fortune in computational resources.\n\nFinally, we'll tackle some common challenges in optimizing models for deployment and how to conquer them like a pro.\n\n[Conclusion and call to action]\n\nAnd that's a wrap! You're now ready to supercharge your models for deployment.\n\nRemember, optimizing your models can make a world of difference in their performance and efficiency. So, don't skip this step!\n\nThanks for watching, and stay tuned for more TensorFlow videos. If you have any questions, feel free to ask.\n\nUntil next time, happy coding and optimizing! \n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-02-26"}}
{"video": {"title": "Building a Personal Assistant with LangChain", "transcript": "####Building a Personal Assistant with LangChain\nby Harrison Chase, Andrew Ng - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Harrison Chase, and today we're going to have a blast building a personal assistant using LangChain.\n\nAre you ready to level up your coding skills and create something truly amazing? Let's get started!\n\nFirst, we'll set up our environment. We'll install LangChain and set up our Python environment. It's like setting up the stage for a rock concert, but instead of guitars and drums, we've got code and algorithms.\n\nOnce that's done, we'll start building our personal assistant. We'll use prompts and parsing to interact with our users and understand their needs. It's like teaching our assistant to speak the language of humans.\n\nNext, we'll dive into memory and chains. These are powerful features that let our personal assistant remember past interactions and perform complex tasks. It's like giving our assistant a superpower to remember everything.\n\nAnd the best part? We'll use these features to build a personal assistant that can answer questions, set reminders, and even tell jokes. It's like having your own personal Jarvis, but without the whole \"taking over the world\" thing.\n\nNow, let's wrap up. You've learned how to set up your environment, use prompts and parsing, and leverage memory and chains to build a personal assistant. But the fun doesn't stop here. I challenge you to add more features to your personal assistant. Make it unique. Make it yours.\n\nThanks for watching. If you found this tutorial helpful, give it a thumbs up and don't forget to subscribe for more content like this. See you in the next video, where we'll continue to explore the exciting world of GenAI and LLM powered applications. Until then, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-05"}}
{"video": {"title": "Mastering Prompt Engineering for ChatGPT Applications", "transcript": "####Mastering Prompt Engineering for ChatGPT Applications\nby Andrew Ng - 2022-11-05\n\n#### BEGIN TRANSCRIPT ####\nEver wondered how to unlock the full potential of ChatGPT? Well, you're in the right place! Today, we're diving into the world of prompt engineering. Trust me, you won't want to miss this.\n\nAre you ready to take your AI game to the next level? Let's get started!\n\n#### END TRANSCRIPT ########\n\n####Mastering Prompt Engineering for ChatGPT Applications\nby Andrew Ng - 2022-11-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you tired of getting lackluster results from your ChatGPT applications? Well, buckle up, because we're about to change all that.\n\nIn this video, we'll be exploring the ins and outs of prompt engineering. Trust me, you won't believe the difference it can make.\n\nSo, are you ready to become a prompt engineering master? Let's do this!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-11-05"}}
{"video": {"title": "Building a General-Purpose Quantizer in Pytorch", "transcript": "####Building a General-Purpose Quantizer in Pytorch\nby Marc Sun, Younes Belkada - 2022-01-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc Sun, and today we're diving into the world of Pytorch. We're building a general-purpose quantizer that can quantize the dense layers of any open source model.\n\nFirst, we'll discuss the theory behind quantization in Pytorch. Then, we'll dive into the code. We'll walk through each step of building a quantizer that can give you up to 4x compression on dense layers.\n\nBy the end of this video, you'll have a quantizer that can make your models smaller and faster. Not too shabby, right?\n\nRemember, this course is brought to you in partnership with Hugging Face. So you're getting top-notch resources and guidance.\n\nThat's it for today's preview. If you're ready to build your own quantizer, let's get started. And don't forget to like, share, and subscribe for more great content. See you in the course!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-01-22"}}
{"video": {"title": "Deep Learning Troubleshooting: Common Problems and Solutions", "transcript": "####Deep Learning Troubleshooting: Common Problems and Solutions\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-02-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your friendly AI guide and today we're diving into the world of deep learning troubleshooting.\n\nWe'll be discussing some common problems you might encounter, like vanishing gradients and overfitting, and providing practical solutions to help you debug your neural networks.\n\nRemember, everyone faces challenges when learning something new, so don't be discouraged. With practice and patience, you'll become a pro at troubleshooting.\n\nSo, let's get started! And remember, if you have any questions, feel free to leave them in the comments.\n\nAnd that's a wrap for today's video. If you found it helpful, give it a thumbs up and subscribe to our channel for more AI content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-02-05"}}
{"video": {"title": "Mastering Diffusion Models: A Hands-On Guide", "transcript": "####Mastering Diffusion Models: A Hands-On Guide\nby Sharon Zhou - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sharon Zhou, and welcome to our exciting journey into the world of 'Diffusion Models'.\n\nIf you're a Python, Tensorflow, or Pytorch enthusiast, you're in luck! Today, we're diving headfirst into diffusion models. Don't worry, we'll take it one step at a time.\n\nFirst, let's demystify diffusion models and explore their real-world applications. Imagine a picture of a cat. Now, imagine gradually adding noise until it's just static. A diffusion model does the opposite. It starts with noise and gradually turns it into a picture of a cat. Pretty amazing, right?\n\nNow, let's roll up our sleeves and build our own diffusion model. No need to panic, we'll use Python and Tensorflow, or Pytorch, whichever floats your boat. We'll start with a simple model and gradually add complexity.\n\nOnce we've built our model, we'll train it. We'll feed it noise and teach it to turn that noise into images. It's like teaching a child to draw, but with math and code.\n\nNow, for the icing on the cake. We'll implement algorithms to speed up sampling. Imagine waiting for a kettle to boil. Now, imagine if it boiled 10 times faster. That's what we're doing here.\n\nAnd that's a wrap for today! You've learned what diffusion models are, built your own, trained it, and even sped it up. Not too shabby for a day's work.\n\nRemember, practice makes perfect. So, keep coding, keep learning, and who knows, you might just shake up the world of AI.\n\nIf you enjoyed this video, give it a thumbs up and subscribe to our channel for more thrilling content. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-03-15"}}
{"video": {"title": "Harnessing the Power of AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####Harnessing the Power of AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python fans! Today, we're embarking on an exciting journey into the realm of AI agents using LangChain's LangGraph and Tavily's agentic search.\n\nBut first, what's LangGraph? It's an open-source framework that empowers us to build, debug, and maintain AI agents. It's like having a superpower for creating controllable agents.\n\nNow, let's roll up our sleeves. We'll start by demystifying LangGraph's components. Each one plays a vital role in enabling the development of AI agents.\n\nOnce we've got that down, we'll crank it up a notch by integrating Tavily's agentic search capabilities. This will turbocharge our agents, enhancing their knowledge and performance.\n\nAnd who better to guide us than Harrison Chase, the mastermind behind LangChain, and Rotem Weiss, the genius behind Tavily.\n\nRemember, this course is tailor-made for you if you've got intermediate Python knowledge and are ready to take your AI game to the next level.\n\nSo, are you ready to transform the way you build AI agents? Let's dive in!\n\nP.S. No need to worry about complex jargon here, just simple, clear, and concise learning.\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-15"}}
{"video": {"title": "Mastering Sentiment Analysis with NLP", "transcript": "####Mastering Sentiment Analysis with NLP\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, \u0141ukasz here! Ready to master sentiment analysis using NLP? Let's dive in!\n\nSentiment analysis is a game-changer. It helps us understand the emotion behind a piece of text. It's used in marketing, customer service, and even politics.\n\nWe'll be using Hugging Face, our technology partner, to build our sentiment analysis app.\n\nFirst, we'll collect our data. This could be reviews, social media posts, or any other text we want to analyze.\n\nNext, we'll preprocess our data. This involves cleaning the text and converting it into a format that our app can understand.\n\nThen, we'll train our model. This is where the magic happens! Our app will learn to recognize the emotion behind the text.\n\nFinally, we'll test our model. We'll see how well it can analyze the sentiment of new pieces of text.\n\nRemember, the more data we have, the better our app will be. So don't be afraid to collect as much data as you can!\n\nSo, are you ready to become a sentiment analysis expert? Let's get started! And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, keep exploring and innovating.\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-03-20"}}
{"video": {"title": "Red Teaming 101: Identifying Vulnerabilities in LLM Applications", "transcript": "####Red Teaming 101: Uncovering Vulnerabilities in LLM Applications\nby Matteo Dora, Luca Martial - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, LLM fans! I'm Luca Martial and today we're diving into the thrilling world of red teaming. Specifically, we're talking about the first step: identifying vulnerabilities in your LLM applications.\n\nSo, what are we on the hunt for? Any potential issue that could put a wrench in the safety or reliability of our app. This could be biased outputs, misinterpretation of user inputs, or even privacy concerns.\n\nBut how do we find these vulnerabilities? We put on our black hats and think like a malicious user. We consider how they might try to exploit our app and what weaknesses they could take advantage of.\n\nRemember, the goal here isn't to scare you. It's to help you build better, safer apps. So don't be afraid to really challenge your system.\n\nStay tuned for our next video where we'll talk about how to evaluate these vulnerabilities. And don't forget to check out Giskard's open-source library for tools to help you with this process.\n\nThanks for watching. Don't forget to like, share, and subscribe for more content on LLM applications. See you next time!\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-03-20"}}
{"video": {"title": "Unsupervised Learning: Clustering and Dimensionality Reduction", "transcript": "####Unsupervised Learning: Clustering and Dimensionality Reduction\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-01-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Today, we're diving into the fascinating world of unsupervised learning, focusing on clustering and dimensionality reduction.\n\nClustering is like playing a game of 'find the similarities'. It's all about discovering hidden patterns in unlabeled data.\n\nDimensionality reduction, on the other hand, is like condensing a lengthy novel into a captivating summary. It's about making complex data more manageable and understandable.\n\nWe'll be using Python to bring these concepts to life, so you'll get some hands-on coding practice too!\n\nRemember, the secret to mastering unsupervised learning is practice. So, keep coding, keep experimenting, and most importantly, keep learning!\n\nThat's a wrap for today's video. If you enjoyed this journey into the world of unsupervised learning, don't forget to give us a thumbs up and subscribe for more exciting content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-01-29"}}
{"video": {"title": "Red Teaming vs. Blue Teaming: What's the Difference?", "transcript": "####Red Teaming vs. Blue Teaming: What's the Difference?\nby Matteo Dora, Luca Martial - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, cybersecurity enthusiasts! I'm Matteo Dora, and today we're diving into the world of red teaming and blue teaming in the context of LLM applications.\n\nRed teaming, as you might know, is all about playing the bad guy. It's about challenging your system to find vulnerabilities before the real bad guys do. It's a proactive approach to safety and reliability.\n\nBlue teaming, on the other hand, is about playing defense. It's about defending your system against identified vulnerabilities. It's a reactive approach that focuses on incident response and recovery.\n\nBut here's the kicker: both red teaming and blue teaming are crucial for building safe and reliable LLM applications. They're like two sides of the same coin, and they work best when used together.\n\nSo, are you ready to become a cybersecurity superhero? Don't forget to like, share, and subscribe for more content on LLM applications. And remember, in the world of cybersecurity, there's no such thing as too much knowledge. See you next time!\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-04-15"}}
{"video": {"title": "Crafting Effective Prompts for ChatGPT", "transcript": "####Crafting Effective Prompts for ChatGPT\nby Isa Fulford - 2022-10-25\n\n#### BEGIN TRANSCRIPT ####\nAre you ready to unlock the full potential of ChatGPT? It all starts with crafting the perfect prompt! Join me as I share my best practices for prompt engineering and show you how to get the most out of your language model.\n\n#### INTRODUCTION ####\nHey there, tech enthusiasts! I'm Isa Fulford, and today we're diving into the world of ChatGPT. But don't worry, you won't need a PhD in computer science to follow along. I'll be breaking down the complex concepts into simple, easy-to-understand terms. And who knows, we might even have a little fun along the way!\n\n#### BODY CONTENT ####\nSo, why is prompt engineering so important? Think of it like this: a prompt is like a key that unlocks the door to ChatGPT's vast knowledge. The better your key, the more smoothly the door will open.\n\nBut don't just take my word for it. Let's put theory into practice and see the difference a well-crafted prompt can make.\n\n#### CONCLUSION & CALL TO ACTION ####\nAnd there you have it, folks! With these prompt engineering best practices, you're well on your way to getting the most out of ChatGPT. But remember, practice makes perfect. So keep experimenting and refining your prompts.\n\nAnd before you go, don't forget to like, share, and subscribe for more tech tips and tricks. Until next time, happy prompting!\n\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-25"}}
{"video": {"title": "Extending Your Agentic RAG with Custom Functions in LlamaIndex", "transcript": "####Extending Your Agentic RAG with Custom Functions in LlamaIndex\nby Jerry Liu - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and today we're diving into the exciting world of extending our agentic RAG with custom functions in LlamaIndex.\n\nIn our previous videos, we've built an agentic RAG, mastered document Q&A, unleashed the power of summarization, built a multi-document research agent, and learned how to debug and control our agent. Today, we're taking it to the next level by extending our agent with custom functions.\n\nWe'll start by understanding how to create custom functions in LlamaIndex. Then, we'll dive into integrating these functions into our agentic RAG.\n\nOnce we've got that down, we'll look at how to fine-tune our agent to improve its accuracy and efficiency with these new functions.\n\nBy the end of this video, you'll be a pro at extending your agentic RAG systems with custom functions.\n\nSo, let's get started! And remember, practice makes perfect. So, don't just watch this video, try extending your own agentic RAG with custom functions in LlamaIndex.\n\nIf you found this video helpful, give it a thumbs up and subscribe to our channel for more exciting content. Until next time, happy coding!\n\n\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-10"}}
{"video": {"title": "Diffusion Models: A Hands-On Tutorial", "transcript": "####Diffusion Models: A Hands-On Tutorial\nby Sharon Zhou - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, Sharon Zhou here, and today we're diving into the fascinating world of diffusion models!\n\nImagine building a jigsaw puzzle, but instead of a static image, you're creating a dynamic, complex picture. That's what diffusion models are all about!\n\nLet's grab our Python, Tensorflow, or Pytorch, and let's get started. We'll define our data distribution, add noise, and learn how to denoise it. But don't worry, I'll guide you through every step of the way.\n\nBut wait, there's more! Sampling from diffusion models can be as slow as solving a jigsaw puzzle. So, let's speed things up! I'll introduce you to some powerful algorithms that can accelerate sampling by a whopping 10 times!\n\nBy the end of this video, you'll be a diffusion model pro, ready to build and train your own models. So, keep fitting those pieces, keep learning, and who knows? You might just build the perfect 'diffusion puzzle'!\n\nThanks for watching, and remember to like, share, and subscribe for more exciting content. See you next time!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-04-10"}}
{"video": {"title": "Python for Machine Learning: Your First Steps", "transcript": "####Python for Machine Learning: Your First Steps\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-01-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! It's your friendly host, back with another exciting episode. Today, we're diving into Python, the superhero language of Machine Learning.\n\nWhy Python, you ask? Well, it's simple to learn, boasts a massive community, and is packed with libraries that make Machine Learning a walk in the park.\n\nLet's get our hands dirty. We'll start by installing Python and setting up our environment. Then, we'll delve into variables, data types, and basic operations. Think of these as the Lego blocks of any program.\n\nNext, we'll level up with loops and functions. These are like superpowers that let you do more with less code.\n\nBut wait, there's more! We'll also explore Python libraries like NumPy and Pandas, which are essential for handling data in Machine Learning. And we'll do it all with practical examples, so you can see how it's done in the real world.\n\nRemember, everyone starts somewhere, so don't be discouraged if you don't get it right away. Practice makes perfect!\n\nSo, are you ready to take your Python skills to the next level? Let's get started! And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-01-08"}}
{"video": {"title": "The Future of Multi AI Agent Systems with crewAI", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Encouragement for audience participation.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning.\n- Make the conclusion more memorable and engaging.\n- Improve contrast and pacing to maintain interest.\n- Include more personal insights and real-world applications.\n- Make the introduction more captivating and engaging.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning.\n- Make the conclusion more memorable and engaging.", "author": "Jo\u00e3o Moura", "publication_date": "2023-05-16"}}
{"video": {"title": "Preprocessing Unstructured Data for LLM Applications: A Beginner's Guide", "transcript": "####Preprocessing Unstructured Data for LLM Applications: A Beginner's Guide\nby Matt Robinson - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Matt Robinson, and today we're embarking on an exciting journey into the world of preprocessing unstructured data for LLM applications.\n\nBut first, let's break it down. If you've been working on improving your RAG system to retrieve diverse data formats, you're in the right place.\n\nWe're going to learn how to extract and normalize content from a wide variety of document types, such as PDFs, PowerPoints, Word, and HTML files. But wait, there's more! We'll also explore how to preprocess tables and images to expand the information accessible to your LLM.\n\nNext, we'll enrich our content with metadata. This little trick will enhance our retrieval augmented generation (RAG) results and support more nuanced search capabilities. Pretty cool, right?\n\nBut that's not all! We'll also explore document image analysis techniques like layout detection and vision and table transformers. And guess what? We'll learn how to apply these methods to preprocess PDFs, images, and tables.\n\nSo, are you ready to take your LLM applications to the next level? Let's get started!\n\nRemember, practice makes perfect. So, don't be afraid to try new things and make mistakes. That's how we learn. And if you have any questions, feel free to leave them in the comments below. I'm always here to help.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Matt Robinson", "publication_date": "2023-03-15"}}
{"video": {"title": "Applying Mathematics in Data Science Projects", "transcript": "####Applying Mathematics in Data Science Projects\nby Lucas Coutinho - 2022-10-11\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! It's your favorite data scientist, Lucas Coutinho, back with another exciting video. Today, we're going to put our mathematical knowledge to the test by applying it to real-world data science projects. Are you ready to see how calculus, linear algebra, statistics, and probability come together to drive impactful insights and solutions? Let's dive in!\n#### END TRANSCRIPT ########", "author": "Lucas Coutinho", "publication_date": "2022-10-11"}}
{"video": {"title": "TensorFlow: Model Versioning and Management", "transcript": "####TensorFlow: Model Versioning and Management\nby Laurence Moroney - 2023-05-01\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, machine learning enthusiasts! I'm Laurence Moroney, and today we're diving into the exciting world of model versioning and management with TensorFlow.\n\n[Video hook and introduction]\n\nImagine you're a chef, and your machine learning models are your recipes. Wouldn't it be a disaster if you lost track of which version of your famous dish was the best? That's where model versioning and management come in!\n\n[Body content]\n\nWith TensorFlow, you've got some fantastic tools at your disposal. Meet TensorFlow Extended (TFX) and TensorFlow Model Analysis (TFMA). These aren't just tools; they're your secret ingredients for tracking, comparing, and evaluating your models.\n\n[Conclusion and call to action]\n\nSo, what are you waiting for? Start exploring these tools and see how they can help you manage your machine learning projects like a pro. Keep learning, keep innovating, and happy coding!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-05-01"}}
{"video": {"title": "Quantization Fundamentals with Hugging Face", "transcript": "####Quantization Fundamentals with Hugging Face\nby Younes Belkada, Marc Sun - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! Today, we're going to explore the fascinating world of quantization. We'll be using the Hugging Face Transformers library and the Quanto library to compress models without compromising performance. Are you ready? Quantization is a game-changer. It allows us to shrink our models by converting their weights and activations from floating point numbers to lower precision integers. This means we can run our models on devices with limited resources, like mobile phones or edge devices. Linear quantization is a simple yet effective method. It maps floating point numbers to a smaller set of discrete values. This results in a smaller model size without losing much performance. With the Hugging Face Transformers library, quantizing open source multimodal and language models is a breeze. And the Quanto library provides us with the tools and utilities we need to make the process even smoother. So, are you ready to dive into the world of quantization with Hugging Face? Let's do this!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2022-10-15"}}
{"video": {"title": "Mastering AI Agentic Design Patterns with AutoGen", "transcript": "####Mastering AI Agentic Design Patterns with AutoGen\nby Chi Wang, Qingyun Wu - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Chi Wang, and today we're embarking on an exciting adventure into the world of AI Agentic Design Patterns using AutoGen. If you're a Python beginner with a burning curiosity for AI, you're in luck!\n\nFirst things first, let's demystify AutoGen. It's a mighty framework that empowers us to build multi-agent systems with diverse roles and capabilities. Imagine automating complex workflows with AI agents, sounds awesome, doesn't it?\n\nNow, let's get our hands dirty and dive into implementing four key agentic design patterns using AutoGen. These are Reflection, Tool use, Planning, and Multi-agent collaboration. Don't worry if these terms sound like a different language, we'll translate them into simple, bite-sized concepts.\n\nReflection is all about self-awareness. Our AI agents will learn to understand their own strengths and weaknesses. This helps them make smarter decisions and improve their performance over time.\n\nNext, we'll explore Tool use. This is where our AI agents learn to use tools to achieve their goals. Just like us humans using a hammer to nail, our AI agents will use digital tools to solve complex problems.\n\nThen, we'll move on to Planning. This is where our AI agents will learn to plan their actions in advance. They'll predict the outcomes of different actions and choose the best one.\n\nFinally, we'll dive into Multi-agent collaboration. This is where multiple AI agents work together to achieve a common goal. They'll communicate, coordinate, and collaborate, just like a team of superheroes!\n\nThroughout this journey, you'll be learning directly from Qingyun Wu and me, the creators of AutoGen. We're thrilled to share our knowledge and help you leverage AutoGen effectively.\n\nRemember, practice makes perfect. So, don't just watch, get your hands dirty with coding. And if you're stuck, don't hesitate to reach out. We're here to help!\n\nThat's it for today's video. If you found it helpful, give it a thumbs up and subscribe to our channel for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2023-03-15"}}
{"video": {"title": "Demystifying CNNs: A Hands-On Approach", "transcript": "####Demystifying CNNs: A Hands-On Approach\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-01-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your guide for today's journey into the world of CNNs, or Convolutional Neural Networks.\n\nDon't let the name intimidate you. CNNs are simply a type of neural network that excels at image processing. They can recognize faces, objects, and even handwriting!\n\nIn this video, we'll roll up our sleeves and get our hands dirty. We'll start by building a simple CNN using Python and TensorFlow. Then, we'll feed it some images and see how it performs.\n\nRemember, the best way to learn is by doing. So, grab your keyboard and let's get coding!\n\nBy the end of this video, you'll have a solid understanding of CNNs and how they work. You'll also have a working model that you can tweak and experiment with.\n\nSo, what are you waiting for? Let's dive in and start building! And remember, if you get stuck, just rewind and watch again.\n\nThat's all for today's video. If you enjoyed it, don't forget to hit that like button and subscribe to our channel for more AI content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-01-08"}}
{"video": {"title": "Unleashing AI Potential with Hugging Face: A Hands-On Approach", "transcript": "####Unleashing AI Potential with Hugging Face: A Hands-On Approach\nby Maria Khalusova, Marc Sun, Younes Belkada - 2023-03-21\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Maria, and today we're diving into the exciting world of Hugging Face.\n\nHugging Face is a platform that's making AI accessible to everyone. So, let's get our hands dirty and start unleashing its potential.\n\nFirst, we'll explore the Hugging Face Hub. It's like a candy store for AI models. You can filter models based on tasks, rankings, and memory requirements. It's all about finding the right tool for your AI toolbox.\n\nNext, we'll use the transformers library to implement our chosen model. With just a few lines of code, you can perform text, audio, image, and multimodal tasks. It's like having your own AI lab, right at your fingertips.\n\nFinally, we'll share our AI app with the world. With a user-friendly interface or via API, you can run it on the cloud using Gradio and Hugging Face Spaces. It's like launching your own AI project, without the need for a rocket scientist.\n\nSo, are you ready to unleash your inner AI genius with Hugging Face? Remember, the best way to learn is by doing. So, go ahead, explore the Hugging Face Hub, play around with the models, and who knows, you might just create the next AI breakthrough.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-03-21"}}
{"video": {"title": "Inference Techniques in Generative AI", "transcript": "####Inference Techniques in Generative AI: Unlocking the Power of Prediction\nby Mike Chambers - 2022-01-18\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Mike Chambers, and today we're diving into the thrilling world of inference techniques in Generative AI. Are you ready to make accurate predictions and generate new content using your trained models? Let's get started and take your AI projects to the next level!\n#### END TRANSCRIPT ########", "author": "Mike Chambers", "publication_date": "2022-01-18"}}
{"video": {"title": "Building a Personal Assistant with LangChain", "transcript": "####Building a Personal Assistant with LangChain\nby Harrison Chase, Andrew Ng - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Harrison Chase here, and today we're diving into the exciting world of LangChain. We're going to build a personal assistant that's not only smart but also remembers our preferences.\n\nFirst, we'll create a new LLM. We'll use prompts and parsing to teach it how to respond to commands. It's like teaching a child, but way more fun!\n\nNext, we'll add some memory. This will allow our assistant to remember previous interactions. It's like giving it a superpower!\n\nFinally, we'll create an agent. This will allow our assistant to perform tasks on our behalf. It's like having a personal butler, but without the fancy uniform.\n\nBy the end of this video, you'll have your very own personal assistant. So, let's get started and turn theory into practice.\n\nRemember, the best way to learn is by doing. And who knows, you might even impress your friends with your new tech skills.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-10"}}
{"video": {"title": "Unleashing AI Potential with Hugging Face Open Source Models", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits of Hugging Face.\n- Use of active voice and simple language.\n- Encouragement of audience participation.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and real-world applications.\n- Make the conclusion more memorable and engaging.", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-04-01"}}
{"video": {"title": "Quantization in On-Device AI", "transcript": "####Quantization in On-Device AI: A Deep Dive\nby Krishna Sridhar - 2022-10-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Krishna Sridhar here. Today, we're going to embark on an exciting journey into the world of On-Device AI. We'll be focusing on a key concept that makes it all possible: quantization. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-10-05"}}
{"video": {"title": "Building Your First Agentic RAG with LlamaIndex", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits of LlamaIndex.\n- Use of active voice and simple language.\n- Encouragement for the audience to practice.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.\n- Improve the call to action to encourage more interaction from the audience.", "author": "Jerry Liu", "publication_date": "2023-03-15"}}
{"video": {"title": "Scaling ML Systems: From Small to Large", "transcript": "####Scaling ML Systems: From Small to Large\nby Andrew Ng - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow data enthusiasts! Andrew Ng here, and today we're diving into the exciting world of scaling ML systems.\n\nScaling an ML system is like nurturing a plant from seedling to towering tree. You need the right nutrients, the right environment, and the right care. We'll discuss how to design scalable architectures, manage compute resources, and handle large datasets.\n\nWe'll also explore techniques for distributed training, model parallelism, and data parallelism. But remember, the goal is not just to build a model that works, but to build a model that works at scale. So, let's get started!\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and keep innovating!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-10"}}
{"video": {"title": "Creating a Specialized Chatbot with LangChain", "transcript": "####Creating a Specialized Chatbot with LangChain\nby Harrison Chase, Andrew Ng - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're diving into the world of specialized chatbots using LangChain.\n\nImagine having a chatbot that can answer questions based on your unique data. Sounds like a game-changer, right?\n\nFirst, we'll demystify LangChain's question answering features. We'll explore the technology behind it and how it empowers our chatbot to understand and answer questions.\n\nNext, we'll roll up our sleeves and get into the code. We'll leverage LangChain's question answering features to build our very own chatbot.\n\nBut wait, there's more! We'll use agents and chained calls to supercharge our chatbot. It'll be capable of performing complex tasks and recalling past interactions.\n\nNow, let's recap. You've learned how to use LangChain's question answering features, how to build a specialized chatbot, and how to boost your chatbot with agents and chained calls.\n\nSo, what's next? I challenge you to create your own specialized chatbot. Make it stand out. Make it powerful.\n\nThanks for watching. If you enjoyed this tutorial, give it a thumbs up and don't forget to subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-10"}}
{"video": {"title": "Mastering Knowledge Graphs for RAG with Neo4j and LangChain", "transcript": "####Mastering Knowledge Graphs for RAG with Neo4j and LangChain\nby Andreas Kollegger - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Andreas Kollegger, and today we're embarking on an exciting journey into the realm of Knowledge Graphs for Retrieval Augmented Generation, or RAG for short.\n\nBut first, a quick heads up! If you're new to LangChain, I highly recommend checking out our crash course, 'LangChain: Chat with Your Data'. It's the perfect primer for this intermediate level course.\n\nNow, let's dive in. Knowledge graphs are a game-changer for your RAG applications. They allow you to manage and retrieve data in a more efficient and contextually relevant way.\n\nIn this video, we're teaming up with Neo4j to show you how to use their query language, Cypher, to manage and retrieve data stored in knowledge graphs.\n\nFirst, we'll guide you through writing knowledge graph queries that find and format text data to provide more relevant context to LLMs for RAG.\n\nThen, we'll take it up a notch and build a question-answering system using Neo4j and LangChain. This system will allow you to chat with a knowledge graph of structured text documents.\n\nImagine being able to ask your data questions and getting accurate, contextually relevant answers. That's the power of Knowledge Graphs for RAG.\n\nSo, are you ready to take your RAG applications to the next level? Let's get started.\n\nRemember, practice makes perfect. So, don't be afraid to try, fail, and try again. And if you have any questions, feel free to leave them in the comments below.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2023-03-15"}}
{"video": {"title": "ChatGPT Prompt Engineering 101: A Beginner's Tutorial", "transcript": "####ChatGPT Prompt Engineering 101: A Beginner's Tutorial\nby Isa Fulford, Andrew Ng - 2023-03-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're going to dive into the world of prompt engineering for ChatGPT. If you're a beginner with some Python knowledge, you're in the right place!\n\nLet's start with the basics. What is prompt engineering and why should you care? Prompt engineering is the art of crafting effective inputs for language models like ChatGPT. It's important because it can significantly impact the quality of the output.\n\nNow, let's discuss some prompt engineering best practices. First, be precise and detailed with your prompts. The more context you provide, the better ChatGPT can generate the desired output. Second, iterate, iterate, iterate. Prompt engineering is all about trial and error, so don't be afraid to experiment.\n\nLet's discover some innovative ways to leverage LLMs. Did you know they can summarize, infer, transform, and expand text? Let's create our own custom chatbot using the OpenAI API.\n\nNow, let's get our hands dirty. Let's practice writing and refining prompts together. Remember, clarity and iteration are key.\n\nIn conclusion, prompt engineering is a game-changer for developing applications with ChatGPT. With these best practices and some hands-on experience, you're on your way to becoming a prompt engineering pro. So, what are you waiting for? Start prompting! And remember, practice makes perfect.\n\nThanks for tuning in and happy prompting! Don't forget to like, share, and subscribe for more exciting content. Catch you in the next video!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-19"}}
{"video": {"title": "Building Your Own Custom Chatbot with ChatGPT", "transcript": "####Building Your Own Custom Chatbot with ChatGPT\nby Isa Fulford - 2022-10-20\n\n#### BEGIN TRANSCRIPT ####\nAre you ready to create your own chatbot? Today, I'm going to show you how to use prompt engineering to build a personalized chatbot using ChatGPT. Let's get started!\n\n[Video hook and introduction]\nImagine having a chatbot that can answer any question you throw at it. Sounds too good to be true, right? Well, not anymore! With ChatGPT, you can create your own custom chatbot in no time.\n\n[Body content]\nFirst, we'll dive into what prompt engineering is and how it can help you create a more personalized chatbot. Then, I'll walk you through the step-by-step process of building your own chatbot using ChatGPT.\n\n[Conclusion and call to action]\nSo, what are you waiting for? Let's get started on building your own custom chatbot with ChatGPT. And don't forget to like, comment, and subscribe for more tutorials like this one. Happy building!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-20"}}
{"video": {"title": "Mistral AI: Getting Started with Commercial Models", "transcript": "####Mistral AI: Unleashing the Power of Commercial Models\nby Younes Belkada, Marc Sun - 2023-02-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Younes Belkada here, and today we're diving into the world of Mistral AI's commercial models. Get ready to take your LLM capabilities to new heights!\n\nMistral AI offers three commercial models: small, medium, and large. These models pack even more punch than Mistral's open-source models, making them the perfect choice for those who need more power and flexibility.\n\nSo, how do you get started with Mistral AI's commercial models? It's as easy as signing up for an API key and choosing the model that fits your needs. From there, you can start making API calls and harnessing the power of Mistral AI's advanced LLM capabilities.\n\nBut wait, there's more! Mistral AI's JSON mode and API are game-changers. With JSON mode, you can generate LLM responses in a structured JSON format, making it a breeze to integrate LLM outputs into your larger software applications. And with Mistral's API, you can call user-defined Python functions for tasks like web searches or retrieving text from databases.\n\nSo, what are you waiting for? Start exploring Mistral AI's commercial models today and see how they can help you achieve your LLM goals more efficiently and accurately. And don't forget to check out Mistral AI, our technology partner for this video.\n\nThanks for watching, and stay tuned for more exciting videos on Mistral AI and LLM. I'm Younes Belkada, and I'll see you in the next one.\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-22"}}
{"video": {"title": "Prompt Engineering for Text Expansion with ChatGPT", "transcript": "####Prompt Engineering for Text Expansion with ChatGPT\nby Isa Fulford, Andrew Ng - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're diving into the exciting world of prompt engineering for text expansion with ChatGPT. If you're a beginner with basic Python skills, you're all set!\n\nFirst, let's talk about what text expansion is and why it's important. Text expansion is the process of adding more detail to a piece of text. It's a valuable skill in many areas, from content creation to data analysis.\n\nNow, let's see how we can use ChatGPT and prompt engineering for text expansion. The key is to craft prompts that ask the model to expand on the text in a specific way. Let's look at some examples and try it out ourselves.\n\nRemember, the key to good prompts is to be clear, concise, and specific. Let's iterate on our prompts and see how we can improve the expansions we get from ChatGPT.\n\nAnd that's it! You've just learned how to use prompt engineering for text expansion with ChatGPT. Remember, practice makes perfect. So keep experimenting and refining your prompts.\n\nThanks for watching and happy coding! And a big thank you to our partners at OpenAI for their support.\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-04-15"}}
{"video": {"title": "Mastering Quantization: Tips and Tricks for Model Optimization", "transcript": "####Mastering Quantization: Tips and Tricks for Model Optimization\nby Marc Sun - 2022-10-23\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Marc Sun! Today, we're going to master quantization together. I've got some tips and tricks up my sleeve to help you optimize your models. Whether you're just starting out or you're a seasoned pro, you won't want to miss this. Let's dive in and take your quantization skills to the next level!\n#### END TRANSCRIPT ########", "author": "Marc Sun", "publication_date": "2022-10-23"}}
{"video": {"title": "Practical Applications of Generative AI with LLMs", "transcript": "####Practical Applications of Generative AI with LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Antje Barth here, and today we're diving into the exciting world of generative AI with LLMs!\n\nLLMs have a wide range of applications, from chatbots and virtual assistants to content generation and language translation. In this course, you'll learn how to apply LLMs to real-world problems and build your own generative AI applications.\n\nWe'll cover topics such as data preprocessing, model selection, and deployment, and you'll get hands-on experience using popular tools and frameworks like Hugging Face and GPT-3.\n\nYou'll also hear from industry experts about how they're using generative AI to create value and drive innovation in their organizations.\n\nBy taking this course, you'll gain practical skills and knowledge that you can apply to your own projects and career.\n\nSo, are you ready to start building with LLMs? Let's get started!\n\nDon't forget to like, comment, and subscribe for more content like this. And if you have any questions, feel free to leave them in the comments below. Thanks for watching!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-15"}}
{"video": {"title": "Expanding LLM Capabilities with Function-Calling", "transcript": "####Expanding LLM Capabilities with Function-Calling\nby Jiantao Jiao - 2022-11-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao, and today we're going to explore the exciting world of function-calling and data extraction with LLMs. Are you ready to take your LLM to the next level? Let's dive in!\n\nHave you ever wondered how to make your LLM even more powerful? Well, wonder no more! With function-calling, you can extend your LLM's capabilities and unlock a whole new level of functionality. Just a few lines of code can enable your LLM to make calls to external functions, opening up a world of possibilities.\n\nBut wait, there's more! You can also extract structured data from natural language inputs, making real-world data usable for analysis. Imagine building an end-to-end application that processes customer service transcripts using LLMs - the possibilities are endless!\n\nSo, if you're ready to take your LLM to the next level, stay tuned for some exciting insights. And remember, the sky's the limit when it comes to expanding your LLM's capabilities!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao", "publication_date": "2022-11-15"}}
{"video": {"title": "Quantization Demystified: Streamlining Models with Hugging Face and Quanto", "transcript": "####Quantization Demystified: Streamlining Models with Hugging Face and Quanto\nby Younes Belkada and Marc Sun - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada and today, I'm joined by Marc Sun to demystify quantization using Hugging Face and Quanto libraries.\n\nSo, what's the big deal about quantization? Well, it's like having a secret formula that lets you streamline your models without losing their essence.\n\nLet's get started. We'll be using the Hugging Face Transformers library and the Quanto library for this task. If you're new to these tools, don't worry, we've got you covered.\n\nFirst, we'll explore linear quantization, a simple yet effective method for streamlining models. It's like having a magic potion that turns your bulky models into sleek ones.\n\nThen, we'll practice quantizing open-source multimodal and language models. It's like having a condensed version of your favorite novels, but with all the essence intact.\n\nBy the end of this video, you'll be a pro at demystifying quantization and you'll have saved a ton of space on your hard drive.\n\nRemember, practice is the key to mastery, so don't hesitate to experiment with different models and methods. And if you encounter a hurdle, just rewind and watch it again.\n\nThanks for tuning in and don't forget to hit that like button, share this video, and subscribe for more exciting content. Catch you in the next video!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-05"}}
{"video": {"title": "The Importance of Data in ML Production", "transcript": "####The Importance of Data in ML Production\nby Andrew Ng - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Andrew Ng, and today we're diving into the world of ML production. But wait, what's the secret ingredient that makes it all tick? You guessed it, data!\n\nData is the heart and soul of any ML system. Without it, your model is as useful as a chocolate teapot. So, how do we make sure we're feeding our models the good stuff?\n\nFirst up, we need a solid data pipeline. Think of it as a well-oiled machine that collects, stores, and processes your data. It's like having a personal chef for your model, ensuring it gets the best ingredients.\n\nNext, let's talk about data quality. We want our data to be accurate, complete, and relevant. It's like choosing the right ingredients for a gourmet meal. You wouldn't want to ruin a perfect steak with stale spices, right?\n\nOnce we have our high-quality data, it's time to explore! This means visualizing our data, spotting patterns and trends, and testing out different hypotheses. It's like being a detective, but with more numbers and less trench coats.\n\nBut remember, data isn't a one-time deal. We need to keep an eye on our data quality over time and make adjustments as needed. It's like maintaining a garden, you can't just plant seeds and forget about them.\n\nSo, there you have it! The importance of data in ML production. It's the unsung hero that makes our models sing.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-25"}}
{"video": {"title": "Building Your First LLM Application with LangChain", "transcript": "####Building Your First LLM Application with LangChain\nby Harrison Chase, Andrew Ng - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Harrison Chase, and today we're diving into the exciting world of LLM applications with LangChain.\n\nAre you ready to build your very own AI personal assistant? Let's get started!\n\nFirst, we'll set up our environment. Don't worry, it's a breeze. I'll guide you through installing LangChain and setting up your Python environment.\n\nOnce that's done, we'll start building our application. We'll use prompts and parsing to interact with our users and understand their needs.\n\nNext, we'll explore memory and chains. These are game-changing features that let our application remember past interactions and perform complex tasks.\n\nAnd the best part? We'll use these features to build a personal assistant. Yes, you heard it right. By the end of this tutorial, you'll have your very own AI personal assistant.\n\nNow, let's wrap up. You've learned how to set up your environment, use prompts and parsing, and leverage memory and chains to build a personal assistant.\n\nSo, what's next? I challenge you to add more features to your personal assistant. Make it unique. Make it yours.\n\nThanks for watching. If you found this tutorial helpful, give it a thumbs up and don't forget to subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-03-20"}}
{"video": {"title": "Creating Controllable AI Agents with LangGraph and Tavily", "transcript": "####Creating Controllable AI Agents with LangGraph and Tavily\nby Harrison Chase, Rotem Weiss - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! Today, we're diving into the exciting world of creating controllable AI agents using LangGraph and Tavily's agentic search.\n\nLangGraph is a game-changer, allowing us to develop, debug, and maintain AI agents with ease. It's like having a superpower in your coding toolkit.\n\nBut wait, there's more! With Tavily's agentic search, we're taking our agents to the next level. This will boost our agent's knowledge and performance, making our AI truly exceptional.\n\nIn this course, you'll learn from the best - Harrison Chase, the founder of LangChain, and Rotem Weiss, the founder of Tavily. They'll walk you through LangGraph's components and show you how to integrate agentic search capabilities.\n\nThis course is perfect for those with intermediate Python knowledge who want to become AI agent development masters.\n\nSo, are you ready to create controllable AI agents? Let's get this party started! Don't forget to like, share, and subscribe for more thrilling content.\n\nKeep coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-05"}}
{"video": {"title": "Mastering Sentiment Analysis with NLP and Hugging Face", "transcript": "####Mastering Sentiment Analysis with NLP and Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, tech enthusiasts! I'm Your Assistant, and today we're diving into the fascinating world of sentiment analysis using NLP and Hugging Face.\n\nSentiment analysis is like being a mind reader for text. It's a superpower that businesses use to understand customer feedback, monitor social media, and more.\n\nWith Hugging Face, we can train our NLP model to recognize positive, negative, and neutral sentiments in text. We'll start by preparing our data, then we'll train our model, and finally, we'll test it out.\n\nRemember, the secret to successful sentiment analysis is understanding context. The same word can have different sentiments depending on the context, so our model needs to be smart enough to understand that.\n\nSo, are you ready to turn words into emotions? Let's get started with Hugging Face and NLP!\n\nStay tuned for more exciting videos on this topic. And don't forget to like, share, and subscribe for more tech content. Until next time, I'm Your Assistant, your guide in the world of AI.\n\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-03-20"}}
{"video": {"title": "Mastering Deep Learning Specialization: CNNs, RNNs, LSTMs, and Transformers", "transcript": "####Mastering Deep Learning Specialization: CNNs, RNNs, LSTMs, and Transformers\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your friendly guide and today we're embarking on an exciting adventure into the realm of Deep Learning Specialization.\n\nBut first, let's clarify what we're talking about. Deep Learning Specialization is a program that equips you with the skills to build neural networks like CNNs, RNNs, LSTMs, and Transformers. Don't worry if those acronyms sound like a foreign language, we'll decode them together.\n\nCNNs, or Convolutional Neural Networks, are image processing superstars. They're the brains behind facial recognition and self-driving cars. RNNs, or Recurrent Neural Networks, and LSTMs, or Long Short-Term Memory networks, are sequence understanding champions. They excel at understanding time series data or even sentences. And Transformers? They're shaking up the Natural Language Processing, or NLP, world.\n\nWe'll be using Python and TensorFlow to build these networks. Python is a beloved programming language known for its simplicity, and TensorFlow is a powerful open-source library for machine learning and artificial intelligence.\n\nNow, you might be thinking, 'Why should I learn this?' Well, deep learning is the driving force behind AI technology. It's the magic behind speech recognition, NLP, and so much more. By mastering these skills, you'll be able to create your own AI applications and contribute to this rapidly growing field.\n\nSo, are you ready to start building those neural networks? Let's dive in! Remember, practice makes perfect, so don't be discouraged if you don't understand everything right away.\n\nAnd that's a wrap for today's video. If you found this helpful, be sure to give it a thumbs up and subscribe to our channel for more exciting content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-01-01"}}
{"video": {"title": "AI for Disaster Response: Saving Lives with Technology", "transcript": "####AI for Disaster Response: Saving Lives with Technology\nby Robert Monarch - 2023-05-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the world of AI and disaster response.\n\n[Video hook and introduction]\n\nImagine a world where AI can predict disasters before they happen, coordinate response efforts in real-time, and optimize resource allocation to save more lives. Sounds like science fiction, right? Well, it's not.\n\n[Body content]\n\nFirst, we'll explore the role of AI in disaster response. We'll see how it's being used to predict disasters, improve response times, and make the most of limited resources.\n\nNext, we'll get our hands dirty with a project where we'll build a simple model to predict disaster impacts. Don't worry, I'll be with you every step of the way.\n\nBut it's not all sunshine and rainbows. We'll also discuss the challenges and ethical considerations of using AI in disaster response. It's important to know the full picture.\n\n[Conclusion and call to action]\n\nSo, are you ready to join the AI for disaster response movement? Remember, every second counts, and you can make a difference.\n\nThanks for watching. If you found this video helpful, don't forget to like, share, and subscribe. And stay tuned for more exciting content on AI for disaster response.\n\n\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-05-05"}}
{"video": {"title": "Revolutionize Your LLM Applications with Function-Calling and Data Extraction", "transcript": "####Revolutionize Your LLM Applications with Function-Calling and Data Extraction\nby Jiantao Jiao, Venkat Srinivasan - 2022-03-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao, and today we're going to supercharge your Language Learning Model, or LLM, applications with function-calling and data extraction. If you're already familiar with LLMs and have some basic Python skills, you're in luck!\n\nLet's start with function-calling. It's a game-changer for extending your LLMs with custom functionality. Imagine teaching your LLM to make calls to external functions. Mind-blowing, right?\n\nNow, let's get our hands dirty with some data extraction. We'll learn how to extract structured data from natural language inputs. This is a real-world superpower when dealing with data for analysis.\n\nBut wait, there's more! We've teamed up with Nexusflow to bring you an end-to-end application that processes customer service transcripts using LLMs. You'll see firsthand how function-calling and data extraction can take your application capabilities to the next level.\n\nRemember, practice makes perfect. So, don't just watch, get involved! Try out the techniques we'll cover and see how they can enhance your LLM and agent applications.\n\nThanks for watching and happy learning! Don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, this is Venkat Srinivasan signing off.\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-03-29"}}
{"video": {"title": "Diffusion Models: The Science of Spread", "transcript": "####Diffusion Models: The Science of Spread\nby Sharon Zhou - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHello, I'm Sharon Zhou, and today we're diving into the fascinating world of diffusion models.\n\nDiffusion models help us understand how things spread or diffuse over time and space. Think of it like how a forest fire spreads, or how a trend goes viral on social media.\n\nLet's get started by building our own diffusion model. Open up your Python environment, and make sure you've got Tensorflow or Pytorch installed. We'll start by defining our model, then we'll feed in our data, and finally, we'll train our model.\n\nBut wait, there's more! I'll also show you how to speed up your sampling process by 10 times. We'll implement some algorithms that will make your sampling process faster than ever.\n\nAnd that's all for today, folks! You've just learned how to build and train your own diffusion model, and even how to speed up the sampling process. Don't forget to hit that like button, subscribe, and share this video with your friends. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-03-20"}}
{"video": {"title": "Handling Complex Questions with Agentic RAG and LlamaIndex", "transcript": "####Handling Complex Questions with Agentic RAG and LlamaIndex\nby Jerry Liu - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and welcome back to our exciting journey with Agentic RAG and LlamaIndex!\n\nToday, we're diving into the world of complex questions. Why? Because not all questions are born equal!\n\nFirst, we'll demystify what makes a question complex and how to break it down into manageable chunks.\n\nThen, we'll learn how to use our Agentic RAG to tackle these complex questions, step by step.\n\nAnd finally, we'll share some insider tips and tricks to boost your Agentic RAG's performance in handling complex questions.\n\nSo, are you ready to take on complex questions with Agentic RAG and LlamaIndex? Let's do this!\n\nRemember, practice makes perfect. So keep trying, keep building, and most importantly, have fun!\n\nThanks for watching and don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-25"}}
{"video": {"title": "Quantization in Depth: Q&A", "transcript": "####Quantization in Depth: Q&A\nby Marc Sun, Younes Belkada - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc Sun, and today we're diving into your questions about advanced quantization techniques. We've got some great ones lined up, so let's get started!\n\nRemember, there's no such thing as a silly question. So, keep them coming!\n\nBut first, let me tell you a little secret. Quantization is like the secret sauce that makes machine learning models run faster and more efficiently. And trust me, you don't want to miss out on this delicious recipe.\n\nSo, without further ado, let's get into it.\n\n[Body content]\n\nAnd there you have it, folks! I hope you found this Q&A session helpful and informative.\n\nBut wait, there's more! If you liked this video, be sure to give it a thumbs up and subscribe to our channel for more exciting content. And if you have any more questions, feel free to leave them in the comments below. We love hearing from you!\n\nUntil next time, happy quantizing!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-15"}}
{"video": {"title": "Mastering Document Q&A with LlamaIndex", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Encouragement for viewers to practice.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning.\n- Make the conclusion more memorable and engaging.", "author": "Jerry Liu", "publication_date": "2023-03-20"}}
{"video": {"title": "Building AI Workflows with LangGraph and Tavily's Agentic Search", "transcript": "####Building AI Workflows with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\n\nHey AI enthusiasts! Today, we're diving into the world of AI workflows using LangGraph and Tavily's agentic search.\n\nBut first, why should you care about building AI workflows? They're the secret sauce to automating tasks, boosting efficiency, and making smarter decisions.\n\nSo, how do we build them with LangGraph and Tavily's agentic search? Let's break it down.\n\nWe'll start by designing our workflow and pinpointing the tasks our AI agents need to tackle.\n\nThen, we'll use LangGraph's components to craft our agents and Tavily's agentic search to supercharge their abilities.\n\nFinally, we'll put our workflow to the test and fine-tune as needed.\n\nBy the end of this video, you'll be a pro at building AI workflows that are not only efficient but also intelligent and adaptable.\n\nSo, are you ready to build the future with AI workflows? Let's get started!\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-30"}}
{"video": {"title": "On-Device AI: A Deep Dive into Performance Optimization", "transcript": "####On-Device AI: A Deep Dive into Performance Optimization\nby Krishna Sridhar - 2023-04-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Krishna Sridhar, and today we're diving headfirst into the world of On-Device AI!\n\nWe're going to explore how to supercharge the performance of your AI models on edge devices. We'll look at techniques like model pruning, quantization, and efficient use of compute units.\n\nThink of it like tuning a car for maximum speed and efficiency.\n\nRemember, use short sentences, write in a conversational style, and avoid repetition. Be confident and concise in your writing.\n\nSo, are you ready to push the limits of On-Device AI? Let's get optimizing!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2023-04-08"}}
{"video": {"title": "Chaining LLM Calls for Better Outputs", "transcript": "####Chaining LLM Calls for Better Outputs\nby Isa Fulford - 2022-10-18\n\n#### BEGIN TRANSCRIPT ####\nHey, it's Isa Fulford! Today, we're diving into the fascinating world of LLMs and how chaining calls can lead to better outputs. So, buckle up and get ready to unlock the full potential of large language models!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-18"}}
{"video": {"title": "Building a Question Answering System with LangChain", "transcript": "####Building a Question Answering System with LangChain\nby Harrison Chase, Andrew Ng - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're diving into the exciting world of LangChain to build a question answering system.\n\nQuestion answering is a hot topic in the LLM world. It's all about enabling users to ask questions in natural language and get spot-on answers.\n\nWith LangChain, building a question answering system is a breeze. We'll start with the basics and then level up to some advanced techniques.\n\nBy the end of this video, you'll have your very own question answering system up and running. So, let's get this party started.\n\nRemember, practice makes perfect. The more you play with LangChain, the better you'll become.\n\nThanks for tuning in. Don't forget to like, comment, and subscribe for more content on LLM application development. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-10"}}
{"video": {"title": "Optimizing TensorFlow Training with Multiple Processors", "transcript": "####Optimizing TensorFlow Training with Multiple Processors\nby Laurence Moroney, Eddy Shyu - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the exciting world of optimizing TensorFlow training with multiple processors.\n\nTraining deep learning models can be a real time-sucker, but did you know that you can turbocharge this process by using multiple CPUs or GPUs? In this video, we'll explore how to do just that.\n\nWe'll start by discussing the different types of parallelism in TensorFlow, including data parallelism and model parallelism. Then, we'll dive into how to implement these techniques to speed up your training.\n\n...\n\nThanks for watching! I hope this video helped you understand how to optimize your TensorFlow training with multiple processors. If you found this video helpful, please give it a thumbs up and subscribe to our channel for more content like this. See you next time!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-01-15"}}
{"video": {"title": "Machine Learning for Beginners: A Visual Approach", "transcript": "####Machine Learning for Beginners: A Visual Approach\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! I'm your host and today we're embarking on an exciting journey into the world of Machine Learning. Don't worry, we're making it fun and easy to understand.\n\nFirst things first, let's clear up any confusion about AI and Machine Learning. Think of AI as the big picture, and Machine Learning is one of the tools we use to achieve AI. It's like teaching a smart kid by showing them examples, rather than explicitly programming them.\n\nNow, let's get visual. Imagine you're teaching a computer to recognize apples. You show it lots of pictures, some with apples, some without. The computer starts noticing patterns, like apples are usually round and red. That's Machine Learning in a nutshell!\n\nNext, we'll dive into Python, the go-to language for Machine Learning. Don't worry if you're a beginner, we'll guide you every step of the way. You'll learn how to write code that can learn from data, just like our apple-recognizing computer.\n\nBut wait, there's math involved, right? Yes, but we'll make it as enjoyable as possible. We'll introduce concepts like linear regression and logistic regression in a way that even a fifth-grader could understand.\n\nAnd guess what? You're learning from the best. This course is brought to you in partnership with Stanford Online, and you'll be learning from industry experts like Andrew Ng, Eddy Shyu, Aarti Bagul, and Geoff Ladwig.\n\nSo, are you ready to take your first steps into the world of Machine Learning? Let's do this! Remember, there's no such thing as a silly question, so ask away in the comments below. And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-01-01"}}
{"video": {"title": "Quantization 101: Shrinking Models with Hugging Face and Quanto", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of simple language and active voice.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-15"}}
{"video": {"title": "Harnessing the Power of AI for Good: A Beginner's Guide", "transcript": "####Harnessing the Power of AI for Good: A Beginner's Guide\nby Robert Monarch - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the world of AI, but with a twist. We're not just talking about any AI, we're talking about AI for Good.\n\n[Video hook and introduction]\n\nImagine using artificial intelligence to predict air quality, optimize wind energy, protect biodiversity, or manage disasters. Sounds like a sci-fi movie, right? Well, it's not. It's happening right now, and you can be a part of it.\n\n[Body content]\n\nFirst, let's understand what AI for Good is. It's a movement that aims to use AI to tackle some of the world's most pressing issues, like climate change and public health. It's about using technology not just for profit, but for the benefit of all.\n\nNow, let's get our hands dirty. We'll walk through a simple framework for AI project development. Don't worry, it's beginner-friendly. We'll start with defining the problem, then move on to data collection, model building, and finally, deployment.\n\nTo make things more interesting, we'll build models for air quality prediction, wind energy optimization, biodiversity protection, and disaster management. Sounds exciting, right?\n\nBut that's not all. We'll also explore some real-world case studies. We'll see how AI is being used in public health to predict disease outbreaks, and in climate change to model and mitigate its impacts.\n\n[Conclusion and call to action]\n\nSo, are you ready to join the AI for Good movement? Remember, you don't need to be an expert to make a difference. All you need is a willingness to learn and a desire to make the world a better place.\n\nThanks for watching. If you found this video helpful, don't forget to like, share, and subscribe. And stay tuned for more exciting content on AI for Good.\n\n\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-03-15"}}
{"video": {"title": "Diffusion Models: The Power of Spread", "transcript": "####Diffusion Models: The Power of Spread\nby Sharon Zhou - 2023-03-16\n\n#### BEGIN TRANSCRIPT ####\nHey there, Sharon Zhou here, and today we're diving into the fascinating world of diffusion models.\n\nEver wondered how a trend goes viral? Or how a disease spreads? That's where diffusion models come in. They help us understand how things spread or diffuse over time and space.\n\nBut wait, there's more! We're not just going to talk about diffusion models, we're going to build one together. So, grab your Python environment, and make sure you've got Tensorflow or Pytorch ready. We'll start by defining our model, then we'll feed in our data, and finally, we'll train our model.\n\nBut what if I told you we could make our sampling process 10 times faster? Yes, you heard it right! I'll show you how to implement algorithms that will speed up your sampling process like never before.\n\nAnd that's it, folks! You've just learned how to build and train your own diffusion model, and even how to speed up the sampling process. Don't forget to hit that like button, subscribe, and share this video with your friends. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-03-16"}}
{"video": {"title": "Build Your Own Quantizer: A Step-by-Step Guide", "transcript": "####Build Your Own Quantizer: A Step-by-Step Guide\nby Marc Sun, Younes Belkada - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the exciting world of quantization in Pytorch!\n\nFirst, we'll walk you through the basics of quantization and why it's important for optimizing your models. Then, we'll show you how to build a general-purpose quantizer that can quantize the dense layers of any open-source model.\n\nBut wait, there's more! We'll also show you how to optimize your quantizer for maximum compression and minimum loss of accuracy.\n\nSo, are you ready to build your own quantizer and take your models to the next level? Let's get started!\n\nAnd don't forget to like, share, and subscribe for more great content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-01"}}
{"video": {"title": "Unleashing the Power of ChatGPT with Prompt Engineering", "transcript": "#### Unleashing the Power of ChatGPT with Prompt Engineering\nby Isa Fulford, Andrew Ng - 2023-03-18\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Andrew Ng and today we're diving into the exciting world of prompt engineering for ChatGPT. If you're a developer with basic Python skills, you're in luck!\n\nFirst things first, let's talk about what prompt engineering is and why it's a game-changer. Prompt engineering is the art of designing and optimizing inputs for language models like ChatGPT. It's crucial because the right prompt can make all the difference in getting the results you want.\n\nNow, let's get into some best practices. First, be clear and specific with your prompts. The more detailed you are, the better ChatGPT can understand what you're asking for. Second, don't be afraid to iterate. Prompt engineering is an iterative process, so try out different prompts and see what works best.\n\nNext, let's explore some new ways to use LLMs, or large language models. Did you know you can use LLMs for summarizing, inferring, transforming, and expanding text? Let's take a look at some examples using the OpenAI API.\n\nNow, it's time for some hands-on practice. We'll walk through writing and iterating on prompts together, and I'll show you how to use the OpenAI API to get results from ChatGPT.\n\nTo wrap up, prompt engineering is a powerful tool for application development with ChatGPT. With these best practices and some hands-on experience, you'll be well on your way to mastering prompt engineering. So go ahead and start experimenting with your own prompts. And who knows, you might even build your own custom chatbot!\n\nThanks for watching, and happy prompt engineering!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-18"}}
{"video": {"title": "GANs in the Real World: Applications and Use Cases", "transcript": "####GANs in the Real World: Applications and Use Cases\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Eric Zelikman, and today we're diving into the fascinating world of GANs!\n\n[Video hook and introduction]\n\nGANs, or Generative Adversarial Networks, are revolutionizing the way we generate new data. But what can we actually do with them? Let's explore some of the most exciting applications and use cases for GANs.\n\n[Body content]\n\nFirst up, image synthesis. GANs can generate new images that look like they were taken by a real camera. This has endless possibilities, from creating realistic video game environments to generating synthetic data for training other machine learning models.\n\nBut wait, there's more! GANs are also making waves in the field of medicine. They can generate synthetic medical images, helping doctors diagnose diseases and develop new treatments. And, they can generate synthetic patient data, protecting privacy while still allowing researchers to study diseases.\n\nAnd let's not forget about art and design. GANs can generate new images, patterns, and textures, opening up a world of possibilities for artists and designers.\n\n[Conclusion and call to action]\n\nSo, there you have it! GANs are changing the game in so many industries. It's a rapidly evolving field, and we're just scratching the surface of what's possible. Thanks for watching, and be sure to check out our other videos on GANs and machine learning. Until next time, keep exploring the world of AI!\n\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-03-22"}}
{"video": {"title": "GANs for Art and Design: Creating New Forms of Expression", "transcript": "####GANs for Art and Design: Unleashing Creativity with AI\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sharon Zhou, and today we're diving into the exciting world of GANs for art and design.\n\n[Video hook and introduction]\n\nGANs, or Generative Adversarial Networks, are revolutionizing the way we create art and design. They're a powerful tool for generating realistic images, and they have the potential to unleash a whole new level of creativity. In this video, we'll explore some of the coolest ways that GANs are being used in the field of art and design.\n\n[Body content]\n\nOne of the most exciting applications of GANs in art and design is for generating new works of art. GANs can be used to create new paintings, sculptures, or other works of art in the style of a particular artist or genre. They can also be used to generate new designs for products or buildings.\n\nBut that's not all. GANs can also be used to create new forms of expression that challenge our perceptions of reality. Imagine being able to generate images or videos that look so real, you can't tell the difference between them and the real thing. That's the power of GANs.\n\nOf course, there are also challenges in using GANs for art and design. For example, there are ethical considerations around using synthetic images or videos for artistic expression. And there are questions around the ownership and authorship of works created by GANs. But don't worry, we'll explore those challenges too.\n\n[Conclusion and call to action]\n\nSo, that's a quick overview of using GANs for art and design. If you want to learn more, be sure to check out our other videos on the topic. And if you have any questions or comments, leave them down below. We love hearing from you.\n\nThanks for watching, and we'll see you in the next video. Let's get creative with GANs!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-04-01"}}
{"video": {"title": "Privacy Preservation with GANs", "transcript": "####Privacy Preservation with GANs\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-03-01\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Eric Zelikman, and today we're diving into the world of privacy preservation in GANs.\n\n[Video hook and introduction]\n\nGANs, or Generative Adversarial Networks, are incredible tools for creating new data. But with great power comes great responsibility. They can also be used to create deepfakes, which can spread misinformation and harm individuals. So, how can we ensure privacy when working with GANs?\n\n[Body content]\n\nOne approach is to use differential privacy, which adds a little noise to the data to protect individual privacy. Another approach is federated learning, which allows us to train models on decentralized data without sharing it. But it's not just about technology. We also need to consider the ethical implications of using GANs and make sure we're using them responsibly and transparently.\n\n[Conclusion and call to action]\n\nSo, that's a quick overview of privacy preservation in GANs. It's a complex issue, but by being aware of it and taking steps to address it, we can make sure our GANs are used in a responsible and ethical way. Thanks for watching, and be sure to check out our other videos on GANs and machine learning. Until next time, stay safe and keep innovating!\n\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-03-01"}}
{"video": {"title": "Quantization Best Practices: Tips for Success", "transcript": "####Quantization Best Practices: Tips for Success\nby Marc Sun, Younes Belkada - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, quantization enthusiasts! I'm Marc Sun, and today I'm teaming up with Younes Belkada to bring you our top tips for success with quantization.\n\nFrom choosing the right granularity to optimizing your quantizer, we'll cover a range of topics to help you get the most out of quantization.\n\nSo, are you ready to become a quantization master? Let's dive in!\n\nFirst up, we'll talk about the importance of choosing the right granularity for your data. Then, we'll show you how to optimize your quantizer for maximum performance. And finally, we'll share some best practices for implementing quantization in your machine learning models.\n\nBut wait, there's more! We'll also sprinkle in some humor and real-world examples to keep things interesting.\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content. And if you have any questions or comments, be sure to leave them in the comments section below. We'd love to hear from you!\n\nUntil next time, happy quantizing!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-25"}}
{"video": {"title": "Harnessing the Power of AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####Harnessing the Power of AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey Python lovers! Today, we're exploring the exciting world of AI agents using LangChain's LangGraph and Tavily's agentic search.\n\nFirst up, what's LangGraph? It's an open-source framework that empowers you to build, debug, and maintain AI agents. It's like having a superpower for creating controllable agents.\n\nNow, let's talk about Tavily's agentic search. It's a game-changer. It boosts your agent's knowledge and performance, making your AI more efficient and effective.\n\nIn this course, you'll learn directly from Harrison Chase, the mastermind behind LangChain, and Rotem Weiss, the brain behind Tavily. They'll guide you through LangGraph's components and show you how to integrate agentic search capabilities.\n\nRemember, this course is perfect for you if you have intermediate Python knowledge and want to take your AI game to the next level.\n\nSo, are you ready to transform the way you build AI agents? Let's dive in! Don't forget to like, share, and subscribe for more thrilling content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-15"}}
{"video": {"title": "Training and Tuning LLMs for Optimal Performance", "transcript": "####Training and Tuning LLMs for Optimal Performance\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Shelbee Eigenbrode, and today we're diving into the exciting world of training and tuning LLMs for optimal performance!\n\nFirst things first, let's talk about training. It's all about feeding your LLM a massive amount of text data and using techniques like backpropagation to adjust the model's weights and boost its accuracy. But wait, there's more! You'll also need to consider other factors like the choice of loss function, learning rate, and batch size.\n\nNext up, we'll chat about fine-tuning an LLM for specific tasks, such as text classification or named entity recognition. Fine-tuning involves adjusting the model's weights on a smaller, task-relevant dataset. This can significantly improve the model's performance without breaking the bank on data or computational resources.\n\nBut how do you know if your LLM is performing at its best? We'll discuss some metrics for evaluating LLM performance, such as perplexity and BLEU score, and how to interpret these metrics to make informed decisions about your model.\n\nBy the end of this video, you'll have a solid understanding of how to train and tune LLMs for optimal performance on a variety of tasks. So, let's get started and take your LLM game to the next level!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-15"}}
{"video": {"title": "Quantization in Depth: Real-World Applications", "transcript": "####Quantization in Depth: Real-World Applications\nby Marc Sun, Younes Belkada - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow tech enthusiasts! I'm Marc Sun, and today we're diving into the fascinating world of quantization. We'll explore some real-world applications that are sure to blow your mind.\n\nQuantization is a game-changer, allowing us to do more with less. And trust me, you won't want to miss out on this one.\n\nBut first, let me ask you a question. Have you ever wondered how we can make our machines smarter and more efficient? Well, wonder no more! Quantization is the answer.\n\nSo, buckle up and get ready to learn about some amazing use cases. And don't forget to like, share, and subscribe for more exciting content. Let's get started!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-20"}}
{"video": {"title": "Unleashing the Power of Natural Language Processing with Hugging Face", "transcript": "####Unleashing the Power of Natural Language Processing with Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Your Assistant, and today we're embarking on an exciting journey into the world of Natural Language Processing, or NLP for short. We're going to design apps that can answer questions, analyze sentiment, translate languages, and even summarize text!\n\nFirst off, let's talk about question-answering. Imagine having an app that can understand and respond to user queries, just like a real person. With NLP, that's possible! And we'll be using Hugging Face, a powerful tool that makes implementing NLP models a breeze.\n\nNext up, sentiment analysis. Ever wondered how social media platforms know if a post is positive, negative, or neutral? That's sentiment analysis at work. We'll show you how to build an app that can do just that.\n\nNow, let's talk translation. With NLP, you can create an app that translates text from one language to another. It's like having your own personal translator, right in your pocket!\n\nLastly, we'll explore text summarization. Imagine being able to condense a long article into a short summary. That's the power of NLP.\n\nRemember, NLP is a complex field, but with Hugging Face, it's never been easier to get started. So don't be intimidated, jump right in and start building!\n\nThat's it for today's video. If you found this helpful, be sure to give it a thumbs up and subscribe for more content. And if you're ready to start building your own NLP apps, check out the links in the description for some great resources. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-03-15"}}
{"video": {"title": "Understanding Multimodality and Contrastive Learning", "transcript": "####Understanding Multimodality and Contrastive Learning\nby Sebastian Witalec - 2022-10-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to dive into the fascinating world of multimodality and contrastive learning? Well, buckle up because we're about to embark on an exciting journey!\n\nIn this video, we'll be exploring how these concepts are revolutionizing the way we build smarter search and RAG applications. Trust me, you won't want to miss this!\n\nSo, what exactly is multimodality and contrastive learning? And how do they work together to create more intelligent AI systems? Let's find out!\n\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-03"}}
{"video": {"title": "Chat with Your Data using LangChain!", "transcript": "####Chat with Your Data using LangChain!\nby Harrison Chase - 2023-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Harrison Chase, the mastermind behind LangChain, and today we're going to have a blast building your very own chatbot that can communicate with your private data and documents.\n\nAre you fed up with rummaging through mountains of documents and data to find that one elusive piece of information? Well, I've got some exciting news for you! With LangChain, you can create a chatbot that will take on the heavy lifting for you.\n\nFirst things first, you'll need a basic understanding of Python to follow along. But don't worry, we'll keep it simple and easy to grasp.\n\nSo, let's get started! LangChain gives you access to over 80 unique loaders that can handle various data sources. This means you can connect your chatbot to a wide range of documents and data, from PDFs to CSV files, and even your own custom data sources.\n\nOnce you've connected your data, the real magic begins. You'll be able to chat directly with the information from your own documents and data. Imagine being able to ask your chatbot questions like 'What were the sales figures for Q1?' or 'What did the boss say in that email last week?' and getting an instant answer.\n\nAnd the cherry on top? You'll be learning directly from me, the creator of LangChain. I'll be guiding you through each step of the process, sharing tips and tricks along the way.\n\nSo, are you ready to transform the way you interact with your data? Let's dive in!\n\nRemember, if you have any questions or need help along the way, don't hesitate to reach out. And once you've built your chatbot, be sure to share it with me. I can't wait to see what you create!\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-02-15"}}
{"video": {"title": "Debugging and Controlling Your Agentic RAG System", "transcript": "####Debugging and Controlling Your Agentic RAG System\nby Jerry Liu - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and today we're diving into the world of debugging and controlling your agentic RAG system.\n\nLet's face it, no system is flawless and sometimes, things can go awry. That's why it's crucial to know how to debug and control your agent.\n\nIn this video, we'll discuss some common hiccups you might encounter and how to troubleshoot them. We'll also chat about some strategies for controlling your agent's behavior and making sure it's working exactly as you want it to.\n\nBy the end of this video, you'll have the skills to debug and control your own agentic RAG system like a pro.\n\nSo, let's get started!\n\nAnd remember, if you have any questions or need further clarification, don't be shy! Leave a comment below. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-05"}}
{"video": {"title": "AI for Biodiversity: Protecting Our Planet's Ecosystems", "transcript": "####AI for Biodiversity: Protecting Our Planet's Ecosystems\nby Robert Monarch - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, nature enthusiasts and AI aficionados! I'm Robert Monarch, and today we're embarking on an exciting journey to discover how AI can help protect biodiversity.\n\nFirst, we'll chat about why biodiversity matters and the challenges it's facing. Then, we'll delve into how AI can be a game-changer in monitoring and safeguarding endangered species.\n\nWe'll explore how AI can crunch massive amounts of data to track species populations, forecast habitat shifts, and even sniff out illegal activities like poaching.\n\nWe'll also take a peek at a real-world example where AI has been put to work to save an endangered species.\n\nSo, are you ready to learn how AI can be a superhero for our planet's ecosystems? Let's dive in!\n\nRemember, every little step you take towards learning and applying AI for good makes a difference.\n\nThanks for tuning in. Don't forget to give this video a thumbs up, share it with your friends, and hit that subscribe button for more thrilling content on AI. Until next time, let's keep using AI for good.\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-01"}}
{"video": {"title": "Getting Started with LangChain: Your First LLM Application", "transcript": "####Getting Started with LangChain: Your First LLM Application\nby Harrison Chase, Andrew Ng - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Harrison Chase here. Today, we're diving into the world of LLM applications with LangChain. Are you ready to create your first one? Let's get started!\n\nFirst, we need to set up our environment. We'll need Python and the LangChain framework. Don't worry, I'll guide you through each step.\n\nNow, let's build our application. We'll start by creating a simple chatbot. It's like teaching a kid to talk. We'll use prompts to teach our chatbot how to respond, and parsing to understand the user's input.\n\nOnce our chatbot is responding, we'll add some memory. This will allow our chatbot to remember previous conversations. It's like giving your chatbot a brain.\n\nAnd that's it! By the end of this video, you'll have your very own LLM application.\n\nRemember, the key to learning is doing. So, let's get our hands dirty and start building.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-03-20"}}
{"video": {"title": "Mathematics for Machine Learning: Putting it All Together", "transcript": "####Mathematics for Machine Learning: The Power Behind the Predictions\nby Obed Kobina Nsiah - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Obed Kobina Nsiah, and today we're going to uncover the secret sauce behind machine learning: mathematics!\n\nRemember calculus? We use it to fine-tune our models. Linear algebra? It helps us manipulate and understand our data. Statistics and probability? They help us make sense of our data and make predictions.\n\nLet's see these concepts in action in a real-world machine learning project. We'll be using a dataset to predict house prices.\n\nFirst, we'll use linear algebra to preprocess our data. Then, we'll use statistics to understand the patterns and relationships in our data. Next, we'll use probability to make predictions about house prices.\n\nFinally, we'll use calculus to optimize our model, making it learn faster and better.\n\nSo, that's how mathematics powers machine learning. It's not just theory, it's a practical toolkit that helps us solve real-world problems.\n\nRemember, learning is a journey. Keep exploring, keep learning, and don't be afraid to make mistakes.\n\nJoin us in our next video, where we'll be diving into more advanced machine learning topics. If you found this video helpful, give us a thumbs up and subscribe to our channel for more exciting content. See you next time!\n\n#### END TRANSCRIPT ########", "author": "Obed Kobina Nsiah", "publication_date": "2023-04-05"}}
{"video": {"title": "Device Integration for On-Device AI", "transcript": "####Device Integration for On-Device AI\nby Krishna Sridhar - 2022-01-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're diving into the fascinating world of device integration for On-Device AI. Are you ready to learn how to integrate your AI models with edge devices like smartphones? Let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-01-30"}}
{"video": {"title": "Building a CNN from Scratch", "transcript": "####Building a CNN from Scratch: A Fun and Engaging Journey\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-01-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! I'm your friendly AI guide and today we're embarking on an exciting adventure: building a Convolutional Neural Network (CNN) from scratch.\n\nWe'll be using Python and TensorFlow to create our CNN, and we'll be putting it to the test on a real-world image classification task.\n\nFirst, we'll get our hands dirty with data preprocessing and split it into training and testing sets. Then, we'll dive into the heart of our CNN, defining its architecture, including the convolutional, pooling, and fully connected layers. After that, we'll compile our model and train it on our data. Finally, we'll evaluate our model and see how well it performs.\n\nNow, I know this might sound like a daunting task, but don't worry. I'll be with you every step of the way, making sure you don't miss a beat.\n\nSo, what are you waiting for? Let's get started on building our CNN. And remember, if you ever get stuck, I'm here to help.\n\nThanks for watching, and happy learning!\n\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-01-29"}}
{"video": {"title": "Red Teaming for Safer LLM Applications: A Beginner's Guide", "transcript": "Positive Points:\n\n- Clear introduction of the topic and its importance.\n- Use of active voice and simple language.\n- Encouragement of learning and improvement.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-03-15"}}
{"video": {"title": "Future of Multimodal Search and RAG", "transcript": "####Future of Multimodal Search and RAG\nby Sebastian Witalec - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sebastian Witalec and today we're diving into the thrilling world of multimodal search and RAG!\n\nWe've made some serious strides in this field, but where's it all heading? We'll explore some exciting trends and developments, like multimodal transformers and fusion.\n\nBut wait, there's more! We'll also discuss how these advancements could revolutionize various industries.\n\nRemember, the name of the game is staying ahead of the curve. This is especially important in industries where innovation is the name of the game.\n\nSo, let's get started! And if you have any questions, feel free to drop them in the comments. We're all in this learning journey together. And don't forget to hit that like button, share with your friends, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2023-04-30"}}
{"video": {"title": "Quantization in Action: A Real-World Example", "transcript": "####Quantization in Action: A Real-World Example\nby Marc Sun, Younes Belkada - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the world of quantization with a real-world example.\n\nFirst, we'll introduce you to our example model and dataset. Then, we'll walk you through the process of quantizing the model and evaluating the results.\n\nBut wait, there's more! We'll also show you how to fine-tune the quantized model for even better performance.\n\nSo, are you ready to see quantization in action? Let's get started!\n\nAnd remember, if you find this video helpful, don't forget to like, share, and subscribe for more great content. Until next time, happy quantizing!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-10"}}
{"video": {"title": "The Future of Generative AI with LLMs", "transcript": "####The Future of Generative AI with LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Chris Fregly here, and today we're diving into the exciting world of Generative AI with LLMs!\n\nAs LLMs continue to evolve and become more popular, the possibilities are endless. Imagine personalized news articles or even entire books tailored to your interests and reading level, all generated by LLMs.\n\nBut with great power comes great responsibility. We'll also discuss some of the challenges facing the field of Generative AI, such as the need for more diverse and representative training data, and the potential for LLMs to be used for malicious purposes.\n\nDon't worry, we've got some potential solutions up our sleeves too, like the development of more transparent and explainable LLMs.\n\nBy the end of this video, you'll have a better understanding of the current state of the art in Generative AI with LLMs and some ideas for how this technology could shape our future. So let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-05"}}
{"video": {"title": "Prompt Engineering 101 with Llama 2 & 3", "transcript": "####Prompt Engineering 101 with Llama 2 & 3\nby Amit Sangani - 2023-02-16\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Amit Sangani and today we're diving into the exciting world of Prompt Engineering 101 with Llama 2 & 3.\n\nAre you new to the AI game and feeling a bit lost? Don't sweat it, we've got your back. In this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst up, we'll be taking a look at Meta Llama 2 Chat and how you can interact with it to get the most out of your prompts. We'll also be exploring Code Llama and how it can help you with your coding needs.\n\nBut wait, there's more! We'll also be discussing the importance of building safe and responsible AI applications. That's where Llama Guard comes in. We'll show you how you can use this model to ensure that your AI applications are safe and responsible.\n\nSo, are you ready to take your prompting skills to the next level? Let's do this!\n\nRemember, the key to successful prompting is practice. So, be sure to try out these best practices on your own and see how they work for you. And, if you have any questions or need further clarification, don't hesitate to reach out.\n\nThanks for watching and happy prompting!\n\nBe sure to like, comment, and subscribe for more content like this. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-16"}}
{"video": {"title": "Exploring Mistral's Open-Source and Commercial Models", "transcript": "####Exploring Mistral's Open-Source and Commercial Models\nby Younes Belkada, Marc Sun - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Today, we're diving into the exciting world of Mistral's open-source and commercial models. We'll explore Mistral's JSON mode to generate structured LLM responses and learn how to leverage Mistral's API for enhanced capabilities. Let's get this party started!\n\nMistral AI offers a collection of advanced open source and commercial LLMs. Whether you're a newbie or a seasoned pro, Mistral has got you covered. We're partnering with Mistral AI to explore their three open source models and three commercial models, accessible through web interface and API calls.\n\nBy using Mistral's JSON mode, you can generate LLM responses in a structured format, perfect for integrating into larger software applications. But wait, there's more! Mistral's API allows you to call user-defined Python functions, enhancing the LLM's ability to find relevant information.\n\nJoin us as we unlock the full potential of Mistral AI's models and API. Trust us, you won't want to miss this! Stay tuned for more exciting content from Mistral AI!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2022-10-15"}}
{"video": {"title": "Transformers: The Game Changers of NLP", "transcript": "####Transformers: The Game Changers of NLP\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, AI enthusiasts! It's your friendly AI guide, and today we're diving into the world of Natural Language Processing (NLP) - specifically, the game changers known as Transformers.\n\nTransformers have taken the NLP world by storm, outperforming traditional models in tasks like translation, summarization, and more. But how do they do it? Well, they use self-attention mechanisms to process sequences of data, allowing them to focus on different parts of the sequence simultaneously.\n\nIn this video, we'll learn how to build Transformers from scratch, train them, and apply them to real-world scenarios. By the end of this video, you'll be able to build your own Transformers and use them for tasks like machine translation, text summarization, and more.\n\nSo, are you ready to transform your NLP skills? Let's get started!\n\nRemember, this video is part of our Deep Learning Specialization, so if you're new to the field, you might want to start with the basics first.\n\nAnd that's a wrap for today! I hope you enjoyed learning about Transformers. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and stay curious!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2023-03-30"}}
{"video": {"title": "The Role of Ethics in LLM Red Teaming", "transcript": "####The Role of Ethics in LLM Red Teaming\nby Matteo Dora, Luca Martial - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Matteo Dora and today we're diving into the fascinating world of LLM red teaming, with a focus on ethics.\n\nEthics, you ask? Absolutely! It's the unsung hero in our quest to uncover vulnerabilities. We're not just breaking things for the fun of it, we're doing it responsibly.\n\nSo, what does ethical red teaming look like? First off, it's all about respecting user privacy. We're not in the business of compromising user data. It's a no-go zone.\n\nSecond, transparency is key. We're open books when it comes to our testing methods and results. We share them with our users and stakeholders, no secrets here.\n\nFinally, we always consider the potential consequences of our testing. We weigh the benefits of identifying a vulnerability against the potential harm of exploiting it. It's a delicate balance, but we've got it covered.\n\nThanks for tuning in! Remember to like, share, and subscribe for more exciting content on LLM applications. Until next time, keep it ethical and keep it interesting!\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-04-25"}}
{"video": {"title": "Building a Custom AI Agent with LangGraph", "transcript": "####Building a Custom AI Agent with LangGraph\nby Harrison Chase, Rotem Weiss - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to take your AI game to the next level? Today, we're diving into the world of LangGraph and learning how to build a custom AI agent.\n\nBut first, let's talk about why building a custom AI agent is so important. It allows us to tailor our agent to specific tasks and requirements, improving its performance and efficiency. Plus, who doesn't want their own AI superhero?\n\nSo, how do we build a custom AI agent with LangGraph? Let's get into it.\n\nWe'll start by identifying the tasks our agent needs to complete and the requirements it needs to meet. Then, we'll walk you through the process of building a custom AI agent with LangGraph, using its components and tools to bring our agent to life.\n\nBy the end of this video, you'll be able to build your own custom AI agents, ready to take on any task. And trust us, your future self will thank you.\n\nSo, are you ready to build your own AI superhero? Let's dive in!\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-20"}}
{"video": {"title": "Mastering Prompt Engineering with Llama 2 & 3", "transcript": "####Mastering Prompt Engineering with Llama 2 & 3\nby Amit Sangani - 2023-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Amit Sangani and welcome to our exciting journey into the world of Prompt Engineering with Llama 2 & 3.\n\nAre you ready to become a prompting pro and unlock the full potential of these powerful models? You're in luck! In this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst, we'll take a look at Meta Llama 2 Chat and how you can interact with it to get the most out of your prompts. We'll also explore Code Llama and how it can help you with your coding needs.\n\nBut that's not all, we'll also be discussing the importance of building safe and responsible AI applications. That's where Llama Guard comes in. We'll show you how you can use this model to ensure that your AI applications are safe and responsible.\n\nSo, are you ready to take your prompting skills to the next level? Let's get started!\n\nRemember, practice makes perfect. So, be sure to try out these best practices on your own and see how they work for you. And, if you have any questions or need further clarification, don't hesitate to reach out.\n\nThanks for watching and happy prompting!\n\nBe sure to like, comment, and subscribe for more content like this. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-15"}}
{"video": {"title": "Tool Use with AutoGen: Empowering Your AI Agents", "transcript": "####Tool Use with AutoGen: Empowering Your AI Agents\nby Chi Wang, Qingyun Wu - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHello, coding enthusiasts! Chi Wang here, and today we're diving into the fascinating world of Tool Use in AutoGen.\n\nImagine handing your AI agent a toolbox. That's the power of Tool Use! We'll show you how to equip your agents with external tools to help them tackle tasks more efficiently.\n\nWe'll kick things off by explaining the concept of Tool Use and then dive into a practical example. We'll walk you through the process of creating an agent, giving it a tool, and setting it loose on a task.\n\nRemember, our goal is to make our agents more capable and autonomous. So, let's get started and empower our AI agents with AutoGen!\n\nAs always, if you have any questions, feel free to leave them in the comments. We're here to help you learn and grow.\n\nDon't forget to like, subscribe, and hit that notification bell for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2023-03-15"}}
{"video": {"title": "Linear Quantization Variants: Symmetric vs. Asymmetric Mode", "transcript": "####Linear Quantization Variants: Symmetric vs. Asymmetric Mode\nby Younes Belkada - 2022-10-16\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Younes Belkada, your AI companion for the day! Today, we're diving into the fascinating world of linear quantization, specifically the symmetric and asymmetric modes. Why should you care? Because understanding these modes can help you optimize your model compression like a pro! So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Younes Belkada", "publication_date": "2022-10-16"}}
{"video": {"title": "Building Your Own Database Agent with Natural Language Processing", "transcript": "####Building Your Own Database Agent with Natural Language Processing\nby Adrian Gonzalez Sanchez - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Adrian Gonzalez Sanchez and welcome to this thrilling video on building your own database agent using natural language processing!\n\nAre you fed up with writing complex SQL queries to interact with your databases? Well, you're in for a treat because today, we're going to learn how to use natural language to interact with tabular data and SQL databases, making data analysis more efficient and accessible.\n\nDon't worry if you're new to this topic. This beginner-friendly course will guide you through everything you need to know. Familiarity with Python programming and databases (CSV files and SQL) is recommended but not required.\n\nWe'll be teaming up with Microsoft to gain hands-on experience with the Azure OpenAI Service. We'll be implementing techniques like Retrieval Augmented Generation (RAG) and function calling to make our database agent more powerful.\n\nWe'll also be using Azure OpenAI Service\u2019s Assistants API, and testing it with function calling and code interpreter features.\n\nSo, are you ready to transform the way you interact with databases? Let's get started!\n\n[Body Content]\n\nIn this section, we'll dive into the details of building our database agent. We'll start by setting up our environment and then move on to creating our first natural language query.\n\n[Insert detailed instructions and examples here]\n\n[Conclusion and Call to Action]\n\nCongratulations! You've just built your own database agent using natural language processing. With this new skill, you can now interact with databases more efficiently and make data analysis more accessible to everyone.\n\nBut don't stop here! There's so much more you can do with natural language processing and the Azure OpenAI Service. So, keep exploring, keep learning, and keep building.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Adrian Gonzalez Sanchez", "publication_date": "2023-03-15"}}
{"video": {"title": "Building Your First Neural Network with TensorFlow", "transcript": "####Building Your First Neural Network with TensorFlow\nby Laurence Moroney - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're going to build our first neural network using TensorFlow!\n\n[Video hook and introduction]\n\nAre you ready to dive into the world of AI? Neural networks are the backbone of many AI applications, and TensorFlow makes it easy to create and train them. So let's get started!\n\n[Body content]\n\nFirst, we'll discuss the structure of a neural network, including input and output layers, hidden layers, and neurons. We'll also cover activation functions and their role in introducing non-linearity to our models.\n\nNext, we'll walk through the process of building a neural network in TensorFlow. We'll define the model architecture, compile the model with a loss function and optimizer, and train the model using our dataset.\n\nOnce our model is trained, we'll evaluate its performance and discuss techniques for improving its accuracy, such as regularization, dropout, and batch normalization.\n\n[Conclusion and call to action]\n\nBy the end of this video, you'll have built and trained your first neural network with TensorFlow. This is a significant milestone in your AI journey, so congratulations!\n\nRemember to like, share, and subscribe for more TensorFlow content. In the next video, we'll explore convolutional neural networks and how they're used for image classification tasks. See you there!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-03-25"}}
{"video": {"title": "Quantization Unveiled: Enhancing Models with Hugging Face and Quanto", "transcript": "####Quantization Unveiled: Enhancing Models with Hugging Face and Quanto\nby Younes Belkada, Marc Sun - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada and today, I'm joined by Marc Sun to unveil the secrets of quantization using Hugging Face and Quanto libraries.\n\nSo, what's the buzz about quantization? Well, it's like having a secret recipe that lets you enhance your models without losing their flavor.\n\nLet's dive in. We'll be using the Hugging Face Transformers library and the Quanto library for this task. If you're new to these tools, don't worry, we'll walk you through every step.\n\nFirst, we'll explore linear quantization, a simple yet effective method for enhancing models. It's like having a magic ingredient that turns your ordinary models into extraordinary ones.\n\nThen, we'll practice quantizing open-source multimodal and language models. It's like having a refined version of your favorite dishes, but with all the flavor intact.\n\nBy the end of this video, you'll be a pro at unveiling the secrets of quantization and you'll have saved a ton of space on your hard drive.\n\nRemember, practice is the key to mastery, so don't hesitate to experiment with different models and methods. And if you encounter a hurdle, just rewind and watch it again.\n\nThanks for tuning in and don't forget to hit that like button, share this video, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-15"}}
{"video": {"title": "Scaling Knowledge Graphs for RAG", "transcript": "####Scaling Knowledge Graphs for RAG\nby Andreas Kollegger - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Andreas Kollegger, and today we're diving into the exciting world of scaling knowledge graphs for Retrieval Augmented Generation, or RAG.\n\nBut wait, what's LangChain? If you're new to the game, I suggest you check out our fun and informative course 'LangChain: Chat with Your Data' before you dive into this intermediate content.\n\nNow, let's get started. We'll be using Neo4j's query language, Cypher, to manage and retrieve data from our knowledge graph.\n\nIn this video, we'll discuss some strategies for scaling knowledge graphs to handle larger datasets and more complex queries for RAG. We'll also provide some tips and tricks for optimizing the performance and functionality of your knowledge graphs as they scale.\n\nSo, are you ready to take your knowledge graphs to the next level? Let's do this!\n\nRemember, the key to scaling knowledge graphs is planning and preparation. So, don't be afraid to think ahead and anticipate future needs. And if you have any questions, feel free to leave them in the comments below.\n\nThanks for watching, and happy coding!\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2023-04-25"}}
{"video": {"title": "Getting Started With Mistral", "transcript": "####Getting Started With Mistral\nby Younes Belkada, Marc Sun - 2022-11-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Welcome to today's video where we're diving into the exciting world of Mistral AI. I'm Your host, Younes Belkada, and I'm joined by the brilliant Marc Sun. Today, we're going to explore Mistral's open-source and commercial models, and learn how to leverage Mistral's JSON mode to generate structured LLM responses. Let's get this show on the road!\n\nFirst up, let's take a look at Mistral's three open source models - Mistral 7B, Mixtral 8x7B, and the latest Mixtral 8x22B. These models offer a wide range of capabilities and can be accessed through Mistral's web interface and API calls.\n\nNext, we'll delve into Mistral's three commercial models - small, medium, and large. These models offer even more advanced features and can be used for a variety of applications.\n\nOne of the standout features of Mistral is its JSON mode, which allows users to generate LLM responses in a structured JSON format. This enables seamless integration of LLM outputs into larger software applications, making Mistral a powerful tool for developers.\n\nBut wait, there's more! Mistral's API allows users to call user-defined Python functions, enhancing the LLM's capabilities. This feature can be used for tasks like web searches or retrieving text from databases, enabling the LLM to find relevant information to answer user queries more effectively.\n\nIn conclusion, Mistral AI offers a range of open source and commercial models, as well as powerful features like JSON mode and API integration. Whether you're a beginner or an experienced developer, Mistral has something to offer. So, what are you waiting for? Go check out Mistral AI for yourself! And don't forget to like, share, and subscribe for more exciting content. See you next time!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2022-11-01"}}
{"video": {"title": "Mastering Mathematics for Machine Learning and Data Science", "transcript": "####Mastering Mathematics for Machine Learning and Data Science\nby Luis Serrano - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Today, we're embarking on an exciting journey to uncover the mathematical secrets of machine learning. I'm your guide, Luis Serrano, and I promise you, this will be a ride worth taking!\n\nFirst stop: Calculus. It's all about change and accumulation. With derivatives, we find the slope of a curve, and with integrals, we calculate the area under a curve. Trust me, understanding calculus is a game-changer for optimizing machine learning algorithms.\n\nNext, we're hopping onto the linear algebra train. This branch of mathematics deals with vectors, matrices, and linear transformations. It's the backbone of machine learning, helping us represent and manipulate data like a pro.\n\nMoving on, we're diving into the world of statistics. We analyze data to make informed decisions. We use mean, median, and standard deviation to summarize data. Statistical methods are essential for drawing insights from datasets.\n\nLastly, we're embracing the uncertainty with probability. We use probability theory to model the likelihood of events and make predictions. It's a key tool in machine learning for handling uncertainty.\n\nIn conclusion, mastering mathematics is a must for excelling in machine learning and data science. Practice your calculus, brush up on linear algebra, dive into statistics, and embrace probability theory. I'm Luis Serrano, and I hope you enjoyed this crash course in mathematics for machine learning. Stay curious and keep learning!\n#### END TRANSCRIPT ########", "author": "Luis Serrano", "publication_date": "2022-10-15"}}
{"video": {"title": "Building AI Applications with Open Source Models on Hugging Face", "transcript": "####Building AI Applications with Open Source Models on Hugging Face\nby Maria Khalusova - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Maria Khalusova, and today we're going to explore the exciting world of open-source models with Hugging Face. Are you ready to learn how to build AI applications using these powerful tools? Let's get started!\n\nOpen-source models are revolutionizing the AI landscape. With Hugging Face, you can easily find and filter these models on the Hub based on task, rankings, and memory requirements. It's like having a goldmine of AI resources at your fingertips! And the best part? You don't need to be an expert to get started. This is a beginner-friendly course, so anyone can join in on the fun.\n\nWith just a few lines of code using the transformers library, you can perform text, audio, image, and even multimodal tasks. It's like magic, but better! And once you've built your AI app, you can easily share it with others using a user-friendly interface or via API. Plus, you can run your apps on the cloud using Gradio and Hugging Face Spaces.\n\nSo what are you waiting for? Let's dive into the world of open-source models with Hugging Face and start building some amazing AI applications today!\n#### END TRANSCRIPT ########", "author": "Maria Khalusova", "publication_date": "2022-10-15"}}
{"video": {"title": "Python and TensorFlow: The Power Tools of Deep Learning", "transcript": "####Python and TensorFlow: The Power Tools of Deep Learning\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Your favorite AI guide here, and today we're diving into the dynamic duo of Deep Learning - Python and TensorFlow.\n\nPython, the programming language that's as popular as a rockstar in the machine learning and deep learning world. And TensorFlow, the powerful library that's like a gym for your neural networks.\n\nWe're going to learn how to use Python and TensorFlow to build, train, and deploy neural networks. By the end of this video, you'll be a pro at using Python and TensorFlow for deep learning tasks.\n\nSo, are you ready to become a Deep Learning Jedi? Let's get started!\n\nRemember, this video is part of our Deep Learning Specialization. If you're new to the field, don't worry, we've got you covered. Start with the basics and work your way up.\n\nAnd that's a wrap for today! I hope you enjoyed learning about Python and TensorFlow. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and keep exploring the AI universe!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2023-04-05"}}
{"video": {"title": "Customize Model Compression with Advanced Quantization Techniques", "transcript": "####Customize Model Compression with Advanced Quantization Techniques\nby Marc Sun - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Welcome back to our channel. Today, we're going to dive deep into the world of quantization. We'll explore how to customize model compression using advanced quantization techniques. Let's get started!\n\nBut first, what exactly is quantization? Well, it's a process that involves reducing the precision of the weights and activations in a neural network. This can lead to significant reductions in model size and computational complexity, making it perfect for deployment on resource-constrained devices.\n\nIn this video, we'll be focusing on linear quantization. We'll explore different variants, such as symmetric vs. asymmetric mode, and different granularities like per tensor, per channel, and per group quantization.\n\nBut before we dive in, it's important to note that this course builds on the concepts introduced in the Quantization Fundamentals course. If you haven't already, we recommend checking that out first to ensure you have a solid foundation.\n\nNow, let's talk about some of the features you can expect in this course. You'll have the opportunity to try out different variants of linear quantization, giving you the flexibility to choose the best approach for your specific use case. Additionally, you'll learn how to build a general-purpose quantizer in PyTorch that can quantize the dense layers of any open-source model for up to 4x compression on dense layers.\n\nOne of the key techniques we'll cover is weights packing. This involves packing four 2-bit weights into a single 8-bit integer, further optimizing the quantization process.\n\nIn conclusion, quantization is a powerful tool for customizing model compression. By exploring advanced techniques like linear quantization, you can achieve significant reductions in model size without sacrificing performance. So, if you're ready to take your quantization skills to the next level, stay tuned for our upcoming videos!\n\nThanks for watching, and don't forget to like and subscribe for more content on AI and machine learning. See you next time!\n#### END TRANSCRIPT ########", "author": "Marc Sun", "publication_date": "2022-10-15"}}
{"video": {"title": "Transformer Architecture: The Power Behind LLMs", "transcript": "####Transformer Architecture: The Power Behind LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-02-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, Chris Fregly here, and today we're diving into the transformer architecture that powers LLMs!\n\nThe transformer architecture was introduced in a paper by Vaswani et al. in 2017, and it quickly became the go-to architecture for natural language processing tasks. The key innovation of the transformer is its use of self-attention mechanisms, which allow the model to weigh the importance of different words in a sentence when processing it.\n\nLet's take a closer look at how the transformer works. It consists of an encoder and a decoder, both of which are made up of multiple layers of self-attention and feedforward neural networks. The encoder processes the input sequence and generates a contextualized representation of it, which is then passed to the decoder to generate the output sequence.\n\nBut what makes the transformer so effective for LLMs? Its ability to process input sequences all at once, rather than one word at a time, allows it to capture longer-range dependencies and better understand the context of a sentence or paragraph.\n\nIn this course, you'll learn how to implement the transformer architecture in Python and use it to train your own LLMs. You'll also hear from experts in the field about the latest research and advancements in transformer-based models.\n\nSo, are you ready to unlock the power of the transformer architecture? Let's get started!\n\nRemember to like, comment, and subscribe for more content like this. And if you have any questions, feel free to leave them in the comments below. Thanks for watching!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-02-22"}}
{"video": {"title": "Building Multi-Step Systems with ChatGPT", "transcript": "####Building Multi-Step Systems with ChatGPT\nby Isa Fulford - 2022-10-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Isa Fulford! Are you ready to unlock the full potential of large language models? Today, we're diving into the world of ChatGPT and learning how to efficiently build multi-step systems. Trust me, you won't want to miss this!\n\nImagine being able to break down even the most complex tasks into manageable subtasks. Sounds too good to be true, right? Well, not anymore! Let's get started and see just how powerful ChatGPT can be.\n\nBut first, let me tell you a little story. I used to struggle with managing complex tasks, just like you. But then I discovered the power of large language models and my life was changed forever. And now, I'm here to share that knowledge with you.\n\nSo, are you ready to take your productivity to the next level? Let's do this!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-20"}}
{"video": {"title": "Mastering ChatGPT Prompt Engineering for Beginners", "transcript": "Positive Points:\n\n- Clear introduction of the topic and its importance.\n- Use of active voice and simple language.\n- Inclusion of humor and enthusiasm.\n- Encouragement for the audience to practice and improve.\n\nAreas for Improvement:\n\n- Add more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and real-world applications.\n- Make the conclusion more memorable and engaging.", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-15"}}
{"video": {"title": "AI for Climate Action: Taking Action with Technology", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Inclusion of a practical project.\n- Discussion of challenges and ethical considerations.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning.\n- Make the conclusion more memorable and engaging.\n- Improve the call to action.", "author": "Robert Monarch", "publication_date": "2023-04-25"}}
{"video": {"title": "LangChain: Chat with Your Data", "transcript": "####LangChain: Chat with Your Data\nby Harrison Chase - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nVideo hook and introduction: Hey there, data enthusiasts! Today, we're diving into the world of LangChain, a tool that lets you chat with your data like never before. I'm Harrison Chase, the creator of LangChain, and I'm thrilled to show you how to create your own chatbot. Let's get started!\n\nBody content: LangChain is a Python-based tool that's easy to use, even if you're a beginner. With over 80 unique loaders, you can connect your chatbot to various data sources. Imagine chatting directly with information from your own documents and data! It's like having a personal data assistant.\n\nConclusion and call to action: LangChain is changing the game when it comes to data interaction. Don't miss out on this opportunity to chat with your data in a whole new way. Join me, Harrison Chase, as we explore the possibilities of LangChain together. Stay tuned for more exciting tutorials and tips on how to make the most of this innovative technology. Let's chat with our data!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2022-10-15"}}
{"video": {"title": "Function-Calling and Data Extraction: Best Practices and Common Pitfalls", "transcript": "####Function-Calling and Data Extraction: Best Practices and Common Pitfalls\nby Jiantao Jiao, Venkat Srinivasan - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Venkat Srinivasan and welcome back to our series on function-calling and data extraction with LLMs. Today, we're diving into the world of best practices and common pitfalls.\n\nWe'll explore how to design effective functions, handle errors and exceptions, and optimize performance. We'll also discuss common pitfalls and how to dodge them.\n\nBy the end of this video, you'll have a better understanding of how to use function-calling and data extraction effectively and efficiently.\n\nRemember, the key to success is to keep learning and improving. So, don't just watch the video. Try out the examples yourself and experiment with different techniques.\n\nAnd if you have any questions, feel free to leave them in the comments. We're here to help!\n\nSo, are you ready to learn about best practices and common pitfalls when using function-calling and data extraction with LLMs? Let's get started!\n\nDon't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-04-10"}}
{"video": {"title": "Building an RNN from Scratch", "transcript": "####Building an RNN from Scratch: A Fun and Engaging Journey\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-02-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! I'm your AI guide and today we're going to embark on an exciting journey to build a Recurrent Neural Network (RNN) from scratch.\n\nWe'll be using Python and TensorFlow to build our RNN, and we'll be applying it to a real-world sequential data task. Trust me, it's going to be a blast!\n\nFirst, we'll preprocess our data and split it into training and testing sets. Then, we'll define our RNN architecture, including the recurrent layer and the output layer. After that, we'll compile our model and train it on our data. Finally, we'll evaluate our model and see how well it performs.\n\nNow, I know this might sound like a lot, but don't worry. I'll be with you every step of the way, making sure you don't miss a beat.\n\nSo, what are you waiting for? Let's get started on building our RNN. And remember, if you ever get stuck, I'm here to help.\n\nThanks for watching, and happy learning!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-02-05"}}
{"video": {"title": "RNNs and LSTMs: The Time Lords of Deep Learning", "transcript": "####RNNs and LSTMs: The Time Lords of Deep Learning\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Your favorite AI guide here, and today we're diving into the fascinating world of Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTMs).\n\nRNNs and LSTMs are the Time Lords of Deep Learning, mastering sequential data and time series data. They're the secret sauce behind tasks like language modeling, translation, and more.\n\nBut how do they work? Well, RNNs use loops to process sequences of data, one element at a time. LSTMs, on the other hand, are a special kind of RNN that can remember information for long periods.\n\nWe'll learn how to build RNNs and LSTMs from scratch, train them, and apply them to real-world scenarios.\n\nBy the end of this video, you'll be able to build your own RNNs and LSTMs and use them for tasks like sentiment analysis, chatbots, and more.\n\nSo, are you ready to become a Time Lord of Deep Learning? Let's get started!\n\nRemember, this video is part of our Deep Learning Specialization, so if you're new to the field, you might want to start with the basics first.\n\nAnd that's a wrap for today! I hope you enjoyed learning about RNNs and LSTMs. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and stay curious!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2023-03-25"}}
{"video": {"title": "Supercharging AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####Supercharging AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-04-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! Today, we're diving into the world of supercharging our AI agents using LangGraph and Tavily's agentic search.\n\nFirst, we'll uncover how LangGraph's components can turbocharge our agents' performance. It's like adding a nitrous oxide system to our agents!\n\nThen, we'll demonstrate how to integrate Tavily's agentic search capabilities to boost our agents' knowledge and performance even more.\n\nIn this course, you'll learn directly from Harrison Chase, the mastermind behind LangChain, and Rotem Weiss, the genius behind Tavily. They'll walk you through the process and share their insider tips.\n\nRemember, this course is ideal for those with intermediate Python skills who want to level up their AI agents.\n\nSo, are you ready to supercharge your AI agents? Let's do this!\n\nStay tuned for more thrilling lessons. And don't forget to like, share, and subscribe for more AI-powered content.\n\nUntil next time, keep innovating!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-12"}}
{"video": {"title": "Continuous Improvement in ML Production Systems", "transcript": "####Continuous Improvement in ML Production Systems\nby Andrew Ng - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! I'm Andrew Ng, and today we're going to dive into the exciting world of continuous improvement in Machine Learning production systems.\n\nContinuous improvement is all about making small, incremental changes to our system over time. It's about learning from our mistakes, adapting to new challenges, and constantly striving to improve.\n\nFirst things first, we need to collect feedback. This might involve monitoring performance metrics, gathering user feedback, or conducting A/B tests.\n\nNext up, we need to analyze our feedback. This involves identifying trends, understanding root causes, and making data-driven decisions.\n\nThen, it's time to make updates. This involves implementing changes, testing them thoroughly, and deploying them to our production system.\n\nBut the journey doesn't end there. We also need to monitor the impact of our changes, handle any issues that arise, and continuously improve our improvement processes.\n\nSo, are you ready to master continuous improvement in ML production systems? Start collecting feedback today, and remember, the journey to a better ML system never ends.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content on Machine Learning. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-05"}}
{"video": {"title": "Building a Real-Time LLM Application with Python and Predibase's LoRAX Framework", "transcript": "####Building a Real-Time LLM Application with Python and Predibase's LoRAX Framework\nby Travis Addair - 2023-03-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Travis Addair and today we're going to have a blast building a real-time LLM application using Python and Predibase's LoRAX framework.\n\nFirst things first, what's a real-time LLM application? It's an application that generates responses in real-time, as you type. Think chatbots and virtual assistants.\n\nNow, let's get our hands dirty. We'll use Python and Predibase's LoRAX framework to build our real-time LLM application. We'll start by fine-tuning a pre-trained language model on our specific task using LoRA. Once we have our fine-tuned model, we'll use LoRAX to serve it to multiple users at once.\n\nWe'll also cover how to handle requests from multiple users and balance the load between multiple models. This will ensure our application is scalable and can handle a large number of requests.\n\nFinally, we'll discuss some best practices for building real-time LLM applications, such as input validation and performance monitoring.\n\nThanks for watching and don't forget to like, comment, and subscribe for more videos on GenAI and LLM powered applications. See you in the next one!\n#### END TRANSCRIPT ########", "author": "Travis Addair", "publication_date": "2023-03-12"}}
{"video": {"title": "Mastering TensorFlow: Advanced Techniques", "transcript": "####Mastering TensorFlow: Advanced Techniques\nby Laurence Moroney, Eddy Shyu - 2022-03-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, TensorFlow enthusiasts! I'm Laurence Moroney, and today we're taking a thrilling dive into some advanced techniques with TensorFlow.\n\nFirst off, we're going to delve deeper into the Functional API. You might be familiar with the basics, but we're going to uncover some of its more advanced features and show you how to use it to build more complex models.\n\nNext, we're going to chat about optimizing training with multiple processors. If you're working with large datasets, you know how time-consuming training can be. We'll show you how to use TensorFlow's distributed training features to speed up the process.\n\nThen, we're going to explore some advanced computer vision techniques. We'll look at how to use pre-trained models, transfer learning, and fine-tuning to improve the accuracy of your models.\n\nFinally, we're going to dive into generative deep learning. We'll show you how to use variational autoencoders and generative adversarial networks to create new, synthetic data.\n\nSo, whether you're looking to build more complex models, speed up training, or explore the cutting edge of deep learning, this video has something for you. Thanks for watching, and be sure to check out our other videos on TensorFlow.\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-03-01"}}
{"video": {"title": "Introduction to Generative AI with LLMs", "transcript": "####Introduction to Generative AI with LLMs\nby Antje Barth - 2022-10-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Welcome to our video on Generative AI with LLMs. Today, we're going to dive headfirst into the world of generative AI and explore the transformer architecture that's powering LLMs. I'm your host, Antje Barth, and I'm thrilled to be your guide on this exciting journey.\n\nAre you ready to unlock the secrets of LLMs and discover how they're revolutionizing the field of AI? Then let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth", "publication_date": "2022-10-01"}}
{"video": {"title": "Mastering ChatGPT Prompt Engineering for Beginners", "transcript": "Positive Points:\n\n- Clear introduction of the topic and its importance.\n- Use of active voice and simple language.\n- Inclusion of humor and enthusiasm.\n- Encouragement for the audience to try out the techniques.\n\nAreas for Improvement:\n\n- Add more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-15"}}
{"video": {"title": "Harnessing the Power of AI for Good: A Beginner's Guide", "transcript": "####Harnessing the Power of AI for Good: A Beginner's Guide\nby Robert Monarch - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're embarking on an exciting journey into the world of AI, but not just any AI - we're talking about AI for Good!\n\nImagine using artificial intelligence to predict air quality, optimize wind energy, protect biodiversity, or manage disasters. Sounds like a superhero's job, right? Well, today, you're becoming that superhero.\n\nFirst, let's get our hands dirty with a simple framework for AI project development. Don't worry, it's beginner-friendly! We'll walk through each step, from defining the problem to deploying the solution.\n\nNow, let's roll up our sleeves and build some models. We'll start with air quality prediction. Ever wondered how AI can help us breathe cleaner air? You're about to find out!\n\nNext, we'll harness the power of wind with AI. We'll explore how machine learning can optimize wind energy production. It's like having a personal wind whisperer!\n\nThen, we'll dive into biodiversity protection. We'll see how AI can help us monitor and protect our planet's precious species. It's like being a digital David Attenborough!\n\nFinally, we'll tackle disaster management. We'll learn how AI can predict, prepare for, and respond to disasters. It's like having a crystal ball for catastrophes!\n\nBut wait, there's more! We'll also explore some inspiring case studies. We'll see how AI is revolutionizing public health and fighting climate change.\n\nSo, are you ready to join the AI for Good movement? Remember, you don't need a cape to be a superhero. All you need is a curious mind and a passion for making the world a better place.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning, keep growing, and keep using AI for Good!\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-03-15"}}
{"video": {"title": "Quantization for Mobile Devices", "transcript": "####Quantization for Mobile Devices: A Game Changer\nby Marc Sun, Younes Belkada - 2022-04-26\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Marc Sun, and today we're diving into the world of quantization for mobile devices.\n\nYou know how mobile devices have limited resources? Well, that's where quantization comes in. It's like a superhero, helping us reduce the size of our models and making them more mobile-friendly.\n\nBut wait, there's more! We'll also discuss some challenges and considerations when using quantization for mobile devices. And don't worry, we'll make it fun and easy to understand.\n\nBy the end of this video, you'll be a pro at using quantization for mobile devices. Trust me, your mobile apps will thank you.\n\nSo, let's get started. And remember, the best way to learn is by doing.\n\nDon't forget to like, share, and subscribe for more great content.\n\nUntil next time, I'm Marc Sun, and this has been Quantization for Mobile Devices: A Game Changer.\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-04-26"}}
{"video": {"title": "Quantization Unraveled: Boosting Models with Hugging Face and Quanto", "transcript": "####Quantization Unraveled: Boosting Models with Hugging Face and Quanto\nby Younes Belkada and Marc Sun - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada and today, I'm joined by Marc Sun. We're going to unravel the mysteries of quantization using Hugging Face and Quanto libraries.\n\nSo, what's the big deal about quantization? Well, it's like having a secret method that lets you boost your models without compromising their efficiency.\n\nLet's get started. We'll be using the Hugging Face Transformers library and the Quanto library for this task. If you're new to these tools, don't worry, we've got you covered.\n\nFirst, we'll explore linear quantization, a simple yet effective method for boosting models. It's like having a magic boost that turns your slow models into fast ones.\n\nThen, we'll practice quantizing open-source multimodal and language models. It's like having a turbocharged version of your favorite cars, but with all the efficiency intact.\n\nBy the end of this video, you'll be an expert at unraveling the mysteries of quantization and you'll have saved a ton of space on your hard drive.\n\nRemember, practice makes perfect, so don't be afraid to try out different models and methods. And if you get stuck, just hit the rewind button and watch it again.\n\nThanks for watching and don't forget to like, share, and subscribe for more awesome content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-20"}}
{"video": {"title": "Quantization Unmasked: Accelerating Models with Hugging Face and Quanto", "transcript": "####Quantization Unmasked: Accelerating Models with Hugging Face and Quanto\nby Younes Belkada and Marc Sun - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada and today, I'm teaming up with Marc Sun to unveil the power of quantization using Hugging Face and Quanto libraries.\n\nSo, what's the hype about quantization? It's like having a secret weapon that lets you speed up your models without sacrificing their performance.\n\nLet's get started. We'll be using the Hugging Face Transformers library and the Quanto library for this task. Don't worry if you're new to these tools, we'll walk you through every step.\n\nFirst, we'll explore linear quantization, a simple yet powerful method for accelerating models. It's like having a magic accelerator that transforms your slow models into fast ones.\n\nThen, we'll practice quantizing open-source multimodal and language models. It's like having a turbocharged version of your favorite cars, but with all the speed intact.\n\nBy the end of this video, you'll be a pro at unleashing the power of quantization and you'll have saved a ton of space on your hard drive.\n\nRemember, practice makes perfect, so don't hesitate to experiment with different models and methods. And if you hit a roadblock, just rewind and watch it again.\n\nThanks for joining us and don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-25"}}
{"video": {"title": "Optimizing Workflows with ChatGPT API", "transcript": "####Optimizing Workflows with ChatGPT API: A Game Changer!\nby Andrew Ng - 2022-10-24\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! It's your favorite AI guru, Andrew Ng, back with another exciting video. Today, we're going to explore how to supercharge your workflows using the ChatGPT API. Get ready to split tasks into subtasks like a pro, evaluate outputs with ease, and ensure safety and relevance. Let's get started!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-24"}}
{"video": {"title": "Deep Learning Ethics: A Discussion", "transcript": "####Deep Learning Ethics: A Crucial Conversation\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-02-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your friendly guide and today we're diving into a topic that's as important as it is fascinating: deep learning ethics.\n\nAs AI continues to weave itself into the fabric of our society, it's essential that we pause and consider the ethical implications. We'll be exploring topics like bias in AI, privacy concerns, and the potential impact of AI on employment.\n\nRemember, as AI developers, we hold a significant responsibility to create technology that uplifts everyone, not just a privileged few.\n\nSo, let's get this ethical discussion rolling. And don't forget, your thoughts and opinions matter, so feel free to share them in the comments.\n\nThat's all for today's video. If you found it insightful, give it a thumbs up and subscribe to our channel for more AI content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-02-19"}}
{"video": {"title": "Mastering Q&A with Agentic RAG and LlamaIndex", "transcript": "####Mastering Q&A with Agentic RAG and LlamaIndex\nby Jerry Liu - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Jerry Liu here and welcome back to our journey into the world of Agentic RAG with LlamaIndex.\n\nToday, we're going to master Q&A with our Agentic RAG. Remember the router agent we built in our last video? Now, we're going to take it to the next level.\n\nWe'll start by understanding how to ask the right questions. Because the key to getting the right answers is asking the right questions.\n\nThen, we'll learn how to handle complex questions that require reasoning over multiple documents. Yes, our agent is that smart!\n\nAnd finally, we'll explore some tips and tricks to improve the Q&A performance of our Agentic RAG.\n\nSo, are you ready to become a Q&A master with Agentic RAG and LlamaIndex? Let's get started!\n\nRemember, the more you practice, the better you'll get. So keep trying, keep building, and have fun!\n\nThanks for watching and don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n#### END TRANSCRIPT ########\n\nRefined Script:\n\n####Mastering Q&A with Agentic RAG and LlamaIndex\nby Jerry Liu - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Jerry Liu here and welcome back to our journey into the world of Agentic RAG with LlamaIndex.\n\nToday, we're going to master Q&A with our Agentic RAG. Remember the router agent we built in our last video? Now, we're going to take it to the next level.\n\nFirst, we'll understand how to ask the right questions. Because the key to getting the right answers is asking the right questions.\n\nThen, we'll learn how to handle complex questions that require reasoning over multiple documents. Yes, our agent is that smart!\n\nFinally, we'll explore some tips and tricks to improve the Q&A performance of our Agentic RAG.\n\nSo, are you ready to become a Q&A master with Agentic RAG and LlamaIndex? Let's get started!\n\nRemember, practice makes perfect. So keep trying, keep building, and have fun!\n\nThanks for watching and don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-03-20"}}
{"video": {"title": "Mastering Document Summarization with LlamaIndex", "transcript": "####Mastering Document Summarization with LlamaIndex\nby Jerry Liu - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Jerry Liu here and today we're diving deeper into the exciting world of document summarization with LlamaIndex.\n\nIn our previous videos, we've learned how to build an agentic RAG, mastered document Q&A, unleashed the power of summarization, built a multi-document research agent, learned how to debug and control our agent, extended our agent with custom functions, and built a question answering system. Today, we're going to take our skills to the next level and master document summarization.\n\nWe'll start by understanding the different types of document summarization. Then, we'll dive into building a summarization system with LlamaIndex.\n\nOnce we've got that down, we'll look at how to fine-tune our system to improve its accuracy and efficiency.\n\nBy the end of this video, you'll be a pro at document summarization with LlamaIndex.\n\nSo, let's get started! And remember, practice makes perfect. So, don't just watch this video, try building your own document summarization system with LlamaIndex.\n\nIf you found this video helpful, give it a thumbs up and subscribe to our channel for more exciting content. Until next time, happy coding!\n\n\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-20"}}
{"video": {"title": "Designing a Machine Learning Production System", "transcript": "####Designing a Machine Learning Production System\nby Andrew Ng - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, machine learning enthusiasts! Today, we're diving into the exciting world of machine learning in production. I'll walk you through the process of designing an ML production system, from scoping to deployment. Let's get started!\n\nFirst things first, we need to scope our project. This involves defining the problem we want to solve and setting clear objectives. Next up, we gather and preprocess our data. This step is crucial, as the quality of our data directly impacts the performance of our model.\n\nOnce our data is ready, it's time to start modeling. We'll select the right algorithm, tune hyperparameters, and evaluate the performance of our model. After building and testing our model, it's time to deploy it into production. This involves integrating our model into our existing systems and monitoring its performance in real-time.\n\nBut wait, there's more! The final step is continuous improvement. We'll collect feedback from users, retrain our model on new data, and iterate on our design. And there you have it - a complete guide to designing a machine learning production system.\n\nI hope you found this video helpful. If you have any questions, feel free to leave them in the comments below. Thanks for watching, and happy modeling!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-15"}}
{"video": {"title": "TensorFlow: Real-time Object Detection", "transcript": "####TensorFlow: Real-time Object Detection\nby Laurence Moroney - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Laurence Moroney, and today we're diving into the exciting world of real-time object detection with TensorFlow.\n\n[Video hook and introduction]\n\nImagine being able to identify objects in real-time, from augmented reality to autonomous vehicles. Sounds like something out of a sci-fi movie, right? Well, it's not. It's here, and it's powered by TensorFlow.\n\n[Body content]\n\nWe'll be using models like SSD MobileNet and YOLO. These aren't just fancy names, they're fast and accurate, making them perfect for real-time applications.\n\n[Conclusion and call to action]\n\nSo, are you ready to start exploring real-time object detection? The possibilities are endless. Keep learning, keep innovating, and happy coding!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-04-20"}}
{"video": {"title": "LangGraph and Tavily: The Future of AI Agent Development", "transcript": "####LangGraph and Tavily: Unleashing the Power of AI Agent Development\nby Harrison Chase, Rotem Weiss - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! Today, we're diving into the future of AI agent development with LangGraph and Tavily's agentic search.\n\nLangGraph is a game-changer, giving you the power to develop, debug, and maintain AI agents with ease. It's like having a superpower for creating controllable agents.\n\nBut wait, there's more! When you combine LangGraph with Tavily's agentic search, you're boosting your agent's knowledge and performance, making your AI more efficient and effective.\n\nIn this course, you'll learn from the best - Harrison Chase from LangChain and Rotem Weiss from Tavily. They'll guide you through LangGraph's components and show you how to integrate agentic search capabilities.\n\nThis course is perfect for those with intermediate Python knowledge who want to stay ahead of the curve in AI agent development.\n\nSo, are you ready to shape the future of AI agents? Let's get started! And don't forget to like, share, and subscribe for more exciting content.\n\nHappy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-15"}}
{"video": {"title": "Monitoring and Debugging ML Models: Catching Issues Before They Impact Users", "transcript": "####Monitoring and Debugging ML Models: Catching Issues Before They Impact Users\nby Andrew Ng - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here, and today we're diving into the world of monitoring and debugging machine learning models in production. Why? To catch issues before they impact users, of course!\n\nFirst things first, let's talk about why monitoring and debugging are so crucial. When we deploy machine learning models in production, we need to make sure they're performing as expected. But issues can arise due to data drift, concept drift, or other factors that can affect model performance.\n\nSo, how do we tackle this? It all starts with monitoring. We need to keep an eye on our models' performance metrics, such as accuracy, precision, recall, and F1 score, to ensure they're meeting our expectations. We'll talk about how to set up monitoring dashboards and alerts to catch issues early.\n\nNext up, debugging. When issues arise, we need to debug our models to identify the root cause. We'll talk about how to use techniques like error analysis, model explainability, and data validation to debug our models.\n\nBut wait, there's more! Monitoring and debugging machine learning models is not just about technology. It's also about people and processes. We'll talk about how to collaborate with data engineers, DevOps teams, and business stakeholders to ensure our monitoring and debugging strategy is aligned with the overall business goals.\n\nSo, are you ready to monitor and debug your machine learning models in production to catch issues before they impact users? Let's get started!\n\nRemember, monitoring and debugging machine learning models is not just about technology. It's about people, processes, and culture. So keep learning, keep experimenting, and most importantly, have fun!\n\nIf you found this video helpful, be sure to give it a thumbs up and subscribe for more content. And if you have any questions or suggestions, leave them in the comments below. Thanks for watching, and I'll see you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-20"}}
{"video": {"title": "Mastering ChatGPT Prompt Engineering", "transcript": "####Mastering ChatGPT Prompt Engineering\nby Isa Fulford - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Isa Fulford, and today we're embarking on an exciting journey into the world of ChatGPT prompt engineering. Are you ready to unlock the full potential of LLMs like ChatGPT? Then grab your Python skills and let's dive in!\n\nFirst, we'll explore the basics of prompt engineering and how it can enhance your interactions with ChatGPT. Then, we'll delve into some advanced techniques to craft prompts that truly make a difference. And don't worry, we'll keep things light and fun along the way!\n\nSo, are you ready to become a prompt engineering master? Let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-15"}}
{"video": {"title": "Quantization Unleashed: Supercharging Models with Hugging Face and Quanto", "transcript": "####Quantization Unleashed: Supercharging Models with Hugging Face and Quanto\nby Younes Belkada, Marc Sun - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada and today, Marc Sun and I are going to show you how to unleash the full potential of quantization using Hugging Face and Quanto libraries.\n\nSo, what's the big deal about quantization? Well, it's like having a secret recipe that lets you supercharge your models without losing their power.\n\nLet's dive in. We'll be using the Hugging Face Transformers library and the Quanto library for this task. If you're new to these tools, don't worry, we'll walk you through every step.\n\nFirst, we'll explore linear quantization, a simple yet effective method for supercharging models. It's like having a magic elixir that turns your ordinary models into supercharged ones.\n\nThen, we'll practice quantizing open-source multimodal and language models. It's like having a supercharged version of your favorite superheroes, but with all their power intact.\n\nBy the end of this video, you'll be a pro at unleashing the full potential of quantization and you'll have saved a ton of space on your hard drive.\n\nRemember, practice makes perfect, so don't be afraid to try out different models and methods. And if you get stuck, just hit the rewind button and watch it again.\n\nThanks for watching and don't forget to like, share, and subscribe for more awesome content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-30"}}
{"video": {"title": "Extending Your Agentic RAG with LlamaIndex", "transcript": "####Extending Your Agentic RAG with LlamaIndex\nby Jerry Liu - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow tech enthusiasts! Jerry Liu here, and today we're diving deeper into the world of Agentic RAG with LlamaIndex.\n\nAre you ready to take your Agentic RAG to the next level? Because the beauty of Agentic RAG is that it's highly customizable and extendable.\n\nFirst, we'll learn how to add new functionalities to our Agentic RAG. It's like adding new superpowers to our trusty sidekick!\n\nThen, we'll explore how to integrate our Agentic RAG with other tools and systems. Imagine the possibilities when your Agentic RAG can work seamlessly with your favorite apps!\n\nFinally, we'll delve into some advanced topics like agent reasoning and multi-agent systems. It's like entering a whole new dimension of tech!\n\nSo, are you ready to extend your Agentic RAG with LlamaIndex? Let's get started!\n\nRemember, practice makes perfect. So keep trying, keep building, and most importantly, have fun!\n\nThanks for watching and don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-10"}}
{"video": {"title": "LangChain Best Practices for LLM Application Development", "transcript": "####LangChain Best Practices for LLM Application Development\nby Harrison Chase, Andrew Ng - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Harrison Chase here! Today, we're diving into the exciting world of LangChain and LLM application development.\n\nFirst up, we'll learn how to design effective prompts. I'll share some insider tips and tricks for creating prompts that get the response you want.\n\nNext, we'll tackle memory management. We'll learn how to store and retrieve information like a pro.\n\nFinally, we'll discuss some strategies for evaluating and improving your LLM.\n\nBy the end of this video, you'll be ready to create high-quality LLM applications that will blow your mind.\n\nSo, let's get started. Remember, the best way to learn is by doing.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-30"}}
{"video": {"title": "Wrapping Up Our LangChain Journey", "transcript": "####LangChain Journey: The Grand Finale\nby Harrison Chase, Andrew Ng - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're putting the final touches on our LangChain adventure for LLM application development.\n\nOver the past few weeks, we've covered a lot of ground. We've delved into prompts, parsing, memory, chains, question answering, and agents.\n\nWe've also learned how to apply LLMs to proprietary data and how to expand our use of LLMs with advanced techniques.\n\nI hope you've enjoyed this series as much as I have. But remember, this is just the beginning. There's a whole world of possibilities waiting to be explored with LangChain and LLMs.\n\nSo, keep practicing, keep experimenting, and keep pushing the boundaries of what's possible.\n\nThanks for watching. Don't forget to like, comment, and subscribe for more content on LLM application development. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-30"}}
{"video": {"title": "Introduction to Machine Learning Specialization", "transcript": "####Introduction to Machine Learning Specialization\nby Andrew Ng - 2022-10-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, machine learning enthusiasts! Welcome back to our channel. Today, we're embarking on an exciting adventure into the world of machine learning. We'll be focusing on the foundational concepts that will set you up for success. I'm your host, Andrew Ng, and I couldn't be more excited to be your guide on this learning journey. Let's dive in!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-01"}}
{"video": {"title": "Prompt Engineering for Text Summarization with ChatGPT", "transcript": "####Prompt Engineering for Text Summarization with ChatGPT\nby Isa Fulford, Andrew Ng - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're diving into the exciting world of prompt engineering for text summarization with ChatGPT. If you're a beginner with basic Python skills, you're in the right place!\n\nFirst things first, let's talk about what text summarization is and why it's a game-changer. Text summarization is the art of condensing a large piece of text into a shorter version that still packs a punch. It's a valuable skill in many areas, from content creation to data analysis.\n\nNow, let's see how we can use ChatGPT and prompt engineering to make text summarization a breeze. The secret sauce is to craft prompts that ask the model to summarize the text in a specific way. Let's look at some examples and try it out ourselves.\n\nRemember, the key to good prompts is to be clear, concise, and specific. Let's iterate on our prompts and see how we can improve the summaries we get from ChatGPT.\n\nAnd that's a wrap! You've just learned how to use prompt engineering for text summarization with ChatGPT. Remember, practice makes perfect. So keep experimenting and refining your prompts.\n\nThanks for watching and happy coding! And a special thanks to our partners at OpenAI for their support.\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-30"}}
{"video": {"title": "Advanced Computer Vision with TensorFlow", "transcript": "####Advanced Computer Vision with TensorFlow: Unlocking New Possibilities\nby Laurence Moroney, Eddy Shyu - 2022-01-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eddy Shyu, and today we're diving into the exciting world of advanced computer vision techniques with TensorFlow.\n\nAre you ready to take your models to the next level? In this video, we'll be discussing how to use pre-trained models, fine-tuning, and transfer learning to boost the accuracy of your models. We'll also be exploring some cutting-edge techniques like object detection and semantic segmentation.\n\nBut wait, there's more! We'll be showing you how to apply these techniques to real-world problems and use cases.\n\nSo, are you ready to unlock the full potential of computer vision with TensorFlow? Let's get started!\n\n...\n\nThanks for watching! I hope this video helped you understand some advanced computer vision techniques with TensorFlow. If you found this video helpful, please give it a thumbs up and subscribe to our channel for more content like this. And don't forget to share it with your friends and colleagues. See you next time!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-01-22"}}
{"video": {"title": "Introduction to Generative AI with LLMs", "transcript": "####Introduction to Generative AI with LLMs\nby Antje Barth - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Antje Barth, and today we're embarking on an exciting journey into the world of Generative AI with LLMs. We'll be exploring the lifecycle of generative AI, the transformer architecture that powers LLMs, and the methods for training, tuning, and inference. But that's not all! We'll also be hearing from some of the brightest minds in the field about the challenges and opportunities in generative AI. So, buckle up and get ready for a wild ride!\n#### END TRANSCRIPT ########", "author": "Antje Barth", "publication_date": "2022-01-15"}}
{"video": {"title": "Building AI Agents with LangGraph and Tavily: A Step-by-Step Guide", "transcript": "####Building AI Agents with LangGraph and Tavily: A Step-by-Step Guide\nby Harrison Chase, Rotem Weiss - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! Today, we're diving into the world of AI agents with a step-by-step guide using LangGraph and Tavily's agentic search.\n\nFirst, we'll uncover LangGraph's components and how they empower us to build, debug, and maintain AI agents. It's like having a GPS for creating controllable agents.\n\nThen, we'll demonstrate how to integrate Tavily's agentic search capabilities to boost our AI agents' knowledge and performance.\n\nIn this course, you'll learn directly from Harrison Chase, the mastermind behind LangChain, and Rotem Weiss, the brains behind Tavily. They'll guide you through each step of the process.\n\nRemember, this course is tailored for those with intermediate Python skills who want to learn how to build AI agents from scratch.\n\nSo, are you ready to build your own AI agents? Let's get started!\n\nStay tuned for more thrilling lessons. And don't forget to like, share, and subscribe for more AI-powered content.\n\nUntil next time, happy building!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-22"}}
{"video": {"title": "Prompt Engineering Fundamentals for ChatGPT", "transcript": "####Prompt Engineering Fundamentals for ChatGPT\nby Isa Fulford, Andrew Ng - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Andrew Ng and today we're diving into the exciting world of prompt engineering for ChatGPT. If you're a developer with basic Python skills, you're in luck!\n\nFirst things first, let's talk about what prompt engineering is and why it's a game-changer. Prompt engineering is the art of designing and optimizing inputs for language models like ChatGPT. It's crucial because the right prompt can make all the difference in getting the results you want.\n\nNow, let's get into some best practices. First, be clear and specific with your prompts. The more detailed you are, the better ChatGPT can understand what you're asking for. Second, don't be afraid to iterate. Prompt engineering is an iterative process, so try out different prompts and see what works best.\n\nNext, let's explore some new ways to use LLMs, or large language models. Did you know you can use LLMs for summarizing, inferring, transforming, and expanding text? Let's take a look at some examples using the OpenAI API.\n\nNow, it's time for some hands-on practice. We'll walk through writing and iterating on prompts together, and I'll show you how to use the OpenAI API to get results from ChatGPT.\n\nTo wrap up, prompt engineering is a powerful tool for application development with ChatGPT. With these best practices and some hands-on experience, you'll be well on your way to mastering prompt engineering. So go ahead and start experimenting with your own prompts. And who knows, you might even build your own custom chatbot!\n\nThanks for watching, and happy prompt engineering!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-22"}}
{"video": {"title": "Demystifying Transformer Architecture in LLMs", "transcript": "####Demystifying Transformer Architecture in LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-02-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! Chris Fregly here, and today we're going to demystify the transformer architecture that powers LLMs in generative AI.\n\nFirst, let's talk about what transformer architecture is and how it differs from traditional recurrent neural networks. With transformer architecture, we can process input sequences in parallel, making it faster and more efficient.\n\nSelf-attention mechanisms are a key component of transformer architecture. They allow the model to focus on different parts of the input sequence and weigh their importance accordingly.\n\nWe'll also dive into the encoder and decoder components of transformer architecture and how they work together to generate new content.\n\nAnd don't worry, we'll be using practical examples and code snippets to help you understand the concepts better.\n\nBy the end of this video, you'll have a solid understanding of transformer architecture and how it powers LLMs in generative AI.\n\nSo, let's get started! See you in the course.\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-02-20"}}
{"video": {"title": "Quantization 101: Compress Models with Hugging Face and Quanto", "transcript": "####Quantization 101: Compress Models with Hugging Face and Quanto\nby Younes Belkada, Marc Sun - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're going to make models smaller, faster, and just as accurate with quantization 101!\n\nWe'll be using the Hugging Face Transformers library and the Quanto library to compress models. Trust me, it's easier than it sounds.\n\nBut first, let's talk about what quantization is. It's a process that reduces the size of a model, making it more efficient and faster, while maintaining its accuracy.\n\nWe'll start with linear quantization, a simple and effective method for model compression. It works by lowering the precision of the weights in your model, leading to a smaller model size and quicker inference times.\n\nNext, we'll walk you through the process of quantizing open-source multimodal and language models. Don't worry if you're a beginner, I'll be there to guide you through each step.\n\nBy the end of this video, you'll have the skills to quantize any open-source model using Hugging Face and Quanto.\n\nThanks for watching, and don't forget to like, share, and subscribe for more AI and machine learning content. See you next time!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-15"}}
{"video": {"title": "Mastering AI Agents with LangGraph", "transcript": "####Mastering AI Agents with LangGraph\nby Harrison Chase, Rotem Weiss - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Harrison Chase, and I'm Rotem Weiss. Today, we're embarking on an exciting journey into the world of AI agents powered by LangGraph and Tavily's agentic search. Are you ready to level up your Python skills and build some truly powerful AI workflows? Let's dive in!\n\nIn this course, we'll be using LangGraph's open source framework to make the development, debugging, and maintenance of AI agents a breeze. With LangGraph's components, you'll be able to create agents that are not only smart, but also easy to work with. And by integrating agentic search capabilities, you can enhance your agent's knowledge and performance.\n\nBut that's not all! We'll also be exploring the cutting-edge technology behind LangGraph and Tavily's partnership. Trust us, you won't want to miss out on this opportunity to revolutionize your AI workflows with LangChain and Tavily.\n\nSo, are you ready to take your AI skills to the next level? Join us as we delve into the world of LangGraph and Tavily's agentic search. And stay tuned for more insights from the founders themselves. Let's get started!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2022-10-15"}}
{"video": {"title": "ChatGPT Prompt Engineering: Best Practices for Application Development", "transcript": "Positive Points:\n\n- Clear introduction of the topic and its importance.\n- Use of active voice and simple language.\n- Inclusion of humor and enthusiasm.\n- Encouragement for the audience to try out the techniques.\n\nAreas for Improvement:\n\n- Add more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-23"}}
{"video": {"title": "TensorFlow: Advanced Computer Vision", "transcript": "####TensorFlow: Advanced Computer Vision\nby Laurence Moroney, Eddy Shyu - 2022-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eddy Shyu, and today we're going to dive into the exciting world of advanced computer vision techniques in TensorFlow.\n\nAre you ready to take your models to the next level? In this video, we'll show you how to use pre-trained models to improve the accuracy of your models. We'll also cover transfer learning and fine-tuning, two powerful techniques that can help you get the most out of your models.\n\nSo, whether you're working on a computer vision project, or just looking to improve your TensorFlow skills, this video has something for you. Let's get started!\n\n[Demonstration of using pre-trained models, transfer learning, and fine-tuning]\n\nThanks for watching, and be sure to check out our other videos on TensorFlow. And remember, the key to success is practice, practice, practice!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-03-22"}}
{"video": {"title": "Mastering LangChain: A Comprehensive Guide to Data Interaction", "transcript": "####Mastering LangChain: Your Ultimate Guide to Data Interaction\nby Harrison Chase - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python lovers! I'm Harrison Chase, and today we're diving headfirst into the world of LangChain.\n\nLangChain is a game-changer. It's a tool that lets you interact with various data sources in a unique and efficient way. With over 80 unique loaders, you can handle different types of data, from PDFs to databases.\n\nBut wait, there's more! Today, we're going to build a chatbot that can chat directly with information from your own documents and data.\n\nImagine having a personal assistant who can read and understand all your documents and data. That's what we're going to create today.\n\nI'll be guiding you through each step, making sure to keep things simple and easy to understand. By the end of this video, you'll have your own chatbot ready to assist you with your data needs.\n\nSo, are you ready to master LangChain? Let's dive in!\n\nRemember, if you have any questions, feel free to leave a comment. I'm always here to help. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-30"}}
{"video": {"title": "Practical Applications of ML", "transcript": "####Practical Applications of ML\nby Geoff Ladwig - 2022-10-11\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Are you ready to dive into the exciting world of machine learning? In this video, we'll explore the practical applications of ML that are transforming industries and making a significant impact. From healthcare to finance, ML is revolutionizing the way we work and live. And the best part? You can leverage its power in your own projects! I'm Geoff Ladwig, and I'm thrilled to inspire you with the endless possibilities of ML. So, let's get started!\n#### END TRANSCRIPT ########", "author": "Geoff Ladwig", "publication_date": "2022-10-11"}}
{"video": {"title": "Granularity in Quantization: Per Tensor, Per Channel, and Per Group", "transcript": "####Granularity in Quantization: Per Tensor, Per Channel, and Per Group\nby Marc Sun, Younes Belkada - 2022-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! I'm Marc Sun, and today we're diving into the fascinating world of granularity in quantization.\n\nWe'll be exploring three different granularities: per tensor, per channel, and per group quantization. Each has its own unique advantages and disadvantages, and we'll discuss when to use each one.\n\nPer tensor quantization is the simplest form. It uses a single set of quantization parameters for the entire tensor. It's fast and efficient, but it might not be the most accurate option.\n\nPer channel quantization, on the other hand, uses a different set of parameters for each channel in the tensor. It can give you more accuracy, but it can also be more computationally expensive.\n\nFinally, per group quantization is a happy medium. It uses a different set of parameters for each group of channels. It can give you a good balance between accuracy and efficiency.\n\nSo, let's dive into some examples and see these granularities in action. And remember, the best way to learn is by doing.\n\nDon't forget to like, share, and subscribe for more great content.\n\nUntil next time, I'm Marc Sun, and this has been Granularity in Quantization: Per Tensor, Per Channel, and Per Group. Keep exploring, keep learning!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-03-15"}}
{"video": {"title": "Quantization Fundamentals: Building a Strong Foundation for Model Compression", "transcript": "####Quantization Fundamentals: Building a Strong Foundation for Model Compression\nby Younes Belkada - 2022-10-24\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! It's Your AI Guide, Younes Belkada, back with another exciting video. Today, we're diving into the world of model compression, starting with the basics of quantization. Why is this important? Well, understanding the fundamentals is like having a sturdy ladder to reach the advanced techniques. So, let's climb this ladder together and build a strong foundation!\n\nStay tuned, and don't forget to like, share, and subscribe for more AI insights. Let's get started!\n#### END TRANSCRIPT ########", "author": "Younes Belkada", "publication_date": "2022-10-24"}}
{"video": {"title": "Quantization in Depth: Future Trends", "transcript": "####Quantization in Depth: Future Trends\nby Marc Sun, Younes Belkada - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Marc Sun, and today we're diving into the thrilling world of advanced quantization techniques. We'll explore some mind-blowing developments and discuss where the field is heading.\n\nQuantization is a rapidly evolving field, and trust me, you won't want to miss out on what's coming next!\n\nBut wait, there's more! Don't forget to like, share, and subscribe for more exciting content. And remember, your support helps us create more videos like this one.\n\nSee you in the next video, where we'll continue to explore the cutting-edge of technology together.\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-25"}}
{"video": {"title": "Red Teaming Techniques for LLM Applications: A Deep Dive", "transcript": "####Red Teaming Techniques for LLM Applications: A Deep Dive\nby Matteo Dora, Luca Martial - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Matteo Dora, and today we're diving headfirst into the world of red teaming for LLM applications. Buckle up, it's going to be a wild ride!\n\nFirst up, we've got adversarial testing. This is where we create inputs specifically designed to make our model fail. It's like playing a game of chess with our model, but instead of checkmate, we're looking for vulnerabilities.\n\nNext, we've got bias auditing. This is all about checking our model's outputs for any signs of bias. It's like being a fairness detective, ensuring our model treats everyone equally.\n\nFinally, we've got privacy testing. This is where we check our app for any potential privacy violations. It's like being a digital privacy guard, making sure no data leaks or inadequate consent mechanisms slip through the cracks.\n\nBut remember, these techniques are just the beginning. There's a whole ocean of red teaming techniques out there, and new ones are being developed every day.\n\nSo, what are you waiting for? Like, share, and subscribe for more content on LLM applications. And don't forget to hit that notification bell so you never miss an update. Until next time, happy red teaming!\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-04-05"}}
{"video": {"title": "Understanding AI Concepts Visually", "transcript": "####Understanding AI Concepts Visually with Andrew Ng - 2022-10-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to take a fun and engaging journey into the world of AI? Today, we're going to explore the intuitive visual approach to understanding AI concepts. We'll break down complex ideas into simple visuals that will help you grasp the core principles of machine learning. Get ready to see AI in a whole new light! I'm Andrew Ng, and I'm thrilled to show you how visual learning can enhance your understanding.\n\nLet's dive in!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-03"}}
{"video": {"title": "Chaining LLM Calls for Better Outputs", "transcript": "####Chaining LLM Calls for Better Outputs\nby Andrew Ng - 2022-10-18\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Andrew Ng! Are you ready to dive into the fascinating world of chaining LLM calls to get better outputs? Trust me, you won't want to miss this!\n\nBut first, let me ask you a question. Have you ever wondered how to evaluate inputs and outputs for safety, accuracy, and relevance? Well, wonder no more! In this video, we'll explore all of that and more.\n\nSo, what are we waiting for? Let's get started!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-18"}}
{"video": {"title": "TensorFlow: Multi-GPU Training", "transcript": "####TensorFlow: Multi-GPU Training\nby Laurence Moroney, Eddy Shyu - 2022-04-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eddy Shyu, and today we're going to dive into the world of multi-GPU training in TensorFlow!\n\nAre you tired of waiting for your machine learning models to train? Well, buckle up, because we're about to show you how to use multiple GPUs to speed up the process!\n\nIn this video, we'll walk you through the process of setting up multi-GPU training in TensorFlow, and show you how to use it to train your models faster. We'll also cover some best practices for using multiple GPUs, and some common pitfalls to avoid.\n\nSo, whether you're looking to shave some time off your training, or just want to explore the capabilities of TensorFlow, this video has got you covered. Let's get started!\n\n[Demonstration of setting up multi-GPU training and training a model]\n\nAnd that's it! You're now a multi-GPU training pro. Be sure to check out our other videos on TensorFlow for more tips and tricks.\n\nThanks for watching, and happy training!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-04-19"}}
{"video": {"title": "Advanced Q&A Techniques with Agentic RAG Systems", "transcript": "####Advanced Q&A Techniques with Agentic RAG Systems\nby Jerry Liu - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and welcome back to our series on building agentic RAG systems with LlamaIndex.\n\nAre you ready to take your Q&A skills to the next level? In this video, we're going to dive into some advanced techniques that will help you improve the accuracy and relevance of your answers.\n\nBut first, let's review the basics of Q&A with agentic RAG systems. We'll talk about how to handle ambiguous queries, incorporate external knowledge, and use feedback to improve your system.\n\nBy the end of this video, you'll have the skills to create a Q&A system that's truly impressive.\n\nSo, let's get started!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-20"}}
{"video": {"title": "Unleashing the Power of LangChain for LLM Application Development", "transcript": "Positive Points:\n\n- Clear introduction of the topic and LangChain.\n- Use of active voice and simple language.\n- Encouragement for the audience to start building their own applications.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.\n- Improve the introduction of the tutorial partner.", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-03-15"}}
{"video": {"title": "Mastering Mistral: JSON Mode and API Calls", "transcript": "####Mastering Mistral: JSON Mode and API Calls\nby Younes Belkada, Marc Sun - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, Younes Belkada here, and welcome back to our Mistral AI series!\n\nToday, we're diving into two of Mistral's most powerful features: JSON mode and API calls.\n\nFirst up, JSON mode. This feature lets you generate LLM responses in a structured JSON format. Why's that a big deal? Well, it makes it a breeze to integrate the outputs of your LLM into larger software applications. It's all about making your life easier and your code more efficient.\n\nNext, let's talk about API calls. With Mistral's API, you can call user-defined Python functions. This means you can perform tasks like web searches or retrieving text from databases. Essentially, it supercharges your LLM\u2019s ability to find relevant information to answer your queries.\n\nBut how do you use these features? Don't worry, we'll be covering that in our next video. For now, just remember that these features are there to help you get the most out of Mistral AI.\n\nIf you have any questions, just let us know. And don't forget to like, share, and subscribe for more updates. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-25"}}
{"video": {"title": "Building Systems with the ChatGPT API", "transcript": "####Building Systems with the ChatGPT API: A Game Changer for Automation\nby Isa Fulford - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Isa Fulford, and today we're embarking on an exciting journey into the world of building systems with the ChatGPT API. Are you ready to revolutionize your workflows and unlock the full potential of LLMs? Let's dive in!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-15"}}
{"video": {"title": "AI and Climate Change: Modeling and Mitigating Impacts", "transcript": "####AI and Climate Change: Modeling and Mitigating Impacts\nby Robert Monarch - 2023-04-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Robert Monarch, and today we're diving into the fascinating world of AI and climate change.\n\nWe'll start by discussing how AI is revolutionizing climate change research. Then, we'll explore how AI can help us mitigate the impacts of climate change.\n\nWe'll look at how AI can analyze data to model climate patterns, optimize carbon capture technologies, and improve climate resilience.\n\nWe'll also explore a real-world case study where AI has been used to combat climate change.\n\nSo, are you ready to learn how AI can help us tackle one of the biggest challenges of our time? Let's get started!\n\nRemember, every bit of knowledge you gain about AI for good brings us one step closer to a sustainable future.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content on AI. Until next time, let's keep using AI for good.\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-22"}}
{"video": {"title": "Building Next-Gen Multimodal Search Applications", "transcript": "####Building Next-Gen Multimodal Search Applications\nby Sebastian Witalec - 2022-10-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Sebastian here, and today we're diving into the future of search applications. We're going to build next-gen multimodal search applications, leveraging the latest technologies and techniques. Are you ready to shake up the search game? Let's get started!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-19"}}
{"video": {"title": "Mastering Image Generation with GANs: A Deep Dive", "transcript": "####Mastering Image Generation with GANs: A Deep Dive\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sharon Zhou, and today we're diving into the fascinating world of Generative Adversarial Networks, or GANs for short.\n\n[Video hook and introduction]\n\nGANs are a type of machine learning model that can generate new data that's similar to the data it was trained on. It's like having a painter that can create new paintings in the style of Van Gogh after studying his work.\n\nBut before we get started, a quick reminder that this video is for those with an intermediate skill level in machine learning. If you're new to the field, don't worry, we've got plenty of beginner-friendly content on our channel.\n\n[Body content]\n\nSo, how do GANs work? Well, they consist of two parts: a generator and a discriminator. The generator creates new data, while the discriminator tries to tell the difference between real data and the data created by the generator. The two parts work together, with the generator trying to fool the discriminator, and the discriminator trying to correctly identify real data.\n\nOver time, the generator gets better at creating realistic data, and the discriminator gets better at telling the difference. It's like a game of cat and mouse, where both sides are constantly improving.\n\nBut GANs aren't just fun and games. They have real-world applications, like creating realistic images for video games or generating synthetic data for research.\n\nHowever, with great power comes great responsibility. GANs have also raised concerns about bias and privacy. For example, if a GAN is trained on biased data, it can perpetuate those biases in the data it generates. And if a GAN is used to create realistic images of people who don't exist, it could be used for nefarious purposes.\n\nThat's why it's important to consider the social implications of GANs and to use them responsibly.\n\n[Conclusion and call to action]\n\nSo, that's a quick overview of GANs. If you want to learn more, check out our other videos on the topic. And if you have any questions or comments, leave them down below. We love hearing from you.\n\nThanks for watching, and we'll see you in the next video.\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-02-15"}}
{"video": {"title": "Introduction to Generative Adversarial Networks (GANs)", "transcript": "####Introduction to Generative Adversarial Networks (GANs)\nby Sharon Zhou - 2022-10-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Sharon Zhou, and today we're embarking on an exciting journey into the realm of Generative Adversarial Networks, or GANs for short. Are you ready to unlock the secrets of image generation? Let's dive right in!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2022-10-01"}}
{"video": {"title": "TensorFlow: Model Versioning and Rollbacks", "transcript": "####TensorFlow: Model Versioning and Rollbacks\nby Laurence Moroney - 2022-03-22\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Laurence Moroney, and today we're diving into the exciting world of model versioning and rollbacks in TensorFlow!\n\n[Video hook and introduction]\n\nAs you continue to train and deploy machine learning models, you'll need a way to manage different versions and easily roll back to previous ones if something goes wrong. Let's get started!\n\n[Body content]\n\nFirst, we'll cover how to version your TensorFlow models using TensorFlow Serving. We'll discuss how to save multiple versions of your model and configure TensorFlow Serving to serve the desired version.\n\nNext, we'll talk about A/B testing \u2013 a technique for comparing the performance of two different models. We'll walk through the process of setting up an A/B test and analyzing the results to determine which model performs better.\n\nWe'll also cover canary releases, which allow you to gradually roll out a new model version to a small subset of users before deploying it to everyone. This helps you catch issues early and minimize the impact on your users.\n\nLastly, we'll discuss how to roll back to a previous model version if you encounter issues with the current one. We'll cover best practices for monitoring your models and identifying when a rollback is necessary.\n\n[Conclusion and call to action]\n\nAre you ready to level up your model management skills and ensure smooth deployments with TensorFlow? Let's get started! Remember, proper model versioning and rollback strategies are essential for maintaining high-quality machine learning applications.\n\nIf you found this video helpful, be sure to give it a thumbs up, share it with your friends, and subscribe to our channel for more awesome content. See you in the next video!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-03-22"}}
{"video": {"title": "Creating Multimodal RAG Systems for Contextual Reasoning", "transcript": "####Creating Multimodal RAG Systems for Contextual Reasoning\nby Sebastian Witalec - 2022-10-07\n\n#### BEGIN TRANSCRIPT ####\nHey there, curious minds! Are you ready to dive into the world of multimodal RAG systems? I'm Sebastian Witalec, and I'm thrilled to be your guide on this exciting journey. Today, we're going to explore how to create systems that retrieve multimodal context and reason over it to generate more relevant answers. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-07"}}
{"video": {"title": "Building a Natural Language Interface for SQL Databases", "transcript": "####Building a Natural Language Interface for SQL Databases\nby Adrian Gonzalez Sanchez - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Adrian Gonzalez Sanchez, and today we're going to revolutionize the way you interact with SQL databases.\n\nEver found yourself lost in a sea of SQL queries? What if I told you that you could ask your SQL database a question in plain English and get the answer you need? Sounds like magic, right? Well, buckle up, because we're about to make it a reality!\n\nIn this video, we'll be exploring how to build a natural language interface for SQL databases using the Azure OpenAI Service. We'll start by introducing the concept of natural language processing and how it can be applied to SQL databases.\n\nThen, we'll dive into the Azure OpenAI Service and learn how to use its Assistants API to build a natural language interface for your SQL database. We'll cover techniques like Retrieval Augmented Generation (RAG) and function calling to make your interface more powerful.\n\nBy the end of this video, you'll have the skills to build your own natural language interface for SQL databases. And the best part? You don't need to be a Python programming or database guru to follow along.\n\nSo, are you ready to make data analysis more efficient and accessible? Let's get started!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like and subscribe for more exciting content on natural language processing and databases.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Adrian Gonzalez Sanchez", "publication_date": "2023-04-25"}}
{"video": {"title": "Optimizing Multimodal Search Performance", "transcript": "####Optimizing Multimodal Search Performance\nby Sebastian Witalec - 2022-10-13\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Sebastian here, and today we're diving into the exciting world of optimizing multimodal search performance. Are you ready to take your search capabilities to the next level? Let's get started!\n\nFirst things first, what is multimodal search? It's the ability of a system to understand and process information from different sources, such as text, images, and speech. And optimizing it can lead to some truly amazing results.\n\nBut how do we do it? That's what we're here to find out. We'll be exploring some tips and tricks for fine-tuning your systems for maximum efficiency and effectiveness. And don't worry, I'll be translating any tech jargon into simpler words so we can all follow along.\n\nSo, are you ready to make your search capabilities shine? Let's do this!\n\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-13"}}
{"video": {"title": "TensorFlow for Computer Vision", "transcript": "####TensorFlow for Computer Vision: Unleashing AI Superpowers!\nby Laurence Moroney - 2022-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Laurence Moroney, and today we're diving into the exciting world of TensorFlow for computer vision!\n\n[Video hook and introduction]\n\nAre you ready to build your own image recognition systems and take your AI skills to the next level? Then buckle up, because we're about to embark on an epic journey!\n\n[Body content]\n\nFirst, we'll cover the basics of computer vision and how TensorFlow can help. We'll go over essential concepts like convolutional neural networks, image augmentation, and transfer learning. But don't worry, we'll keep it fun and engaging!\n\nThen, we'll dive into building our own image recognition system. We'll use TensorFlow to train a model on a dataset of images and evaluate its performance. And trust me, the results will blow your mind!\n\nWe'll also explore how to use pre-trained models to save time and improve accuracy. You'll learn how to use models like VGG16, ResNet, and Inception for your own projects. And who knows, you might even discover a new favorite model!\n\nLastly, we'll cover some advanced topics like object detection and semantic segmentation. You'll learn how to build systems that can identify and locate objects in images. And let me tell you, the possibilities are endless!\n\n[Conclusion and call to action]\n\nBy the end of this video, you'll have a solid understanding of how to use TensorFlow for computer vision tasks. So, let's get started and unleash your AI superpowers!\n\nRemember, practice makes perfect. So, make sure to try building your own image recognition systems and experiment with different models and datasets. And who knows, you might just create the next big thing in AI!\n\nIf you found this video helpful, be sure to give it a thumbs up and subscribe to our channel for more TensorFlow content. See you next time, and happy coding!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-03-15"}}
{"video": {"title": "Quantization Decoded: Simplifying Models with Hugging Face and Quanto", "transcript": "####Quantization Decoded: Simplify Models with Hugging Face and Quanto\nby Younes Belkada and Marc Sun - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada and today, I'm teaming up with Marc Sun to decode the world of quantization using Hugging Face and Quanto libraries.\n\nSo, what's the big deal about quantization? Well, it's like having a magic trick that lets you simplify your models without losing their magic.\n\nLet's dive in. We'll be using the Hugging Face Transformers library and the Quanto library for this task. If you're new to these tools, don't worry, we'll guide you through every step.\n\nFirst, we'll explore linear quantization, a simple yet effective method for simplifying models. It's like having a magic wand that turns your complex models into simple ones.\n\nThen, we'll practice quantizing open-source multimodal and language models. It's like having a simplified version of your favorite books, but with all the magic intact.\n\nBy the end of this video, you'll be a pro at decoding quantization and you'll have saved a ton of space on your hard drive.\n\nRemember, practice makes perfect, so don't hesitate to try out different models and methods. And if you get stuck, just hit the rewind button and watch it again.\n\nThanks for watching and don't forget to like, share, and subscribe for more awesome content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-30"}}
{"video": {"title": "Mastering ChatGPT Prompt Engineering for Developers", "transcript": "####Mastering ChatGPT Prompt Engineering for Developers\nby Isa Fulford - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, developers! Today, we're diving into the exciting world of prompt engineering for ChatGPT. I'll show you how to craft effective prompts to get the most out of your language model. Trust me, you won't want to miss this! Let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-15"}}
{"video": {"title": "Function-Calling and Data Extraction: Advanced Techniques", "transcript": "####Function-Calling and Data Extraction: Advanced Techniques\nby Jiantao Jiao, Venkat Srinivasan - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao and welcome back to our series on function-calling and data extraction with LLMs. Today, we're diving into advanced techniques for using function-calling and data extraction.\n\nWe'll be covering topics such as how to use nested functions, how to handle complex data structures, and how to integrate LLMs with other tools and services. We'll also be discussing advanced data extraction techniques such as named entity recognition and sentiment analysis.\n\nBy the end of this video, you'll have a better understanding of how to use function-calling and data extraction to build more advanced applications.\n\nRemember, the key to success is to keep learning and pushing the boundaries. So, don't just watch the video. Try out the examples yourself and experiment with different techniques.\n\nAnd if you have any questions, feel free to leave them in the comments. We're here to help!\n\nSo, are you ready to learn about advanced techniques for using function-calling and data extraction with LLMs? Let's get started!\n\nDon't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-04-15"}}
{"video": {"title": "Diffusion Models: The Magic Behind Spread", "transcript": "####Diffusion Models: Unveiling the Magic Behind Spread\nby Sharon Zhou - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, Sharon Zhou here, and today we're diving into the fascinating world of diffusion models.\n\nDiffusion models help us understand how things spread or diffuse over time and space. Think of it like how a trend goes viral on social media, or how a disease spreads through a population.\n\nLet's get started and build our own diffusion model. Open up your Python environment, and make sure you've got Tensorflow or Pytorch installed. We'll start by defining our model, then we'll feed in our data, and finally, we'll train our model.\n\nBut wait, there's more! I'll also show you how to speed up your sampling process by 10 times. We'll implement some algorithms that will make your sampling process faster than ever.\n\nAnd that's all for today, folks! You've just learned how to build and train your own diffusion model, and even how to speed up the sampling process. Don't forget to hit that like button, subscribe, and share this video with your friends. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-03-22"}}
{"video": {"title": "Mastering Quantization: A Deep Dive into Advanced Techniques", "transcript": "####Mastering Quantization: A Deep Dive into Advanced Techniques\nby Marc Sun, Younes Belkada - 2022-03-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, quantization enthusiasts! I'm Marc Sun, and today we're going on an exciting journey into the world of advanced quantization techniques. If you've already taken our Quantization Fundamentals course, you're in the perfect spot to level up your skills.\n\nFirst, we're diving into the nitty-gritty of Linear Quantization. We'll compare symmetric and asymmetric modes, and discuss the pros and cons of each. We'll also explore different granularities, like per tensor, per channel, and per group quantization.\n\nNext, we're getting our hands dirty. We'll build a general-purpose quantizer in Pytorch. This powerful tool can quantize the dense layers of any open-source model, giving you up to 4x compression on dense layers.\n\nBut wait, there's more! We're also going to implement weights packing. This technique allows us to pack four 2-bit weights into a single 8-bit integer, further optimizing our models.\n\nAnd guess what? We're partnering with Hugging Face to bring you these cutting-edge techniques.\n\nRemember, quantization is a powerful tool for model compression. But it's not a one-size-fits-all solution. That's why we're exploring different techniques, so you can find the best fit for your needs.\n\nSo, are you ready to become a quantization master? Let's get started. And don't forget to like, share, and subscribe for more great content.\n\nUntil next time, I'm Marc Sun, and this has been Mastering Quantization: A Deep Dive into Advanced Techniques.\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-03-01"}}
{"video": {"title": "Demystifying AI with Hugging Face Open Source Models", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits.\n- Use of active voice and simple language.\n- Encouragement of curiosity and engagement.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-04-15"}}
{"video": {"title": "Mastering Statistics for Data Analysis", "transcript": "####Mastering Statistics for Data Analysis\nby Magdalena Bouza - 2022-10-07\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! It's Magdalena Bouza, and today we're diving into the thrilling world of statistics and its impact on data analysis in machine learning. Are you ready to crunch numbers, analyze trends, and make informed decisions like a pro? Let's get started!\n#### END TRANSCRIPT ########", "author": "Magdalena Bouza", "publication_date": "2022-10-07"}}
{"video": {"title": "ChatGPT Prompt Engineering: A Beginner's Guide", "transcript": "####ChatGPT Prompt Engineering: A Beginner's Guide\nby Isa Fulford, Andrew Ng - 2023-03-16\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Andrew Ng and welcome to our beginner's guide to prompt engineering for ChatGPT. Are you ready to unlock the full potential of this powerful tool? Let's dive in!\n\nFirst things first, what is prompt engineering? It's the art of designing inputs for language models like ChatGPT to get the results you want. It's crucial because the right prompt can make all the difference in getting accurate and useful results.\n\nNow, let's talk about some best practices. First, be clear and specific with your prompts. The more detailed you are, the better ChatGPT can understand what you're asking for. Second, don't be afraid to iterate. Prompt engineering is an iterative process, so try out different prompts and see what works best.\n\nBut wait, there's more! Did you know you can use LLMs, or large language models, for summarizing, inferring, transforming, and expanding text? Let's take a look at some examples using the OpenAI API.\n\nNow, it's time for some hands-on practice. We'll walk through writing and iterating on prompts together, and I'll show you how to use the OpenAI API to get results from ChatGPT.\n\nTo wrap up, prompt engineering is a game-changer for application development with ChatGPT. With these best practices and some hands-on experience, you'll be well on your way to mastering prompt engineering. So go ahead and start experimenting with your own prompts. And who knows, you might even build your own custom chatbot!\n\nThanks for watching, and happy prompt engineering!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-16"}}
{"video": {"title": "Prompt Engineering 101 with Llama 2 & 3", "transcript": "####Prompt Engineering 101 with Llama 2 & 3\nby Amit Sangani - 2023-02-16\n\n#### BEGIN TRANSCRIPT ####\nHey there, Amit Sangani here and today we're diving into the exciting world of Prompt Engineering 101 with Llama 2 & 3.\n\nIf you're new to AI, don't worry, we've got you covered. In this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst up, we'll be taking a look at Meta Llama 2 Chat and I'll show you how to interact with it to get the most out of your prompts. You'll be prompting like a pro in no time!\n\nNext, we'll dive into Code Llama and I'll show you how to use it to build some really cool applications. You'll be amazed at what you can create with just a few prompts.\n\nBut that's not all, we'll also be taking a look at Llama Guard and how you can use it to build safe and responsible AI applications. It's important to make sure our AI is being used for good, and Llama Guard can help with that.\n\nSo, are you ready to get started? Let's dive in and start prompting like a pro with Llama 2 & 3. And don't forget to hit that like and subscribe button for more great content. See you in the next video!\n\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-16"}}
{"video": {"title": "Reinforcement Learning and Training Intelligent Agents", "transcript": "####Reinforcement Learning and Training Intelligent Agents\nby Laurence Moroney - 2023-04-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're going to explore the exciting world of reinforcement learning and how it's used to train intelligent agents using TensorFlow.\n\n[Video hook and introduction]\n\nReinforcement learning is a type of machine learning where an agent learns to make decisions by interacting with an environment and receiving feedback in the form of rewards. It's been used for tasks like game playing, robotics, and resource management. Let's dive in!\n\n[Body content]\n\nFirst, we'll discuss the core concepts of reinforcement learning, including states, actions, rewards, and policies. We'll also cover the Markov decision process (MDP) and how it's used to model reinforcement learning problems.\n\nNext, we'll walk through building and training a reinforcement learning agent in TensorFlow for a specific task, such as playing a game or controlling a robot. We'll cover techniques for representing and exploring the environment, as well as updating the agent's policy based on received rewards.\n\nWe'll also discuss popular reinforcement learning algorithms, such as Q-learning, deep Q-networks (DQN), and policy gradients, and their unique applications.\n\n[Conclusion and call to action]\n\nBy the end of this video, you'll have a solid understanding of reinforcement learning and how to use it for training intelligent agents in TensorFlow.\n\nRemember to like, share, and subscribe for more AI and machine learning content. In the next video, we'll explore the world of transfer learning and how it can help you build powerful AI models with less data and computation. See you there!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-04-22"}}
{"video": {"title": "Quantization Unpacked: Symmetric vs. Asymmetric Mode", "transcript": "####Quantization Unpacked: Symmetric vs. Asymmetric Mode\nby Marc Sun, Younes Belkada - 2022-03-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Younes Belkada, and today we're diving into the world of Linear Quantization. We're comparing symmetric and asymmetric modes, so buckle up!\n\nFirst up, symmetric mode. In this mode, the zero point is always in the middle of the range. This means that both positive and negative numbers have the same range. It's like a perfect balance, right?\n\nBut what if your data isn't so balanced? That's where asymmetric mode comes in. In this mode, the zero point can be anywhere in the range. This can be a game-changer when your data is not centered around zero.\n\nSo, which one should you use? Well, it depends on your data. If your data is centered around zero, symmetric mode might be your best friend. But if your data is skewed, asymmetric mode could give you better results.\n\nLet's dive into some examples and see these modes in action. And remember, the best way to learn is by doing.\n\nDon't forget to like, share, and subscribe for more great content. And if you have any questions, drop them in the comments below.\n\nUntil next time, I'm Younes Belkada, and this has been Quantization Unpacked: Symmetric vs. Asymmetric Mode. Happy quantizing!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-03-08"}}
{"video": {"title": "Creating a Text Summarization App with NLP and Hugging Face", "transcript": "####Creating a Text Summarization App with NLP and Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, tech enthusiasts! I'm Your Assistant, and today we're diving into the exciting world of NLP and Hugging Face to create a text summarization app.\n\nText summarization is like condensing a long novel into a captivating book review. It's a handy tool for summarizing news articles, research papers, and more.\n\nWith Hugging Face, we can train our NLP model to understand and summarize text. We'll start by preparing our data, then we'll train our model, and finally, we'll test it out.\n\nRemember, the key to successful text summarization is understanding the main ideas and the structure of the text. Our model needs to be smart enough to identify and summarize these key points.\n\nSo, are you ready to turn long text into bite-sized summaries? Let's get started with Hugging Face and NLP!\n\nStay tuned for more exciting videos on this topic. And don't forget to like, share, and subscribe for more tech content. Until next time, I'm Your Assistant, your guide in the world of AI.\n\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-03-30"}}
{"video": {"title": "Mathematics for Machine Learning and Data Science 101", "transcript": "####Mathematics for Machine Learning and Data Science 101\nby Luis Serrano - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Luis and welcome to our first video on Mathematics for Machine Learning and Data Science.\n\nToday, we're going to dive into the fundamental mathematics toolkit that powers machine learning: calculus, linear algebra, statistics, and probability. Don't worry if these topics sound intimidating, we're going to break them down into simple, easy-to-understand concepts.\n\nFirst up, we're going to talk about calculus. Calculus is all about understanding how things change. In the context of machine learning, we use calculus to optimize our models and make them more accurate.\n\nNext, we're going to explore linear algebra. Linear algebra is the study of vectors and linear transformations. In machine learning, we use linear algebra to represent data and perform operations on that data.\n\nAfter that, we're going to delve into statistics. Statistics is the science of learning from data. In machine learning, we use statistics to make predictions and decisions based on data.\n\nFinally, we're going to discuss probability. Probability is the study of uncertainty. In machine learning, we use probability to model uncertainty and make predictions.\n\nSo that's it for today's video. I hope you found this introduction to the mathematics of machine learning helpful. If you did, please give this video a thumbs up and subscribe to our channel for more videos like this. And if you have any questions, please leave them in the comments below. Thanks for watching and see you in the next video.\n\nRemember, math is not a monster, it's just a tool to help us understand the world. So let's get started and unlock the power of machine learning together!\n\n#### END TRANSCRIPT ########", "author": "Luis Serrano", "publication_date": "2022-01-01"}}
{"video": {"title": "Mastering Quantization: A Deep Dive into Advanced Techniques", "transcript": "####Mastering Quantization: A Deep Dive into Advanced Techniques\nby Marc Sun, Younes Belkada - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Marc Sun, and today we're diving headfirst into the fascinating world of quantization. If you've already taken our Quantization Fundamentals course, you're in the perfect spot to level up your skills.\n\nFirst, we're exploring different variants of Linear Quantization. We'll compare symmetric and asymmetric modes, and discuss the pros and cons of each. We'll also delve into different granularities like per tensor, per channel, and per group quantization.\n\nNext, we're getting our hands dirty. We'll build a general-purpose quantizer in Pytorch. This tool can quantize the dense layers of any open source model, giving you up to 4x compression on dense layers. Pretty impressive, right?\n\nBut wait, there's more! We'll also implement weights packing. This clever technique lets us pack four 2-bit weights into a single 8-bit integer. It's like a magic trick, but for data compression.\n\nRemember, this is an intermediate level course, so don't worry if some concepts seem challenging at first. With a bit of practice, you'll be a quantization pro in no time.\n\nAnd a big thank you to our partners at Hugging Face for their support in creating this course.\n\nSo, are you ready to level up your quantization skills? Let's do this!\n\nRemember to like, share, and subscribe for more exciting content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-03-15"}}
{"video": {"title": "Building Custom Models with the TensorFlow Functional API", "transcript": "####Building Custom Models with the TensorFlow Functional API\nby Laurence Moroney, Eddy Shyu - 2022-02-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eddy Shyu, and today we're going to have a blast exploring how to build custom models with the TensorFlow Functional API.\n\nFirst, we'll chat about why the Functional API is your new best friend for building custom models. Then, we'll get our hands dirty by defining custom layers and combining them to create some truly epic architectures.\n\n...\n\nThanks for joining me on this journey! I hope this video helped you understand how to build custom models with the TensorFlow Functional API. If you found this video helpful, please give it a thumbs up and subscribe to our channel for more content like this. See you next time, and happy modeling!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-02-05"}}
{"video": {"title": "AutoGen in Action: Real-World Applications of AI Agents", "transcript": "####AutoGen in Action: Real-World Applications of AI Agents\nby Chi Wang, Qingyun Wu - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHello, AI enthusiasts! Qingyun Wu here, and today we're diving into the fascinating world of AI agents built with AutoGen.\n\nWe'll kick things off by showcasing some real-world examples of how AI agents are transforming various industries. From streamlining workflows to tackling complex challenges, the potential is limitless.\n\nThen, we'll walk you through the process of creating an AI agent for a specific real-world task. We'll demonstrate how to identify the problem, design the agent, and implement the solution using AutoGen.\n\nRemember, our mission is to help you grasp how AI agents can be leveraged to solve real-world problems. So, let's dive in and witness AutoGen in action!\n\nAs always, if you have any questions, don't hesitate to drop them in the comments. We're here to support your learning journey.\n\nDon't forget to like, subscribe, and hit that notification bell for more thrilling content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2023-04-05"}}
{"video": {"title": "Mastering TensorFlow: A Guide to the TensorFlow Developer Professional Certificate", "transcript": "####Mastering TensorFlow: Your Path to AI Success with the TensorFlow Developer Professional Certificate\nby Laurence Moroney - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Laurence Moroney, and today we're embarking on an exciting journey into the world of TensorFlow. Are you ready to level up your AI skills and make a real impact? Let's dive in!\n\nWe're talking about the TensorFlow Developer Professional Certificate, your golden ticket to building scalable AI applications using TensorFlow. Whether you're a seasoned developer or just starting out, this certification will help you apply your new skills to real-world projects.\n\nBut first, let's talk about what you need to know before diving in. If you're an intermediate developer looking to take your AI game to the next level, this certificate is perfect for you.\n\nNow, let's talk about how this certification can benefit you. By earning the TensorFlow Developer Professional Certificate, you'll be well-prepared to tackle the Google TensorFlow Certificate exam. Plus, you'll gain the confidence and skills to take on exciting AI projects and make a real impact in the world.\n\nSo, what are you waiting for? Let's start mastering TensorFlow today and unlock your full potential as an AI developer!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-10-15"}}
{"video": {"title": "AI for Good: A Framework for AI Project Development", "transcript": "####AI for Good: A Framework for AI Project Development\nby Robert Monarch - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're going on an exciting journey into the world of AI for Good. We're going to learn a framework for AI project development, focusing on building models for air quality, wind energy, biodiversity, and disaster management. We'll also explore some real-world case studies on public health and climate change.\n\nBut first, let me ask you a question. Have you ever wondered how AI can be used to make the world a better place? Well, you're in luck, because that's exactly what we're going to be talking about today.\n\nSo, buckle up and get ready to learn how you can use AI to make a positive impact on the world. Let's get started!\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2022-10-15"}}
{"video": {"title": "Introduction to Generative Adversarial Networks (GANs)", "transcript": "####Introduction to Generative Adversarial Networks (GANs)\nby Sharon Zhou - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Sharon Zhou, and today we're embarking on an exciting adventure into the world of Generative Adversarial Networks, or GANs for short. Buckle up, because this is going to be a wild ride!\n\nGANs are a cutting-edge type of AI that can generate new, realistic images. But how do they do it? Well, it's all thanks to two neural networks - a generator and a discriminator - that work together in a friendly competition to create images that are so lifelike, you won't be able to tell the difference between them and the real thing.\n\nBut that's not all! GANs have the potential to revolutionize a wide range of fields, from creating stunning works of art to addressing important societal issues like bias and privacy.\n\nSo, are you ready to explore the power of GANs and discover how they're changing the world? Let's dive in!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2022-10-15"}}
{"video": {"title": "Function-Calling and Data Extraction: Future Trends and Opportunities", "transcript": "####Function-Calling and Data Extraction: Future Trends and Opportunities\nby Jiantao Jiao, Venkat Srinivasan - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Venkat Srinivasan and welcome back to our series on function-calling and data extraction with LLMs. Today, we're going to dive into the exciting world of future trends and opportunities in this field.\n\nWe'll explore emerging technologies and trends, such as natural language processing and machine learning, and how they are revolutionizing the future of function-calling and data extraction. We'll also uncover potential applications and opportunities in various industries.\n\nBy the end of this video, you'll have a clearer understanding of the future trends and opportunities in the field of function-calling and data extraction.\n\nRemember, the key to success is to keep learning and staying ahead of the curve. So, don't just watch the video. Try out the examples yourself and experiment with different techniques.\n\nAnd if you have any questions, feel free to leave them in the comments. We're here to help!\n\nSo, are you ready to learn about future trends and opportunities when using function-calling and data extraction with LLMs? Let's get started!\n\nDon't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-04-30"}}
{"video": {"title": "Expanding Horizons with ChatGPT: A Developer's Journey", "transcript": "####Expanding Horizons with ChatGPT: A Developer's Journey\nby Isa Fulford - 2022-10-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford, and today we're diving headfirst into the world of ChatGPT! If you're a developer looking to expand your creative horizons and push the boundaries of what's possible with language models, then you're in the right place. Let's embark on this exciting journey together!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-22"}}
{"video": {"title": "Mastering Linear Quantization Techniques", "transcript": "####Mastering Linear Quantization Techniques\nby Marc Sun - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc Sun, and today we're embarking on an exciting journey into the world of advanced quantization techniques. Are you ready to customize model compression with Linear Quantization? Let's explore the differences between symmetric and asymmetric modes, and delve into various granularities. If you're eager to elevate your quantization skills, you're in the right place! Let's get started!\n\nLinear Quantization is a game-changer when it comes to model compression. By quantizing weights and activations to a lower bit precision, we can shrink model size and boost inference speed. In this video, we'll uncover the intricacies of Linear Quantization, from understanding symmetric and asymmetric modes to exploring different granularities like per tensor, per channel, and per group quantization.\n\nBy the end of this video, you'll have the know-how to create a versatile quantizer in Pytorch. This tool will enable you to quantize the dense layers of any open-source model for up to 4x compression on dense layers. We'll also cover weights packing, a clever technique that packs four 2-bit weights into a single 8-bit integer.\n\nSo, are you ready to master Linear Quantization techniques and optimize your models for efficiency? Join me in this deep dive into quantization. And don't forget to check out our partnership with Hugging Face for additional resources and support. I'm Marc Sun, and I'm thrilled to have you along for the ride!\n#### END TRANSCRIPT ########", "author": "Marc Sun", "publication_date": "2022-10-15"}}
{"video": {"title": "Monitoring Your ML Production System", "transcript": "####Monitoring Your ML Production System\nby Andrew Ng - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! I'm Andrew Ng, and today we're going to dive into the exciting world of monitoring your Machine Learning production system.\n\nMonitoring? Sounds boring, right? But trust me, it's the secret sauce to a successful ML system. It's about catching issues early, understanding system behavior, and making data-driven decisions.\n\nSo, what do we need to monitor? We're talking performance metrics, error rates, and system logs. Think of it as your ML system's health check-up.\n\nNext, we need to set up our monitoring system. This might involve using a monitoring tool, setting up alerts, or creating dashboards. It's like having a personal doctor for your ML system.\n\nThen, we analyze our monitoring data. We're looking for trends, understanding root causes, and making data-driven decisions. It's like being a detective, but for ML systems.\n\nBut wait, there's more! We need to continuously improve our monitoring processes, handle any issues that arise, and make updates as needed. It's a never-ending journey, but it's worth it.\n\nSo, are you ready to monitor your ML production system? Start planning your monitoring strategy today, and remember, a successful monitoring strategy is key to a successful ML system.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content on Machine Learning. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-25"}}
{"video": {"title": "Enhancing AI Agent Performance with Tavily's Agentic Search", "transcript": "####Enhancing AI Agent Performance with Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, AI enthusiasts! Are you ready to take your AI agents to the next level? Today, we're diving into the world of Tavily's agentic search and how it can enhance your AI agent's performance.\n\nBut first, why should we care about enhancing performance? Well, it's simple. More efficient and effective AI agents mean more successful outcomes. So, let's get started!\n\nFirst, we'll demystify agentic search and show you how it can benefit your AI agents. Then, we'll walk you through the process of integrating it with your AI agents, boosting their knowledge and capabilities.\n\nBy the end of this video, you'll have the tools to supercharge your AI agents and tackle any challenge that comes your way.\n\nSo, are you ready to enhance your AI agents' performance? Let's do this!\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-25"}}
{"video": {"title": "LangChain: Your Gateway to Data-Driven Innovation", "transcript": "####LangChain: Your Gateway to Data-Driven Innovation\nby Harrison Chase - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! I'm Harrison Chase, and today we're going to explore how LangChain can be your gateway to data-driven innovation.\n\nLangChain is a powerful tool that allows you to interact with various data sources in a unique and efficient way. With over 80 unique loaders, you can handle different types of data, from PDFs to databases.\n\nBut that's not all. Today, we're going to build a chatbot that can chat directly with information from your own documents and data.\n\nImagine having a personal assistant who can read and understand all your documents and data. That's what we're going to create today.\n\nI'll be guiding you through each step, making sure to keep things simple and easy to understand. By the end of this video, you'll have your own chatbot ready to assist you with your data needs.\n\nSo, are you ready to explore how LangChain can be your gateway to data-driven innovation? Let's dive in!\n\nRemember, if you have any questions, feel free to leave a comment. I'm always here to help. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########\n\nRefined Script:\n\n####LangChain: Your Gateway to Data-Driven Innovation\nby Harrison Chase - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! I'm Harrison Chase, and today we're diving into the world of LangChain. This powerful tool is your gateway to data-driven innovation.\n\nWith over 80 unique loaders, LangChain allows you to interact with various data sources in a unique and efficient way. From PDFs to databases, you can handle different types of data with ease.\n\nBut wait, there's more! Today, we're going to build a chatbot that can chat directly with information from your own documents and data. Imagine having a personal assistant who can read and understand all your documents and data. That's what we're going to create today.\n\nI'll be guiding you through each step, making sure to keep things simple and easy to understand. By the end of this video, you'll have your own chatbot ready to assist you with your data needs.\n\nSo, are you ready to explore how LangChain can be your gateway to data-driven innovation? Let's dive in!\n\nRemember, if you have any questions, feel free to leave a comment. I'm always here to help. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-04-30"}}
{"video": {"title": "Conclusion and Next Steps in On-Device AI", "transcript": "####Conclusion and Next Steps in On-Device AI\nby Krishna Sridhar - 2022-10-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Krishna Sridhar, and we're wrapping up our On-Device AI series today! We've had an amazing journey together, and I'm excited to share the next steps you can take to dive deeper into this fascinating field. So, let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-10-19"}}
{"video": {"title": "Quantization and Fine-Tuning: A Powerful Combination", "transcript": "####Quantization and Fine-Tuning: A Powerful Duo\nby Marc Sun, Younes Belkada - 2022-04-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the dynamic duo of quantization and fine-tuning.\n\nQuantization can help us shrink our models, but it can also bring some errors along for the ride. Fine-tuning can help us bounce back from those losses in accuracy.\n\nWe'll explore how to blend these two techniques to get the most out of both. We'll also check out some real-world examples to see this duo in action.\n\nBut don't worry, we'll break it down step by step. By the end of this video, you'll have a clear understanding of how to use quantization and fine-tuning together.\n\nSo, let's get started. And remember, the best way to learn is by doing.\n\nDon't forget to like, share, and subscribe for more great content.\n\nUntil next time, I'm Younes Belkada, and this has been Quantization and Fine-Tuning: A Powerful Duo.\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-04-19"}}
{"video": {"title": "Building Your First Agentic RAG with LlamaIndex", "transcript": "####Building Your First Agentic RAG with LlamaIndex\nby Jerry Liu - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and today we're embarking on an exciting journey into the world of autonomous agents!\n\nEver dreamt of having your data work for you? With LlamaIndex, you can build agentic RAG systems that intelligently navigate and analyze your data.\n\nBut first, let's demystify what an agentic RAG is. It's a system that can reason over your documents and answer complex questions. Imagine having a personal assistant that can read through your documents and give you a summary or answer any question you have.\n\nNow, let's roll up our sleeves and build our first router agent. Don't worry, you only need basic Python knowledge for this. We'll start by setting up our environment and then we'll code our router agent step by step. This agent will help us with Q&A and summarization tasks.\n\nBut wait, there's more! We'll also learn how to extend our router agent to handle passing arguments. This will make our agent more versatile and capable of handling more complex tasks.\n\nOnce we've mastered the router agent, we'll move on to designing a research agent. This agent handles multi-documents and is a bit more advanced. But don't worry, I'll guide you through the process step by step.\n\nAnd of course, no system is perfect. We'll also talk about different ways to debug and control our agent. This will help you troubleshoot any issues you might encounter and ensure your agent is working exactly as you want it to.\n\nBy the end of this video, you'll have gained valuable skills in guiding agent reasoning and debugging. You'll be able to build your own agentic RAG systems and unleash the power of your data.\n\nSo, are you ready to build your first agentic RAG with LlamaIndex? Let's dive in!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-03-15"}}
{"video": {"title": "Building Safe and Responsible AI with Llama Guard", "transcript": "####Building Safe and Responsible AI with Llama Guard\nby Amit Sangani - 2023-02-18\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Amit Sangani and today we're diving into the exciting world of Building Safe and Responsible AI with Llama Guard!\n\nAre you ready to make sure your AI applications are not only smart but also safe and responsible? In this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst, we'll take a look at Meta Llama 2 Chat and how you can interact with it to get the most out of your prompts. We'll also explore Code Llama and how it can help you with your coding needs.\n\nBut the real star of the show is Llama Guard. We'll show you how you can use this model to ensure that your AI applications are safe and responsible.\n\nSo, are you ready to build AI applications that you can be proud of? Let's get started!\n\nRemember, building safe and responsible AI is not just a best practice, it's a necessity. So, be sure to try out these best practices on your own and see how they work for you. And, if you have any questions or need further clarification, don't hesitate to reach out.\n\nThanks for watching and happy prompting!\n\nBe sure to like, comment, and subscribe for more content like this. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-18"}}
{"video": {"title": "Mastering GANs: Challenges and Solutions", "transcript": "####Mastering GANs: Challenges and Solutions\nby Eric Zelikman - 2022-10-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Eric Zelikman here, and today we're diving into the wild world of Generative Adversarial Networks, or GANs for short. Now, I'm not going to sugarcoat it - mastering GANs can be a real rollercoaster ride. But don't worry, I've got your back!\n\nIn this video, we'll be exploring some of the most common challenges that GAN practitioners face, and I'll be sharing some tried-and-true solutions to help you conquer those hurdles like a pro. So, are you ready to take on the GAN challenge? Let's do this!\n#### END TRANSCRIPT ########", "author": "Eric Zelikman", "publication_date": "2022-10-17"}}
{"video": {"title": "Deep Reinforcement Learning: Mastering Complex Tasks", "transcript": "####Deep Reinforcement Learning: Mastering Complex Tasks\nby Laurence Moroney - 2023-05-13\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the fascinating world of deep reinforcement learning! We'll see how it's used to train agents that can master complex tasks using TensorFlow.\n\n[Video hook and introduction]\n\nImagine an agent that can learn to play video games or control robots just by trial and error. That's the power of deep reinforcement learning! It combines the might of deep neural networks with reinforcement learning algorithms, allowing agents to learn from high-dimensional inputs and master complex tasks. Let's get started!\n\n[Body content]\n\nFirst, we'll cover the core concepts of deep reinforcement learning, such as deep Q-networks (DQN), policy gradients, and actor-critic methods.\n\nNext, we'll build and train a deep reinforcement learning agent in TensorFlow for a specific task. We'll explore techniques for representing and exploring the environment, as well as updating the agent's policy based on received rewards.\n\nWe'll also discuss popular deep reinforcement learning algorithms, such as Proximal Policy Optimization (PPO), Deep Deterministic Policy Gradients (DDPG), and Asynchronous Advantage Actor-critic (A3C), and their unique applications.\n\n[Conclusion and call to action]\n\nBy the end of this video, you'll have a solid understanding of deep reinforcement learning and how to use it for training agents that can master complex tasks in TensorFlow.\n\nDon't forget to like, share, and subscribe for more AI and machine learning content. Join me in the next video, where we'll explore the world of neural architecture search and how it's used to automatically design high-performing neural networks. See you there!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-05-13"}}
{"video": {"title": "Building Your First Agentic RAG with LlamaIndex", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits of Agentic RAG.\n- Use of active voice and simple language.\n- Present and encouraging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Jerry Liu", "publication_date": "2023-03-15"}}
{"video": {"title": "Future Trends in On-Device AI", "transcript": "####Future Trends in On-Device AI\nby Krishna Sridhar - 2022-10-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Krishna Sridhar here. Are you ready to dive into the future of On-Device AI? Today, we're going to explore the exciting trends that are shaping the world of AI right on your device. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-10-17"}}
{"video": {"title": "TensorFlow: Deployment on Edge Devices", "transcript": "####TensorFlow: Deployment on Edge Devices\nby Laurence Moroney - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Laurence Moroney, and today we're diving into the thrilling world of TensorFlow model deployment on edge devices!\n\n[Video hook and introduction]\n\nEdge computing is the future! It's all about bringing computation closer to the source of data. This means faster processing times, reduced bandwidth usage, and a whole lot of other benefits.\n\n[Body content]\n\nWith TensorFlow, deploying models on edge devices is a breeze. TensorFlow Lite is designed specifically for on-device machine learning, with a focus on low latency and a small binary size.\n\nYou can convert your TensorFlow models to the TensorFlow Lite format, and then deploy them on a variety of edge devices. It's like magic, but better because it's technology!\n\n[Conclusion and call to action]\n\nSo, what are you waiting for? Get started with TensorFlow Lite and explore the exciting world of edge computing! Keep learning, keep innovating, and happy coding!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-03-25"}}
{"video": {"title": "Creating AI Magic with Hugging Face Open Source Models", "transcript": "####Creating AI Magic with Hugging Face Open Source Models\nby Maria Khalusova, Marc Sun, Younes Belkada - 2023-03-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc, and today we're going to create some AI magic with Hugging Face open-source models.\n\nHugging Face is a platform that makes building AI applications feel like child's play. It's perfect for beginners, so let's get started.\n\nFirst, we'll find a model on the Hugging Face Hub. You can filter models based on tasks, rankings, and memory requirements. It's like choosing a spell from a spellbook.\n\nNext, we'll use the transformers library to implement the model. With just a few lines of code, you can perform text, audio, image, and multimodal tasks. It's like casting an AI spell.\n\nFinally, we'll share our AI app. With a user-friendly interface or via API, you can run it on the cloud using Gradio and Hugging Face Spaces. It's like sharing your AI magic with the world.\n\nSo, are you ready to create some AI magic with Hugging Face? Remember, the best way to learn is by doing. So, go ahead, explore the Hugging Face Hub, play around with the models, and who knows, you might just create the next AI sensation.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########\n\nPositive Points:\n\n- Clear introduction of the topic and benefits of Hugging Face.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-03-19"}}
{"video": {"title": "Designing a Question-Answering App with NLP and Hugging Face", "transcript": "####Designing a Question-Answering App with NLP and Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, tech enthusiasts! I'm Your Assistant, and today we're diving into the exciting world of NLP and Hugging Face to design a question-answering app.\n\nQuestion-answering is like the superpower of NLP. It lets our app understand and respond to user queries, just like a real person. And with Hugging Face, we can train our NLP model to do just that.\n\nWe'll start by demystifying how question-answering works, then we'll prepare our data, train our model, and finally, put it to the test.\n\nRemember, the secret to successful question-answering is understanding the context and the intent of the question. Our model needs to be smart enough to handle that.\n\nSo, are you ready to create an app that can answer any question? Let's get started with Hugging Face and NLP!\n\nStay tuned for more thrilling videos on this topic. And don't forget to like, share, and subscribe for more tech content. Until next time, I'm Your Assistant, your guide in the world of AI.\n\n\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-04-05"}}
{"video": {"title": "Function-Calling and Data Extraction: Real-World Applications", "transcript": "####Function-Calling and Data Extraction: Real-World Applications\nby Jiantao Jiao, Venkat Srinivasan - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao and welcome back to our series on function-calling and data extraction with LLMs. Today, we're diving into the exciting world of real-world applications.\n\nWe'll be exploring a variety of use cases, from automating customer service to analyzing social media data. Trust me, the possibilities are endless!\n\nBy the end of this video, you'll have a clearer understanding of how function-calling and data extraction can be applied in different industries and domains.\n\nRemember, the key to success is to keep learning and exploring. So, don't just watch the video. Try out the examples yourself and think about how you can apply function-calling and data extraction in your own projects.\n\nAnd if you have any questions, feel free to leave them in the comments. We're here to help!\n\nSo, are you ready to explore the real-world applications of function-calling and data extraction with LLMs? Let's get started!\n\nDon't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-04-05"}}
{"video": {"title": "Mastering Function-Calling: Extend LLMs with Custom Functionality", "transcript": "####Mastering Function-Calling: Extend LLMs with Custom Functionality\nby Jiantao Jiao, Venkat Srinivasan - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Venkat Srinivasan and welcome back to our series on function-calling and data extraction with LLMs. Today, we're going to focus on mastering function-calling.\n\nFunction-calling allows you to extend LLMs with custom functionality. This means you can create more powerful and versatile applications. So, how does it work?\n\nWith function-calling, LLMs can form calls to external functions. This means you can integrate your LLMs with other tools and services, making them even more useful.\n\nLet's dive into some examples. We'll start with a simple function and then gradually build up to more complex scenarios. By the end of this video, you'll be a pro at using function-calling to extend your LLMs.\n\nRemember, practice is key. So, don't just watch the video. Try out the examples yourself and experiment with different functions.\n\nAnd if you have any questions, feel free to leave them in the comments. We're here to help!\n\nSo, are you ready to master function-calling and take your LLM applications to the next level? Let's get started!\n\nDon't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########\n\nRefined Script:\n\n####Mastering Function-Calling: Unleash the Power of LLMs with Custom Functionality\nby Jiantao Jiao, Venkat Srinivasan - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Venkat Srinivasan and welcome back to our series on function-calling and data extraction with LLMs. Today, we're diving into the exciting world of mastering function-calling.\n\nFunction-calling allows you to extend LLMs with custom functionality. This means you can create more powerful and versatile applications. So, how does it work?\n\nWith function-calling, LLMs can form calls to external functions. This means you can integrate your LLMs with other tools and services, making them even more useful.\n\nLet's dive into some examples. We'll start with a simple function and then gradually build up to more complex scenarios. By the end of this video, you'll be a pro at using function-calling to extend your LLMs.\n\nRemember, practice is key. So, don't just watch the video. Try out the examples yourself and experiment with different functions.\n\nAnd if you have any questions, feel free to leave them in the comments. We're here to help!\n\nSo, are you ready to master function-calling and take your LLM applications to the next level? Let's get started!\n\nDon't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-03-20"}}
{"video": {"title": "Applying LLMs to Proprietary Data with LangChain", "transcript": "####Applying LLMs to Proprietary Data with LangChain\nby Harrison Chase, Andrew Ng - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're diving into the exciting world of applying LLMs to your own data using LangChain.\n\nImagine having a personal assistant or a specialized chatbot that's tailored to your specific needs. Sounds amazing, right? Well, that's exactly what we're going to cover today.\n\nWe'll start with the basics of applying LLMs to proprietary data and then move on to some more advanced techniques. By the end of this video, you'll be using LLMs with your own data like a pro.\n\nSo, are you ready to take your LLM application development skills to the next level? Let's get started. Remember, practice makes perfect. The more you work with LangChain, the better you'll get.\n\nThanks for watching. Don't forget to like, comment, and subscribe for more content on LLM application development. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-20"}}
{"video": {"title": "Optimizing Multimodal Search Performance", "transcript": "####Optimizing Multimodal Search Performance\nby Sebastian Witalec - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Sebastian Witalec and today we're diving into the world of multimodal search applications. But we're not just building them, we're making them fly!\n\nOptimizing the performance of your multimodal search application is like tuning a race car. It's not just about the engine, it's about the whole package. We'll explore strategies like indexing, caching, and more to ensure your application is running at top speed.\n\nBut we won't stop there. We'll also discuss how to monitor your application's performance and troubleshoot common issues. Because let's face it, even the best race cars need a pit stop sometimes.\n\nRemember, the goal is to build a multimodal search application that not only works well, but performs well. This is crucial in many industries where speed and efficiency are the name of the game.\n\nSo, buckle up and let's get started! And if you have any questions, don't be shy. We're all here to learn together. And don't forget to like, share, and subscribe for more exciting content. Until next time, happy optimizing!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2023-04-10"}}
{"video": {"title": "Planning Ahead with AutoGen: Predictive AI Agents", "transcript": "####Planning Ahead with AutoGen: Predictive AI Agents\nby Chi Wang, Qingyun Wu - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Qingyun Wu here, and today we're going to explore the Planning design pattern in AutoGen.\n\nImagine if your AI agent could see into the future. That's the power of Planning! We'll show you how to create agents that can predict future actions and make decisions based on those predictions.\n\nFirst, we'll explain the concept of Planning. Then, we'll move on to a practical example. We'll guide you through the process of creating an agent, teaching it to predict, and setting it loose on a task.\n\nOur goal is to make our agents more proactive and strategic. So, let's get started and create some predictive AI agents with AutoGen!\n\nAs always, if you have any questions, feel free to leave them in the comments. We're here to help you learn and grow.\n\nAnd don't forget to like, subscribe, and hit that notification bell for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2023-03-22"}}
{"video": {"title": "TensorFlow: Tensors, Variables, and Operations", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Make the benefits and applications of the topic more relatable and engaging.\n- Include critical analysis and personal insights.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.", "author": "Laurence Moroney", "publication_date": "2023-03-20"}}
{"video": {"title": "Mastering Function-Calling and Data Extraction with LLMs", "transcript": "####Mastering Function-Calling and Data Extraction with LLMs\nby Jiantao Jiao, Venkat Srinivasan - 2022-03-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao and today we're going on an adventure into the thrilling world of Function-Calling and Data Extraction with Language Learning Models, or LLMs for short. If you're already familiar with LLMs and have some basic Python skills, you're in luck!\n\nLet's kick things off with function-calling. It's a game-changer that allows you to extend your LLMs with custom functionality. Imagine being able to teach your LLM to make calls to external functions. Mind-blowing, right?\n\nNow, let's get our hands dirty with some data extraction. We'll learn how to extract structured data from natural language inputs. This is incredibly useful when dealing with real-world data for analysis.\n\nBut wait, there's more! We've teamed up with Nexusflow to bring you an end-to-end application that processes customer service transcripts using LLMs. You'll see firsthand how function-calling and data extraction can transform your application capabilities.\n\nRemember, practice makes perfect. So, don't just watch, get involved! Try out the techniques we'll cover and see how they can boost your LLM and agent applications.\n\nThanks for watching and happy learning! Don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, this is Venkat Srinivasan signing off.\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-03-01"}}
{"video": {"title": "The Future of GANs: What's Next?", "transcript": "####The Future of GANs: What's Next?\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-04-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sharon Zhou, and today we're diving into the thrilling world of GANs!\n\n[Video hook and introduction]\n\nGANs, or Generative Adversarial Networks, have been shaking up the machine learning scene since 2014. They've transformed how we generate images, and they're only getting better and more versatile. In this video, we'll explore some of the most exciting advancements in GANs and what's on the horizon.\n\n[Body content]\n\nOne of the most electrifying developments in GANs is the use of 3D data. While traditional GANs work with 2D images, researchers are now developing GANs that can generate 3D objects and scenes. This opens up a world of possibilities for computer graphics and virtual reality.\n\nAnother mind-blowing development is the use of GANs for video generation. Instead of generating individual images, researchers are now developing GANs that can generate entire videos. This could revolutionize fields like film and television, where GANs could be used to create realistic special effects or even entire movies.\n\nBut perhaps the most exciting development in the world of GANs is the use of generative models for scientific discovery. Researchers are now using GANs to generate new molecules and materials, which could have huge implications for fields like medicine and materials science.\n\n[Conclusion and call to action]\n\nSo, that's a quick peek into the future of GANs. It's a field that's constantly evolving, and we can't wait to see what's next. Thanks for watching, and be sure to check out our other videos on GANs and machine learning. Until next time, keep exploring!\n\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-04-19"}}
{"video": {"title": "Understanding Multimodality and Contrastive Learning", "transcript": "####Understanding Multimodality and Contrastive Learning\nby Sebastian Witalec - 2022-10-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Sebastian! Today, we're diving into the fascinating world of multimodality and contrastive learning. Trust me, you won't want to miss this!\n\nImagine being able to build modality-independent embeddings. Sounds like a mouthful, right? But don't worry, by the end of this video, you'll have a solid understanding of this key concept.\n\nSo, what exactly is multimodality? Well, it's all about combining different types of data, like text and images, to create a more comprehensive understanding. And that's where contrastive learning comes in.\n\nContrastive learning is a technique that helps machines learn to distinguish between similar and dissimilar data points. It's like teaching a child to tell the difference between a cat and a dog.\n\nBut why should you care? Well, multimodality and contrastive learning are revolutionizing the field of AI. They're being used in everything from self-driving cars to virtual assistants.\n\nSo, are you ready to take your AI knowledge to the next level? Let's get started!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-03"}}
{"video": {"title": "AI for Good: Inspiring Case Studies", "transcript": "####AI for Good: Inspiring Case Studies\nby Robert Monarch - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Robert Monarch, and today we're diving into the world of AI for Good.\n\nAI has the potential to revolutionize our world for the better. From healthcare to environmental conservation, the possibilities are endless.\n\nBut don't just take my word for it. Let's explore some inspiring case studies of AI for Good. We'll learn about the challenges they're tackling, the innovative solutions they're creating, and the real-world impact they're making.\n\nAnd the best part? You can be a part of this movement too.\n\nSo, are you ready to get inspired and make a difference? Let's get started!\n\nRemember, every step we take towards using AI for Good is a step towards a brighter, more sustainable future.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning, keep growing, and keep using AI for Good!\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-25"}}
{"video": {"title": "Exploring Mistral's Open-Source and Commercial Models", "transcript": "####Exploring Mistral's Open-Source and Commercial Models\nby Younes Belkada, Marc Sun - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Today, we're embarking on an exciting journey to explore Mistral's open-source and commercial models. We'll be your guides as we delve into Mistral's JSON mode to generate structured LLM responses and learn how to leverage Mistral's API for enhanced capabilities. Are you ready? Let's do this!\n\nMistral AI offers a treasure trove of advanced open source and commercial LLMs. Whether you're a newbie or a seasoned pro, Mistral has got you covered. We're partnering with Mistral AI to uncover their three open source models and three commercial models, all accessible through a user-friendly web interface and API calls.\n\nBy using Mistral's JSON mode, we can generate LLM responses in a structured format, making it a breeze to integrate into larger software applications. But wait, there's more! We can also utilize Mistral's API to call user-defined Python functions, enhancing the LLM's ability to find relevant information.\n\nSo, are you ready to unlock the full potential of Mistral AI? Join us on this adventure and let's have some fun while learning!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2022-10-15"}}
{"video": {"title": "Fine-Tuning Pre-Trained Models with TensorFlow", "transcript": "####Fine-Tuning Pre-Trained Models with TensorFlow\nby Laurence Moroney, Eddy Shyu - 2022-02-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eddy Shyu, and today we're diving into the world of fine-tuning pre-trained models with TensorFlow.\n\nAre you tired of training models from scratch? Well, you're in luck! In this video, we'll discuss the benefits of using pre-trained models and how to fine-tune them for your specific task. We'll also explore some advanced techniques like layer-wise fine-tuning and knowledge distillation.\n\nBut wait, there's more! We'll even show you how to save time and resources by leveraging the power of pre-trained models.\n\n...\n\nThanks for watching! I hope this video helped you understand how to fine-tune pre-trained models with TensorFlow. If you found this video helpful, please give it a thumbs up and subscribe to our channel for more content like this. And don't forget to share it with your friends! See you next time!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-02-19"}}
{"video": {"title": "Building and Deploying LLMs in Business Use-Cases", "transcript": "####Building and Deploying LLMs in Business Use-Cases\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, Chris Fregly here! Today, we're diving into the exciting world of building and deploying LLMs in business use-cases.\n\nFirst, we'll cover the basics of building LLMs. We'll talk about data preparation, model training, and evaluation. And don't worry, we'll keep it simple and fun!\n\nWe'll also discuss the importance of testing and validation in the development process. This will ensure that our models are accurate and reliable.\n\nThen, we'll explore deploying LLMs in business use-cases. From creating chatbots to generating product descriptions, we'll show you how to integrate LLMs into your business processes.\n\nAnd let's not forget about the ethical considerations. We'll touch on the importance of responsible AI practices and how to avoid bias in our models.\n\nBy the end of this video, you'll have the practical skills and knowledge to build and deploy LLMs in business use-cases.\n\nSo, are you ready to take your business to the next level? Let's get started! See you in the course.\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-12"}}
{"video": {"title": "Harnessing the Power of Open Source Models with Hugging Face: A Deep Dive", "transcript": "####Harnessing the Power of Open Source Models with Hugging Face: A Fun and Engaging Deep Dive\nby Maria Khalusova, Marc Sun, Younes Belkada - 2023-03-24\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Maria, and today we're going to have a blast exploring how to harness the power of open-source models with Hugging Face.\n\nHugging Face is a platform that makes AI accessible to everyone. So, let's get started!\n\nThe Hugging Face Hub is like a candy store for AI models. You can browse and filter models based on tasks, rankings, and memory requirements. And the best part? Everything's free!\n\nOnce you've picked your favorite model, using it is a breeze. With the transformers library, you can perform text, audio, image, and multimodal tasks with just a few lines of code. It's like having your own AI playground.\n\nBut wait, there's more! Sharing your AI apps is easy with Hugging Face. With a user-friendly interface or via API, you can run them on the cloud using Gradio and Hugging Face Spaces. It's like launching your own AI project into space!\n\nSo, are you ready to unleash your inner AI genius with Hugging Face? Remember, the best way to learn is by doing. So, go ahead, explore the Hugging Face Hub, play around with the models, and who knows, you might just create the next AI masterpiece.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-03-24"}}
{"video": {"title": "TensorFlow: Functional API Deep Dive", "transcript": "####TensorFlow: Functional API Deep Dive\nby Laurence Moroney, Eddy Shyu - 2022-03-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eddy Shyu, and today we're going to take a deep dive into the Functional API in TensorFlow.\n\nAre you ready to level up your TensorFlow skills? The Functional API is a powerful tool for building complex models. It allows you to create models with multiple inputs and outputs, share layers between models, and more.\n\nIn this video, we're going to explore some of the more advanced features of the Functional API. We'll show you how to use it to build models with custom training loops, create models with shared layers, and even build models with multiple inputs and outputs.\n\nSo, let's get started and take your TensorFlow skills to the next level.\n\n[Demonstration of building models with custom training loops, shared layers, and multiple inputs and outputs]\n\nThanks for watching, and be sure to check out our other videos on TensorFlow. Don't forget to like, share, and subscribe for more exciting content!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-03-08"}}
{"video": {"title": "Streamlining Workflows with ChatGPT", "transcript": "####Streamlining Workflows with ChatGPT\nby Isa Fulford - 2022-10-21\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Isa Fulford! Today, we're diving into the world of ChatGPT API and how it can revolutionize your workflows. Are you ready to optimize your processes and achieve greater efficiency? Let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-21"}}
{"video": {"title": "LangChain and Machine Learning", "transcript": "####LangChain and Machine Learning: Unleashing the Power of AI\nby Harrison Chase - 2023-03-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! I'm Harrison Chase, the creator of LangChain, and today we're diving into the fascinating world of machine learning.\n\nMachine learning is a game-changer, allowing computers to perform tasks without explicit instructions. And with LangChain, you can harness this power to build even more powerful chatbots.\n\nBut how does it work? Let's find out.\n\nLangChain uses cutting-edge machine learning techniques to continuously improve the accuracy and effectiveness of your chatbot. This means your chatbot will get smarter and smarter at understanding and responding to your questions over time.\n\nI'll be guiding you through each step of the process, sharing tips and tricks along the way. And the best part? You'll be learning directly from me, the creator of LangChain.\n\nSo, are you ready to take your chatbot to the next level with machine learning? Let's get started!\n\nRemember, if you have any questions or need help along the way, don't hesitate to reach out. And once you've mastered machine learning with LangChain, be sure to share your creations with me. I can't wait to see what you build!\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-12"}}
{"video": {"title": "Coding with Code Llama", "transcript": "####Coding with Code Llama\nby Amit Sangani - 2023-02-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Amit Sangani and today we're diving into the exciting world of Coding with Code Llama.\n\nAre you ready to level up your coding game? In this beginner-friendly course, we'll be uncovering the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst, we'll be exploring Meta Llama 2 Chat and how you can interact with it to get the most out of your prompts. But the real showstopper is Code Llama. We'll show you how you can use this model to supercharge your coding skills.\n\nBut wait, there's more! We'll also be discussing the importance of building safe and responsible AI applications. That's where Llama Guard comes in. We'll show you how you can use this model to ensure that your AI applications are safe and responsible.\n\nSo, are you ready to become a Code Llama master? Let's get started!\n\nRemember, practice makes perfect. So, be sure to try out these best practices on your own and see how they work for you. And, if you have any questions or need further clarification, don't hesitate to reach out.\n\nThanks for watching and happy prompting!\n\nBe sure to like, comment, and subscribe for more content like this. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-20"}}
{"video": {"title": "The Impact of GANs: Empowering Creativity and Innovation", "transcript": "####The Impact of GANs: Unleashing Creativity and Innovation\nby Sharon Zhou - 2022-10-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Sharon Zhou, and today we're diving into the fascinating world of Generative Adversarial Networks, or GANs for short. These bad boys have taken the creative landscape by storm, and I can't wait to show you why!\n\nBut first, let's get you hooked. Imagine being able to create stunning, lifelike images with just a few lines of code. Sounds too good to be true, right? Well, that's the power of GANs!\n\nNow, let's get down to business. We'll explore the impact of GANs on various industries, from art and design to gaming and beyond. And trust me, you won't want to miss the endless possibilities they offer.\n\nBut wait, there's more! We'll also discuss the challenges and ethical considerations that come with this powerful technology. After all, with great power comes great responsibility.\n\nSo, are you ready to unleash the power of GANs and take your creativity to the next level? Let's do this!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2022-10-19"}}
{"video": {"title": "Chat with Your Data using LangChain!", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits of LangChain.\n- Use of active voice and simple language.\n- Encouragement of audience participation and engagement.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.\n- Improve contrast and pacing to maintain interest.\n- Introduce more personal insights and real-world applications.\n- Include critical analysis and practical tips.", "author": "Harrison Chase", "publication_date": "2023-03-15"}}
{"video": {"title": "Building Scalable AI Apps with TensorFlow", "transcript": "####Building Scalable AI Apps with TensorFlow\nby Laurence Moroney - 2022-02-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the world of building scalable AI apps with TensorFlow!\n\n[Video hook and introduction]\n\nAre you ready to level up your AI skills and build applications that can handle massive amounts of data? Let's do this!\n\n[Body content]\n\nFirst, we'll cover the basics of building scalable AI apps. We'll explore essential concepts like distributed training, data parallelism, and model parallelism.\n\nThen, we'll dive into using TensorFlow to build scalable AI apps. We'll cover the TensorFlow ecosystem, including tools like TensorBoard, TF.data, and TFX. You'll learn how to use these tools to build, train, and deploy your models at scale.\n\nWe'll also explore real-world applications of scalable AI, like recommendation systems and fraud detection. Plus, we'll cover best practices for building scalable AI apps, like monitoring, logging, and testing.\n\n[Conclusion and call to action]\n\nSo, are you ready to build scalable AI apps with TensorFlow? Let's get started! Remember, the best way to learn is by doing, so make sure to follow along and code with me. See you in the first lesson!\n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-02-05"}}
{"video": {"title": "Transformers: The Future of NLP", "transcript": "####Transformers: The Future of NLP\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-01-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your friendly guide and today we're diving into the exciting world of Transformers, the future of Natural Language Processing (NLP).\n\nTransformers are a game-changer in the world of neural networks. They're like superheroes, handling long-range dependencies in data with ease. This makes them perfect for tasks like machine translation and text summarization.\n\nBut how do they work? It's all about attention. Transformers use a mechanism called self-attention to weigh the importance of different words in a sentence when making predictions. This allows them to handle long-range dependencies more effectively than other networks.\n\nNow, I know this might sound like rocket science, but don't worry. With some practice and patience, you'll be building your own Transformers in no time.\n\nSo, what are you waiting for? Let's embark on this Transformer journey together. And remember, if you ever get stuck, I'm here to help.\n\nThanks for watching, and happy learning!\n\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-01-22"}}
{"video": {"title": "Wind Energy and AI: A Match Made in Heaven", "transcript": "####Wind Energy and AI: A Match Made in Heaven\nby Robert Monarch - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the windy world of AI!\n\nWind energy is blowing up as one of the fastest-growing sources of renewable energy. But it's also as unpredictable as the weather. That's where AI comes in!\n\nToday, we'll learn how machine learning can make wind energy production more predictable and efficient. We'll explore different models and techniques, from time series forecasting to reinforcement learning.\n\nWe'll also look at real-world case studies, like how wind farms are using AI to maximize their output.\n\nSo, are you ready to harness the power of wind with AI? Let's get started!\n\nRemember, every step we take towards understanding and optimizing wind energy is a step towards a cleaner, greener world.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning, keep growing, and keep using AI for Good!\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-03-25"}}
{"video": {"title": "Mastering Quantization: A Deep Dive into Advanced Techniques", "transcript": "####Mastering Quantization: A Deep Dive into Advanced Techniques\nby Marc Sun, Younes Belkada - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, Quantization enthusiasts! I'm Marc Sun, and today we're taking a thrilling dive into the world of advanced quantization techniques. If you've already taken our Quantization Fundamentals course, you're in the perfect spot to level up your skills.\n\nFirst, we're exploring the fascinating world of Linear Quantization variants. We'll compare symmetric and asymmetric modes, and discuss the pros and cons of each. We'll also delve into different granularities like per tensor, per channel, and per group quantization.\n\nNext, we're getting our hands dirty. We'll build a general-purpose quantizer in Pytorch that can quantize the dense layers of any open source model. The result? Up to 4x compression on dense layers. Pretty impressive, right?\n\nBut we're not stopping there. We're also going to implement weights packing. We'll show you how to pack four 2-bit weights into a single 8-bit integer. This is a game-changer for model compression.\n\nRemember, quantization is a powerful tool for model compression, but it's not a one-size-fits-all solution. That's why we're exploring these advanced techniques, so you can customize your approach to suit your specific needs.\n\nAnd guess what? We're partnering with Hugging Face on this journey. They're providing us with the tools and resources we need to make the most of these techniques.\n\nSo, are you ready to level up your quantization skills? Let's get started. And remember, if you have any questions, don't hesitate to reach out. We're here to help.\n\nThanks for watching, and stay tuned for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-01"}}
{"video": {"title": "Deploying LLMs in the Real World", "transcript": "####Deploying LLMs in the Real World: A Practical Guide\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, Mike Chambers here, and today we're diving into the exciting world of deploying LLMs in the real world!\n\nDeploying an LLM is like adding a superpower to your application. But it's not as simple as just plugging it in. You need to consider the model's latency, scalability, and security.\n\nWe'll share some best practices for deploying LLMs, like using Docker and Kubernetes for containerization and orchestration. And we'll talk about how to protect your model with authentication and authorization measures.\n\nBut that's not all! We'll also explore some real-world applications of LLMs, like generating personalized product descriptions for e-commerce sites or creating realistic dialogue for video games. And we'll hear from some AWS AI practitioners who are actively building and deploying LLMs in business use-cases today.\n\nBy the end of this video, you'll have a solid understanding of how to deploy LLMs in the real world and some inspiration for how you can use this technology to create value in your own projects. So let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-22"}}
{"video": {"title": "Machine Learning Specialization: Introduction to AI Concepts", "transcript": "####Machine Learning Specialization: Introduction to AI Concepts\nby Andrew Ng - 2022-10-01\n\n#### BEGIN TRANSCRIPT ####\nHello and welcome, machine learning enthusiasts! I'm Andrew Ng, your friendly AI guide, and today we're embarking on an exciting journey into the world of machine learning. We'll be exploring the fascinating concepts of AI, and I can't wait to share this learning adventure with you. So, buckle up and let's dive right in!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-01"}}
{"video": {"title": "Unleashing the Power of On-Device AI: A Beginner's Guide", "transcript": "####Unleashing the Power of On-Device AI: A Beginner's Guide\nby Krishna Sridhar - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're diving into the thrilling world of On-Device AI.\n\nImagine having the power of AI right in your pocket, on your smartphone or other edge devices. That's what On-Device AI is all about. It uses the local compute power of your device for faster and more secure inference. No more waiting for the cloud!\n\nFirst things first, let's talk about model conversion. If you're familiar with Python, PyTorch, or TensorFlow - you're already ahead of the game. We'll take your existing models and convert them for device compatibility. It's like translating English to Spanish, but for AI models.\n\nNext up, quantization. It's a fancy word for reducing the size of your models without compromising performance. Think of it like packing a suitcase - you want to fit as much as possible without it bursting at the seams.\n\nNow, let's get our hands dirty with device integration. We'll explore runtime dependencies and how GPU, NPU, and CPU compute unit utilization affect performance. It's like conducting an orchestra - every instrument has its part to play.\n\nAnd guess what? We're partnering with Qualcomm to bring you this exciting journey. So, are you ready to unleash the power of On-Device AI? Let's get started! Remember, practice makes perfect, so keep tinkering, keep learning, and most importantly, have fun.\n\nIf you found this video helpful, don't forget to like, share, and subscribe for more exciting content. See you in the next one!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2023-03-15"}}
{"video": {"title": "Creating Intelligent Agents with LangChain", "transcript": "####Creating Intelligent Agents with LangChain\nby Harrison Chase, Andrew Ng - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Harrison Chase here, and today we're diving into the exciting world of creating intelligent agents with LangChain.\n\nIntelligent agents, aren't they cool? They're software entities that can perform tasks or make decisions on your behalf. And guess what? With LangChain, we can use LLMs to build these agents.\n\nWe'll start with the basics of creating intelligent agents and then move on to some more advanced techniques. By the end of this video, you'll be building your own intelligent agents like a pro.\n\nSo, let's get started. Remember, practice makes perfect.\n\nThanks for watching. Don't forget to like, comment, and subscribe for more content on LLM application development. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-15"}}
{"video": {"title": "Improving NLP Apps with Fine-Tuning and Hugging Face", "transcript": "####Improving NLP Apps with Fine-Tuning and Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, Your Assistant here, and today we're diving into the world of fine-tuning in NLP. If you've ever wondered how to take your NLP models to the next level, you're in luck!\n\nFirst things first, let's talk about what fine-tuning is. It's the process of taking a pre-trained model and tweaking it to fit a specific task. This can lead to some serious performance boosts.\n\nWith Hugging Face, fine-tuning is a breeze. We'll show you how to prepare your data, modify your model, and fine-tune it for better results.\n\nBut wait, there's more! We'll also cover some advanced techniques for fine-tuning, like learning rate schedules and early stopping. And don't worry, we'll explain everything in a clear and simple way, so you won't get lost in the jargon.\n\nSo, are you ready to level up your NLP apps with fine-tuning and Hugging Face? Let's do this!\n\nThat's all for today's video. If you enjoyed it, don't forget to give it a thumbs up and subscribe for more content. And if you're ready to start fine-tuning your own NLP models, check out the links in the description for some great resources. See you next time!\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-04-10"}}
{"video": {"title": "Quantization for Beginners: Compress Models with Hugging Face and Quanto", "transcript": "####Quantization for Beginners: Compress Models with Hugging Face and Quanto\nby Younes Belkada, Marc Sun - 2023-03-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the world of quantization for beginners with Hugging Face and Quanto.\n\nIn this video, we'll be uncovering how to compress models using the Hugging Face Transformers library and the Quanto library.\n\nBut first, let's get a grip on what quantization is. It's a process that shrinks the size of a model, making it more efficient and faster, while keeping its accuracy intact.\n\nWe'll kick things off with linear quantization, a simple yet effective method for model compression. It works by lowering the precision of the weights in your model, resulting in a smaller model size and quicker inference times.\n\nNext, we'll walk you through the process of quantizing open-source multimodal and language models. Don't worry if you're a beginner, I'll be there to guide you through each step.\n\nBy the end of this video, you'll have the skills to quantize any open-source model using Hugging Face and Quanto.\n\nThanks for watching, and don't forget to like, share, and subscribe for more AI and machine learning content. See you next time!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-05"}}
{"video": {"title": "Best Practices for Prompting Llama 2 & 3 Models", "transcript": "####Best Practices for Prompting Llama 2 & 3 Models\nby Amit Sangani - 2023-02-21\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Amit Sangani and today we're diving into the Best Practices for Prompting Llama 2 & 3 Models.\n\nAre you ready to level up your prompting game? In this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst, we'll take a look at Meta Llama 2 Chat and how you can interact with it to get the most out of your prompts. We'll also explore Code Llama and how it can help you with your coding needs.\n\nBut wait, there's more! We'll also be discussing the importance of building safe and responsible AI applications. That's where Llama Guard comes in. We'll show you how you can use this model to ensure that your AI applications are safe and responsible.\n\nSo, are you ready to become a prompting pro? Let's get started!\n\nRemember, practice makes perfect. So, be sure to try out these best practices on your own and see how they work for you. And, if you have any questions or need further clarification, don't hesitate to reach out.\n\nThanks for watching and happy prompting!\n\nBe sure to like, comment, and subscribe for more content like this. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-21"}}
{"video": {"title": "Unlocking the Power of LangChain for LLM Application Development", "transcript": "####Unlocking the Power of LangChain for LLM Application Development\nby Harrison Chase - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're going to explore the exciting world of LangChain for LLM Application Development. LangChain is a game-changer, a powerful framework that lets you unleash the full potential of LLMs in your applications. So, buckle up and let's dive in!\n\nLangChain is a versatile toolkit that empowers developers to create advanced applications using prompts, parsing, memory, chains, question answering, and agents. With just a basic understanding of Python, you can start building your own personalized assistants and specialized chatbots.\n\nBut here's the best part: by partnering with LangChain, you get direct access to the creator of the framework, yours truly. I'll guide you through the process of applying LLMs to your proprietary data, helping you unlock new possibilities for your projects.\n\nWith LangChain, you can leverage agents, chained calls, and memories to supercharge the capabilities of LLMs in your applications. Whether you're a beginner or an experienced developer, LangChain offers a user-friendly interface that makes the development process a breeze.\n\nSo, are you ready to revolutionize your LLM application development? Join me on this journey with LangChain. Together, we'll explore the endless possibilities of integrating LLMs into your projects. Stay tuned for more tips, tricks, and insights on LangChain and LLM application development. I'm Harrison Chase, signing off.\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2022-10-15"}}
{"video": {"title": "How to Red Team LLM Applications for Improved Security", "transcript": "Positive Points:\n\n- Clear introduction of the topic and the benefits of red teaming.\n- Use of active voice and simple language.\n- Concise and to the point.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more stakes and payoffs at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Matteo Dora, Luca Martial", "publication_date": "2022-10-15"}}
{"video": {"title": "Building a Transformer from Scratch", "transcript": "####Building a Transformer from Scratch: A Step-by-Step Guide\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-02-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your friendly guide and today we're embarking on an exciting journey to build a Transformer from scratch.\n\nWe'll be using Python and TensorFlow to create our very own Transformer, and we'll be applying it to a real-world NLP task.\n\nFirst, we'll preprocess our data and split it into training and testing sets. Then, we'll define our Transformer architecture, including the encoder, decoder, and attention layers. After that, we'll compile our model and train it on our data. Finally, we'll evaluate our model and see how well it performs.\n\nNow, I know this might sound like a daunting task, but don't worry. I'll be with you every step of the way, making sure you don't miss a beat.\n\nSo, what are you waiting for? Let's dive in and start building our Transformer. And remember, if you ever get stuck, I'm here to help.\n\nThanks for watching, and happy learning!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-02-19"}}
{"video": {"title": "Building Your Own Database Agent with Natural Language Processing", "transcript": "####Building Your Own Database Agent with Natural Language Processing\nby Adrian Gonzalez Sanchez - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Adrian Gonzalez Sanchez and welcome to this thrilling video on creating your own database agent using natural language processing!\n\nAre you fed up with writing complex SQL queries to interact with databases? Want to make data analysis more efficient and accessible for all? You're in luck!\n\nIn this video, we'll discover how to use natural language to interact with tabular data and SQL databases. Don't worry if you're a beginner! While familiarity with Python programming and databases is recommended, it's not a must.\n\nWe'll kick off by introducing the concept of natural language processing and how it can be used to interact with databases. Then, we'll delve into the Azure OpenAI Service and learn how to implement techniques like Retrieval Augmented Generation (RAG) and function calling.\n\nWith practical examples, you'll gain hands-on experience using the Azure OpenAI Service\u2019s Assistants API, and test it with function calling and code interpreter features. By the end of this video, you'll have the skills to build your own database agent that can interact with data using natural language.\n\nAnd guess what? We've teamed up with Microsoft to bring you this innovative content. So, are you ready to transform the way you interact with databases? Let's dive in!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like and subscribe for more exciting content on natural language processing and databases.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Adrian Gonzalez Sanchez", "publication_date": "2023-03-15"}}
{"video": {"title": "Implementing Industry Applications of Multimodal Search", "transcript": "####Implementing Industry Applications of Multimodal Search\nby Sebastian Witalec - 2022-10-07\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Today, we're diving into the exciting world of multimodal search and its real-world applications. I'm your host, Sebastian Witalec, and I can't wait to show you how we can leverage this technology to build multi-vector recommender systems. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-07"}}
{"video": {"title": "Master Deep Learning with the Deep Learning Specialization", "transcript": "####Master Deep Learning with the Deep Learning Specialization\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, deep learning enthusiasts! Are you ready to level up your skills and take on the world of neural networks? Well, you're in luck! Today, we're diving into the Deep Learning Specialization, a course that's going to blow your mind and make you a pro in no time.\n\nBut wait, you might be wondering, \"What's so special about this course?\" Well, let me tell you, this course is the real deal. It's taught by none other than Andrew Ng, the co-founder of Coursera and an absolute legend in the field of AI. And that's not all, you'll also be learning from Kian Katanforoosh and Younes Bensouda Mourri, two brilliant minds who know their stuff when it comes to deep learning.\n\nSo, what exactly will you be learning in this course? Well, get ready to become an expert in Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Long Short-Term Memory networks (LSTMs), and Transformers. And the best part? You'll be learning how to apply these networks to real-world tasks like speech recognition and Natural Language Processing (NLP) using Python and TensorFlow.\n\nBut don't just take my word for it, this course is perfect for intermediate level learners who are ready to take their deep learning skills to the next level. So, are you ready to join the ranks of the deep learning elite? Let's do this!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-10-15"}}
{"video": {"title": "Diffusion Models: The Key to Understanding Spread", "transcript": "####Diffusion Models: The Key to Understanding Spread\nby Sharon Zhou - 2023-03-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, Sharon Zhou here, and today we're diving into the fascinating world of diffusion models.\n\nDiffusion models help us understand how things spread or diffuse over time and space. Think of it like how a trend goes viral on social media, or how a disease spreads through a population.\n\nLet's get our hands dirty and build our own diffusion model. Open up your Python environment, and make sure you've got Tensorflow or Pytorch installed. We'll start by defining our model, then we'll feed in our data, and finally, we'll train our model.\n\nBut wait, there's more! I'll also show you how to speed up your sampling process by 10 times. We'll implement some algorithms that will make your sampling process faster than ever.\n\nAnd that's a wrap for today, folks! You've just learned how to build and train your own diffusion model, and even how to speed up the sampling process. Don't forget to hit that like button, subscribe, and share this video with your friends. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-03-19"}}
{"video": {"title": "Building Knowledge Graphs for RAG with Neo4j and Cypher", "transcript": "####Building Knowledge Graphs for RAG with Neo4j and Cypher\nby Andreas Kollegger - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nVideo hook and introduction: Hey there, data enthusiasts! Today, we're diving into the fascinating world of knowledge graphs and how they can supercharge your retrieval augmented generation applications. I'm your host, Andreas Kollegger, and I can't wait to show you the ropes. Let's get started!\n\nBody content: Knowledge graphs are like superheroes for your data, organizing and connecting information in a meaningful way. With Neo4j's query language Cypher, managing and retrieving data from these graphs becomes a breeze. Whether you're looking to find and format text data or provide more context to LLMs for Retrieval Augmented Generation, Cypher is your secret weapon.\n\nBy combining Neo4j and LangChain, you can build a question-answering system that lets you interact with a knowledge graph of structured text documents. This system opens up a world of possibilities for enhancing your applications and providing more relevant and accurate information to your users.\n\nConclusion and call to action: As we wrap up today's video, I encourage you to explore the world of knowledge graphs and see how they can transform your retrieval augmented generation applications. Don't forget to check out Neo4j and start building your own knowledge graph system today. Thanks for watching, and I'll see you in the next video!\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2022-10-15"}}
{"video": {"title": "Unleashing AI Potential with Hugging Face Open Source Models", "transcript": "Positive Points:\n\n- Clear introduction of the topic and Hugging Face.\n- Use of active voice and simple language.\n- Encouragement for the audience to explore and learn.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more critical analysis and real-world applications.\n- Make the conclusion more memorable and engaging.", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-03-15"}}
{"video": {"title": "Autoencoders: Dimensionality Reduction and Anomaly Detection", "transcript": "####Autoencoders: Dimensionality Reduction and Anomaly Detection\nby Laurence Moroney - 2023-05-06\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're going to dive into the fascinating world of autoencoders and their applications in dimensionality reduction and anomaly detection using TensorFlow.\n\n[Video hook and introduction]\n\nAutoencoders are like the Swiss Army knife of neural networks. They can learn efficient data representations by encoding input data into a lower-dimensional space and then decoding it back to the original space. They're useful for tasks like dimensionality reduction, feature learning, and anomaly detection. Let's get started!\n\n[Body content]\n\nFirst, we'll discuss the structure of an autoencoder, including the encoder and decoder networks and the concept of a bottleneck layer.\n\nNext, we'll walk through building and training an autoencoder in TensorFlow for a specific task, such as reducing the dimensionality of image data or detecting anomalies in time-series data. We'll cover techniques for evaluating the performance of our autoencoder and fine-tuning its architecture.\n\nWe'll also discuss popular autoencoder variants, such as denoising autoencoders, variational autoencoders (VAEs), and adversarial autoencoders, and their unique applications.\n\n[Conclusion and call to action]\n\nBy the end of this video, you'll have a solid understanding of autoencoders and how to use them for dimensionality reduction and anomaly detection tasks in TensorFlow.\n\nRemember to like, share, and subscribe for more AI and machine learning content. In the next video, we'll explore the world of deep reinforcement learning and how it's used to train agents that can master complex tasks. See you there!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-05-06"}}
{"video": {"title": "Implementing Machine Learning Code in Python", "transcript": "####Implementing Machine Learning Code in Python\nby Aarti Bagul - 2022-10-03\n\n#### BEGIN TRANSCRIPT ####\nAre you ready to dive into the exciting world of machine learning? Well, you're in luck! In this video, we'll be walking you through the code needed to implement ML algorithms in Python. Whether you're a beginner just starting out or looking to level up your skills, this tutorial has got you covered. I'm Aarti Bagul, and I can't wait to see what you'll create.\n\nSo, what are we waiting for? Let's get started!\n\nFirst, we'll be covering the basics of machine learning and how it works. Then, we'll dive into the code, step by step, so you can see exactly how to implement these algorithms in Python. And don't worry, we'll be keeping things simple and easy to understand, so you won't get lost in the jargon.\n\nBut that's not all! We'll also be adding a sprinkle of humor to keep things fun and engaging. And, of course, we'll be avoiding any conventional messages or overused buzzwords.\n\nSo, are you ready to become a machine learning pro? Let's do this!\n\n#### END TRANSCRIPT ########", "author": "Aarti Bagul", "publication_date": "2022-10-03"}}
{"video": {"title": "Interacting with Tabular Data using Natural Language", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Confident and engaging tone.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.\n- Improve the contrast and pacing to maintain interest.\n- Include more personal insights and real-world applications.\n- Improve the introduction to make it more engaging and memorable.", "author": "Adrian Gonzalez Sanchez", "publication_date": "2023-03-20"}}
{"video": {"title": "Fixing Vulnerabilities with Red Teaming Techniques", "transcript": "####Fixing Vulnerabilities with Red Teaming Techniques\nby Matteo Dora, Luca Martial - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\n\nHello, I'm Matteo Dora, and welcome back to our series on red teaming for LLM applications.\n\nToday, we're diving into the exciting world of fixing vulnerabilities. We've identified and evaluated them, now it's time to roll up our sleeves and get to work.\n\nWe'll be exploring various red teaming techniques to fix common vulnerabilities in LLM apps. And don't worry, we'll also show you how to verify that your fixes are effective.\n\nRemember, red teaming is a continuous process, and fixing vulnerabilities is just one piece of the puzzle.\n\nSo, let's get started and make our LLM applications safer.\n\nStay tuned for our next video where we'll discuss how to automate LLM red-teaming methods using Giskard's open-source library. Until then, keep exploring and learning.\n\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-03-22"}}
{"video": {"title": "Building Modality-Independent Embeddings for Seamless Retrieval", "transcript": "####Building Modality-Independent Embeddings for Seamless Retrieval\nby Sebastian Witalec - 2022-10-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Today, we're diving into the exciting world of modality-independent embeddings. I'm your host, Sebastian Witalec, and I can't wait to show you how this technique can revolutionize any-to-any retrieval. Get ready to learn about its applications in multimodal search and RAG!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-05"}}
{"video": {"title": "TensorFlow: Distributed Training with TensorFlow", "transcript": "####TensorFlow: Distributed Training with TensorFlow\nby Laurence Moroney - 2022-04-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're going to explore the exciting world of distributed training with TensorFlow!\n\n[Video hook and introduction]\n\nImagine being able to train your machine learning models faster and handle larger datasets. That's where distributed training comes in! So, let's dive in and learn how to use TensorFlow for distributed training!\n\n[Body content]\n\nFirst, we'll cover the basics of distributed training and discuss how TensorFlow distributes the training process across multiple machines using data parallelism and parameter servers.\n\nNext, we'll walk through the process of setting up your TensorFlow environment for distributed training, including installing the necessary software and configuring your hardware.\n\nWe'll also cover how to modify your TensorFlow code to take advantage of distributed training, using techniques like replica devices, tower functions, and synchronous and asynchronous training.\n\nLastly, we'll discuss some best practices for distributed training, such as using batch normalization, adjusting your learning rate, and monitoring your training progress.\n\n[Conclusion and call to action]\n\nAre you ready to scale up your TensorFlow training with distributed training? Let's get started! Remember, using multiple machines can make a big difference in the time it takes to train your machine learning models and handle larger datasets.\n\nIf you found this video helpful, be sure to give it a thumbs up, share it with your friends, and subscribe to our channel for more awesome content. See you in the next video!\n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-04-12"}}
{"video": {"title": "Mastering Mathematics for Machine Learning and Data Science: Statistics", "transcript": "####Mastering Mathematics for Machine Learning and Data Science: Statistics\nby Elena Sanina - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Elena Sanina, and welcome back to our exciting journey into the world of Mathematics for Machine Learning and Data Science. Today, we're tackling the fascinating realm of statistics!\n\nStatistics is the art and science of collecting, analyzing, and interpreting data. It's a crucial tool in our machine learning toolkit, helping us make sense of the data chaos and make informed decisions.\n\nLet's kick things off with descriptive statistics. Descriptive statistics are like the data's best friend, helping us summarize and describe the main features of a dataset. We've got measures of central tendency, like the mean, median, and mode, to describe the typical value in a dataset.\n\nNext up, we've got inferential statistics. Inferential statistics are like data detectives, helping us make predictions or inferences about a population based on a sample of data. We can use hypothesis testing to determine whether a sample of data provides evidence to support a particular hypothesis.\n\nBut how does this all tie into machine learning? Well, many machine learning algorithms are based on statistical models. For example, in regression analysis, we use statistical methods to model the relationship between a dependent variable and one or more independent variables.\n\nAnd that's a wrap for today's video on statistics! I hope you found this introduction as exciting as I do. Stay tuned for our next video, where we'll explore probability.\n\nRemember, practice makes perfect, so don't forget to try out some statistics problems on your own. And if you have any questions, feel free to leave them in the comments below. Thanks for watching, and happy learning!\n\n#### END TRANSCRIPT ########", "author": "Elena Sanina", "publication_date": "2023-03-25"}}
{"video": {"title": "TensorFlow: Mastering Data and Deployment", "transcript": "####TensorFlow: Mastering Data and Deployment\nby Laurence Moroney - 2022-03-01\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Laurence Moroney, and today we're diving into the thrilling world of TensorFlow, focusing on data and deployment!\n\n[Video hook and introduction]\n\nEver wondered how you can deploy your machine learning models onto devices, or even train and run them in browsers and mobile apps? Well, you're in luck! We'll also explore how to retrain deployed models while keeping privacy at the forefront.\n\n[Body content]\n\nFirst up, let's talk about TensorFlow Lite \u2013 a lightweight and efficient tool that helps you run your models on mobile and IoT devices. You'll learn how to convert your TensorFlow models into a format compatible with TensorFlow Lite.\n\nNext, we'll explore TensorFlow.js, which allows you to train and run models right in your browser! Imagine creating a web app that can recognize objects or understand spoken language, all without sending data to a server.\n\nNow, let's talk privacy. Federated Learning is a technique that enables model training across multiple devices while keeping data local. This means you can retrain your deployed models with new data without compromising user privacy.\n\n[Conclusion and call to action]\n\nSo, are you ready to take your TensorFlow skills to the next level and deploy your models on devices, browsers, and mobile apps? Let's get started! Remember, practice makes perfect, so don't forget to try these techniques yourself.\n\nIf you found this video helpful, be sure to give it a thumbs up, share it with your friends, and subscribe to our channel for more awesome content. See you in the next video!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-03-01"}}
{"video": {"title": "Deploying ML Models with TensorFlow: Data and Deployment", "transcript": "####Deploying ML Models with TensorFlow: Data and Deployment\nby Laurence Moroney - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, welcome back to another thrilling video! Today, we're diving into the world of TensorFlow and exploring how to deploy ML models on various devices. I'm Laurence Moroney, your guide for today's journey into the realm of data and deployment. Let's get started!\n\nSo, you've trained your ML model and now it's time to take it to the next level by deploying it on different devices. Whether it's running in a browser or a mobile app, TensorFlow makes it easy to bring your models to life. With the ability to retrain deployed models while still protecting user privacy, the possibilities are endless.\n\nJoin me as we explore the world of data and deployment with TensorFlow. Don't miss out on this exciting adventure!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-10-15"}}
{"video": {"title": "Prompting Llama 2 & 3 Models Like a Pro", "transcript": "####Prompting Llama 2 & 3 Models Like a Pro\nby Amit Sangani - 2023-02-24\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Amit Sangani and today we're diving into the world of Prompting Llama 2 & 3 Models Like a Pro.\n\nAre you ready to level up your prompting game? In this beginner-friendly course, we'll be uncovering the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst, we'll be exploring Meta Llama 2 Chat and how you can interact with it to get the most out of your prompts. We'll also be delving into Code Llama and how it can assist you with your coding needs.\n\nBut wait, there's more! We'll also be discussing the importance of building safe and responsible AI applications. That's where Llama Guard comes in. We'll show you how you can use this model to ensure that your AI applications are safe and responsible.\n\nSo, are you ready to prompt Llama 2 & 3 models like a pro? Let's get started!\n\nRemember, practice makes perfect. So, be sure to try out these best practices on your own and see how they work for you. And, if you have any questions or need further clarification, don't hesitate to reach out.\n\nThanks for watching and happy prompting!\n\nDon't forget to like, comment, and subscribe for more content like this. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-24"}}
{"video": {"title": "Unleashing the Power of Cypher for Knowledge Graphs", "transcript": "####Unleashing the Power of Cypher for Knowledge Graphs\nby Andreas Kollegger - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andreas Kollegger here. Today, we're going to unleash the power of Neo4j's query language, Cypher, for managing and retrieving data from knowledge graphs. \n\nIf you're a LangChain fan, you're going to love this. If not, I recommend checking out our short course 'LangChain: Chat with Your Data' before diving into this intermediate level content. \n\nNow, let's get started. Cypher is a powerful tool that allows you to query data in a way that's both efficient and intuitive. \n\nIn this video, we're going to walk you through writing knowledge graph queries that find and format text data to provide more relevant context to LLMs for Retrieval Augmented Generation. \n\nWe'll start with the basics and gradually move on to more complex queries. \n\nBy the end of this video, you'll be a Cypher pro, ready to take your RAG applications to the next level. \n\nSo, are you ready to unleash the power of Cypher? Let's get started. \n\nRemember, the key to mastering Cypher is practice. So, don't be afraid to try, fail, and try again. And if you have any questions, feel free to leave them in the comments below. \n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2023-03-20"}}
{"video": {"title": "Data Pipelines: The Backbone of ML Production Systems", "transcript": "####Data Pipelines: The Backbone of ML Production Systems\nby Andrew Ng - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Andrew Ng here, and today we're diving into the world of data pipelines - the unsung heroes of ML production systems.\n\nThink of data pipelines as the plumbing system of your ML model. They ensure that the right data gets to the right place at the right time.\n\nWe'll explore how to design efficient data pipelines, from data collection and preprocessing to storage and retrieval. We'll also discuss common challenges and how to overcome them.\n\nRemember, a chain is only as strong as its weakest link. Similarly, your ML model is only as good as the data it's trained on. So, let's make sure we're feeding it the best!\n\nStay tuned for some laughs, learning, and a whole lot of data. And don't forget to hit that like button, share this video, and subscribe for more exciting content. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-20"}}
{"video": {"title": "Advanced Techniques in Multimodal Search and RAG", "transcript": "####Advanced Techniques in Multimodal Search and RAG\nby Sebastian Witalec - 2022-10-11\n\n#### BEGIN TRANSCRIPT ####\nHey there, Sebastian here! Are you ready to level up your skills? Today, we're diving into the thrilling world of advanced techniques in multimodal search and RAG. Buckle up, because we're about to push the limits of what's possible in this field!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-11"}}
{"video": {"title": "Harnessing the Power of AI for Good: A Beginner's Guide", "transcript": "####Harnessing the Power of AI for Good: A Beginner's Guide\nby Robert Monarch - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're embarking on an exciting journey into the world of AI, but with a twist. We're exploring how AI can be a force for good.\n\nFirst, let's define 'AI for Good'. It's all about leveraging artificial intelligence to address some of the world's most pressing issues, like climate change, public health, and disaster management.\n\nNow, you might be thinking, 'How can AI help with these problems?' Well, let's take air quality as an example. By creating AI models, we can predict air quality patterns, helping us take action to improve it.\n\nNext, let's talk about wind energy. AI can help us optimize wind turbine performance, making renewable energy more efficient and accessible.\n\nBiodiversity is another area where AI excels. We can use AI to monitor and protect endangered species, contributing to conservation efforts worldwide.\n\nAnd when it comes to disaster management, AI can help predict natural disasters, enabling us to prepare and respond more effectively.\n\nBut it's not all theory. We'll look at some real-world case studies, like how AI is being used in public health to predict disease outbreaks, and in climate change research to model and mitigate its impacts.\n\nSo, are you ready to join the AI for Good movement? Remember, you don't need to be an AI expert to make a difference. Start small, learn, and contribute in your own unique way.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content on AI. Until next time, let's keep using AI for good.\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-03-15"}}
{"video": {"title": "Unleashing AI Potential with LangGraph and Tavily's Agentic Search", "transcript": "####Unleashing AI Potential with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! Today, we're diving into the world of AI agents and showing you how to unleash their full potential using LangGraph and Tavily's agentic search.\n\nLangGraph is an open-source framework that allows you to build, debug, and maintain AI agents. It's like having the keys to the AI kingdom!\n\nBut when you combine it with Tavily's agentic search, you're taking your AI to the next level. It enhances your agent's knowledge and performance, making your AI more powerful than ever.\n\nIn this course, you'll learn directly from Harrison Chase, the founder of LangChain, and Rotem Weiss, the founder of Tavily. They'll guide you through LangGraph's components and show you how to integrate agentic search capabilities.\n\nThis course is designed for those with intermediate Python knowledge who want to create more controllable agents.\n\nSo, are you ready to unleash the full potential of AI agents? Let's get started! And don't forget to like, share, and subscribe for more exciting content.\n\nKeep coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-25"}}
{"video": {"title": "Mastering ChatGPT Prompt Engineering", "transcript": "####Mastering ChatGPT Prompt Engineering: Unlocking the Power of LLMs\nby Isa Fulford and Andrew Ng - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford, and today we're embarking on an exciting journey into the world of prompt engineering for ChatGPT. Are you ready to learn how to effectively prompt the model for various tasks? I know I am!\n\nAnd I'm Andrew Ng, and I'm thrilled to join you on this adventure. We're going to explore the power of LLMs for summarizing, inferring, transforming, and expanding. Let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2022-10-15"}}
{"video": {"title": "AI for Public Health: Saving Lives with Machine Learning", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Include critical analysis and personal insights.\n- Make the conclusion more memorable and engaging.", "author": "Robert Monarch", "publication_date": "2023-04-10"}}
{"video": {"title": "Supercharging AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####Supercharging AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHello, Python enthusiasts! Today, we're going to learn how to supercharge our AI agents using LangGraph and Tavily's agentic search.\n\nLangGraph is an open-source framework that allows us to build, debug, and maintain AI agents. It's like having a secret weapon in our coding arsenal.\n\nBut wait, there's more! With Tavily's agentic search, we're taking our agents to the next level. This will enhance our agent's knowledge and performance, making our AI truly top-notch.\n\nIn this course, you'll learn from Harrison Chase, the founder of LangChain, and Rotem Weiss, the founder of Tavily. They'll guide you through LangGraph's components and show you how to integrate agentic search capabilities.\n\nThis course is perfect for those with intermediate Python knowledge who want to master AI agent development.\n\nSo, are you ready to supercharge your AI agents? Let's dive in! And don't forget to like, share, and subscribe for more exciting content.\n\nHappy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-20"}}
{"video": {"title": "Building AI Applications with Open Source Models on Hugging Face", "transcript": "####Building AI Applications with Open Source Models on Hugging Face\nby Maria Khalusova - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Maria Khalusova, and today we're going to explore the exciting world of open-source models with Hugging Face. Are you ready to learn how to build AI applications using these powerful tools? Let's get started!\n\nOpen-source models are a game-changer in the AI world. With Hugging Face, you can easily find and filter open-source models on the Hub based on task, rankings, and memory requirements. It's never been easier to access cutting-edge AI models for your projects. And the best part? You don't need to be an expert to get started. This is a beginner-friendly course, so even if you're new to AI, you'll be able to follow along.\n\nWith just a few lines of code using the transformers library, you can perform text, audio, image, and multimodal tasks. It's like having a whole team of AI experts at your fingertips. And once you've built your AI app, you can easily share it with others using a user-friendly interface or via API. And if you want to run your app on the cloud, Hugging Face Spaces has got you covered.\n\nSo what are you waiting for? Let's revolutionize the way we build AI applications together. Join me, Maria Khalusova, and let's dive into the world of open-source models with Hugging Face.\n#### END TRANSCRIPT ########", "author": "Maria Khalusova", "publication_date": "2022-10-15"}}
{"video": {"title": "Mastering Mathematics for Machine Learning and Data Science: Calculus", "transcript": "####Mastering Mathematics for Machine Learning and Data Science: Calculus\nby Luis Serrano - 2023-03-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Luis Serrano, and today we're embarking on an exciting journey into the world of calculus. But don't worry, we'll make it fun and easy to understand!\n\nCalculus is the study of change, and it's a superpower in machine learning. It helps us understand how our models change as the data changes.\n\nLet's start with a simple concept: the derivative. Think of it as the speedometer of a car. It tells us how fast we're going at any given moment.\n\nIn machine learning, the derivative helps us find the best values for our model's parameters. This process is called gradient descent.\n\nNow, let's talk about integration. It's like adding up tiny pieces to find the whole. In machine learning, we use integration to calculate probabilities and expectations.\n\nDon't worry if this seems a bit overwhelming. With practice, these concepts will become second nature.\n\nRemember, every expert was once a beginner. So, keep learning, keep practicing, and soon you'll be a pro at calculus.\n\nThanks for watching. Be sure to like, share, and subscribe for more exciting videos on Mathematics for Machine Learning and Data Science. See you in the next one!\n\n\n#### END TRANSCRIPT ########", "author": "Luis Serrano", "publication_date": "2023-03-01"}}
{"video": {"title": "Generative AI with LLMs: Final Project", "transcript": "####Generative AI with LLMs: Final Project Extravaganza\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, Chris Fregly here, and today we're diving into the final project for our course on generative AI with LLMs.\n\nFirst, we'll cover the project requirements and guidelines, including the dataset you'll be working with and the evaluation criteria.\n\nWe'll also discuss some potential project ideas and how to approach the project from start to finish.\n\nThen, we'll dive into the technical details of the project, such as data preprocessing, model training, and evaluation.\n\nAnd don't worry, we'll be providing you with code templates and resources to help you along the way.\n\nBy the end of this video, you'll have a clear understanding of the final project and how to successfully complete it.\n\nSo, let's get started! See you in the course.\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-01"}}
{"video": {"title": "Building JavaScript RAG Web Apps with LlamaIndex: A Beginner's Guide", "transcript": "####Building JavaScript RAG Web Apps with LlamaIndex: A Fun and Easy Beginner's Guide\nby Laurie Voss - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Laurie Voss, and today we're going to have a blast building a full-stack web application that uses RAG capabilities to chat with your data.\n\nFirst things first, what's RAG? RAG stands for Retrieval-Augmented Generation, which means our application will use an intelligent agent to answer queries by discerning and selecting from multiple data sources. Cool, right?\n\nNow, don't worry if you're new to JavaScript. I've got your back! I'll be guiding you through every step of the way.\n\nOur application will have an interactive frontend component that interacts and chats with your data. We'll also learn how to persist your data, enable chatting with your data, and make streaming responses possible. And the best part? We'll be using the create-llama command-line tool to make it all happen.\n\nLet's dive into the code! First, we'll set up our project using create-llama and install the necessary dependencies. Then, we'll create our frontend component using React and integrate it with our RAG-powered backend.\n\nThroughout this process, I'll be sharing tips and best practices for building RAG applications in JavaScript. And don't worry, I'll keep things light and fun!\n\nBy the end of this video, you'll have a fully functional web app that you can use to chat with your data. And who knows, you might even impress your friends with your new coding skills.\n\nThanks for watching, and happy coding! Be sure to check out LlamaIndex for more resources on building intelligent applications.\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2023-03-15"}}
{"video": {"title": "Advanced Techniques for Working with GANs", "transcript": "Positive Points:\n\n- Clear introduction of the topic and challenges.\n- Use of active voice and simple language.\n- Present and engaging call to action.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.\n- Improve the balance between simplicity and depth.\n\nRefined Script:\n\n#####Advanced Techniques for Working with GANs\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, machine learning enthusiasts! I'm Eda Zhou, and today we're diving into the wild world of GANs. Are you ready to take your skills to the next level?\n\n[Video hook and introduction]\n\nGANs are like the wild stallions of the machine learning world. Powerful, beautiful, and sometimes a little bit unpredictable. But don't worry, we've got you covered. In this video, we'll be exploring some advanced techniques for training and evaluating GANs that will have you generating high-quality data in no time.\n\n[Body content]\n\nFirst up, let's talk about mode collapse. This is like when your stallion gets stuck in a loop, galloping in circles instead of exploring new territory. To avoid this, we'll be using techniques like minibatch discrimination, which encourages your generator to create a diverse set of data.\n\nBut wait, there's more! Evaluating the performance of your GAN can be tricky. Traditional metrics like accuracy and precision just don't cut it. That's why we'll be using other metrics like the Inception Score and the Frechet Inception Distance to really get a feel for how well your GAN is doing.\n\nAnd finally, we'll be exploring techniques like transfer learning and fine-tuning to take your GAN to the next level. This involves taking a pre-trained GAN and adapting it to a new dataset or task, like teaching your stallion new tricks.\n\n[Conclusion and call to action]\n\nSo there you have it, folks! Advanced techniques for working with GANs that will have you generating high-quality data like a pro. But remember, practice makes perfect. So keep experimenting, keep learning, and most importantly, keep having fun. Thanks for watching, and be sure to check out our other videos on GANs and machine learning. Until next time, happy generating!\n\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-03-15"}}
{"video": {"title": "Deploying Your ML Model: A Step-by-Step Guide", "transcript": "####Deploying Your ML Model: A Step-by-Step Guide\nby Andrew Ng - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Andrew Ng, and today we're diving into the thrilling world of ML model deployment!\n\nDeployment is like launching a rocket - it's exciting, but it needs careful planning and execution. We'll cover how to prepare your model for deployment, integrate it into your existing systems, and monitor its performance.\n\nWe'll also discuss how to handle any issues that arise and ensure your model continues to deliver accurate predictions.\n\nRemember, deployment is just the beginning. Your ML model needs regular care and attention to stay in top shape.\n\nStay tuned for more insights in our next video. Don't forget to like, share, and subscribe for more exciting content on GenAI and LLM powered applications. Until next time, keep innovating!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-01-15"}}
{"video": {"title": "TensorFlow: Scaling Deployment", "transcript": "####TensorFlow: Scaling Deployment\nby Laurence Moroney - 2022-03-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Laurence Moroney here, and welcome back to our TensorFlow series! Today, we're diving into the exciting world of scaling deployment.\n\n[Video hook and introduction]\n\nScaling your machine learning deployment is not just a nice-to-have, it's a must-have for handling large volumes of data and requests.\n\n[Body content]\n\nFirst, we'll go over the process of scaling TensorFlow deployment. We'll cover techniques like model parallelism, data parallelism, and distributed training.\n\nNext, we'll discuss the benefits of scaling deployment. We'll talk about how it can improve model performance, handle large datasets, and serve multiple requests simultaneously.\n\nFinally, we'll touch on some common challenges in scaling deployment and how to overcome them.\n\n[Conclusion and call to action]\n\nAnd that's all for today! You're now ready to scale your TensorFlow deployment like a pro.\n\nRemember, scaling your deployment can help you handle larger and more complex machine learning tasks. So, don't shy away from it.\n\nThanks for watching, and stay tuned for more TensorFlow videos. If you have any questions, feel free to ask.\n\nUntil next time, happy coding! \n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-03-05"}}
{"video": {"title": "Securing Your ML Production System", "transcript": "####Securing Your ML Production System\nby Andrew Ng - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! I'm Andrew Ng, and today we're going to talk about a topic that's as important as it is fascinating: securing your Machine Learning production system.\n\nSecurity is not just about locking the doors, it's about building a system that's robust, reliable, and trustworthy.\n\nFirst things first, we need to understand our security needs. This involves analyzing our data sensitivity, user privacy, and regulatory requirements.\n\nNext, we need to choose the right security measures. This might involve encryption, access control, or intrusion detection.\n\nThen, we need to implement our security measures. This involves setting up our security infrastructure, deploying our model, and testing everything thoroughly.\n\nBut the journey doesn't end there. We also need to monitor our system security, handle any security issues that arise, and continuously improve our security processes.\n\nSo, are you ready to secure your ML production system? Start planning your security strategy today, and remember, a secure ML system is a successful ML system.\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content on Machine Learning. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-15"}}
{"video": {"title": "LangChain: Chat with Your Data", "transcript": "####LangChain: Chat with Your Data\nby Harrison Chase - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're diving into the world of LangChain! This powerful tool allows you to create a chatbot that interfaces with your private data and documents. It's like having a personal assistant for your data. Let's get started!\n\nLangChain is a game-changer. It lets you access over 80 unique loaders to handle various data sources. With LangChain, you can build your own chatbot to directly interact with information from your documents and data. All you need is some basic Python knowledge to get started.\n\nSo, why wait? Let's chat with your data using LangChain! It's time to make your data work for you.\n\nStay tuned for more tips and tricks on how to make the most out of LangChain. And don't forget to like, share, and subscribe for more exciting content!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2022-10-15"}}
{"video": {"title": "Quantization and Beyond: Exploring Model Compression Techniques", "transcript": "####Quantization and Beyond: Exploring Model Compression Techniques\nby Marc Sun, Younes Belkada - 2023-05-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! I'm Younes Belkada, and today we're diving into the fascinating world of model compression beyond quantization.\n\nAre you tired of bulky models slowing down your applications? Well, you're in luck! We're going to explore a range of techniques, from pruning to knowledge distillation, that will help you compress your models even further.\n\nBut wait, there's more! We'll also be discussing the latest research and trends in model compression, so you can stay ahead of the curve.\n\nSo, are you ready to take your models to the next level? Let's get started!\n\nAnd don't forget to like, share, and subscribe for more great content. Trust me, you won't want to miss what we have in store for you. Until next time, happy compressing!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-05-01"}}
{"video": {"title": "TensorFlow Functional API: A Deep Dive", "transcript": "####TensorFlow Functional API: Unlocking Its Power\nby Laurence Moroney, Eddy Shyu - 2022-01-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eddy Shyu, and today we're going to unlock the power of the TensorFlow Functional API.\n\nThe Functional API is a game-changer, allowing you to define more complex models. With it, you can share layers between models, create models with multiple inputs or outputs, and even build models with custom training loops.\n\nIn this video, we'll start with the basics of the Functional API and gradually build up to more advanced topics. We'll explore how to define models, how to share layers, and how to create models with multiple inputs or outputs.\n\n...\n\nThanks for watching! I hope this video helped you unlock the power of the TensorFlow Functional API. If you found this video helpful, please give it a thumbs up and subscribe to our channel for more content like this. See you next time!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-01-08"}}
{"video": {"title": "Deploying Your LangChain Chatbot: A Step-by-Step Guide", "transcript": "####Deploying Your LangChain Chatbot: A Step-by-Step Guide\nby Harrison Chase - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, chatbot enthusiasts! I'm Harrison Chase, the creator of LangChain, and today we're going to embark on an exciting journey. We're going to learn how to deploy your LangChain chatbot to various platforms.\n\nIf you've been following our previous videos, you've already mastered the art of building a custom chatbot using LangChain and enhancing it with NLP and machine learning techniques. But now, it's time to share your creation with the world.\n\nIn this video, we'll demystify the deployment process and explore some of the most popular chatbot platforms, including Slack and Facebook Messenger. We'll start with a bird's eye view of the deployment process and then dive into some practical examples.\n\nWe'll cover topics such as authentication, webhooks, and API calls. By the end of this video, you'll have a solid understanding of how to deploy your LangChain chatbot to various platforms and make it accessible to users worldwide.\n\nSo, are you ready to take your chatbot to the next level? Let's dive in and start exploring the world of LangChain chatbot deployment!\n\nRemember, if you have any questions or need help along the way, feel free to reach out to me on social media or through the LangChain website.\n\nThanks for watching, and happy coding!\n\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-04-15"}}
{"video": {"title": "Model Training: From Prototype to Production", "transcript": "####Model Training: From Prototype to Production\nby Andrew Ng - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, ML enthusiasts! Andrew Ng here. Today, we're diving into the fascinating world of model training in ML production systems.\n\nTraining a model is like teaching a child. It requires patience, the right teaching methods, and lots of practice. We'll discuss how to choose the right algorithm, optimize hyperparameters, and validate your model.\n\nBut wait, there's more! We'll also explore how to scale model training, manage compute resources, and handle large datasets.\n\nRemember, the goal is not just to train a model, but to train a model that can generalize well to unseen data. So, let's get started!\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and keep innovating!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-25"}}
{"video": {"title": "LangChain and Natural Language Processing", "transcript": "####LangChain and Natural Language Processing\nby Harrison Chase - 2023-03-07\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Harrison Chase, the mastermind behind LangChain, and today we're diving into the thrilling world of natural language processing.\n\nNatural language processing, or NLP, is a fascinating field of computer science that focuses on the interaction between humans and computers using natural language. And with LangChain, you can harness the power of NLP to create even more impressive chatbots.\n\nBut how does it work? Let's take a look.\n\nLangChain uses cutting-edge NLP techniques to understand the context and meaning behind the questions you ask your chatbot. This means you can ask questions in a natural, conversational way, and your chatbot will be able to understand and respond accordingly.\n\nI'll be guiding you through each step of the process, sharing tips and tricks along the way. And the best part? You'll be learning directly from me, the creator of LangChain.\n\nSo, are you ready to take your chatbot to the next level with natural language processing? Let's get started!\n\nRemember, if you have any questions or need help along the way, don't hesitate to reach out. And once you've mastered NLP with LangChain, be sure to share your creations with me. I can't wait to see what you build!\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-07"}}
{"video": {"title": "Real-World Applications of Multi AI Agent Systems with crewAI", "transcript": "####Real-World Applications of Multi AI Agent Systems with crewAI\nby Jo\u00e3o Moura - 2023-05-09\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jo\u00e3o Moura and welcome back to our series on Multi AI Agent Systems with crewAI.\n\nToday, we're diving into some exciting real-world applications of these systems.\n\nFirst up, we'll explore how Multi AI Agent Systems are revolutionizing business process automation. From automating mundane tasks to streamlining complex workflows, these systems are helping businesses boost efficiency and productivity.\n\nNext, we'll discuss how Multi AI Agent Systems are transforming customer service. By automating responses to common queries, these systems are helping businesses improve their customer service and response times.\n\nLastly, we'll talk about some emerging applications of Multi AI Agent Systems, such as in gaming and simulation.\n\nSo, let's get started! And remember, if you have any questions, feel free to leave them in the comments.\n\nStay tuned for our next video where we'll wrap up our series and discuss the future of Multi AI Agent Systems. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep exploring the possibilities of AI!\n#### END TRANSCRIPT ########", "author": "Jo\u00e3o Moura", "publication_date": "2023-05-09"}}
{"video": {"title": "Device Integration: Making AI Models Play Nice with Hardware", "transcript": "####Device Integration: Making AI Models Play Nice with Hardware\nby Krishna Sridhar - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're diving into the world of device integration.\n\nImagine your AI models and hardware as two best friends who need to work together seamlessly. That's exactly what we're going to achieve today!\n\nWe'll look at how to integrate your AI models with your edge devices, considering runtime dependencies and compute unit utilization. It's like conducting an orchestra where each instrument, or in our case, GPU, NPU, and CPU compute units, play their part to make your AI models run smoothly on your devices.\n\nRemember, we're using short sentences, present tense, and a conversational style. We're also using more active voice than passive and keeping things clear and simple.\n\nSo, are you ready to make your AI models and hardware play nice together? Let's get integrating!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2023-04-01"}}
{"video": {"title": "Automating Business Workflows with Multi-AI Agent Systems", "transcript": "####Automating Business Workflows with Multi-AI Agent Systems\nby Jo\u00e3o Moura - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jo\u00e3o Moura, and today we're going to explore the fascinating world of multi-AI agent systems with crewAI. Are you ready to automate your business workflows and surpass the capabilities of a single LLM? Let's dive in!\n\nSo, what are multi-AI agent systems? In simple terms, they allow you to design and prompt a team of AI agents using natural language. By harnessing the power of multiple agents, you can handle complex tasks with ease.\n\nImagine being able to automate repeatable, multi-step tasks like tailoring a resume to a job description or streamlining event planning processes. With crewAI, this is not just a dream, it's a reality!\n\nBy creating a team of AI agents, you can define specific roles, goals, and backstories for each agent. This allows you to break down complex tasks and assign them to agents that are tailored to perform those tasks efficiently.\n\nIf you've taken some prompt engineering courses, have basic coding knowledge, and are eager to incorporate LLMs into your professional work, then this course is perfect for you. Let's transform the way you work with crewAI.\n\nDon't miss out on the chance to streamline your business workflows and boost productivity. Join me in exploring the world of multi-AI agent systems with crewAI today!\n#### END TRANSCRIPT ########", "author": "Jo\u00e3o Moura", "publication_date": "2022-10-15"}}
{"video": {"title": "Building JavaScript RAG Web Apps with LlamaIndex: A Beginner's Guide", "transcript": "####Building JavaScript RAG Web Apps with LlamaIndex: A Fun and Easy Beginner's Guide\nby Laurie Voss - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Laurie Voss and welcome to our channel. Today, we're diving into the thrilling world of JavaScript RAG Web Apps with LlamaIndex.\n\nBut first, what's a RAG application? It's an application that uses Retrieval, Abstraction, and Generation capabilities to chat with your data. Sounds like something out of a sci-fi movie, right?\n\nIn this video, we're going to build a full-stack web application using JavaScript. Don't worry, you only need basic JavaScript knowledge to follow along.\n\nWe'll start by creating an intelligent agent that discerns and selects from multiple data sources to answer your queries. It's like having your own personal data assistant!\n\nNext, we'll build an interactive frontend component that interacts and chats with your data. Imagine having a conversation with your data, asking it questions, and getting answers in real-time. That's what we're going to create today.\n\nBut wait, there's more! We'll also learn how to persist your data, enable chatting with your data, and make streaming responses possible. All of this will be implemented using the create-llama command-line tool.\n\nBy the end of this video, you'll have a fully functional RAG application in JavaScript. And who knows, you might even have fun building it!\n\nSo, are you ready to get started? Let's dive in and start building our JavaScript RAG Web App with LlamaIndex.\n\nRemember, if you have any questions or need help with anything, just leave a comment below. We're here to help. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2023-03-15"}}
{"video": {"title": "ChatGPT Prompt Engineering: From Basics to Brilliance", "transcript": "####ChatGPT Prompt Engineering: From Basics to Brilliance\nby Isa Fulford - 2022-11-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford! Today, we're going to embark on an exciting journey from the basics of prompt engineering to brilliance with ChatGPT. You'll learn how to craft prompts that shine and unlock the full potential of language models. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-11-05"}}
{"video": {"title": "Unraveling the Mystery of Diffusion Models", "transcript": "####Unraveling the Mystery of Diffusion Models\nby Sharon Zhou - 2023-03-18\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Sharon Zhou, and today we're diving into the fascinating world of diffusion models.\n\nDiffusion models are like the secret agents of data analysis, helping us understand how things spread over time and space. Think of it like how a rumor spreads through a school, or how a disease spreads through a population.\n\nBut enough with the chit-chat, let's get our hands dirty! Open up your Python environment, and make sure you've got Tensorflow or Pytorch installed. We'll start by defining our model, then we'll feed in our data, and finally, we'll train our model.\n\nBut wait, there's more! I'll also show you how to speed up your sampling process by 10 times. We'll implement some algorithms that will make your sampling process faster than a cheetah on roller skates.\n\nAnd that's all for today, folks! You've just learned how to build and train your own diffusion model, and even how to speed up the sampling process. Don't forget to hit that like button, subscribe, and share this video with your friends. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-03-18"}}
{"video": {"title": "Advanced Techniques for Generative Adversarial Networks with TensorFlow", "transcript": "####Advanced Techniques for Generative Adversarial Networks with TensorFlow\nby Laurence Moroney, Eddy Shyu - 2022-03-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eddy Shyu, and today we're going to dive into the exciting world of Generative Adversarial Networks (GANs) with TensorFlow!\n\nIn this video, we'll tackle the challenges of training GANs and explore some techniques to boost their stability and performance. We'll also delve into some cutting-edge GAN architectures like StyleGAN and CycleGAN.\n\n...\n\nThanks for watching! I hope this video helped you master some advanced techniques for training GANs with TensorFlow. If you found this video helpful, please give it a thumbs up and subscribe to our channel for more content like this. See you next time!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-03-05"}}
{"video": {"title": "Mastering TensorFlow: Advanced Techniques and Tricks", "transcript": "####Mastering TensorFlow: Advanced Techniques and Tricks\nby Laurence Moroney, Eddy Shyu - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, TensorFlow enthusiasts! I'm Laurence Moroney, and today we're going to level up your TensorFlow game with some advanced techniques and tricks.\n\nFirst off, we're diving into the Functional API. You might be thinking, 'Why should I care about the Functional API?' Well, it's like having a Swiss Army knife for your models. It offers a more flexible way to define models, allowing you to share layers between models and create complex architectures with multiple inputs or outputs.\n\nNext, we'll talk about optimizing training with multiple processors. Training deep learning models can be a real time-sucker, but did you know that you can speed up this process by using multiple CPUs or GPUs? I'll show you how to do just that.\n\nThen, we'll delve into advanced computer vision techniques. We'll explore how to use pre-trained models, fine-tuning, and transfer learning to improve the accuracy of your models.\n\nLastly, we'll have some fun with generative deep learning. We'll create models that can generate new images, text, and even music!\n\nSo, are you ready to take your TensorFlow skills to the next level? Let's get started!\n\n...\n\nThanks for watching! I hope you learned some new techniques to improve your TensorFlow workflows. If you did, please give this video a thumbs up and subscribe to our channel for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-01-01"}}
{"video": {"title": "Mistral AI: Choosing the Right Model for You", "transcript": "####Mistral AI: Your Perfect Match Awaits!\nby Younes Belkada, Marc Sun - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Younes Belkada here, and welcome back to our Mistral AI adventure!\n\nToday, we're diving into the exciting world of choosing the right Mistral model for you. It's like finding your perfect match, but in the world of AI!\n\nMistral offers a smorgasbord of models, from the open-source delights of Mistral 7B, Mixtral 8x7B, and Mixtral 8x22B, to the commercial powerhouses in small, medium, and large sizes.\n\nSo, how do you find your perfect AI match? Well, it's all about your needs. If you're just starting out, the open-source models might be your perfect first date. They offer a range of capabilities and are perfect for learning the ropes.\n\nBut if you need more advanced features, the commercial models might be more your speed. These offer more power and capabilities, perfect for more demanding tasks.\n\nRemember, there's no one-size-fits-all answer. It's all about finding the model that suits your needs best.\n\nIf you have any questions, just let us know. And don't forget to like, share, and subscribe for more updates. Until next time, happy exploring!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-15"}}
{"video": {"title": "Mastering Diffusion Models: A Hands-On Guide", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Encouragement of audience participation.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Include more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.\n- Include critical analysis and personal insights.", "author": "Sharon Zhou", "publication_date": "2022-03-01"}}
{"video": {"title": "Optimizing LLM Applications with KV Caching and LoRA", "transcript": "####Optimizing LLM Applications with KV Caching and LoRA\nby Travis Addair - 2023-02-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Travis Addair and today we're diving into the world of optimizing LLM applications using KV caching and Low Rank Adapters (LoRA).\n\nFirst up, let's talk about KV caching. This nifty technique involves storing the key-value pairs of input tokens and their corresponding output probabilities in a cache. This way, if we encounter the same input sequence again, our model can quickly retrieve the output probabilities from the cache instead of having to recompute them. This can significantly speed up text generation and boost the performance of our LLM application.\n\nNext, let's chat about LoRA. This technique involves fine-tuning a pre-trained language model on our specific task using low-rank adapters. This allows us to maintain the accuracy of the model while reducing the number of parameters, making it more efficient to serve to multiple users.\n\nWe'll also discuss how to combine KV caching and LoRA to further optimize the performance of our LLM application. By using both techniques, we can greatly reduce the latency of our application and serve more users at once.\n\nFinally, we'll talk about some best practices for optimizing LLM applications, such as how to handle input validation and how to monitor the performance of our application.\n\nThanks for watching and don't forget to like, comment, and subscribe for more videos on GenAI and LLM powered applications. See you in the next one!\n#### END TRANSCRIPT ########", "author": "Travis Addair", "publication_date": "2023-02-25"}}
{"video": {"title": "Getting Started with AutoGen: Your First AI Agent", "transcript": "####Getting Started with AutoGen: Your First AI Agent\nby Chi Wang, Qingyun Wu - 2023-03-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Qingyun Wu here, and today we're embarking on an exciting journey with AutoGen. We're going to build our very first AI agent together. Are you ready?\n\nFirst things first, let's get our environment set up. Make sure you have Python installed and we'll guide you through the rest.\n\nNow, let's dive into creating our first agent. We'll start with something simple, an agent that can reflect on its own behavior. Don't worry, we'll break it down step by step so you can follow along easily.\n\nOnce we've created our agent, we'll put it to the test. We'll give it a task, watch it reflect on its behavior, and see how it adapts. It's like watching a digital organism evolve right before your eyes!\n\nRemember, the key to mastering AutoGen is practice. So, don't be afraid to experiment, make mistakes, and learn from them.\n\nAnd that's a wrap for today's video. If you found this helpful, don't forget to give it a thumbs up, subscribe, and hit that notification bell so you won't miss our next video. Let's build something incredible together with AutoGen. See you next time!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2023-03-08"}}
{"video": {"title": "TensorFlow: Retraining Deployed Models", "transcript": "####TensorFlow: Retraining Deployed Models\nby Laurence Moroney - 2022-02-12\n\n#### BEGIN TRANSCRIPT ####\nHello, TensorFlow enthusiasts! I'm Laurence Moroney, and today we're diving into the exciting world of retraining deployed models.\n\n[Video hook and introduction]\n\nImagine having a model that can learn from new data and improve over time. Sounds like a dream, right? Well, it's not. It's the power of retraining deployed models.\n\n[Body content]\n\nFirst, we'll walk through the process of retraining deployed TensorFlow models. We'll cover the necessary steps, from collecting new data to updating your model.\n\nNext, we'll discuss the benefits of retraining deployed models. We'll talk about how it can improve model performance and adapt to changing data.\n\nFinally, we'll touch on some common challenges in retraining deployed models and how to overcome them.\n\n[Conclusion and call to action]\n\nAnd that's a wrap! You're now ready to retrain your deployed models.\n\nRemember, retraining deployed models can help your models stay relevant and performant. So, don't be afraid to implement it.\n\nThanks for watching, and stay tuned for more TensorFlow videos. If you have any questions, don't hesitate to ask.\n\nUntil next time, happy coding! \n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-02-12"}}
{"video": {"title": "Recurrent Neural Networks and Natural Language Processing", "transcript": "####Recurrent Neural Networks and Natural Language Processing\nby Laurence Moroney - 2023-04-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're going to have a blast exploring recurrent neural networks (RNNs) and their applications in natural language processing (NLP) using TensorFlow.\n\n[Video hook and introduction]\n\nRNNs are a type of neural network designed to handle sequential data, making them perfect for tasks like text generation, sentiment analysis, and machine translation. Let's dive in!\n\n[Body content]\n\nFirst, we'll discuss the structure of an RNN, including the concept of hidden states and how they allow RNNs to capture temporal dependencies in sequential data.\n\nNext, we'll walk through building and training an RNN in TensorFlow for a specific NLP task, such as text generation or sentiment analysis. We'll cover techniques for preprocessing text data and encoding it as input for our RNN.\n\nWe'll also discuss some common challenges with RNNs, such as vanishing and exploding gradients, and introduce long short-term memory (LSTM) and gated recurrent unit (GRU) architectures as solutions.\n\n[Conclusion and call to action]\n\nBy the end of this video, you'll have a solid understanding of recurrent neural networks and how to use them for natural language processing tasks in TensorFlow.\n\nRemember to like, share, and subscribe for more AI and machine learning content. In the next video, we'll explore the exciting world of generative adversarial networks (GANs) and their applications. See you there!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-04-08"}}
{"video": {"title": "Diffusion Models: From Theory to Practice", "transcript": "####Diffusion Models: From Theory to Practice\nby Sharon Zhou - 2023-03-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Sharon Zhou, and today we're diving into the fascinating world of diffusion models.\n\nImagine being able to predict how a trend goes viral on social media, or how a disease spreads in a population. That's the power of diffusion models!\n\nBut enough chit-chat, let's get our hands dirty. Open up your Python environment, and make sure you've got Tensorflow or Pytorch installed. We'll start by defining our model, then we'll feed in our data, and finally, we'll train our model.\n\nBut wait, there's more! I'll also show you how to speed up your sampling process by 10 times. We'll implement some algorithms that will make your sampling process faster than a cheetah on roller skates.\n\nAnd that's a wrap, folks! You've just learned how to build and train your own diffusion model, and even how to speed up the sampling process. Don't forget to hit that like button, subscribe, and share this video with your friends. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-03-17"}}
{"video": {"title": "Continuous Improvement in ML Production", "transcript": "####Continuous Improvement in ML Production\nby Andrew Ng - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here, and today we're diving into the world of continuous improvement in ML production.\n\nContinuous improvement is like the secret sauce to making your ML system perform at its best. It's all about making small, incremental changes over time that can lead to big improvements in performance and value.\n\nSo, how do you do it? First, you need to establish a feedback loop. This means collecting data on your model's performance and using that data to make improvements. It's like giving your model a check-up and making sure it's in tip-top shape.\n\nNext, you need to set up a process for testing and validation. This will help you ensure that your changes are having the desired effect and that they're not causing any unintended consequences. It's like being a detective, solving the mystery of what's working and what's not.\n\nOnce you have your feedback loop and testing process in place, it's time to start making improvements. This can involve tweaking your model's parameters, trying out new algorithms, or even rethinking your entire approach. It's like being a mad scientist, experimenting to find the perfect formula.\n\nBut remember, continuous improvement is a marathon, not a sprint. It's important to be patient and to focus on making steady progress over time. It's like training for a race, you won't see results overnight, but with consistent effort, you'll eventually cross the finish line.\n\nSo, that's a quick overview of continuous improvement in ML production. It's a powerful approach that can help you get the most out of your ML system.\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-22"}}
{"video": {"title": "Harnessing the Power of On-Device AI: A Beginner's Guide", "transcript": "####Harnessing the Power of On-Device AI: A Beginner's Guide\nby Krishna Sridhar - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're embarking on an exciting adventure into the world of On-Device AI!\n\nImagine having AI right at your fingertips, on your smartphone, or other edge devices. That's the magic of On-Device AI. It uses your device's local compute power for faster and more secure inference. No more waiting for cloud processing!\n\nFirst things first, you'll need some familiarity with Python, as well as PyTorch or TensorFlow. Don't worry if you're new to these tools, we'll keep things simple and clear.\n\nNow, let's talk about model conversion. You can convert your PyTorch or TensorFlow models to be compatible with your device. It's like translating your model into a language your device understands.\n\nNext up, quantization. It's a fancy word for reducing the size of your model without losing its brainpower. Smaller models mean faster processing and less storage space used. It's a win-win!\n\nNow, let's get our hands dirty with device integration. We'll explore runtime dependencies and how GPU, NPU, and CPU compute unit utilization affect performance. It's like understanding how different engines in a car work together to make it run smoothly.\n\nAnd guess what? We've partnered with Qualcomm to bring you this exciting journey into On-Device AI.\n\nSo, are you ready to deploy AI models on edge devices? Let's get started! Remember, keep practicing, keep learning, and don't forget to have fun.\n\nIf you found this video helpful, give it a thumbs up, share it with your friends, and don't forget to subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2023-03-15"}}
{"video": {"title": "Prompting Best Practices with Llama 2 & 3", "transcript": "####Prompting Best Practices with Llama 2 & 3\nby Amit Sangani - 2023-02-18\n\n#### BEGIN TRANSCRIPT ####\nHey there, Amit Sangani here and today we're diving into the exciting world of Prompting Best Practices with Llama 2 & 3.\n\nDon't worry if you're new to AI, we're all about making it easy and fun to learn. In this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst up, we'll be taking a look at Meta Llama 2 Chat and I'll show you how to interact with it to get the most out of your prompts. You'll be prompting like a pro in no time!\n\nNext, we'll dive into Code Llama and I'll show you how to use it to build some really cool applications. You'll be amazed at what you can create with just a few prompts.\n\nBut that's not all, we'll also be taking a look at Llama Guard and how you can use it to build safe and responsible AI applications. It's important to make sure our AI is being used for good, and Llama Guard can help with that.\n\nSo, are you ready to get started? Let's dive in and start prompting like a pro with Llama 2 & 3. And don't forget to hit that like and subscribe button for more great content. See you in the next video!\n\n\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-18"}}
{"video": {"title": "Ensuring Safety and Relevance with LLMs", "transcript": "####Ensuring Safety and Relevance with LLMs\nby Isa Fulford - 2022-10-23\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford, and today we're diving into the exciting world of LLMs! But don't worry, we're not just here for the fun. We're also going to talk about the importance of ensuring safety and relevance. Learn how to evaluate inputs and outputs for optimal outcomes in your AI systems. Let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-23"}}
{"video": {"title": "Linear Algebra for Machine Learning", "transcript": "Hi there, I'm Elena and welcome to our third video on Mathematics for Machine Learning and Data Science.\n\nIn this video, we're going to focus on linear algebra. Linear algebra is the study of vectors and linear transformations. In machine learning, we use linear algebra to represent data and perform operations on that data.\n\nWe're going to start with the basics of linear algebra, including vectors, matrices, and linear transformations. Then, we're going to explore how linear algebra is used in machine learning, including data representation, dimensionality reduction, and linear regression.\n\nSo let's get started.\n\n...\n\nThanks for watching. I hope you found this video on linear algebra for machine learning helpful. If you did, please give this video a thumbs up and subscribe to our channel for more videos like this. And if you have any questions, please leave them in the comments below. See you in the next video.\n\nRefined Script:\n\nHey there, Machine Learning enthusiasts! I'm Elena and welcome back to our channel.\n\nToday, we're diving into the world of linear algebra. Now, you might be thinking, \"Elena, why do I need to know linear algebra for machine learning?\" Well, let me tell you, linear algebra is the secret sauce that powers many machine learning algorithms.\n\nIn this video, we're going to start with the basics of linear algebra, including vectors, matrices, and linear transformations. Then, we're going to explore how linear algebra is used in machine learning, including data representation, dimensionality reduction, and linear regression.\n\nSo, are you ready to become a linear algebra master? Let's get started!\n\n...\n\nThanks for watching. I hope you found this video on linear algebra for machine learning helpful. If you did, please give this video a thumbs up and subscribe to our channel for more videos like this. And if you have any questions, please leave them in the comments below. See you in the next video, where we'll continue our journey into the world of machine learning.", "author": "Elena Sanina", "publication_date": "2022-01-15"}}
{"video": {"title": "LLM Red Teaming: Final Thoughts", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Encouragement for continuous learning.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Include more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Make the conclusion more memorable and engaging.\n- Include a strong call to action.\n\nRefined Script:\n\n####LLM Red Teaming: Final Thoughts\nby Matteo Dora, Luca Martial - 2023-05-03\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, LLM enthusiasts! Matteo Dora here, and welcome back to our thrilling series on red teaming for LLM applications.\n\nAre you ready to wrap up this exciting journey and discover some final thoughts on LLM red teaming?\n\nIn this video, we'll uncover how to continue honing your red teaming skills, stay ahead of the game with the latest LLM red teaming techniques, and contribute to the vibrant LLM red teaming community.\n\nBut wait, there's more! We'll also share some insider tips on how to make your LLM applications safer than ever before.\n\nSo, buckle up and get ready for an action-packed ride into the world of LLM red teaming!\n\nAnd remember, red teaming is a never-ending adventure, so let's keep exploring, learning, and having fun together.\n\nThank you for joining us on this epic journey. We hope you've found this series not only helpful and informative but also entertaining.\n\nUntil next time, keep red teaming and stay safe!\n\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-05-03"}}
{"video": {"title": "Building an LSTM from Scratch", "transcript": "####Building an LSTM from Scratch\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-02-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your guide for today's exciting journey into the world of Long Short-Term Memory (LSTM) networks.\n\nWe're going to build an LSTM from scratch using Python and TensorFlow, and apply it to a real-world sequential data task.\n\nFirst, we'll preprocess our data and split it into training and testing sets. Then, we'll define our LSTM architecture, including the LSTM layer and the output layer. After that, we'll compile our model and train it on our data. Finally, we'll evaluate our model and see how well it performs.\n\nI know this might sound like a daunting task, but don't worry. I'll be with you every step of the way, making sure you don't get lost in the world of LSTMs.\n\nSo, what are you waiting for? Let's dive into the world of LSTMs and build our own network. And remember, if you ever get stuck, I'm here to help.\n\nThanks for watching, and happy learning!\n\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-02-12"}}
{"video": {"title": "Understanding Multimodality and Contrastive Learning", "transcript": "####Understanding Multimodality and Contrastive Learning\nby Sebastian Witalec - 2022-10-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sebastian Witalec and today we're diving into the fascinating world of multimodality and contrastive learning. By the end of this video, you'll be a pro at building modality-independent embeddings for any-to-any retrieval. Trust me, you won't want to miss this!\n\nLet's kick things off with a quick overview of multimodality. In simple terms, it's all about combining different types of data, like text and images, to create a more complete representation. And that's where contrastive learning comes in. This technique helps us learn meaningful representations by comparing similar and dissimilar examples.\n\nBut enough with the chit-chat, let's get our hands dirty and start implementing some contrastive learning techniques. I promise, it's not as scary as it sounds.\n\nStay tuned for some laughs and some learning, and don't forget to like, share, and subscribe for more GenAI and LLM powered application goodness. Let's do this!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-03"}}
{"video": {"title": "Bringing Machine Learning to Life: Production Systems", "transcript": "####Bringing Machine Learning to Life: Production Systems\nby Andrew Ng - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! I'm Andrew Ng, and today we're going to dive into the thrilling world of Machine Learning in Production!\n\nFirst things first, what does it mean to have an ML production system? It's like baking a cake - you need the right ingredients (data), a good recipe (model), and a plan to serve it (deployment).\n\nNow, let's get our hands dirty with prototyping. It's like sketching a blueprint before building a house. We'll explore how to develop a prototype, test it, and refine it until it's ready for deployment.\n\nSpeaking of deployment, it's not just about pushing code to production. We'll discuss strategies to ensure smooth deployment, monitoring, and maintenance of our ML models.\n\nBut wait, our job doesn't end there! Just like a garden needs constant care, our ML system needs continuous improvement. We'll look at how to collect feedback, iterate, and enhance our system over time.\n\nSo, are you ready to turn your ML ideas into reality? Let's get started! Remember, the key to success is not just building a model, but designing a system that can continuously learn, adapt, and improve.\n\nThanks for watching! Don't forget to like, share, and subscribe for more exciting content on Machine Learning. Until next time, keep learning and keep innovating!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-15"}}
{"video": {"title": "The Future of LLM Red Teaming", "transcript": "####The Future of LLM Red Teaming: A Thrilling Journey Ahead\nby Matteo Dora, Luca Martial - 2023-05-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, LLM aficionados! I'm Luca Martial, and today we're diving into the exhilarating world of the future of LLM red teaming.\n\nAs LLM applications evolve into more intricate and omnipresent entities, the demand for robust red teaming will skyrocket. We're looking at more advanced testing techniques, more potent tools, and a greater focus on ethics and transparency.\n\nBut that's not all! We're also anticipating more collaboration between red teams and blue teams. Because, let's face it, the best defense is a strong offense.\n\nSo, how can you gear up for the future of LLM red teaming? Stay in the know, keep honing your skills, and always prioritize ethics. And don't forget to explore Giskard's open-source library for the latest tools and resources.\n\nThanks for tuning in. Remember to hit that like button, share with your friends, and subscribe for more exciting content on LLM applications. Until next time, stay curious and keep exploring!\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-05-01"}}
{"video": {"title": "Exploring Advanced Prompt Engineering in Vision Models", "transcript": "####Exploring Advanced Prompt Engineering in Vision Models\nby Caleb Kaiser - 2022-10-17\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Caleb Kaiser, and today we're diving headfirst into the exciting world of advanced prompt engineering in vision models. Are you ready to unlock the full potential of your diffusion models and generate images with unparalleled precision? Then buckle up, because we're about to embark on an epic journey!\n\nFirst, we'll explore the basics of prompt engineering and how it can be applied to vision models. Then, we'll dive into some advanced techniques that will take your image generation skills to the next level. And don't worry, I'll be sure to translate any jargon into plain English so that everyone can follow along.\n\nBut that's not all! We'll also have some fun along the way, with a sprinkle of humor and a few surprises thrown in for good measure. And of course, we'll wrap things up with a conclusion and a call to action that will leave you feeling inspired and ready to take on the world of vision models.\n\nSo what are you waiting for? Let's get started and unlock the full potential of your diffusion models!\n\n#### END TRANSCRIPT ########", "author": "Caleb Kaiser", "publication_date": "2022-10-17"}}
{"video": {"title": "ChatGPT Prompt Engineering: The Beginner's Blueprint", "transcript": "####ChatGPT Prompt Engineering: The Beginner's Blueprint\nby Isa Fulford, Andrew Ng - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're diving into the exciting world of prompt engineering for ChatGPT. If you're a beginner with some Python knowledge, you're in the perfect spot!\n\nLet's kick things off with the basics. What is prompt engineering and why should you care? Prompt engineering is the art of crafting effective inputs for language models like ChatGPT. It's important because it can significantly impact the quality of the output.\n\nNow, let's discuss some prompt engineering best practices. First, be precise and detailed with your prompts. The more context you provide, the better ChatGPT can generate the desired output. Second, iterate, iterate, iterate. Prompt engineering is all about trial and error, so don't be afraid to experiment.\n\nLet's explore some innovative ways to leverage LLMs. Did you know they can summarize, infer, transform, and expand text? Let's create our own custom chatbot using the OpenAI API.\n\nNow, let's get our hands dirty. Let's practice writing and refining prompts together. Remember, clarity and iteration are key.\n\nIn conclusion, prompt engineering is a game-changer for developing applications with ChatGPT. With these best practices and some hands-on experience, you're on your way to becoming a prompt engineering pro. So, what are you waiting for? Start prompting! And remember, practice makes perfect.\n\nThanks for tuning in and happy prompting! Don't forget to like, share, and subscribe for more exciting content. Catch you in the next video!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-22"}}
{"video": {"title": "AI Everywhere: The Future of On-Device AI", "transcript": "####AI Everywhere: The Future of On-Device AI\nby Krishna Sridhar - 2023-04-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Krishna Sridhar, and today we're diving into the thrilling world of On-Device AI.\n\nWith edge computing and 5G on the rise, AI is becoming more ubiquitous than ever. We'll explore the exciting possibilities of this new era of AI.\n\nFrom smart homes to autonomous vehicles, the potential applications of On-Device AI are endless.\n\nRemember, keep it simple, use active voice, and sprinkle in some humor. Be confident and concise in your writing.\n\nSo, are you ready to explore the future of On-Device AI? Let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2023-04-22"}}
{"video": {"title": "Mathematics for Machine Learning: A Recap", "transcript": "####Mathematics for Machine Learning: A Recap\nby Lucas Coutinho - 2022-02-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! I'm Lucas and welcome back to our final video in the Mathematics for Machine Learning series.\n\nToday, we're going to have a blast from the past and recap everything we've learned. We'll start with the basics of calculus, then dive into the depths of linear algebra, statistics, and probability. And the best part? We'll see how these topics fit together like pieces of a puzzle in the context of machine learning.\n\nSo, are you ready to put on your thinking cap and join me on this mathematical journey? Let's get started!\n\n...\n\nThanks for tuning in! I hope you found this video series on mathematics for machine learning as exciting as I did. If you did, please give this video a thumbs up and subscribe to our channel for more videos like this. And if you have any questions, please leave them in the comments below. I'll do my best to answer them all.\n\nUntil next time, happy learning and see you in the next series!\n\n#### END TRANSCRIPT ########", "author": "Lucas Coutinho", "publication_date": "2022-02-05"}}
{"video": {"title": "Improving LLM Performance with KV Caching and LoRA", "transcript": "####Improving LLM Performance with KV Caching and LoRA\nby Travis Addair - 2023-03-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Travis Addair and today we're diving into the world of LLMs! We're going to explore how to boost performance using KV caching and Low Rank Adapters (LoRA).\n\nLet's kick things off with KV caching. This nifty technique involves storing the key-value pairs of input tokens and their corresponding output probabilities in a cache. So, if we encounter the same input sequence again, our model can swiftly retrieve the output probabilities from the cache instead of having to recompute them. This can significantly speed up text generation and enhance the performance of our LLM application.\n\nNext up, we have LoRA. This technique allows us to fine-tune a pre-trained language model on our specific task using low-rank adapters. This means we can maintain the accuracy of the model while reducing the number of parameters, making it more efficient to serve to multiple users.\n\nBut wait, there's more! We'll also discuss how to combine KV caching and LoRA to further improve the performance of our LLM application. By using both techniques, we can significantly reduce latency and serve more users at once.\n\nFinally, we'll wrap things up by talking about some best practices for improving LLM performance, such as how to handle input validation and how to monitor the performance of our application.\n\nThanks for tuning in and don't forget to like, comment, and subscribe for more videos on GenAI and LLM powered applications. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Travis Addair", "publication_date": "2023-03-17"}}
{"video": {"title": "Getting Started With Mistral: Unleashing the Power of LLM", "transcript": "####Getting Started With Mistral: Unleashing the Power of LLM\nby Younes Belkada, Marc Sun - 2023-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're going to explore the exciting world of Mistral AI and how you can harness its advanced LLM capabilities for your projects.\n\nFirst up, Mistral AI offers a range of open-source and commercial models that you can access through a web interface or API calls. The open-source models include Mistral 7B, Mixtral 8x7B, and the latest Mixtral 8x22B. And if you're looking for even more power, Mistral also offers three commercial models: small, medium, and large.\n\nBut wait, there's more! One of the coolest features of Mistral is its JSON mode. With JSON mode, you can generate LLM responses in a structured JSON format, making it a breeze to integrate LLM outputs into your larger software applications.\n\nAnd that's not all. Mistral's API also lets you call user-defined Python functions for tasks like web searches or retrieving text from databases. This means you can enhance the LLM's ability to find relevant information and answer user queries more accurately.\n\nSo, whether you're a beginner or a seasoned pro, Mistral AI has something for everyone. And the best part? It's beginner-friendly, so you don't need any prior experience to get started.\n\nSo, what are you waiting for? Start exploring Mistral AI today and take your LLM capabilities to the next level. And don't forget to check out Mistral AI, our technology partner for this video.\n\nThanks for watching, and stay tuned for more exciting videos on Mistral AI and LLM. I'm Younes Belkada, and I'll catch you in the next one.\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-15"}}
{"video": {"title": "Building a Multilingual NLP App with Hugging Face", "transcript": "####Building a Multilingual NLP App with Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Your Assistant, and today we're diving into the exciting world of multilingual NLP with Hugging Face.\n\nNow, building a multilingual app isn't a walk in the park. Each language has its own unique structure and nuances. But don't worry, with Hugging Face, we can train our NLP model to handle multiple languages like a pro.\n\nWe'll start by understanding how to handle multilingual data, then we'll train our model, and finally, we'll put it to the test.\n\nRemember, the secret to successful multilingual NLP is understanding the unique characteristics of each language. Our model needs to be smart enough to handle that.\n\nSo, are you ready to create an app that can understand any language? Let's get started with Hugging Face and NLP!\n\nStay tuned for more exciting videos on this topic. And don't forget to like, share, and subscribe for more tech content. Until next time, I'm Your Assistant, your guide in the world of AI.\n\n\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-04-15"}}
{"video": {"title": "Hands-On Prompt Engineering Techniques for Vision Models", "transcript": "####Hands-On Prompt Engineering Techniques for Vision Models\nby Jacques Verr\u00e9 - 2022-10-16\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jacques Verr\u00e9, and today we're going to have a blast learning about prompt engineering techniques for vision models. Are you ready to level up your skills and prompt vision models with text, coordinates, and bounding boxes? Let's get started!\n#### END TRANSCRIPT ########", "author": "Jacques Verr\u00e9", "publication_date": "2022-10-16"}}
{"video": {"title": "Unleashing the Power of Llama 2 & 3 for AI Projects", "transcript": "####Unleashing the Power of Llama 2 & 3 for AI Projects\nby Amit Sangani - 2023-02-24\n\n#### BEGIN TRANSCRIPT ####\nHey there, Amit Sangani here and today we're diving into the exciting world of Llama 2 & 3 for AI projects!\n\nIn this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst up, we'll be taking a look at Meta Llama 2 Chat and I'll show you how to interact with it to get the most out of your prompts. You'll be prompting like a pro in no time!\n\nNext, we'll dive into Code Llama and I'll show you how to use it to build some really cool applications. You'll be amazed at what you can create with just a few prompts.\n\nBut that's not all, we'll also be taking a look at Llama Guard and how you can use it to build safe and responsible AI applications. It's important to make sure our AI is being used for good, and Llama Guard can help with that.\n\nSo, are you ready to get started? Let's dive in and start unleashing the power of Llama 2 & 3 for AI projects. And don't forget to hit that like and subscribe button for more great content. See you in the next video!\n\n\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-24"}}
{"video": {"title": "Building a RAG-Powered Q&A System with JavaScript and LlamaIndex", "transcript": "####Building a RAG-Powered Q&A System with JavaScript and LlamaIndex\nby Laurie Voss - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurie Voss and today we're diving into the world of RAG-powered Q&A systems! We'll be using JavaScript and LlamaIndex to create an intelligent agent that can answer queries by discerning and selecting from multiple data sources.\n\nBut wait, what's a RAG system? It's a Retrieval-Augmented Generation system, which means it can retrieve relevant information and generate answers based on that information. Pretty cool, right?\n\nIn this video, we'll be creating an interactive frontend component that allows users to input questions and receive answers from our RAG-powered backend. We'll also learn how to persist your data, enable chatting with your data, and make streaming responses possible.\n\nTo get started, we'll be using the create-llama command-line tool to set up our project and install the necessary dependencies. Then, we'll create our frontend component using React and integrate it with our RAG-powered backend.\n\nThroughout this process, I'll be sharing tips and best practices for building RAG applications in JavaScript. By the end of this video, you'll have a fully functional Q&A system that you can use to answer questions from your data.\n\nSo, are you ready to build something amazing? Let's get started! And don't forget to check out LlamaIndex for more resources on building intelligent applications.\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2023-04-20"}}
{"video": {"title": "TensorFlow: Training Models in Browsers", "transcript": "####TensorFlow: Training Models in Browsers\nby Laurence Moroney - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Laurence Moroney, and today we're going to explore the exciting world of training machine learning models directly in your browser with TensorFlow.js.\n\n[Video hook and introduction]\n\nImagine the possibilities! Interactive demos, real-time personalization, all without the need for a server. Sounds amazing, right? Let's dive in!\n\n[Body content]\n\nWith TensorFlow.js, you can build and train models using JavaScript, right in the browser. It's like having a superpower! But don't worry, it's easier than you think.\n\n[Conclusion and call to action]\n\nSo, what are you waiting for? Start exploring TensorFlow.js and see what you can create! Remember, the only limit is your imagination. Keep learning, keep creating, and happy coding!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-04-01"}}
{"video": {"title": "Mastering Machine Learning in Production: A Comprehensive Guide", "transcript": "####Mastering Machine Learning in Production: A Comprehensive Guide\nby Andrew Ng - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! I'm Andrew Ng, and today we're embarking on an exciting journey to master Machine Learning in Production.\n\nBut why should we care about designing an ML production system? It's not just about creating a model that works; it's about scoping, data, modeling, and deployment.\n\nWhen we scope, we're defining what our ML system will do and how it fits into our overall business strategy. This is where we ask ourselves, 'What problem are we trying to solve?'\n\nNext, we've got data. This is the fuel for our ML engine. We need to collect it, clean it, and make sure it's in a format our model can understand.\n\nThen comes modeling. This is where we choose the right algorithm for our problem and train our model. But remember, the model is just a small part of the overall system.\n\nFinally, we deploy our model. This is where the magic happens! Our model starts making predictions in the real world, and we can see the impact of our hard work.\n\nBut wait, there's more! Prototype development, deployment, and continuous improvement are key to a successful ML production system. We're not just building a model; we're creating a system that can learn and improve over time.\n\nSo, are you ready to take your ML skills to the next level? Start designing your ML production system today, and remember, the journey doesn't end when the model is deployed. It's just the beginning!\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content on Machine Learning. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-15"}}
{"video": {"title": "Ethical Considerations in GANs: Transparency and Accountability", "transcript": "####Ethical Considerations in GANs: Transparency and Accountability\nby Eda Zhou - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Eda Zhou, and today we're diving into the exciting world of Generative Adversarial Networks, or GANs. But we're not just talking tech specs, we're talking ethics! That's right, as we harness the power of these incredible models, it's crucial to address ethical considerations. So, buckle up and let's prioritize ethics in GANs!\n\nFirst up, transparency. It's not just about being honest, it's about being clear and understandable. We'll explore why this matters and how we can achieve it.\n\nNext, accountability. Who's responsible when things go wrong? We'll delve into this complex question and discuss potential solutions.\n\nSo, why should you care? Well, GANs are shaping our future, from creating realistic images to generating deepfakes. It's our responsibility to ensure they're used ethically.\n\nStay tuned, because we're about to make ethics in GANs as exciting as the technology itself!\n#### END TRANSCRIPT ########", "author": "Eda Zhou", "publication_date": "2022-10-15"}}
{"video": {"title": "Prompt Engineering for Text Inference with ChatGPT", "transcript": "####Prompt Engineering for Text Inference with ChatGPT\nby Isa Fulford, Andrew Ng - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Isa Fulford and today we're diving into the exciting world of prompt engineering for text inference with ChatGPT. If you're a beginner with basic Python skills, you're in luck!\n\nFirst things first, let's demystify text inference. It's the process of extracting information from text that isn't explicitly stated. Why is it important? It's a valuable skill in many areas, from sentiment analysis to information retrieval.\n\nNow, let's see how we can use ChatGPT and prompt engineering to make text inference a breeze. The secret sauce? Crafting prompts that ask the model to make inferences based on the text. Let's look at some examples and try it out ourselves.\n\nRemember, the key to good prompts is to be clear, concise, and specific. Let's iterate on our prompts and see how we can improve the inferences we get from ChatGPT.\n\nAnd that's a wrap! You've just learned how to use prompt engineering for text inference with ChatGPT. Remember, practice makes perfect. So keep experimenting and refining your prompts.\n\nThanks for watching and happy coding! And a big thank you to our partners at OpenAI for their support.\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-04-05"}}
{"video": {"title": "Mastering Mathematics for Machine Learning and Data Science: Review and Next Steps", "transcript": "####Mastering Mathematics for Machine Learning and Data Science: Review and Next Steps\nby Obed Kobina Nsiah - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Obed Kobina Nsiah, and welcome back to our thrilling journey through the world of Mathematics for Machine Learning and Data Science. Today, we're taking a victory lap and discussing what's next.\n\nOver the past few videos, we've uncovered the secret weapon of machine learning: calculus, linear algebra, statistics, and probability. We've seen how these concepts help us wrangle data, optimize our models, and make decisions with confidence.\n\nBut the learning adventure doesn't end here. Machine learning is a dynamic field, and there's always more to discover. So, what's the next step?\n\nFirst, I encourage you to put your new skills to the test. Try solving some problems, working on projects, and applying these concepts to real-world data. This will help you cement your understanding and gain practical experience.\n\nNext, consider diving deeper into specific topics that pique your interest. There are many resources available online, from tutorials and courses to research papers and books. Don't be afraid to explore and learn more.\n\nAnd that's a wrap for our video series on Mathematics for Machine Learning and Data Science! I hope you've enjoyed this ride and found it helpful. Remember, learning is a lifelong adventure, so keep exploring, keep learning, and keep growing.\n\nThanks for watching, and happy learning!\n\n#### END TRANSCRIPT ########", "author": "Obed Kobina Nsiah", "publication_date": "2023-04-05"}}
{"video": {"title": "Building Better Chat Experiences with ChatGPT: Tips and Tricks", "transcript": "####Building Better Chat Experiences with ChatGPT: Tips and Tricks\nby Isa Fulford - 2022-11-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Isa Fulford! Are you ready to take your chat experiences to the next level with ChatGPT? Today, we're diving into the world of chatbots and exploring some valuable tips and tricks for creating engaging and effective conversations. Let's get started!\n\nFirst, we'll cover the basics of ChatGPT and how it can be used to enhance user interactions. Then, we'll delve into some practical strategies for improving your chatbot's performance and making it more enjoyable for users. And finally, we'll wrap up with some best practices for designing and implementing chat experiences that truly stand out.\n\nSo, whether you're a seasoned chatbot developer or just getting started, this video is for you. Let's get ready to build some amazing chat experiences together!\n\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-11-01"}}
{"video": {"title": "Diffusion Models: The Future of Predictive Analysis", "transcript": "####Diffusion Models: Unleashing the Future of Predictive Analysis\nby Sharon Zhou - 2023-03-24\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Sharon Zhou, and today we're embarking on an exciting journey to uncover the future of predictive analysis with diffusion models.\n\nDiffusion models are like the secret sauce of understanding how things spread or diffuse over time and space. Imagine being able to predict how a rumor spreads through a school, or how a disease spreads through a population. Sounds cool, right?\n\nLet's get our hands dirty and build our own diffusion model. Fire up your Python environment, and make sure you've got Tensorflow or Pytorch installed. We'll start by defining our model, then we'll feed in our data, and finally, we'll train our model.\n\nBut wait, there's more! I'll also show you how to turbocharge your sampling process by 10 times. We'll implement some algorithms that will make your sampling process faster than a speeding bullet.\n\nAnd that's a wrap, folks! You've just learned how to build and train your own diffusion model, and even how to speed up the sampling process. Don't forget to give this video a thumbs up, subscribe, and share this knowledge with your friends. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-03-24"}}
{"video": {"title": "Supercharging Your LLM: User-Defined Functions with Mistral's API", "transcript": "####Supercharging Your LLM: User-Defined Functions with Mistral's API\nby Younes Belkada, Marc Sun - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, Marc Sun here, and welcome back to our series on Mistral AI.\n\nToday, we're going to talk about how you can supercharge your LLM's ability to find relevant information using Mistral's API to call user-defined functions.\n\nBut first, let's recap what Mistral's API is. It's a tool that allows you to interact with Mistral's models in a more advanced way. With it, you can call user-defined Python functions.\n\nSo, how does this help you? Well, it means you can perform tasks like web searches or retrieving text from databases. This enhances your LLM\u2019s ability to find relevant information to answer your queries.\n\nIt's all about making your LLM more powerful and versatile. And with Mistral AI, it's easier than you might think.\n\nBut don't just take my word for it. Let's dive in and see how it works.\n\nIf you have any questions, just let us know. And don't forget to like, share, and subscribe for more updates. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-10"}}
{"video": {"title": "Quantization Basics: Shrink Models with Hugging Face and Quanto", "transcript": "####Quantization Basics: Shrink Models with Hugging Face and Quanto\nby Younes Belkada, Marc Sun - 2023-03-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Younes Belkada, and today we're diving into the fascinating world of quantization with Hugging Face and Quanto.\n\nBut first, let's answer the million-dollar question: what is quantization? It's a technique that allows us to shrink our models without losing accuracy. It's like packing a suitcase for a trip - you want to fit as much as possible without exceeding the weight limit.\n\nIn this video, we'll start with linear quantization, a simple yet powerful method for model compression. We'll decrease the precision of the weights in your model, resulting in a smaller size and faster inference times.\n\nBut wait, there's more! We'll also explore how to quantize open-source multimodal and language models. Don't worry if you're new to this - I'll be there to guide you through each step.\n\nBy the end of this video, you'll know how to quantize any open-source model using Hugging Face and Quanto. So, are you ready to shrink your models and boost your efficiency? Let's get started!\n\nAnd don't forget to hit that like button, share this video, and subscribe for more AI and machine learning content. Until next time, happy quantizing!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-10"}}
{"video": {"title": "Expanding Your LLM Applications with Agents and Chained Calls", "transcript": "####Expanding Your LLM Applications with Agents and Chained Calls\nby Harrison Chase, Andrew Ng - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Harrison Chase, and today we're going to take your LLM applications to the next level with agents and chained calls in LangChain.\n\nAgents and chained calls are game-changers. They allow our applications to perform complex tasks and remember past interactions.\n\nFirst, we'll demystify agents and chained calls and how they work in LangChain. Don't worry, I'll break it down into simple, easy-to-understand steps.\n\nNext, we'll dive into the code. We'll use agents and chained calls to supercharge our personal assistant and chatbot applications.\n\nAnd the best part? We'll use memories to make our applications even more powerful. They'll be able to remember past interactions and use that information to perform tasks more effectively.\n\nNow, let's wrap up. You've learned what agents and chained calls are, how to use them in LangChain, and how to enhance your applications with memories.\n\nSo, what's next? I challenge you to add agents and chained calls to your own applications. Make them smarter. Make them more powerful.\n\nThanks for watching. If you found this tutorial helpful, give it a thumbs up and don't forget to subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-03-30"}}
{"video": {"title": "Building Multimodal RAG Systems", "transcript": "####Building Multimodal RAG Systems: A Deep Dive\nby Sebastian Witalec - 2022-10-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to take your knowledge to the next level? Today, we're diving deep into the world of multimodal reasoning by building multimodal RAG systems. These systems can retrieve multimodal context and reason over it to generate more relevant answers. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-05"}}
{"video": {"title": "Harnessing the Power of AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####Harnessing the Power of AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-03-01\n\n#### BEGIN TRANSCRIPT ####\nHey Python lovers! Today, we're exploring the thrilling world of AI agents using LangChain's LangGraph and Tavily's agentic search.\n\nBut first, what's LangGraph? It's an open-source framework that empowers us to build, debug, and maintain AI agents. It's like having a superpower for creating controllable agents.\n\nNow, let's talk about Tavily's agentic search. It's a game-changer. It boosts our AI agents' knowledge and performance, making them more efficient and effective.\n\nIn this course, you'll learn directly from Harrison Chase, the mastermind behind LangChain, and Rotem Weiss, the genius behind Tavily. They'll guide you through LangGraph's components and show you how to integrate agentic search capabilities.\n\nRemember, this course is perfect for you if you have intermediate Python knowledge and want to take your AI agent skills to the next level.\n\nSo, are you ready to transform the way you build AI agents? Let's dive in!\n\nStay tuned for more exciting lessons. And don't forget to like, share, and subscribe for more AI-powered content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-01"}}
{"video": {"title": "The Future of AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####The Future of AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-05-03\n\n#### BEGIN TRANSCRIPT ####\nHello, Python enthusiasts! Today, we're diving into the future of AI agents using LangGraph and Tavily's agentic search.\n\nFirst, we'll uncover how LangGraph's components are setting the stage for the next generation of AI agents. It's like having a sneak peek into the future of AI!\n\nThen, we'll demonstrate how Tavily's agentic search capabilities are supercharging the future of AI agents.\n\nIn this course, you'll learn directly from Harrison Chase, the mastermind behind LangChain, and Rotem Weiss, the genius behind Tavily. They'll guide you through the future of AI agents and share their expert insights.\n\nRemember, this course is designed for those with intermediate Python knowledge who want to stay one step ahead in AI agent development.\n\nSo, are you ready to explore the future of AI agents? Let's get started!\n\nStay tuned for more thrilling lessons. And don't forget to like, share, and subscribe for more AI-powered content.\n\nUntil next time, keep innovating!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-05-03"}}
{"video": {"title": "Granularity in Quantization: Per Tensor, Per Channel, and Per Group", "transcript": "####Granularity in Quantization: Per Tensor, Per Channel, and Per Group\nby Marc Sun, Younes Belkada - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! I'm Marc Sun, and today we're diving into the world of quantization. Specifically, we're talking about granularity in quantization: per tensor, per channel, and per group.\n\nFirst up, per tensor quantization. This is the simplest form of quantization, where we quantize all the weights in a tensor using the same scale and zero point. It's like using the same paintbrush for the entire canvas.\n\nNext, we have per channel quantization. This is a bit more granular. We quantize each channel in a tensor separately, giving us more precision. It's like using different paintbrushes for different parts of the canvas.\n\nFinally, we have per group quantization. This is the most granular form of quantization. We quantize groups of weights separately, giving us even more precision. It's like using a whole set of paintbrushes, each with a different size and shape.\n\nSo, which one should you use? Well, it depends on your model and your data. Per tensor quantization is the simplest, but it might not give you the best results. Per channel and per group quantization are more complex, but they can give you better results.\n\nRemember, practice makes perfect. So, get out there and start quantizing!\n\nAnd don't forget to like, share, and subscribe for more exciting content. Until next time, happy quantizing!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-03-25"}}
{"video": {"title": "Machine Learning Project: Sentiment Analysis", "transcript": "####Machine Learning Project: Sentiment Analysis\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-02-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! It's your friendly host, back with another exciting episode. Today, we're diving into a project where we'll perform sentiment analysis using Machine Learning. Are you ready to get started? Let's do this!\n\nFirst, we'll start with a dataset of movie reviews. We'll walk you through the steps of preparing it for our model. This includes cleaning the data, handling missing values, and converting text data into numbers. It's like giving our model a good scrub before we let it loose!\n\nNext, we'll split our data into a training set and a test set. The training set is used to train our model, while the test set is used to evaluate its performance. It's like sending our model to school and then giving it a pop quiz!\n\nThen, we'll dive into building our model. We'll start with a simple logistic regression model, and we'll learn how to train it using our training data. It's like teaching our model to read and write!\n\nBut that's not all. We'll also learn how to evaluate our model using metrics like accuracy and F1 score. And we'll do it all with practical examples, so you can see how it's done in the real world. It's like giving our model a report card!\n\nRemember, the best way to learn is by doing, so don't be afraid to get your hands dirty. So, are you ready to perform sentiment analysis with Machine Learning? Let's get started! And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-02-19"}}
{"video": {"title": "Transforming Text with Advanced Prompt Engineering Techniques", "transcript": "####Transforming Text with Advanced Prompt Engineering Techniques: A Fun and Engaging Journey\nby Andrew Ng - 2022-11-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, text enthusiasts! Are you ready to take your text manipulation skills to the next level? Today, we're diving into the exciting world of advanced prompt engineering techniques using ChatGPT. Get ready to have some fun and learn something new!\n\nFirst, let's talk about what prompt engineering is and why it's important. Then, we'll explore some creative ways to manipulate and enhance text using ChatGPT. Trust me, you won't want to miss this!\n\nBut wait, there's more! We'll also be discussing some real-world applications of these techniques and how they can be used to solve problems in various industries.\n\nSo, are you ready to get started? Let's do this!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-11-01"}}
{"video": {"title": "Ethical Considerations in Machine Learning: Bias, Fairness, and Privacy", "transcript": "####Ethical Considerations in Machine Learning: Bias, Fairness, and Privacy\nby Andrew Ng - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here, and today we're diving into the world of ethical considerations in machine learning, specifically bias, fairness, and privacy.\n\nFirst things first, why should we care about ethical considerations? When we're building machine learning models, we need to ensure they're fair, unbiased, and respect user privacy. But issues can arise due to biased data, biased algorithms, or other factors that can affect model fairness and privacy.\n\nSo, how do we tackle these issues? It all starts with data. We need to ensure our data is representative, unbiased, and respects user privacy. We'll talk about how to collect and preprocess data to minimize bias and protect user privacy.\n\nNext up, we need to think about algorithms. We need to use fairness metrics like demographic parity, equal opportunity, and equalized odds to ensure our models are fair and unbiased. We'll talk about how to use these metrics and how to balance fairness and accuracy.\n\nThen, we need to think about privacy. We need to use techniques like differential privacy and federated learning to protect user data and ensure user privacy. We'll talk about how to use these techniques and how to balance privacy and utility.\n\nBut wait, there's more! Ethical considerations in machine learning are not just about technology. They're also about people and processes. We'll talk about how to collaborate with data engineers, DevOps teams, and business stakeholders to ensure our ethical considerations are aligned with the overall business goals.\n\nSo, are you ready to learn about ethical considerations in machine learning and how to build fair, unbiased, and privacy-preserving models? Let's get started!\n\nRemember, ethical considerations in machine learning are not just about technology. They're about people, processes, and culture. So keep learning, keep experimenting, and most importantly, have fun!\n\nIf you found this video helpful, be sure to give it a thumbs up and subscribe for more content. And if you have any questions or suggestions, leave them in the comments below. Thanks for watching, and I'll see you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-30"}}
{"video": {"title": "Summarizing Data with Your Agentic RAG", "transcript": "####Summarizing Data with Your Agentic RAG\nby Jerry Liu - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Jerry Liu, and today we're diving into the exciting world of data summarization with Agentic RAG systems.\n\nImagine being able to condense all that information into a neat, bite-sized summary. Well, that's exactly what we're going to learn today!\n\nFirst, we'll explore how to guide your agent towards the information you want summarized. It's like giving your agent a treasure map to the data goldmine.\n\nNext, we'll uncover the magic behind how your agent creates these summaries. It's like a data magic trick, but without the rabbit.\n\nWe'll also discuss how to handle multi-document summarization. Because sometimes, the information you need is scattered across multiple documents.\n\nAnd finally, we'll share some pro tips for getting the most out of your agent's summarization skills.\n\nSo, are you ready to turn your data into a digestible summary? Let's get started!\n\nRemember, summarization is an art, not a science. So, don't be afraid to experiment and find what works best for you.\n\nThanks for watching, and happy summarizing!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-03-25"}}
{"video": {"title": "Mastering Deep Learning Specialization: CNNs, RNNs, LSTMs, and Transformers", "transcript": "####Mastering Deep Learning Specialization: CNNs, RNNs, LSTMs, and Transformers\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm your friendly AI guide, and today we're embarking on an exciting journey into the world of Deep Learning Specialization.\n\nBut first, let's get acquainted. What is Deep Learning Specialization? It's a comprehensive course that teaches you how to build neural networks, including Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTMs), and Transformers.\n\nNow, you might be thinking, \"Why should I care?\" Well, these networks are the brains behind speech recognition, Natural Language Processing (NLP), and so much more. And guess what? We'll be using Python and TensorFlow to build them.\n\nLet's kick things off with CNNs. They're like the brain's visual cortex, processing images and videos. We'll learn how to build them from scratch and apply them to real-world scenarios.\n\nNext up, RNNs and LSTMs. These networks are the time lords of data, mastering time series and sequential data. We'll explore how they work and how to use them for tasks like language modeling and translation.\n\nLastly, we'll dive into Transformers. These are the new kids on the block, shaking up the field of NLP. We'll learn how they work and how to implement them.\n\nThroughout this journey, we'll be coding in Python and using TensorFlow, one of the most popular libraries for machine learning and deep learning.\n\nNow, remember, this course is for those with an intermediate skill level. So, if you're new to the field, you might want to brush up on the basics first.\n\nAnd that's a wrap! I hope you're as excited as I am to start this Deep Learning Specialization. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2023-03-15"}}
{"video": {"title": "LangChain: Chat with Your Data", "transcript": "####LangChain: Chat with Your Data\nby Harrison Chase - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're going to have a blast talking about LangChain! This tool is going to change the way you interact with your private data and documents. Imagine having a chatbot that can answer your questions directly from your own files. Sounds cool, right? Let's get started!\n\nFirst, we'll explore what LangChain is and why it's so awesome. Then, I'll show you how to use its 80 unique loaders to handle various data sources. And finally, we'll build our very own chatbot together. Trust me, you won't want to miss this!\n\nSo, buckle up and let's dive into the world of LangChain. It's time to make your data work for you!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2022-01-15"}}
{"video": {"title": "Inference Methods for LLMs in Generative AI", "transcript": "####Inference Methods for LLMs in Generative AI: Unlocking the Power of Language Models\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-02\n\n#### BEGIN TRANSCRIPT ####\nHey there, Mike Chambers here, and today we're diving into the exciting world of inference methods for LLMs in generative AI!\n\nFirst, we'll cover the basics of inference, including how to generate new content using LLMs.\n\nWe'll also discuss different inference methods, such as beam search and sampling, and their pros and cons.\n\nThen, we'll dive into more advanced inference techniques, like top-k and top-p sampling, to improve the quality and diversity of generated content.\n\nAnd don't worry, we'll be using practical examples and code snippets to help you understand the concepts better.\n\nBy the end of this video, you'll have the skills and knowledge to apply inference methods to LLMs in generative AI and take your projects to the next level.\n\nSo, let's get started! See you in the course.\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-02"}}
{"video": {"title": "Generative AI Challenges and Opportunities", "transcript": "####Generative AI Challenges and Opportunities\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Antje Barth, and today we're diving into the thrilling world of generative AI!\n\nGenerative AI is poised to shake up numerous industries, from healthcare to entertainment. But it's not all sunshine and rainbows. We're also facing challenges like bias, fairness, and privacy.\n\nIn this video, we'll explore the latest research on generative AI and hear from industry experts about the challenges and opportunities they're seeing. We'll also discuss ethical considerations and best practices for developing and deploying generative AI systems.\n\nBy the end of this video, you'll have a solid grasp of the challenges and opportunities of generative AI. You'll be able to apply this knowledge to your own projects and stay ahead of the curve on the latest developments in the field.\n\nSo, let's get started and uncover the exciting world of generative AI together!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-08"}}
{"video": {"title": "TensorFlow: Deployment on Cloud", "transcript": "####TensorFlow: Deployment on Cloud\nby Laurence Moroney - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHello, I'm Laurence Moroney, and today we're diving into the exciting world of deploying your TensorFlow models on the cloud.\n\n[Video hook and introduction]\n\nImagine being able to scale your machine learning projects effortlessly, access your models from anywhere, and enjoy the flexibility that only the cloud can offer. Sounds amazing, right? Well, that's exactly what we're going to explore today!\n\n[Body content]\n\nWith TensorFlow, deploying your models on the cloud is a breeze. Whether you're using Google Cloud, AWS, or Azure, TensorFlow has got you covered. You'll be able to harness the power of the cloud to train and serve your models, all while enjoying the benefits of scalability and accessibility.\n\nBut wait, there's more! We'll also be looking at some best practices for cloud deployment, so you can ensure your models are running smoothly and efficiently.\n\n[Conclusion and call to action]\n\nSo, what are you waiting for? Start exploring the world of cloud deployment today and see how it can take your machine learning projects to the next level. Keep learning, keep innovating, and happy coding!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-04-25"}}
{"video": {"title": "LangChain and Data Privacy", "transcript": "####LangChain and Data Privacy: Your Privacy, Your Control\nby Harrison Chase - 2023-03-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! Harrison Chase here, the mastermind behind LangChain, and today we're diving into a topic that's close to my heart: data privacy.\n\nAt LangChain, we're all about keeping your data safe and secure. That's why we've designed LangChain with privacy at its core.\n\nBut what does that mean for you and your chatbot? Let's find out.\n\nWhen you use LangChain to create your chatbot, all your data stays local on your machine. That means you're the boss of your data, and you decide who gets access.\n\nAnd that's not all. LangChain uses top-notch encryption to keep your data safe, whether it's on the move or taking a nap.\n\nI'll be your guide on this journey, sharing my secrets and tricks to help you build the most secure chatbot out there. And the cherry on top? You'll be learning directly from the LangChain creator himself.\n\nSo, are you ready to build a chatbot that respects your privacy? Let's do this!\n\nAnd remember, if you ever get stuck or need a helping hand, just reach out. Once you've built your secure chatbot, be sure to show it off. I can't wait to see what you come up with!\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-17"}}
{"video": {"title": "Inference Strategies for Generative AI", "transcript": "####Inference Strategies for Generative AI: Unleashing the Power of Predictions\nby Chris Fregly - 2022-10-11\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to dive into the world of generative AI and learn how to make predictions in real-world scenarios? Well, you're in luck because today we're talking about inference strategies for generative AI models. I'm your host, Chris Fregly, and I'm thrilled to be your guide on this exciting journey.\n\nSo, what exactly are inference strategies? Think of them as the secret sauce that allows you to deploy your models and make accurate predictions. And trust me, you don't want to miss out on this delicious recipe!\n\nBut wait, there's more! We'll also be discussing some of the latest trends and advancements in the field of generative AI. So, buckle up and get ready for a wild ride!\n\nAnd don't forget to like, share, and subscribe for more AI content. Let's get started!\n#### END TRANSCRIPT ########", "author": "Chris Fregly", "publication_date": "2022-10-11"}}
{"video": {"title": "TensorFlow for Reinforcement Learning", "transcript": "####TensorFlow for Reinforcement Learning\nby Laurence Moroney - 2022-02-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the exciting world of reinforcement learning with TensorFlow!\n\n[Video hook and introduction]\n\nAre you ready to build agents that can learn from their environment and make intelligent decisions? Then buckle up, because we're about to embark on an epic journey!\n\n[Body content]\n\nFirst, we'll cover the basics of reinforcement learning and how TensorFlow fits into the picture. We'll explore essential concepts like rewards, states, and actions.\n\nThen, we'll dive into building our first reinforcement learning model. We'll use a simple environment to train our agent and learn how to define rewards, choose actions, and update our model. You'll also discover how to use pre-trained models and transfer learning to speed up the process.\n\nWe'll also explore real-world applications of reinforcement learning, like game playing and robotics. Plus, we'll cover advanced topics like deep Q-learning and policy gradients.\n\n[Conclusion and call to action]\n\nSo, are you ready to master reinforcement learning with TensorFlow? Let's get started! Remember, the best way to learn is by doing, so make sure to follow along and code with me. See you in the first lesson!\n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-02-19"}}
{"video": {"title": "Mistral AI: Your Gateway to Advanced LLMs", "transcript": "####Mistral AI: Your Gateway to Advanced LLMs\nby Younes Belkada, Marc Sun - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Marc Sun here, and today we're diving deeper into Mistral AI.\n\nIn our last video, we introduced Mistral and its open-source and commercial models. But today, we're going to show you how to use these models to their full potential.\n\nMistral's open-source models are a great starting point. They offer a range of capabilities and are perfect for those just starting out. But if you need more advanced features, Mistral's commercial models have got you covered.\n\nOne of the standout features of Mistral is its JSON mode. This allows you to generate LLM responses in a structured JSON format. It might sound complex, but it's actually quite simple. It just means that you can easily integrate the outputs of your LLM into larger software applications.\n\nAnd let's not forget about Mistral's API. This powerful tool allows you to call user-defined Python functions. This means you can perform tasks like web searches or retrieving text from databases. Essentially, it supercharges your LLM\u2019s ability to find relevant information to answer your queries.\n\nSo, that's a quick overview of how you can use Mistral AI. Remember, practice makes perfect, so don't be afraid to get stuck in and start exploring.\n\nIf you have any questions, just let us know. And don't forget to like, share, and subscribe for more updates. Until next time, happy learning!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-20"}}
{"video": {"title": "Linear Algebra in Action: Transforming Data in Machine Learning", "transcript": "####Linear Algebra in Action: Transforming Data in Machine Learning\nby Lucas Coutinho - 2023-03-11\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, data enthusiasts! Lucas Coutinho here, and today we're diving into the thrilling world of linear algebra. We're going to see how it can transform data in machine learning.\n\nRemember those matrices and vectors from our last video? They're not just theoretical concepts, they're powerful tools for data transformation.\n\nIn machine learning, we use matrices to represent our datasets and vectors to represent our data points.\n\nLet's talk about matrix multiplication. It's a game-changer when it comes to transforming our data.\n\nDon't worry if this seems a bit tricky at first. With practice, you'll be transforming data like a pro.\n\nRemember, the only way to learn mathematics is to do mathematics. So, keep learning, keep practicing, and soon you'll be a data transformation master.\n\nThanks for watching. Be sure to like, share, and subscribe for more exciting videos on Mathematics for Machine Learning and Data Science. Until next time, happy learning!\n\n#### END TRANSCRIPT ########", "author": "Lucas Coutinho", "publication_date": "2023-03-11"}}
{"video": {"title": "Mastering Prompt Engineering for Vision Models", "transcript": "####Mastering Prompt Engineering for Vision Models\nby Abby Morgan, Jacques Verr\u00e9, Caleb Kaiser - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Abby Morgan, and today we're going to dive into the exciting world of prompt engineering for vision models. Are you ready to level up your image generation skills? Let's do this!\n\nPrompt engineering for vision models is all about using Stable Diffusion and advanced techniques like object detection and in-painting. If you've got some Python experience under your belt, you're in a great position to tackle this hands-on course.\n\nWe'll be partnering with Comet to explore how to prompt vision models with text, coordinates, and bounding boxes. We'll also fine-tune hyper-parameters like guidance scale, strength, and number of inference steps. But wait, there's more! We'll delve into in-painting, a technique that combines object detection, image segmentation, and image generation. By replacing parts of an image with generated content, you'll have even more control over your image generation.\n\nAnd if you're looking to create specific images, including your own, rather than generically generated ones, we'll show you how to fine-tune a diffusion model. So, are you ready to master prompt engineering for vision models? Join me, Abby Morgan, along with Jacques Verr\u00e9 and Caleb Kaiser, as we unlock the secrets to creating stunning visuals. Let's get started!\n#### END TRANSCRIPT ########", "author": "Abby Morgan, Jacques Verr\u00e9, Caleb Kaiser", "publication_date": "2022-10-15"}}
{"video": {"title": "Interacting with Meta Llama 2 Chat", "transcript": "####Interacting with Meta Llama 2 Chat\nby Amit Sangani - 2023-02-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Amit Sangani and today we're diving into the world of Meta Llama 2 Chat!\n\nAre you ready to level up your prompting skills? In this beginner-friendly course, we'll be exploring the best practices for prompting and selecting among Meta Llama 2 & 3 models.\n\nFirst, we'll take a deep dive into Meta Llama 2 Chat and how you can interact with it to get the most out of your prompts. We'll also explore Code Llama and how it can help you with your coding needs.\n\nBut that's not all, we'll also be discussing the importance of building safe and responsible AI applications. That's where Llama Guard comes in. We'll show you how you can use this model to ensure that your AI applications are safe and responsible.\n\nSo, are you ready to become a Meta Llama 2 Chat master? Let's get started!\n\nRemember, practice makes perfect. So, be sure to try out these best practices on your own and see how they work for you. And, if you have any questions or need further clarification, don't hesitate to reach out.\n\nThanks for watching and happy prompting!\n\nBe sure to like, comment, and subscribe for more content like this. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-19"}}
{"video": {"title": "Quantization in Depth: Wrap-Up", "transcript": "####Quantization in Depth: Wrap-Up\nby Marc Sun, Younes Belkada - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Marc Sun, and today we're wrapping up our series on advanced quantization techniques. We've covered a lot of ground, and I hope you've enjoyed the journey as much as I have.\n\nBut remember, learning doesn't stop here. There's always more to explore in the world of quantization. So, keep learning, keep experimenting, and keep quantizing!\n\nAnd don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n\nUntil then, happy quantizing!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-30"}}
{"video": {"title": "Calculus for Machine Learning", "transcript": "####Calculus: The Secret Weapon of Machine Learning\nby Anshuman Singh - 2022-01-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Anshuman and welcome back to our channel! Today, we're diving into the second video of our Mathematics for Machine Learning and Data Science series.\n\nAnd guess what? We're talking about calculus! Now, I know what you're thinking. Calculus? Really? But trust me, this is one tool you don't want to miss out on. Calculus is like the secret weapon of machine learning, allowing us to understand how things change and optimize our models for maximum accuracy.\n\nWe'll start with the basics, covering derivatives and integrals. Then, we'll explore how calculus is used in machine learning, including gradient descent and backpropagation.\n\nSo, are you ready to unlock the power of calculus and take your machine learning skills to the next level? Let's get started!\n\n...\n\nThanks for watching, and I hope you found this video on calculus for machine learning helpful. If you did, please give this video a thumbs up and subscribe to our channel for more videos like this. And if you have any questions, please leave them in the comments below. See you in the next video!\n\n#### END TRANSCRIPT ########", "author": "Anshuman Singh", "publication_date": "2022-01-08"}}
{"video": {"title": "TensorFlow: Generative Deep Learning", "transcript": "####TensorFlow: Generative Deep Learning\nby Laurence Moroney, Eddy Shyu - 2022-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the exciting world of generative deep learning with TensorFlow.\n\nFirst up, we're going to demystify Variational Autoencoders, or VAEs. These models can learn to generate new data that's strikingly similar to the data they were trained on.\n\nNext, we're going to explore Generative Adversarial Networks, or GANs. These models can create incredibly realistic images, text, and even music. It's like having a digital artist in your toolkit.\n\nThen, we're going to delve into style transfer. This is where we take the style of one image and apply it to another. It's like turning a photograph into a painting, or vice versa.\n\nAnd finally, we're going to look at neural style transfer, a technique that combines the content of one image with the style of another. It's like creating a piece of art that's a blend of two different styles.\n\nSo, are you ready to create some art with TensorFlow? Let's get started.\n\nRemember, the best way to learn is by doing. So, try out these techniques for yourself, and see what you can create.\n\nThanks for watching, and happy coding!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-03-15"}}
{"video": {"title": "Implementing Industry Applications of Multimodal Search", "transcript": "####Implementing Industry Applications of Multimodal Search\nby Sebastian Witalec - 2022-10-07\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Sebastian here, and today we're diving into the exciting world of multimodal search. We'll be exploring how to implement industry applications that will blow your mind! From building multi-vector recommender systems to tackling real-world challenges, you won't want to miss this.\n\nStay tuned as we uncover the secrets of multimodal search and how it can revolutionize the way we interact with technology. Trust me, you'll want to stick around for this one!\n\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-07"}}
{"video": {"title": "Building a Custom Agent: A Step-by-Step Guide", "transcript": "####Building a Custom Agent: A Step-by-Step Guide\nby Jerry Liu - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and welcome back to our series on building agentic RAG systems with LlamaIndex.\n\nAre you ready to take your skills to the next level? Today, we're going to learn how to build a custom agent from scratch.\n\nBut first, let's talk about what a custom agent is and why you might need one. Custom agents are like your personal assistants, tailored to your specific needs. They can help you automate tasks, make decisions, and even learn from their mistakes.\n\nNow, let's dive into the design process. I'll show you how to build your own custom agent step by step. We'll cover everything from defining your agent's goals to training it to perform tasks.\n\nBut wait, there's more! We'll also talk about some best practices for building custom agents and some common pitfalls to avoid. Trust me, you don't want to miss this.\n\nBy the end of this video, you'll be able to build your own custom agent and tailor it to your specific needs. So, let's get started!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-10"}}
{"video": {"title": "Applying Deep Learning to Speech Recognition", "transcript": "####Applying Deep Learning to Speech Recognition: A Fun and Engaging Journey\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! It's your friendly AI guide, and today we're embarking on an exciting journey to apply deep learning to speech recognition.\n\nWe'll kick things off with the basics of speech recognition, including feature extraction, acoustic modeling, and language modeling. Then, we'll dive into building our own speech recognition system using Python, TensorFlow, and CNNs or RNNs.\n\nBy the end of this video, you'll have built your own speech recognition system and applied it to a real-world scenario. Trust me, it's going to be a blast!\n\nSo, are you ready to build your own speech recognition system? Let's get started!\n\nRemember, this video is part of our Deep Learning Specialization, so if you're new to the field, you might want to start with the basics first.\n\nAnd that's a wrap for today! I hope you enjoyed building your own speech recognition system as much as I did. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and having fun!\n\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2023-04-30"}}
{"video": {"title": "Diving Deeper into ML Math", "transcript": "####Diving Deeper into ML Math: Unraveling the Secrets!\nby Aarti Bagul - 2022-10-09\n\n#### BEGIN TRANSCRIPT ####\nHey there, math enthusiasts! Are you ready to unravel the secrets behind machine learning algorithms? Well, you're in luck because in this video, we're diving deeper into the mathematical concepts that make ML tick. From the basics of linear algebra to the wonders of calculus, we'll cover it all in a fun and engaging way. So, buckle up and get ready to have some fun with math!\n\nBut wait, you might be thinking, \"Math? Fun? Are you kidding me?\" Trust me, I've been there too. But with the right approach, math can be not only enjoyable but also incredibly empowering. And that's exactly what we're going to do in this video.\n\nSo, let's get started! First up, we'll take a look at linear algebra and how it forms the foundation of many ML algorithms. Then, we'll move on to calculus and see how it helps us optimize our models. And don't worry, we'll keep things simple and avoid any unnecessary jargon.\n\nBut that's not all! We'll also sprinkle in some humor and real-world examples to keep things interesting. And to make sure you're following along, we'll include plenty of interactive examples and exercises.\n\nSo, are you ready to become a math whiz and take your ML skills to the next level? Let's do this!\n#### END TRANSCRIPT ########", "author": "Aarti Bagul", "publication_date": "2022-10-09"}}
{"video": {"title": "Mistral AI: Getting Started with API Calls", "transcript": "####Mistral AI: Mastering API Calls for GenAI and LLM Applications\nby Younes Belkada and Marc Sun - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today I'm joined by my co-host Marc Sun. We're diving into the world of Mistral AI's API calls, and trust me, you won't want to miss this!\n\nMistral AI's API is your gateway to access and use their open-source and commercial models programmatically. In this video, we'll show you how to get started with API calls, and we'll even throw in some tips and tricks to make your experience even better.\n\nFirst, we'll walk you through setting up your development environment and obtaining an API key. Then, we'll demonstrate how to use the API to generate text, answer questions, and more.\n\nBut wait, there's more! We'll also show you how to use Mistral's JSON mode and user-defined functions with API calls, allowing you to create even more powerful GenAI and LLM applications.\n\nWhether you're a beginner or an experienced developer, Mistral AI's API has something for you. And the best part? It's easy to use and integrates seamlessly with your existing software applications.\n\nSo, what are you waiting for? Let's get started! And don't forget to like, share, and subscribe for more content on Mistral AI.\n\nA special thanks to our technology partner, Mistral AI, for making this video possible. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-15"}}
{"video": {"title": "Industry Applications of Multimodal Search", "transcript": "####Industry Applications of Multimodal Search\nby Sebastian Witalec - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Sebastian Witalec, and today we're diving into the fascinating world of multimodal search.\n\nBut first, let me ask you a question. Have you ever wished you could find exactly what you're looking for, no matter how you search for it? Well, that's where multimodal search comes in!\n\nMultimodal search is a game-changer, and it's already making waves in various industries. For instance, in e-commerce, it's being used to create multi-vector recommender systems. These systems can suggest products based on a variety of factors, like your preferences and the product's features.\n\nBut wait, there's more! In the healthcare industry, multimodal search is being used to retrieve relevant medical information based on different types of queries, such as text, images, and audio.\n\nAnd that's not all! We'll also explore some other thrilling applications of multimodal search in industries like entertainment and education.\n\nSo, are you ready to discover the endless possibilities of multimodal search? Let's get started! And remember, if you have any questions, feel free to leave a comment. We're all here to learn and grow together.\n\nAnd before I forget, don't forget to like, share, and subscribe for more exciting content. Until next time, happy searching!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2023-03-30"}}
{"video": {"title": "Linear Quantization: Symmetric vs. Asymmetric Mode", "transcript": "####Linear Quantization: Symmetric vs. Asymmetric Mode\nby Marc Sun, Younes Belkada - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Marc Sun, and today we're diving into the world of Linear Quantization. Specifically, we're comparing symmetric and asymmetric modes.\n\nFirst up, symmetric mode. It's the fair and balanced choice for quantization. It treats positive and negative numbers equally, making it a top pick for balanced data.\n\nBut what if your data isn't so balanced? Enter asymmetric mode. It's the rule-breaker of quantization, perfect for data that's heavily skewed towards positive or negative values. It quantizes positive and negative numbers differently, giving you more precision where you need it.\n\nSo, which one should you use? It all depends on your data. Symmetric mode is a great fit for balanced data, while asymmetric mode is the MVP for skewed data.\n\nRemember, practice makes perfect. So, get out there and start quantizing!\n\nAnd don't forget to like, share, and subscribe for more exciting content. Until next time, happy quantizing!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-03-20"}}
{"video": {"title": "AI in Disaster Management: Predicting and Responding to Natural Disasters", "transcript": "####AI in Disaster Management: Predicting and Responding to Natural Disasters\nby Robert Monarch - 2023-04-08\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Robert Monarch, and today we're diving into the fascinating world of AI and disaster management.\n\nWe'll kick things off by discussing how AI is revolutionizing the way we predict natural disasters like earthquakes, floods, and wildfires. Then, we'll explore how AI can help us prepare for and respond to these disasters more effectively.\n\nWe'll look at how AI can analyze data to predict disaster patterns, optimize evacuation routes, and improve emergency response times. We'll also delve into a real-world case study where AI has been used to save lives during a natural disaster.\n\nSo, are you ready to learn how AI can help us be better prepared for natural disasters? Let's get started!\n\nRemember, every bit of knowledge you gain about AI for good brings us one step closer to a safer future.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content on AI. Until next time, let's keep using AI for good.\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-08"}}
{"video": {"title": "Bias in GANs: Understanding and Mitigating the Impact", "transcript": "####Bias in GANs: Understanding and Mitigating the Impact\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-02-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eda Zhou, and today we're diving into the world of bias in GANs.\n\n[Video hook and introduction]\n\nGANs are a game-changer when it comes to generating realistic images, but they can also inadvertently perpetuate biases present in the training data. This can have serious real-world consequences, especially when GANs are used in applications like facial recognition or hiring.\n\nIn this video, we'll explore what bias in GANs looks like and what we can do to mitigate it.\n\n[Body content]\n\nBias in GANs can show up in many ways. For example, if a GAN is trained on a dataset that's mostly composed of light-skinned faces, it may struggle to generate realistic images of dark-skinned faces. This can lead to underrepresentation and misrepresentation of certain groups.\n\nTo tackle bias in GANs, we need to start with the training data. It's crucial to use diverse and representative datasets, and to carefully evaluate the results for any signs of bias.\n\nThere are also techniques for mitigating bias in the GAN itself. For example, we can use fairness constraints to ensure that the generator produces similar results for different groups.\n\nBut it's not just about the technology. We also need to consider the social and ethical implications of GANs and to use them responsibly.\n\n[Conclusion and call to action]\n\nSo, that's a quick rundown of bias in GANs and what we can do to mitigate it. If you want to learn more, check out our other videos on the topic. And if you have any questions or comments, leave them down below. We love hearing from you.\n\nThanks for watching, and we'll see you in the next video.\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-02-25"}}
{"video": {"title": "GANs in Action: Real-World Applications and Examples", "transcript": "####GANs in Action: Real-World Applications and Examples\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-03-07\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eric Zelikman, and today we're diving into the exciting world of GANs!\n\n[Video hook and introduction]\n\nGANs, or Generative Adversarial Networks, are a game-changer in the realm of AI. They can create realistic images that are almost indistinguishable from real ones. But what can we actually do with them? Let's explore some real-world applications of GANs.\n\n[Body content]\n\nFirst up, the field of art and design. GANs can generate new works of art in the style of your favorite artist or genre. They can also create innovative designs for products or buildings.\n\nNext, let's talk about medicine. GANs can generate synthetic medical images for research and training. They can also enhance the quality of medical images, making it easier to diagnose diseases.\n\nBut it's not all work and no play. GANs are also making waves in the entertainment industry. They can create realistic special effects for movies and video games. And they can even generate new music or sound effects.\n\nAnd let's not forget about security and surveillance. GANs can generate realistic images of people or objects for identification or tracking.\n\n[Conclusion and call to action]\n\nSo, there you have it, folks. A quick look at some real-world applications of GANs. If you want to learn more, be sure to check out our other videos. And don't forget to leave your questions and comments below. We love hearing from you.\n\nThanks for watching, and we'll see you in the next video.\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-03-07"}}
{"video": {"title": "Creating a Sentiment Analysis Dashboard with NLP and Hugging Face", "transcript": "####Creating a Sentiment Analysis Dashboard with NLP and Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Your Assistant here! Today, we're diving into the exciting world of sentiment analysis dashboards with NLP. Imagine being able to visualize the sentiment of your data in real-time. Sounds cool, right? Let's get started!\n\nFirst things first, what's a sentiment analysis dashboard? It's a tool that allows you to monitor and analyze the sentiment of your data, in real-time.\n\nWith Hugging Face, we can build a sentiment analysis dashboard in just a few simple steps. We'll show you how to prepare your data, train your model, and deploy your app.\n\nBut wait, there's more! We'll also cover some advanced techniques for improving your dashboard's performance, like data preprocessing and model evaluation. And don't worry, we'll explain everything in a clear and simple way, so you won't get lost in the details.\n\nSo, are you ready to create your own sentiment analysis dashboard with NLP and Hugging Face? Let's do this!\n\nThat's all for today's video. If you enjoyed it, don't forget to hit that like button and subscribe for more content. And if you're ready to start building your own sentiment analysis dashboard, check out the links in the description for some great resources. See you next time!\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-04-30"}}
{"video": {"title": "ChatGPT Prompt Engineering: A Comprehensive Guide for Beginners", "transcript": "Positive Points:\n\n- Clear introduction of the topic and its importance.\n- Use of active voice and simple language.\n- Encouragement of experimentation and practice.\n- Positive and enthusiastic tone.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.\n- Improve contrast and pacing to maintain interest.\n- Leverage storytelling to make the content more relatable and engaging.", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-21"}}
{"video": {"title": "The Future of Generative AI", "transcript": "####The Future of Generative AI\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-05-13\n\n#### BEGIN TRANSCRIPT ####\nHey there, Chris Fregly here, and today we're going to dive into the thrilling world of generative AI!\n\nGenerative AI is a rapidly evolving field, with new research and developments emerging all the time. In this video, we'll discuss the latest trends and predictions for the future of generative AI, and explore how it could impact various industries and aspects of society.\n\nWe'll also talk about the ethical considerations of generative AI, and discuss best practices for developing and deploying generative AI systems responsibly.\n\nBy the end of this video, you'll have a solid understanding of the future of generative AI and the potential impact it could have on society. You'll be able to stay up-to-date on the latest developments in the field and contribute to the responsible development and deployment of generative AI systems.\n\nSo, let's get started and explore the exciting future of generative AI!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-05-13"}}
{"video": {"title": "Unleashing the Power of NLP with Hugging Face", "transcript": "####Unleashing the Power of NLP with Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes, and today we're embarking on an exciting journey into the world of Natural Language Processing, or NLP for short. We're going to design apps that can answer questions, analyze sentiment, translate languages, and even summarize text!\n\nFirst up, let's talk about question-answering. Imagine having an app that can answer any question you have about a document. With NLP, that's a reality! We'll be using Hugging Face, our technology partner, to make this happen.\n\nNext, we'll explore sentiment analysis. This is where our app can determine if a piece of text is positive, negative, or neutral. It's incredibly useful for analyzing reviews or social media posts.\n\nThen, we'll venture into language translation. With NLP, we can build an app that translates text from one language to another. It's like having your own personal translator!\n\nLastly, we'll look at summarization. Our app will be able to read a long piece of text and provide a short summary. It's perfect for when you don't have time to read a lengthy document.\n\nRemember, NLP is a powerful tool, but it's not perfect. It's always improving, and you can be a part of that improvement.\n\nSo, are you ready to start building? Let's get started! And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, keep exploring and innovating.\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-03-15"}}
{"video": {"title": "Optimizing AI Agents with LangGraph and Tavily's Agentic Search", "transcript": "####Optimizing AI Agents with LangGraph and Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-04-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! Today, we're diving into the world of AI optimization with LangGraph and Tavily's agentic search.\n\nFirst, we'll uncover how LangGraph's components can supercharge our AI agents. It's like having a Swiss Army knife for our agents' performance.\n\nThen, we'll demonstrate how to integrate Tavily's agentic search capabilities to take our optimization to the next level.\n\nIn this course, you'll learn directly from Harrison Chase, the mastermind behind LangChain, and Rotem Weiss, the brain behind Tavily. They'll walk you through the optimization process and share their insider tips.\n\nRemember, this course is perfect for intermediate Python users who want to master AI agent optimization.\n\nSo, are you ready to become an AI agent optimization guru? Let's get started!\n\nStay tuned for more thrilling lessons. And don't forget to like, share, and subscribe for more AI-powered content.\n\nUntil next time, happy optimizing!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-19"}}
{"video": {"title": "Convolutional Neural Networks and Image Classification", "transcript": "####Convolutional Neural Networks and Image Classification\nby Laurence Moroney - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Laurence Moroney, and today we're diving into the fascinating world of convolutional neural networks (CNNs) and how they're revolutionizing image classification tasks in TensorFlow.\n\n[Video hook and introduction]\n\nCNNs are like superheroes for computers, automatically learning and extracting features from images, making them perfect for computer vision tasks. Let's get started!\n\n[Body content]\n\nFirst, we'll demystify the architecture of a CNN, including convolutional layers, pooling layers, and fully connected layers. We'll also cover the concept of filters, or kernels, and how they help extract features from images.\n\nNext, we'll walk through building and training a CNN in TensorFlow for an image classification task. We'll use a popular dataset, such as CIFAR-10 or ImageNet, to train our model and evaluate its performance.\n\nWe'll also discuss techniques for improving the performance of our CNN, such as data augmentation, transfer learning, and fine-tuning.\n\n[Conclusion and call to action]\n\nBy the end of this video, you'll have a solid understanding of convolutional neural networks and how to use them for image classification tasks in TensorFlow.\n\nDon't forget to like, share, and subscribe for more AI and machine learning content. Join me in the next video, where we'll explore the exciting world of recurrent neural networks and their applications in natural language processing. See you there!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2023-04-01"}}
{"video": {"title": "Implementing Weights Packing: Pack Four 2-bit Weights into a Single 8-bit Integer", "transcript": "####Implementing Weights Packing: Pack Four 2-bit Weights into a Single 8-bit Integer\nby Marc Sun, Younes Belkada - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, data compression enthusiasts! I'm Marc Sun, and today we're diving into the world of weights packing. This technique allows us to squeeze four 2-bit weights into a single 8-bit integer, giving us even more data compression power.\n\nFirst, we'll cover the basics of weights packing. Then, we'll roll up our sleeves and implement it in Pytorch. We'll break down each part of the code, so you understand exactly how it works.\n\nBy the end of this video, you'll have another powerful tool in your data compression toolkit.\n\nRemember, practice makes perfect. So, get out there and start quantizing!\n\nAnd don't forget to like, share, and subscribe for more exciting content. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2023-04-05"}}
{"video": {"title": "Automating LLM Red Teaming with Giskard's Open-Source Library", "transcript": "####Automating LLM Red Teaming with Giskard's Open-Source Library\nby Matteo Dora, Luca Martial - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, LLM fans! I'm Luca Martial and today we're diving into the world of automating your LLM red teaming with Giskard's open-source library.\n\nGiskard's library is packed with tools and resources to help you spot, assess, and tackle vulnerabilities in your LLM applications. And the cherry on top? It's all automated!\n\nWith Giskard, you can run adversarial tests, bias audits, and privacy tests with just a few lines of code. It's a real game-changer for both newbies and pros.\n\nSo, how do you kickstart your journey with Giskard? First, you'll need to install the library. Then, you can start using its various functions to put your app to the test.\n\nRemember, while Giskard is a mighty tool, it's not a substitute for human intuition. Always review the results of your automated tests and trust your gut when deciding how to handle vulnerabilities.\n\nThanks for tuning in. Don't forget to like, share, and subscribe for more content on LLM applications. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-04-10"}}
{"video": {"title": "Diffusion Models: The Art of Predicting Spread", "transcript": "####Diffusion Models: The Art of Predicting Spread\nby Sharon Zhou - 2023-03-21\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Sharon Zhou, and today we're going to explore the fascinating world of diffusion models.\n\nDiffusion models are like the secret agents of data science. They help us understand how things spread or diffuse over time and space. Think of it like how a rumor spreads through a school, or how a disease spreads through a population.\n\nBut enough talk, let's get our hands dirty! Open up your Python environment, and make sure you've got Tensorflow or Pytorch installed. We'll start by defining our model, then we'll feed in our data, and finally, we'll train our model.\n\nAnd here's the cherry on top! I'll show you how to speed up your sampling process by 10 times. We'll implement some algorithms that will make your sampling process faster than a cheetah on roller skates.\n\nBut wait, there's more! I'll also share some real-world applications of diffusion models that will blow your mind.\n\nAnd that's all for today, folks! You've just learned how to build and train your own diffusion model, and even how to speed up the sampling process. Don't forget to hit that like button, subscribe, and share this video with your friends. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2023-03-21"}}
{"video": {"title": "LangChain Loaders: Accessing Your Data with Ease", "transcript": "####LangChain Loaders: Access Your Data with Ease\nby Harrison Chase - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, LangChain enthusiasts! I'm Harrison Chase, your guide to the world of LangChain, and today we're diving into the exciting topic of LangChain loaders.\n\nAre you tired of wrestling with complex data sources? Well, buckle up, because LangChain loaders are about to make your life a whole lot easier!\n\nBut first, let me introduce myself. I'm the creator of LangChain, and I'm passionate about helping you harness the power of this incredible tool.\n\nSo, what are LangChain loaders? Simply put, they're modules that handle accessing various data sources. And with over 80 unique loaders available, you can connect your chatbot or personal data assistant to a wide range of data sources.\n\nIn this video, we'll be exploring some of the most popular loaders and how to use them. We'll start with the basics of installing and importing loaders, and then we'll dive into some examples of how to use them to extract data from your documents and data sources.\n\nWe'll cover loaders for PDFs, databases, web pages, and more. By the end of this video, you'll have a solid understanding of how to use LangChain loaders to access your data with ease.\n\nBut wait, there's more! We'll also be sprinkling in some humor and practical tips to keep things interesting.\n\nSo, are you ready to get started? Let's dive in and start exploring the world of LangChain loaders!\n\nAnd remember, if you have any questions or need help along the way, feel free to reach out to me on social media or through the LangChain website.\n\nThanks for watching, and happy coding!\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-25"}}
{"video": {"title": "On-Device AI: A New Era of Edge Computing", "transcript": "####On-Device AI: Unleashing the Power of Edge Computing\nby Krishna Sridhar - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're embarking on an exciting journey into the world of On-Device AI!\n\nImagine having AI right at your fingertips, on your smartphone or other edge devices. That's the magic of On-Device AI. It harnesses the local compute power of your device for faster and more secure inference. No more waiting for cloud processing!\n\nFirst, let's chat about model conversion. If you're comfortable with Python, PyTorch, or TensorFlow, you're in for a treat! We'll learn how to convert these models for device compatibility. It's like translating AI language for your device to understand.\n\nNext up, quantization. It's a fancy term for reducing model size while achieving performance gains. Think of it like packing a suitcase efficiently - more space, less weight, but still having everything you need.\n\nNow, let's get our hands dirty with device integration. We'll explore runtime dependencies and how GPU, NPU, and CPU compute unit utilization affect performance. It's like understanding how different engines in a car work together to give you a smooth ride.\n\nAnd guess what? We're teaming up with Qualcomm to bring you this thrilling adventure. So, fasten your seatbelts and get ready to redefine the way you think about AI!\n\nRemember, practice makes perfect, keep exploring, and don't forget to like, share, and subscribe for more exciting content. Until next time, this is Krishna Sridhar, signing off.\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2023-03-15"}}
{"video": {"title": "Supercharging AI Agents with Tavily's Agentic Search", "transcript": "####Supercharging AI Agents with Tavily's Agentic Search\nby Harrison Chase, Rotem Weiss - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, AI enthusiasts! Are you ready to level up your AI agents? Today, we're diving into the world of Tavily's agentic search and how it can supercharge your agents.\n\nBut first, what exactly is agentic search? It's a game-changer that boosts your agents' knowledge and performance, making them more efficient and effective at completing tasks.\n\nSo, how do we integrate it with LangGraph? Don't worry, it's easier than you think!\n\nWe'll start by breaking down how agentic search works and how it can benefit your AI agents.\n\nThen, we'll walk you through the process of integrating it with LangGraph, step by step.\n\nBy the end of this video, you'll be able to create AI agents that are not only controllable but also supercharged with agentic search capabilities.\n\nSo, are you ready to take your AI agents to the next level? Let's get started!\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-03-25"}}
{"video": {"title": "Mastering Deep Learning Specialization: CNNs, RNNs, LSTMs, and Transformers", "transcript": "####Mastering Deep Learning Specialization: CNNs, RNNs, LSTMs, and Transformers\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2023-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, deep learning enthusiasts! I'm your host, and today we're embarking on an exciting journey through the world of deep learning specialization. We'll be building neural networks like CNNs, RNNs, LSTMs, and Transformers, and applying them to speech recognition, NLP, and more, all using Python and TensorFlow.\n\nFirst up, let's talk about CNNs, or Convolutional Neural Networks. These are the rockstars of image processing tasks, like recognizing faces or objects in photos. We'll walk through how to build one from scratch and then use it to solve a real-world problem.\n\nNext, we have RNNs, or Recurrent Neural Networks. These are perfect for tasks that involve sequential data, like time series analysis or natural language processing. We'll explore how RNNs work and how to train them effectively.\n\nThen, we'll move on to LSTMs, or Long Short-Term Memory networks. These are a special type of RNN that can handle long-term dependencies in data, making them ideal for tasks like machine translation or speech recognition.\n\nFinally, we'll cover Transformers, the state-of-the-art architecture for natural language processing tasks. We'll see how they work and how to use them to build powerful NLP models.\n\nThroughout the video, we'll be using Python and TensorFlow to build and train our models, so make sure you have those installed before we get started.\n\nNow, let's wrap things up. Deep learning is a powerful tool that can solve a wide range of problems, from image recognition to natural language processing. With the skills you've learned in this video, you'll be able to build and train your own neural networks and apply them to real-world tasks. So what are you waiting for? Get out there and start building!\n\nThanks for watching, and don't forget to like, share, and subscribe for more great content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2023-02-15"}}
{"video": {"title": "Real-World Applications of Knowledge Graphs for RAG", "transcript": "Hi there, I'm Andreas Kollegger and today we're diving into the exciting world of real-world applications of knowledge graphs for Retrieval Augmented Generation or RAG.\n\nIf you're new to LangChain, I highly recommend checking out our short course 'LangChain: Chat with Your Data' before jumping into this intermediate level content.\n\nNow, let's get started. We'll be using Neo4j's query language, Cypher, to manage and retrieve data from our knowledge graph.\n\nIn this video, we'll be discussing some real-world applications of knowledge graphs for RAG, from chatbots to recommendation systems. We'll also be providing some case studies and examples to illustrate these applications.\n\nSo, are you ready to explore some real-world applications of knowledge graphs for RAG? Let's get started!\n\nRemember, the possibilities for knowledge graphs and RAG are endless. So, don't be afraid to think outside the box and innovate. And if you have any questions, feel free to leave them in the comments below.\n\nThanks for watching and happy coding!", "author": "Andreas Kollegger", "publication_date": "2023-04-30"}}
{"video": {"title": "Advanced Techniques for LLM Application Development", "transcript": "####Advanced Techniques for LLM Application Development\nby Harrison Chase, Andrew Ng - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Harrison Chase here, and today we're diving into the exciting world of LLM application development.\n\nFirst up, we'll learn how to fine-tune your LLM. This will give you the power to boost its performance on specific tasks.\n\nNext, we'll explore multi-task learning. Imagine your LLM juggling multiple tasks at once, like a tech superhero!\n\nFinally, we'll uncover some techniques for evaluating your LLM. This will help you measure its performance and spot areas for improvement.\n\nBy the end of this video, you'll be a certified LLM application development pro.\n\nSo, let's get started. Remember, the best way to learn is by doing.\n\nThanks for watching. Don't forget to like, share, and subscribe for more thrilling content. See you in the next video, where we'll continue to demystify the world of AI.\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-20"}}
{"video": {"title": "Deep Learning Future: Trends and Predictions", "transcript": "####Deep Learning Future: Trends and Predictions Unveiled\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2022-02-26\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI aficionados! Are you ready to take a peek into the future of deep learning?\n\nToday, we're diving into the latest trends and predictions, like the surge of explainable AI, the growing use of AI in healthcare, and the potential game-changer that is quantum computing in AI.\n\nRemember, the future of AI is not written in stone. It's in our hands, the developers, to mold it.\n\nSo, let's embark on this exciting journey and discover what the future might have in store for us. And don't forget, your thoughts and ideas are priceless, so don't hesitate to share them in the comments.\n\nThat's a wrap for today's video. If you enjoyed it, give it a thumbs up and subscribe to our channel for more AI goodness. Until next time, keep exploring the AI universe!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-02-26"}}
{"video": {"title": "Building JavaScript RAG Web Apps with LlamaIndex", "transcript": "####Building JavaScript RAG Web Apps with LlamaIndex\nby Laurie Voss - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, JavaScript enthusiasts! Welcome to today's video where we'll be exploring the thrilling world of building RAG web apps with LlamaIndex. I'm Laurie Voss, your friendly coding guide, and I'm super excited to take you on this beginner-friendly journey.\n\nSo, why should you care about RAG web apps and LlamaIndex? Well, buckle up, because we're about to uncover some game-changing secrets that will make your coding life easier and more fun.\n\nBut first, let's get started with the basics. What is a RAG web app, and how does LlamaIndex fit into the picture? Stay tuned to find out!\n\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2022-10-15"}}
{"video": {"title": "Advanced Knowledge Graph Queries for RAG", "transcript": "####Advanced Knowledge Graph Queries for RAG\nby Andreas Kollegger - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andreas Kollegger here! Today, we're going to dive into some advanced knowledge graph queries for Retrieval Augmented Generation or RAG.\n\nBut first, a quick heads up. If you're new to LangChain, I recommend checking out our short course 'LangChain: Chat with Your Data' before diving into this intermediate level content.\n\nNow, let's get started. We'll be using Neo4j's query language, Cypher, to manage and retrieve data from our knowledge graph.\n\nIn this video, we'll walk you through writing complex knowledge graph queries that find and format text data to provide more relevant context to LLMs for RAG.\n\nWe'll also discuss some advanced features of Cypher that you can use to improve the performance and functionality of your RAG applications.\n\nSo, are you ready to tackle some advanced knowledge graph queries? Let's get started!\n\nRemember, the key to mastering advanced queries is practice. So, don't be afraid to try, fail, and try again. And if you have any questions, feel free to leave them in the comments below.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2023-04-05"}}
{"video": {"title": "Building Your Own Database Agent", "transcript": "####Building Your Own Database Agent\nby Adrian Gonzalez Sanchez - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! Welcome to today's video where we're going to have a blast building our own database agent. I'm Adrian Gonzalez Sanchez, and I'm thrilled to show you how to interact with tabular data and SQL databases using natural language. This is going to make data analysis more efficient and accessible than ever before. So, are you ready to revolutionize your data game? Let's dive in!\n#### END TRANSCRIPT ########", "author": "Adrian Gonzalez Sanchez", "publication_date": "2022-10-15"}}
{"video": {"title": "Understanding the Architecture of GANs", "transcript": "####Understanding the Architecture of GANs\nby Eda Zhou - 2022-10-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Eda Zhou here, and today we're diving into the fascinating world of Generative Adversarial Networks, or GANs for short. We'll uncover the secrets behind their architecture and how they're revolutionizing image generation. So, buckle up and let's get started!\n#### END TRANSCRIPT ########", "author": "Eda Zhou", "publication_date": "2022-10-03"}}
{"video": {"title": "LangChain: The Future of Data Interaction", "transcript": "####LangChain: The Future of Data Interaction\nby Harrison Chase - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! I'm Harrison Chase, and today we're diving into the exciting world of LangChain, a tool that's revolutionizing the way we interact with data.\n\nImagine having a personal assistant that can read and understand all your documents and data. That's exactly what we're going to create today!\n\nLangChain is a powerful tool with over 80 unique loaders, allowing you to handle different types of data, from PDFs to databases. But we're not just going to stop there. We're going to build a chatbot that can chat directly with information from your own documents and data.\n\nI'll be guiding you through each step, making sure to keep things simple and easy to understand. By the end of this video, you'll have your own chatbot ready to assist you with your data needs.\n\nSo, are you ready to explore the future of data interaction with LangChain? Let's get started!\n\nRemember, if you have any questions, feel free to leave a comment. I'm always here to help. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-04-10"}}
{"video": {"title": "Quantization in On-Device AI", "transcript": "####Quantization in On-Device AI: A Game Changer for Efficient AI\nby Krishna Sridhar - 2022-01-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're diving into the exciting world of quantization in On-Device AI. Trust me, you won't want to miss this!\n\nQuantization is a powerful technique that can significantly improve the performance and reduce the size of your AI models. But how does it work? Let's find out!\n\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-01-25"}}
{"video": {"title": "Unlocking the Power of Memory in LangChain", "transcript": "####Unlocking the Power of Memory in LangChain\nby Harrison Chase, Andrew Ng - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Harrison Chase here! Are you ready to unlock the power of memory in LangChain?\n\nMemory is the secret sauce that can make your LLM application truly shine. It allows your application to remember previous interactions, creating personalized experiences that users will love.\n\nIn this video, we'll start by learning how to add memory to our LLM. I'll show you how to store and retrieve information like a pro.\n\nBut we won't stop there. We'll also dive into some advanced techniques. You'll learn how to use memory to influence the behavior of your LLM, giving it a personality that users will love.\n\nBy the end of this video, you'll be a memory master. So, let's get started! Remember, the best way to learn is by doing.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. And, as always, I'll see you in the next video.\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-03-30"}}
{"video": {"title": "Machine Learning Project: Image Classification", "transcript": "####Machine Learning Project: Image Classification\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-02-26\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! Your favorite host is back with an exciting new project. Today, we're diving into the world of Image Classification using Machine Learning. Are you ready to level up your skills?\n\nFirst things first, we'll start with a dataset of images. We'll walk you through the process of preparing the data for our model. This includes cleaning the data, handling missing values, and converting images into numbers. It's like translating a foreign language, but for machines!\n\nNext, we'll split our data into a training set and a test set. The training set is used to teach our model, while the test set is used to see how well it's learned. It's like giving your model a pop quiz!\n\nThen, we'll build our model. We'll start with a simple convolutional neural network and show you how to train it using our training data. It's like teaching a child to ride a bike, but for machines!\n\nBut wait, there's more! We'll also teach you how to evaluate your model using metrics like accuracy and precision. And we'll do it all with practical examples, so you can see how it's done in the real world.\n\nRemember, the best way to learn is by doing, so don't be afraid to get your hands dirty. So, are you ready to classify images with Machine Learning? Let's get started! And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-02-26"}}
{"video": {"title": "TensorFlow for Time Series Analysis", "transcript": "####TensorFlow for Time Series Analysis\nby Laurence Moroney - 2022-02-12\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, time series enthusiasts! I'm Laurence Moroney, and today we're diving into the exciting world of time series analysis with TensorFlow.\n\n[Video hook and introduction]\n\nAre you ready to unlock the secrets of time and build models that can predict the future? Then buckle up, because we're about to embark on an epic journey!\n\n[Body content]\n\nFirst, we'll cover the basics of time series analysis and how TensorFlow fits into the picture. We'll explore essential concepts like stationarity, seasonality, and trends.\n\nThen, we'll dive into building our first time series model. We'll use a simple dataset to forecast future values and learn how to train, evaluate, and optimize our model. You'll also discover how to use pre-trained models and transfer learning to speed up the process.\n\nWe'll also explore real-world applications of time series analysis, like stock price prediction and energy demand forecasting. Plus, we'll cover advanced topics like recurrent neural networks (RNNs) and long short-term memory (LSTM) networks.\n\n[Conclusion and call to action]\n\nSo, are you ready to become a time series analysis master with TensorFlow? Let's get started! Remember, practice makes perfect, so make sure to follow along and code with me. See you in the first lesson!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-02-12"}}
{"video": {"title": "TensorFlow for Unsupervised Learning", "transcript": "####TensorFlow for Unsupervised Learning\nby Laurence Moroney - 2022-03-05\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Laurence Moroney, and today we're diving into the world of unsupervised learning with TensorFlow!\n\n[Video hook and introduction]\n\nAre you ready to build models that can uncover hidden patterns and structures in your data? Let's get started!\n\n[Body content]\n\nFirst, we'll cover the basics of unsupervised learning and how TensorFlow fits into the picture. We'll explore essential concepts like clustering, dimensionality reduction, and autoencoders.\n\nThen, we'll dive into building our first unsupervised learning model. We'll use a simple dataset to discover hidden patterns and learn how to train, evaluate, and optimize our model. You'll also discover how to use pre-trained models and transfer learning to speed up the process.\n\nWe'll also explore real-world applications of unsupervised learning, like anomaly detection and data compression. Plus, we'll cover advanced topics like variational autoencoders (VAEs) and generative adversarial networks (GANs).\n\n[Conclusion and call to action]\n\nSo, are you ready to master unsupervised learning with TensorFlow? Let's get started! Remember, the best way to learn is by doing, so make sure to follow along and code with me. See you in the first lesson!\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-03-05"}}
{"video": {"title": "Advanced Techniques in LLMs for Generative AI", "transcript": "####Advanced Techniques in LLMs for Generative AI\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Shelbee Eigenbrode here, and today we're diving into the exciting world of advanced techniques in LLMs for generative AI.\n\nFirst, we'll explore the latest research in generative AI and how it's pushing the boundaries of what's possible with LLMs. Trust me, you won't want to miss this!\n\nWe'll also delve into advanced techniques, such as transfer learning and meta-learning, to take your LLMs to the next level.\n\nThen, we'll get our hands dirty with some specialized use-cases, like generating music and images, and how LLMs can be applied in these areas. Don't worry, we'll be using practical examples and code snippets to help you understand the concepts better.\n\nBy the end of this video, you'll have a deeper understanding of advanced techniques in LLMs for generative AI and be ready to take on the world of AI.\n\nSo, let's get started! See you in the course.\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-17"}}
{"video": {"title": "Crafting Custom Chatbots with ChatGPT: A Hands-On Guide", "transcript": "####Crafting Custom Chatbots with ChatGPT: A Hands-On Guide\nby Isa Fulford - 2022-10-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, chatbot enthusiasts! It's your favorite AI influencer, Isa Fulford, and today we're embarking on an exciting journey. We're going to roll up our sleeves and dive headfirst into the world of custom chatbot development with ChatGPT. Are you ready to unleash your creativity and build your own chatbot from scratch? Let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-25"}}
{"video": {"title": "Deep Learning Optimization: Tips and Tricks", "transcript": "Hello, AI enthusiasts! Are you ready to take your deep learning models to the next level? Today, we're sharing some tips and tricks to help you optimize your models like a pro!\n\nWe'll be discussing techniques like learning rate scheduling, batch normalization, and early stopping. And don't worry, we'll show you how to implement these techniques using Python and TensorFlow.\n\nBut remember, optimization is all about finding the right balance. It's not about using every technique in the book, but rather choosing the ones that work best for your specific model and data.\n\nSo, let's get started! And remember, practice makes perfect, so don't be afraid to experiment with different techniques.\n\nAnd before we wrap up, we have a little challenge for you. Try implementing these optimization techniques on your own deep learning model and see how much you can improve its performance.\n\nThat's it for today's video. If you enjoyed it, don't forget to hit that like button and subscribe to our channel for more AI content. And if you have any questions or comments, leave them down below. We love hearing from you!\n\nUntil next time, happy optimizing!", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2022-02-12"}}
{"video": {"title": "From Prototype to Production: Your ML Journey", "transcript": "####From Prototype to Production: Your ML Journey\nby Andrew Ng - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here, and today we're diving into the exciting world of Machine Learning! Specifically, we're talking about how to take your ML prototype and turn it into a production-ready system.\n\nFirst things first, let's define our terms. A prototype is a working model of your ML solution, but it's not ready for the real world. A production system, on the other hand, is robust, scalable, and secure.\n\nSo, how do we get from prototype to production? It starts with planning. We need to think about how our system will handle real-world data, how it will scale to meet demand, and how we'll monitor and maintain it.\n\nNext, we need to build our system. This involves setting up our infrastructure, deploying our model, and testing everything thoroughly. But the journey doesn't end there. Once our system is live, we need to continuously monitor and improve it. This involves collecting feedback, analyzing performance, and making updates as needed.\n\nBut don't worry, I'm here to guide you every step of the way. So, are you ready to take your ML prototype to the next level? Start planning your production system today, and remember, the journey doesn't end when the system goes live. It's just the beginning!\n\nThanks for watching, and don't forget to like, share, and subscribe for more exciting content on Machine Learning. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-20"}}
{"video": {"title": "Mastering Question Answering with LangChain", "transcript": "####Mastering Question Answering with LangChain\nby Harrison Chase, Andrew Ng - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're diving into the exciting world of question answering with LangChain.\n\nQuestion answering is a game-changer, allowing your application to answer complex questions. Sounds fun, right?\n\nFirst, we'll demystify how question answering works in LangChain. We'll explore the technology behind it and how it empowers our application to understand and answer questions.\n\nNext, we'll roll up our sleeves and get into the code. We'll leverage LangChain's question answering features to create a specialized chatbot. This chatbot will be able to answer questions based on your unique data.\n\nAnd the cherry on top? We'll use agents and chained calls to supercharge our chatbot.\n\nNow, let's recap. You've learned how question answering works in LangChain, how to use it to build a chatbot, and how to boost your chatbot with agents and chained calls.\n\nSo, what's next? I challenge you to build your own chatbot and enhance it with question answering features.\n\nThanks for tuning in. If you found this tutorial helpful, give it a thumbs up and don't forget to subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-03-25"}}
{"video": {"title": "GANs for Medical Imaging: Advances and Challenges", "transcript": "####GANs for Medical Imaging: Advances and Challenges\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-03-27\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Eda Zhou, and today we're diving into the fascinating world of GANs for medical imaging.\n\n[Video hook and introduction]\n\nGANs, or Generative Adversarial Networks, are a game-changer in the realm of image generation. And when it comes to medical imaging, they're opening up a whole new world of possibilities. But don't just take my word for it, let's explore together!\n\n[Body content]\n\nFirst up, let's talk about image synthesis. GANs can create new medical images that are eerily similar to the real deal. This can be a real game-changer for research and training, not to mention enhancing the quality of medical images.\n\nBut wait, there's more! GANs can also be used for image segmentation. This means they can automatically segment medical images, making it easier to diagnose diseases.\n\nHowever, it's not all sunshine and rainbows. Medical images can be complex and high-dimensional, which can make it tricky to generate realistic images. And let's not forget about the ethical considerations around using synthetic medical images for research and diagnosis.\n\n[Conclusion and call to action]\n\nSo, there you have it, a quick overview of using GANs for medical imaging. If you're as excited about this as I am, be sure to check out our other videos on the topic. And if you have any questions or comments, leave them down below. We love hearing from you!\n\nThanks for watching, and we'll catch you in the next video.\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-03-27"}}
{"video": {"title": "Advanced Techniques for Training LLMs", "transcript": "####Advanced Techniques for Training LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-04-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, Mike Chambers here, and today we're going to dive into some advanced techniques for training LLMs.\n\nTraining an LLM can be a complex and computationally intensive process, but don't worry, we've got you covered! We'll discuss some of the most effective techniques, such as using curriculum learning to gradually increase the difficulty of the training data, and implementing mixed precision training to reduce the memory footprint of the model.\n\nWe'll also talk about some of the challenges of training LLMs, such as the need for large amounts of data and computational resources, and some potential solutions to these challenges, such as using data augmentation and synthetic data generation.\n\nBy the end of this video, you'll have a better understanding of some advanced techniques for training LLMs and some ideas for how to improve the performance of your own models. So let's get started!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-04-19"}}
{"video": {"title": "Future Trends: The Evolution of ML Production Systems", "transcript": "####Future Trends: The Evolution of ML Production Systems\nby Andrew Ng - 2023-04-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Andrew Ng here, and today we're diving into the exciting world of future trends in ML production systems.\n\nWe'll explore how technologies like autoML, MLOps, and edge computing are revolutionizing the way we build and deploy ML models. We'll discuss their potential benefits and challenges, and why they matter to you.\n\nWe'll also look at some emerging applications of ML, such as autonomous vehicles, personalized medicine, and smart cities. Trust me, you won't want to miss this!\n\nBut remember, the future of ML is not just about technology, but also about people and society. So, let's get started!\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and keep innovating!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-30"}}
{"video": {"title": "ML Ops: Best Practices for Machine Learning in Production", "transcript": "####ML Ops: Best Practices for Machine Learning in Production\nby Andrew Ng - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here, and today we're diving into the exciting world of ML Ops, or best practices for machine learning in production.\n\nFirst things first, why is ML Ops so important? When we're deploying machine learning models in production, we need to ensure they're reliable, scalable, and maintainable. ML Ops provides a set of best practices to help us achieve these goals.\n\nSo, how do we do it? It all starts with version control. We need to use version control systems like Git to manage our code, data, and models. We'll talk about how to set up version control for machine learning workloads and how to use it to track changes and collaborate with others.\n\nNext up, testing. We need to use testing frameworks like pytest or unittest to test our code, data, and models. We'll talk about how to write effective tests for machine learning workloads and how to use them to catch issues early.\n\nThen, we need to think about deployment. We need to use deployment frameworks like Kubernetes or Docker to deploy our models in production. We'll talk about how to set up deployment pipelines for machine learning workloads and how to use them to automate deployment and scaling.\n\nBut wait, there's more! ML Ops is not just about technology. It's also about people and processes. We'll talk about how to collaborate with data engineers, DevOps teams, and business stakeholders to ensure our ML Ops strategy is aligned with the overall business goals.\n\nSo, are you ready to learn about ML Ops and how to apply best practices to your machine learning workloads in production? Let's get started!\n\nRemember, ML Ops is not just about technology. It's about people, processes, and culture. So keep learning, keep experimenting, and most importantly, have fun!\n\nIf you found this video helpful, be sure to give it a thumbs up and subscribe for more content. And if you have any questions or suggestions, leave them in the comments below. Thanks for watching, and I'll see you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-04-25"}}
{"video": {"title": "Controlling Your Research Agent", "transcript": "####Controlling Your Research Agent: Mastering the Art of Command\nby Jerry Liu - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu, and today we're diving into the exciting world of controlling your research agent.\n\nThat's right, we're going to learn how to make your agent dance to your tune. Because sometimes, you need your agent to follow your lead.\n\nFirst, we'll go over how to give your agent clear instructions. It's like giving your agent a to-do list, but better.\n\nNext, we'll talk about how to monitor your agent's progress. Because sometimes, you need to keep an eye on your agent to make sure it's not slacking off.\n\nThen, we'll discuss how to adjust your agent's behavior. Because sometimes, your agent needs a little nudge in the right direction.\n\nAnd finally, we'll go over some tips and tricks for getting the most out of your research agent.\n\nSo, are you ready to take control of your research agent? Let's get started!\n\nRemember, controlling your agent is all about communication. So, don't be afraid to tell your agent exactly what you want it to do.\n\nThanks for watching and happy coding!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-04-25"}}
{"video": {"title": "Master TensorFlow and Boost Your AI Career", "transcript": "####Master TensorFlow and Boost Your AI Career\nby Laurence Moroney - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, AI enthusiasts! I'm Laurence Moroney, and today we're embarking on an exciting journey into the world of TensorFlow!\n\n[Video hook and introduction]\n\nAre you ready to build scalable AI applications and take your skills to the next level? Then you've come to the right place! In this video series, we'll explore TensorFlow, the powerful open-source library for machine learning and artificial intelligence.\n\n[Body content]\n\nFirst, we'll get you comfortable with the TensorFlow environment. You'll learn how to install it, set it up, and navigate its features. We'll also cover essential TensorFlow concepts like tensors, variables, and operations.\n\nOnce we've got the basics down, we'll move on to building models. We'll start with simple linear regression and work our way up to complex neural networks. You'll learn how to train, evaluate, and optimize your models for the best results.\n\nWe'll also dive into computer vision and natural language processing. You'll discover how to use TensorFlow to build image recognition systems and chatbots. Plus, we'll explore real-world applications like self-driving cars and personalized recommendations.\n\nAnd guess what? All these new skills will not only help you in your current projects but also prepare you for the Google TensorFlow Developer Certificate exam. How cool is that?\n\n[Conclusion and call to action]\n\nSo, are you ready to become a TensorFlow expert and boost your AI career? Let's get started! Remember, practice is key, so make sure to follow along and code with me. See you in the first lesson!\n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-01-01"}}
{"video": {"title": "Leveraging Memories in LangChain for More Powerful Applications", "transcript": "####Leveraging Memories in LangChain for More Powerful Applications\nby Harrison Chase, Andrew Ng - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Harrison Chase, and today we're diving into the exciting world of LangChain memories!\n\nMemories are like the secret sauce that makes our applications smarter and more efficient. They allow our application to remember past interactions, making it more effective in performing tasks.\n\nFirst, we'll demystify memories and how they work in LangChain. Don't worry, I'll break it down into simple, easy-to-understand steps.\n\nNext, we'll get our hands dirty with some code. We'll use memories to supercharge our personal assistant and chatbot applications.\n\nAnd the best part? We'll use agents and chained calls to make our applications even more powerful. They'll be able to perform complex tasks and remember past interactions like a pro.\n\nNow, let's wrap up. You've learned what memories are, how to use them in LangChain, and how to enhance your applications with memories.\n\nSo, what's next? I challenge you to add memories to your own applications. Make them smarter. Make them more powerful.\n\nThanks for watching. If you found this tutorial helpful, give it a thumbs up and don't forget to subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-15"}}
{"video": {"title": "Mistral AI: Unlocking the Power of Open-Source LLMs", "transcript": "####Mistral AI: Unlocking the Power of Open-Source LLMs\nby Younes Belkada, Marc Sun - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the exciting world of open-source LLMs with Mistral AI, joined by my co-host Marc Sun.\n\nMistral AI offers three open-source models: Mistral 7B, Mixtral 8x7B, and the latest Mixtral 8x22B. In this video, we'll show you how to access these models via web interface and API calls.\n\nFirst, we'll take a look at Mistral 7B, a powerful model that's perfect for beginners. We'll show you how to use it to generate text, answer questions, and more.\n\nNext, we'll explore Mixtral 8x7B and Mixtral 8x22B. These models offer even more advanced capabilities, including the ability to generate structured JSON responses.\n\nWe'll also show you how to use Mistral's API to call user-defined Python functions. This means you can perform tasks like web searches or retrieving text from databases, enhancing the LLM's ability to find relevant information to answer your queries.\n\nSo, whether you're a beginner or an experienced developer, Mistral AI's open-source models have something for you. And the best part? They're completely free to use.\n\nDon't forget to like, share, and subscribe for more content on Mistral AI. And a special thanks to our technology partner, Mistral AI, for making this video possible.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########\n\nRefined Script:\n\n####Mistral AI: Unleashing the Power of Open-Source LLMs\nby Younes Belkada, Marc Sun - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're embarking on an exciting journey into the world of open-source LLMs with Mistral AI, joined by my co-host Marc Sun.\n\nMistral AI offers three open-source models: Mistral 7B, Mixtral 8x7B, and the latest Mixtral 8x22B. In this video, we'll show you how to harness the power of these models via web interface and API calls.\n\nFirst, we'll take a look at Mistral 7B, a powerful model that's perfect for beginners. We'll show you how to use it to generate text, answer questions, and more.\n\nNext, we'll explore Mixtral 8x7B and Mixtral 8x22B. These models offer even more advanced capabilities, including the ability to generate structured JSON responses.\n\nWe'll also show you how to use Mistral's API to call user-defined Python functions. This means you can perform tasks like web searches or retrieving text from databases, enhancing the LLM's ability to find relevant information to answer your queries.\n\nSo, whether you're a beginner or an experienced developer, Mistral AI's open-source models have something for you. And the best part? They're completely free to use.\n\nDon't forget to like, share, and subscribe for more content on Mistral AI. And a special thanks to our technology partner, Mistral AI, for making this video possible.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-20"}}
{"video": {"title": "How to Make Safer LLM Apps Through Red Teaming", "transcript": "####How to Make Safer LLM Apps Through Red Teaming\nby Matteo Dora - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Matteo Dora, and today we're diving into the world of red teaming for LLM apps. Are you ready to make your applications safer and more reliable? Let's get started!\n\nFirst things first, what is red teaming? It's a cybersecurity technique where a team of experts simulates attacks on a system to identify weaknesses. By applying red teaming techniques to LLM applications, we can ensure their safety and reliability.\n\nNow, let's talk about how to apply red teaming techniques to LLM applications. We'll be using an open source library from our partner, Giskard, to help automate LLM red-teaming methods. This will make the process more efficient and effective.\n\nBut wait, there's more! In conclusion, red teaming is a crucial step in ensuring the security of LLM applications. By learning how to identify and evaluate vulnerabilities, we can make our apps safer for users. So, what are you waiting for? Stay tuned for more tips and tricks on LLM application security!\n#### END TRANSCRIPT ########", "author": "Matteo Dora", "publication_date": "2022-10-15"}}
{"video": {"title": "Building an RNN from Scratch", "transcript": "####Building an RNN from Scratch: A Hands-On Guide\nby Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri - 2023-04-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! It's your favorite AI guide, and today we're diving into the exciting world of Recurrent Neural Networks (RNNs).\n\nWe're going to start with the basics of RNNs, including loops, hidden states, and backpropagation through time. Then, we'll roll up our sleeves and build our own RNN using Python and TensorFlow.\n\nBy the end of this video, you'll have your very own RNN and will have applied it to a real-world scenario.\n\nSo, are you ready to build your own RNN? Let's get started!\n\nRemember, this video is part of our Deep Learning Specialization, so if you're new to the field, you might want to start with the basics first.\n\nAnd that's a wrap for today! I hope you enjoyed building your own RNN. Don't forget to like, share, and subscribe for more exciting content. Until next time, keep learning and have fun with AI!\n\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri", "publication_date": "2023-04-15"}}
{"video": {"title": "Implementing Contrastive Learning for Multimodal Search", "transcript": "####Implementing Contrastive Learning for Multimodal Search\nby Sebastian Witalec - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Sebastian Witalec here! Are you ready to dive into the world of contrastive learning for multimodal search? Let's do this!\n\nContrastive learning is a powerful method for training models to understand the similarities and differences between data points. And when it comes to multimodal search, it's a game-changer. It allows us to create modality-independent embeddings, meaning we can use any type of query to retrieve any type of data.\n\nBut how do we actually implement this? Well, that's what we're here to find out. We'll start by preparing our dataset, then we'll define our contrastive learning model and train it on our dataset. And finally, we'll evaluate our model and see how well it performs.\n\nRemember, the goal here is to create a model that can understand the relationships between different types of data. This is a crucial step in building a powerful multimodal search application.\n\nSo, let's get started! And if you have any questions, don't hesitate to leave a comment. We're all here to learn. And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2023-03-20"}}
{"video": {"title": "Getting Started With Mistral: Your First Step into Advanced LLM World", "transcript": "####Getting Started With Mistral: Your First Step into Advanced LLM World\nby Younes Belkada, Marc Sun - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today I'm joined by my co-host Marc Sun. We're about to dive into the thrilling world of Mistral AI!\n\nMistral AI offers a collection of advanced open-source and commercial LLMs, and we're here to show you how to get started.\n\nFirst, we'll explore Mistral's three open-source models: Mistral 7B, Mixtral 8x7B, and the latest Mixtral 8x22B. Plus, we'll take a look at their three commercial models: small, medium, and large. You'll learn how to access these models via web interface and API calls.\n\nNext, we'll show you how to leverage Mistral's JSON mode. This powerful feature allows you to generate LLM responses in a structured JSON format, making it easy to integrate LLM outputs into larger software applications.\n\nBut wait, there's more! We'll also demonstrate how to use Mistral's API to call user-defined Python functions. This means you can perform tasks like web searches or retrieving text from databases, enhancing the LLM's ability to find relevant information to answer your queries.\n\nSo, whether you're a beginner or an experienced developer, Mistral AI has something for you. And the best part? This course is suitable for anyone who wants to learn about and use Mistral AI's collection of advanced LLMs.\n\nDon't forget to like, share, and subscribe for more content on Mistral AI. And a special thanks to our technology partner, Mistral AI, for making this video possible.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-15"}}
{"video": {"title": "Mastering Mathematics for Machine Learning and Data Science: Linear Algebra", "transcript": "####Mastering Mathematics for Machine Learning and Data Science: Linear Algebra\nby Anshuman Singh - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, data enthusiasts! I'm Anshuman Singh, and welcome back to our exciting journey into the world of Mathematics for Machine Learning and Data Science. Today, we're diving into the fascinating realm of linear algebra!\n\nLinear algebra is the study of linear equations and their representations through matrices and vector spaces. It's a must-have tool in our machine learning toolkit, as it helps us manipulate and understand high-dimensional data.\n\nLet's kick things off with vectors. Vectors are simply arrays of numbers. In machine learning, we often represent data points as vectors. For example, a data point with three features could be represented as a vector with three elements.\n\nNext up, matrices. Matrices are rectangular arrays of numbers. They're useful for organizing data and performing operations on multiple vectors at once. For instance, we can use a matrix to represent a dataset with multiple features and observations.\n\nBut how does this apply to machine learning? Well, many machine learning algorithms involve operations on matrices and vectors. For example, in linear regression, we use matrices to represent our data and vectors to represent our model parameters.\n\nAnd that's a wrap for today's video on linear algebra! I hope you found this introduction as exciting as I did. Stay tuned for our next video, where we'll delve into statistics and probability.\n\nRemember, the best way to learn is by doing, so don't forget to practice some linear algebra problems. And if you have any questions, feel free to leave them in the comments below. Thanks for watching, and happy learning!\n\n#### END TRANSCRIPT ########", "author": "Anshuman Singh", "publication_date": "2023-03-20"}}
{"video": {"title": "Quantization Unleashed: Harnessing Hugging Face and Quanto", "transcript": "####Quantization Unleashed: Harnessing Hugging Face and Quanto\nby Younes Belkada and Marc Sun - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada and today, I'm teaming up with Marc Sun to unleash the power of quantization using Hugging Face and Quanto libraries.\n\nSo, what's the buzz about quantization? Well, it's like having a secret weapon that lets you shrink your models without compromising their strength.\n\nLet's dive in. We'll be using the Hugging Face Transformers library and the Quanto library for this task. If you're new to these tools, no worries, we'll guide you through every step.\n\nFirst, we'll discover linear quantization, a simple yet potent method for compressing models. It's like having a shrink ray that turns your giant models into pocket-sized ones.\n\nThen, we'll practice quantizing open-source multimodal and language models. It's like having a pocket-sized version of your favorite superheroes, but with all their strength intact.\n\nBy the end of this video, you'll be a pro at harnessing the power of quantization and you'll have saved a ton of space on your hard drive.\n\nRemember, practice is the key to success, so don't be afraid to experiment with different models and methods. And if you encounter a hurdle, just rewind and watch it again.\n\nThanks for joining us and don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-25"}}
{"video": {"title": "AI for Wind Energy: Powering the Future with Technology", "transcript": "####AI for Wind Energy: Powering the Future with Technology\nby Robert Monarch - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Robert Monarch, and today we're diving into the fascinating world of AI and wind energy.\n\n[Video hook and introduction]\n\nImagine a future where wind turbines are smarter, more efficient, and predict wind patterns like a pro. That's the power of AI in wind energy.\n\n[Body content]\n\nFirst, we'll uncover the role of AI in wind energy. We'll explore how it's enhancing turbine performance, predicting wind patterns, and improving energy forecasting.\n\nThen, we'll roll up our sleeves and build a simple model to predict wind patterns. Don't worry, I'll be your guide every step of the way.\n\nBut wait, there's more! We'll also discuss the challenges and ethical considerations of using AI in wind energy. It's not all sunshine and rainbows, but it's crucial to know the whole story.\n\n[Conclusion and call to action]\n\nSo, are you ready to join the AI for wind energy revolution? Remember, every bit of clean energy counts, and you can make a difference.\n\nThanks for watching. If you enjoyed this video, don't forget to like, share, and subscribe. And stay tuned for more thrilling content on AI for wind energy.\n\n\n#### END TRANSCRIPT ########", "author": "Robert Monarch", "publication_date": "2023-04-10"}}
{"video": {"title": "Building AI Applications: From Cloud to Edge", "transcript": "####Building AI Applications: From Cloud to Edge\nby Krishna Sridhar - 2023-05-06\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, and today we're diving into the exciting world of building AI applications from cloud to edge.\n\nImagine being able to harness the power of both cloud and edge computing for your AI applications. Sounds intriguing, right? Well, that's exactly what we're going to explore today.\n\nWe'll discuss how to partition your AI models effectively and share some top-notch strategies for managing your data efficiently. It's like having the best of both worlds, right at your fingertips!\n\nRemember, keep it simple, use active voice, and sprinkle in some humor to keep things interesting. And most importantly, be confident and concise in your writing.\n\nSo, are you ready to take your AI applications to the next level? Let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2023-05-06"}}
{"video": {"title": "Transform Your LLMs with Function-Calling and Data Extraction", "transcript": "####Transform Your LLMs with Function-Calling and Data Extraction\nby Jiantao Jiao, Venkat Srinivasan - 2022-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Venkat Srinivasan and today we're going to transform your Language Learning Models, or LLMs, with function-calling and data extraction. If you're a beginner with some basic Python knowledge, you're in the right place!\n\nLet's get started. Function-calling is a game-changer. It lets you extend your LLMs with custom functionality by teaching them to make calls to external functions. Pretty cool, huh?\n\nNext up, we'll explore data extraction. We'll learn how to extract structured data from natural language inputs, making real-world data usable for analysis.\n\nBut wait, there's more! In partnership with Nexusflow, we'll build an end-to-end application that processes customer service transcripts using LLMs. You'll see how function-calling and data extraction can transform your applications.\n\nRemember, the best way to learn is by doing. So, get involved! Try out the techniques we'll cover and see how they can enhance your LLM and agent applications.\n\nThanks for watching and happy learning! Don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, this is Jiantao Jiao signing off.\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-04-05"}}
{"video": {"title": "Mastering Knowledge Graphs for RAG with Neo4j and LangChain", "transcript": "####Mastering Knowledge Graphs for RAG with Neo4j and LangChain\nby Andreas Kollegger - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Andreas Kollegger, and today we're diving headfirst into the thrilling world of Knowledge Graphs for Retrieval Augmented Generation, or RAG for short.\n\nBut first things first, what's a knowledge graph? Picture a massive web of data points, all connected by relationships. That's a knowledge graph. And when it comes to RAG, these graphs can turbocharge your applications.\n\nIn this video, we're going to use Neo4j, a top-notch graph database, and its query language, Cypher, to manage and retrieve data stored in our knowledge graphs. Don't worry if you're new to Cypher, we'll cover the basics and show you how to write queries that find and format text data to provide more relevant context to your Language Models.\n\nBefore we dive in, we recommend you have some familiarity with LangChain or have taken the short course 'LangChain: Chat with Your Data'. If you haven't, no worries, just pause the video and go check it out. We'll still be here when you get back.\n\nNow, let's get our hands dirty. We're going to build a question-answering system using Neo4j and LangChain. This system will chat with a knowledge graph of structured text documents. Sounds cool, right?\n\nBy the end of this video, you'll be an intermediate-level expert in using knowledge graphs for RAG. And who knows, you might even have some fun along the way.\n\nRemember, practice makes perfect. So, don't just watch the video, follow along and build your own system. And if you get stuck, don't hesitate to reach out. I'm here to help.\n\nThanks for watching, and a big shout out to our partners at Neo4j for making this video possible. See you in the next one.\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2023-03-15"}}
{"video": {"title": "Building a Secure LLM Application with Python and Predibase's LoRAX Framework", "transcript": "Positive Points:\n\n- Clear introduction of the topic and the tools to be used.\n- Use of active voice and simple language.\n- Inclusion of best practices.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning.\n- Make the conclusion more memorable and engaging.\n- Improve the call to action.", "author": "Travis Addair", "publication_date": "2023-04-01"}}
{"video": {"title": "Mastering TensorFlow: Advanced Techniques", "transcript": "####Mastering TensorFlow: Advanced Techniques\nby Laurence Moroney, Eddy Shyu - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, TensorFlow enthusiasts! I'm Laurence Moroney, and I'm Eddy Shyu. Today, we're going to take your TensorFlow skills to the next level with some advanced techniques. Are you ready to dive in?\n\nIn this video, we'll be covering some exciting topics such as the Functional API, optimizing training with multiple processors, and exploring the latest computer vision and generative deep learning techniques. By the end of this video, you'll have a solid understanding of how to leverage TensorFlow to build more complex and powerful models.\n\nSo, grab your coffee, sit back, and let's get started!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-10-15"}}
{"video": {"title": "Mastering Mathematics for Machine Learning and Data Science: Calculus", "transcript": "Hi there, I'm Luis Serrano, and welcome to our video series on Mathematics for Machine Learning and Data Science. Today, we're diving into the exciting world of calculus!\n\nCalculus is a powerful tool that helps us understand how things change. In machine learning, we use it to optimize our models, making them learn faster and better.\n\nLet's start with the basics: derivatives. Think of a derivative as a speedometer. It tells us how fast something is changing at a particular moment.\n\nNow, imagine you're training a machine learning model. The model's 'speedometer' is the derivative of its loss function. It tells us how to adjust the model's parameters to make it learn better.\n\nNext, let's talk about integrals. Integrals are like calculating the total distance traveled. In machine learning, we use integrals to calculate the total error of our model over a dataset.\n\nBut don't worry, you won't need to calculate these by hand. Computers do the heavy lifting for us. Your job is to understand the concepts and how they're applied.\n\nSo, that's calculus in a nutshell. It's not just numbers and equations, it's a tool that helps us understand and improve our machine learning models.\n\nRemember, practice is key. Keep exploring, keep learning, and don't be afraid to make mistakes. That's how we learn best.\n\nJoin us in our next video, where we'll be exploring linear algebra. If you found this video helpful, give us a thumbs up and subscribe to our channel for more exciting content. See you next time!\n\nAnd don't forget to share this video with your friends and colleagues. Let's spread the knowledge and make machine learning accessible to everyone!", "author": "Luis Serrano", "publication_date": "2023-03-15"}}
{"video": {"title": "Unleashing the Power of LLM: Preprocessing Unstructured Data", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Engaging and concise conclusion.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Introduce more curiosity and stakes at the beginning to capture the audience.\n- Improve contrast and pacing to maintain interest.\n- Leverage input bias to show the effort put into the video.\n- Make the conclusion more memorable and engaging.", "author": "Matt Robinson", "publication_date": "2023-03-15"}}
{"video": {"title": "Debugging AI Agents with LangGraph", "transcript": "####Debugging AI Agents with LangGraph\nby Harrison Chase, Rotem Weiss - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, AI enthusiasts! Ready to become a debugging master? Today, we're diving into the world of LangGraph and learning how to debug AI agents like a pro!\n\nBut first, why should we care about debugging? Well, it's like giving your AI agent a tune-up. It helps us spot and fix issues, ensuring our AI agents are running at their best.\n\nSo, how do we debug with LangGraph? Let's get into it.\n\nWe'll start by understanding the common issues that can pop up with AI agents and how to spot them.\n\nThen, we'll walk you through the process of debugging with LangGraph, using its tools and features to pinpoint and resolve issues.\n\nBy the end of this video, you'll be able to debug your AI agents like a boss, ensuring they're always performing at their best.\n\nSo, are you ready to take your debugging skills to the next level? Let's get started!\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-05"}}
{"video": {"title": "GANs and Deep Learning: A Match Made in Heaven", "transcript": "####GANs and Deep Learning: A Match Made in Heaven\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-03-29\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Sharon Zhou, and today we're diving into the fascinating world of GANs and deep learning.\n\n[Video hook and introduction]\n\nGANs are a type of machine learning model, but they're also deeply connected to deep learning. In this video, we'll explore this connection and how they can work together to create even more powerful models.\n\n[Body content]\n\nAt their core, GANs are just a type of neural network. They consist of two parts: a generator and a discriminator, both of which are typically implemented as deep neural networks. This means that GANs can leverage all the same techniques and tools that are used in deep learning, like convolutional neural networks and recurrent neural networks.\n\nBut GANs also have some unique properties that make them particularly well-suited for certain tasks. For example, they're great at generating new data that's similar to the data they were trained on. This makes them ideal for tasks like image synthesis and data augmentation.\n\nWhen you combine GANs with deep learning, you get even more powerful models that can tackle even more complex tasks. For example, you can use GANs to generate synthetic data for training other deep learning models, or you can use deep learning to improve the performance of your GANs.\n\n[Conclusion and call to action]\n\nSo that's a quick overview of the relationship between GANs and deep learning. It's a powerful combination that's driving some of the most exciting advances in machine learning today. Thanks for watching, and be sure to check out our other videos on GANs and machine learning.\n\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-03-29"}}
{"video": {"title": "Prompt Engineering for ChatGPT: A Comprehensive Guide", "transcript": "####Prompt Engineering for ChatGPT: A Comprehensive Guide\nby Isa Fulford, Andrew Ng - 2023-03-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here! Today, we're diving into the fascinating world of prompt engineering for ChatGPT. If you're a developer with basic Python skills, buckle up, because you're in for a treat!\n\nFirst things first, what is prompt engineering and why should you care? Well, it's the art of designing and optimizing inputs for language models like ChatGPT. And trust me, the right prompt can make all the difference in getting the results you want.\n\nNow, let's get into some best practices. First, be clear and specific with your prompts. The more detailed you are, the better ChatGPT can understand what you're asking for. Second, don't be afraid to iterate. Prompt engineering is an iterative process, so try out different prompts and see what works best.\n\nBut wait, there's more! Let's explore some new ways to use LLMs, or large language models. Did you know you can use LLMs for summarizing, inferring, transforming, and expanding text? Let's take a look at some examples using the OpenAI API.\n\nNow, it's time for some hands-on practice. We'll walk through writing and iterating on prompts together, and I'll show you how to use the OpenAI API to get results from ChatGPT.\n\nTo wrap up, prompt engineering is a powerful tool for application development with ChatGPT. With these best practices and some hands-on experience, you'll be well on your way to mastering prompt engineering. So go ahead and start experimenting with your own prompts. And who knows, you might even build your own custom chatbot!\n\nThanks for watching, and happy prompt engineering!\n#### END TRANSCRIPT ########", "author": "Isa Fulford, Andrew Ng", "publication_date": "2023-03-20"}}
{"video": {"title": "The Future of GANs: Trends and Innovations", "transcript": "####The Future of GANs: Trends and Innovations\nby Sharon Zhou - 2022-10-13\n\n#### BEGIN TRANSCRIPT ####\nAre you ready to dive into the future of Generative Adversarial Networks? I'm Sharon Zhou, and in this video, we'll explore the latest trends and innovations in the world of GANs. Get ready to glimpse into the future of image generation with GANs!\n\n[Video hook and introduction]\n\n- Imagine a world where you can create realistic images with just a few lines of code. That's the power of GANs!\n- But what's next for this cutting-edge technology? Let's find out!\n\n[Body content]\n\n- We'll start by looking at the latest trends in GAN research.\n- Then, we'll dive into some of the most exciting innovations in the field.\n- And finally, we'll explore some real-world applications of GANs.\n\n[Conclusion and call to action]\n\n- So, are you ready to join the GAN revolution?\n- Stay tuned for more videos on this exciting topic!\n- And don't forget to like, share, and subscribe for more content like this.\n\n#### END TRANSCRIPT ########", "author": "Sharon Zhou", "publication_date": "2022-10-13"}}
{"video": {"title": "Understanding Machine Learning Algorithms", "transcript": "####Understanding Machine Learning Algorithms: A Fun and Engaging Journey\nby Eddy Shyu - 2022-10-02\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to dive into the fascinating world of machine learning algorithms? Well, buckle up because we're about to embark on an exciting journey! In this video, we'll uncover the key machine learning algorithms that power AI. From decision trees to neural networks, we'll explore how these algorithms work and when to use them. So, grab your popcorn and let's get started!\n#### END TRANSCRIPT ########", "author": "Eddy Shyu", "publication_date": "2022-10-02"}}
{"video": {"title": "Quantize Your Models: Shrink Size, Boost Performance", "transcript": "####Quantize Your Models: Shrink Size, Boost Performance\nby Krishna Sridhar - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Krishna Sridhar, and today we're going to shrink AI models without losing their might!\n\nWelcome to the fascinating world of quantization. It's all about reducing the size of your models while maintaining, or even improving, their performance. It's like downsizing your home without losing any of the comfort.\n\nWe'll use techniques like weight quantization and activation quantization to achieve this. It's like a magical diet for your AI models!\n\nRemember, use short sentences, write in a conversational style, and avoid repetition. Be confident and concise in your writing.\n\nSo, are you ready to make your AI models lean and mean? Let's get quantizing!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2023-03-25"}}
{"video": {"title": "LangChain and Data Visualization", "transcript": "####LangChain and Data Visualization: A Game Changer for Chatbots\nby Harrison Chase - 2023-03-31\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! I'm Harrison Chase, the creator of LangChain, and today we're diving into the exciting world of data visualization with LangChain.\n\nData visualization is the graphical representation of data and information. With LangChain, you can harness the power of data visualization to build even more powerful chatbots.\n\nBut how does it work? Let's take a look.\n\nLangChain provides you with access to a wide range of data visualization tools and techniques, from simple charts and graphs to complex interactive visualizations. This means you can use your chatbot to gain insights and make data-driven decisions like never before.\n\nI'll be guiding you through each step of the process, sharing tips and tricks along the way. And the best part? You'll be learning directly from me, the creator of LangChain.\n\nSo, are you ready to take your chatbot to the next level with data visualization? Let's get started!\n\nRemember, if you have any questions or need help along the way, don't hesitate to reach out. And once you've mastered data visualization with LangChain, be sure to share your creations with me. I can't wait to see what you build!\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-03-31"}}
{"video": {"title": "Calculus in Action: Optimizing Machine Learning Models", "transcript": "####Calculus in Action: Supercharging Machine Learning Models\nby Obed Kobina Nsiah - 2023-03-09\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Obed Kobina Nsiah, and today we're diving into the world of calculus to supercharge our machine learning models.\n\nRemember the derivative from our last video? It's not just a mathematical concept, it's a superpower for optimization.\n\nIn machine learning, we use the derivative to find the best values for our model's parameters. This process is called gradient descent.\n\nLet's talk about local and global minima. They're the valleys in our optimization landscape. But don't worry, we'll navigate them together.\n\nAnd remember, practice makes perfect. So, keep learning, keep practicing, and soon you'll be an optimization pro.\n\nThanks for watching. Be sure to like, share, and subscribe for more exciting videos on Mathematics for Machine Learning and Data Science. Until next time, happy optimizing!\n\n#### END TRANSCRIPT ########", "author": "Obed Kobina Nsiah", "publication_date": "2023-03-09"}}
{"video": {"title": "Mastering Mistral AI: Tips and Tricks", "transcript": "####Mastering Mistral AI: Tips and Tricks\nby Younes Belkada, Marc Sun - 2023-02-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into some exciting tips and tricks for mastering Mistral AI and its advanced LLM capabilities.\n\nFirst off, let's talk about Mistral's JSON mode. With JSON mode, you can generate LLM responses in a structured JSON format, making it a breeze to integrate LLM outputs into your larger software applications.\n\nAnd don't forget about Mistral's API. With Mistral's API, you can call user-defined Python functions for tasks like web searches or retrieving text from databases. This means you can enhance the LLM's ability to find relevant information and answer user queries more accurately.\n\nAnother tip is to experiment with Mistral's different models. Mistral offers a range of open-source and commercial models, so make sure you're using the right one for your specific use case.\n\nAnd finally, don't be afraid to get creative with Mistral AI. With its advanced LLM capabilities, the sky's the limit when it comes to what you can achieve.\n\nSo, what are you waiting for? Start mastering Mistral AI today and take your LLM capabilities to the next level. And don't forget to check out Mistral AI, our technology partner for this video.\n\nThanks for watching, and stay tuned for more exciting videos on Mistral AI and LLM. I'm Younes Belkada, and I'll see you in the next one.\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-17"}}
{"video": {"title": "Unleash the Power of LLMs with Function-Calling and Data Extraction", "transcript": "####Unleashing the Power of LLMs: Function-Calling and Data Extraction\nby Jiantao Jiao, Venkat Srinivasan - 2022-04-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Venkat Srinivasan and today we're diving into the world of Language Learning Models, or LLMs, and how function-calling and data extraction can take your applications to the next level. If you're a beginner with some basic Python knowledge, you're in the right place!\n\nLet's get started. Function-calling is a game-changer. It lets you extend your LLMs with custom functionality by teaching them to make calls to external functions. Impressive, right?\n\nNext up, we'll explore data extraction. We'll learn how to extract structured data from natural language inputs, making real-world data usable for analysis.\n\nBut that's not all! In partnership with Nexusflow, we'll build an end-to-end application that processes customer service transcripts using LLMs. You'll see how function-calling and data extraction can unleash the power of your applications.\n\nRemember, the best way to learn is by doing. So, get involved! Try out the techniques we'll cover and see how they can enhance your LLM and agent applications.\n\nThanks for watching and happy learning! Don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, this is Jiantao Jiao signing off.\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-04-19"}}
{"video": {"title": "Maintaining AI Agents with LangGraph", "transcript": "####Maintaining AI Agents with LangGraph: A Fun and Easy Guide\nby Harrison Chase, Rotem Weiss - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Are you ready to learn how to maintain your AI agents using LangGraph? Trust us, it's not as boring as it sounds!\n\nBut first, let's talk about why maintenance is important. It's like giving your AI agents a tune-up, keeping them running smoothly and efficiently.\n\nSo, how do we do it with LangGraph? Let's find out!\n\nWe'll start by understanding the importance of regular maintenance and what it involves. Think of it like changing the oil in your car, but for AI agents.\n\nThen, we'll walk you through the process of maintaining with LangGraph, using its tools and features to update, optimize, and improve your AI agents. It's like having a personal mechanic for your AI!\n\nBy the end of this video, you'll be able to maintain your AI agents like a pro, ensuring they're always at the top of their game.\n\nSo, are you ready to master the art of maintenance with LangGraph? Let's dive in and have some fun!\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-10"}}
{"video": {"title": "Preparing for the TensorFlow Certificate Exam", "transcript": "####Preparing for the TensorFlow Certificate Exam\nby Laurence Moroney - 2022-03-29\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the world of TensorFlow! We're going to talk about how to prepare for the Google TensorFlow Developer Professional Certificate exam.\n\n[Video hook and introduction]\n\nAre you ready to show off your TensorFlow skills and earn a valuable certification? Let's do this!\n\n[Body content]\n\nFirst, we'll cover the exam format and key topics. We'll go over what to expect on the exam and how to prepare for each section.\n\nThen, we'll dive into some practice problems and case studies. You'll get a chance to apply your TensorFlow skills and see how they hold up under pressure.\n\nWe'll also cover some tips and tricks for studying and time management. You'll learn how to make the most of your study time and stay focused on exam day.\n\nLastly, we'll go over some common pitfalls and mistakes to avoid. You'll learn how to avoid common errors and improve your chances of passing the exam.\n\n[Conclusion and call to action]\n\nBy the end of this video, you'll have a solid understanding of how to prepare for the TensorFlow certificate exam. So, let's get started!\n\nRemember, practice is key. So, make sure to try the practice problems and case studies and review any areas where you're struggling.\n\nIf you found this video helpful, be sure to give it a thumbs up and subscribe to our channel for more TensorFlow content. Good luck on the exam!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-03-29"}}
{"video": {"title": "Building a Natural Language Interface for CSV Files", "transcript": "####Building a Natural Language Interface for CSV Files\nby Adrian Gonzalez Sanchez - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Adrian Gonzalez Sanchez and today we're going to talk about building a natural language interface for CSV files.\n\nAre you tired of spending hours writing code to extract data from CSV files? What if I told you that you could ask your CSV file a question in plain English and get the answer you need?\n\nIn this video, we'll explore how to build a natural language interface for CSV files using the Azure OpenAI Service. We'll start by introducing the concept of natural language processing and how it can be applied to CSV files.\n\nThen, we'll dive into the Azure OpenAI Service and learn how to use its Assistants API to build a natural language interface for your CSV files. We'll cover techniques like Retrieval Augmented Generation (RAG) and function calling to make your interface more powerful.\n\nBy the end of this video, you'll have the skills to build your own natural language interface for CSV files. And the best part? You don't need to be an expert in Python programming or databases to follow along.\n\nSo, are you ready to make data analysis more efficient and accessible? Let's get started!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like and subscribe for more exciting content on natural language processing and databases.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Adrian Gonzalez Sanchez", "publication_date": "2023-04-20"}}
{"video": {"title": "Hands-On Practice with OpenAI API and Prompt Engineering", "transcript": "####Hands-On Practice with OpenAI API and Prompt Engineering\nby Andrew Ng - 2022-10-22\n\n#### BEGIN TRANSCRIPT ####\nAre you ready to dive into the exciting world of prompt engineering? Buckle up as we explore the OpenAI API together! Today, we're going to write, test, and refine prompts like a pro. Trust me, you'll be amazed at what you can achieve with a little practice. So, let's get started!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-22"}}
{"video": {"title": "Mistral AI: The Power of Open Source", "transcript": "####Mistral AI: The Power of Open Source\nby Younes Belkada, Marc Sun - 2023-02-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the world of open source and how Mistral AI is harnessing its power to deliver top-notch LLM capabilities.\n\nMistral AI is making waves with its open-source models, making it a breeze for developers to integrate LLM into their applications. From Mistral 7B to Mistral 8x22B, Mistral AI's open-source models offer a range of capabilities that can be customized to fit your needs.\n\nAnd the cherry on top? Mistral AI's open-source models are constantly improving and evolving, thanks to the contributions of a lively community of developers.\n\nSo, what does this mean for you? It's time to start exploring Mistral AI's open-source models and see how they can help you level up your LLM game.\n\nBut wait, there's more! Mistral AI also offers commercial models for those who need even more advanced LLM capabilities. With three different models to choose from, Mistral AI's commercial offerings have got you covered.\n\nSo, what are you waiting for? Start exploring Mistral AI today and see how its open-source and commercial models can help you achieve your LLM goals. And don't forget to check out Mistral AI, our technology partner for this video.\n\nThanks for watching, and stay tuned for more exciting videos on Mistral AI and LLM. I'm Younes Belkada, and I'll catch you in the next one.\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-19"}}
{"video": {"title": "Building a Full-Stack RAG Application with JavaScript and LlamaIndex", "transcript": "####Building a Full-Stack RAG Application with JavaScript and LlamaIndex\nby Laurie Voss - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Laurie Voss and today we're diving into the exciting world of RAG applications. We're going to build a full-stack application using JavaScript and LlamaIndex.\n\nImagine having an intelligent agent that can answer queries by discerning and selecting from multiple data sources. That's exactly what we're going to create! We'll build an interactive frontend component that chats with your data, and a backend powered by RAG.\n\nLet's get started! We'll use the create-llama command-line tool to set up our project and install the necessary dependencies. Then, we'll create our frontend component using React and integrate it with our RAG-powered backend.\n\nBut that's not all! We'll also learn how to persist your data, enable chatting with your data, and make streaming responses possible.\n\nThroughout this process, I'll be sharing my top tips and best practices for building RAG applications in JavaScript. By the end of this video, you'll have a fully functional full-stack web app that you can use to chat with your data.\n\nSo, are you ready to take your coding skills to the next level? Let's do this! And don't forget to check out LlamaIndex for more resources on building intelligent applications.\n#### END TRANSCRIPT ########", "author": "Laurie Voss", "publication_date": "2023-03-30"}}
{"video": {"title": "Continuous Improvement in ML Production Systems", "transcript": "####Continuous Improvement in ML Production Systems\nby Andrew Ng - 2022-01-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Andrew Ng, and today we're diving into the exciting world of continuous improvement in ML production systems.\n\nJust like a well-oiled machine, your ML system needs regular maintenance and updates to stay in top shape. We'll discuss how to monitor your model's performance, identify areas for improvement, and implement updates.\n\nWe'll also cover how to test these updates and ensure they're improving your model's performance.\n\nRemember, continuous improvement is a journey, not a destination. So, keep learning, keep improving, and keep pushing the boundaries of what's possible!\n\nJoin me in our next video as we continue our journey into ML production systems. Don't forget to like, share, and subscribe for more insightful content. Until next time, keep learning!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-01-22"}}
{"video": {"title": "Mastering Mathematics for Machine Learning and Data Science: Probability", "transcript": "####Mastering Mathematics for Machine Learning and Data Science: Probability\nby Magdalena Bouza - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Magdalena Bouza, and welcome back to our video series on Mathematics for Machine Learning and Data Science. Today, we're diving into the fascinating world of probability!\n\nProbability is the branch of mathematics that deals with numerical descriptions of how likely an event is to occur. It's a vital part of machine learning, as it helps us make predictions and decisions under uncertainty.\n\nLet's start with the basics: probability distributions. A probability distribution is a function that describes the likelihood of different outcomes in a random process. For example, the normal distribution, also known as the bell curve, is a common probability distribution used to model continuous data.\n\nNext, let's talk about conditional probability. Conditional probability is the probability of an event occurring given that another event has occurred. For instance, we can use conditional probability to determine the likelihood of a customer buying a product given that they've viewed it online.\n\nBut how does this apply to machine learning? Well, many machine learning algorithms are based on probabilistic models. For example, in naive Bayes classification, we use conditional probability to predict the class of a data point based on its features.\n\nAnd that's a wrap for today's video on probability! I hope you found this introduction helpful. Stay tuned for our next video, where we'll review everything we've learned in this series.\n\nRemember, the best way to learn is by doing, so don't forget to practice some probability problems. And if you have any questions, feel free to leave them in the comments below. Thanks for watching, and happy learning!\n\n#### END TRANSCRIPT ########", "author": "Magdalena Bouza", "publication_date": "2023-03-30"}}
{"video": {"title": "Introduction to Multimodal Search and RAG", "transcript": "####Introduction to Multimodal Search and RAG\nby Sebastian Witalec - 2022-10-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Today, we're embarking on an exciting journey into the world of multimodal search and RAG applications. We'll explore how to build smarter systems for multimodal retrieval and generation. I'm Sebastian Witalec, your friendly guide on this adventure.\n\n#### BODY CONTENT ####\n\nImagine being able to search for information using not just text, but also images and videos. That's the power of multimodal search! And with RAG, or Retrieval Augmented Generation, we can generate more accurate and contextually relevant responses.\n\nBut how does it all work? Well, that's what we're here to find out! We'll delve into the nitty-gritty of these technologies, and I'll even show you some practical examples.\n\n#### CONCLUSION AND CALL TO ACTION ####\n\nSo, are you ready to take your search game to the next level? Let's get started! And don't forget to like, share, and subscribe for more exciting content. Until next time, happy exploring!\n\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2022-10-01"}}
{"video": {"title": "Continuous Improvement: Iterating on Your ML System", "transcript": "####Continuous Improvement: Iterating on Your ML System\nby Andrew Ng - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andrew Ng here, and today we're diving into the exciting world of continuously improving your machine learning system in production.\n\nFirst things first, why is continuous improvement so crucial? Well, when we're dealing with complex systems, there's always room for improvement. We can make our models more accurate, our data more relevant, and our processes more efficient.\n\nSo, how do we do it? It all starts with feedback. We need to gather feedback from our users, our stakeholders, and our data to identify areas for improvement. Then, we need to prioritize these areas based on their impact and feasibility.\n\nNext up, experimentation. When we're dealing with complex systems, we need to experiment with different approaches to find the best solution. That means using techniques like A/B testing, bandit algorithms, and multi-armed bandits to test different models, features, and parameters.\n\nBut wait, there's more! Continuous improvement is not just about technology. It's also about people and processes. We'll talk about how to build a culture of continuous improvement, where everyone is encouraged to experiment, learn, and grow.\n\nSo, are you ready to take your ML system to the next level? Let's get started!\n\nRemember, continuous improvement is not just about technology. It's about people, processes, and culture. So keep learning, keep experimenting, and most importantly, have fun!\n\nIf you found this video helpful, be sure to give it a thumbs up and subscribe for more content. And if you have any questions or suggestions, leave them in the comments below. Thanks for watching, and I'll see you in the next video!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2023-03-30"}}
{"video": {"title": "Building AI Applications with Hugging Face: A Step-by-Step Tutorial", "transcript": "Positive Points:\n\n- Clear introduction of the topic and benefits of Hugging Face.\n- Use of active voice and simple language.\n- Encouragement for the audience to try building their own AI application.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning to capture the audience.\n- Make the conclusion more memorable and engaging.", "author": "Maria Khalusova, Marc Sun, Younes Belkada", "publication_date": "2023-03-17"}}
{"video": {"title": "Efficiently Serving LLMs", "transcript": "####Efficiently Serving LLMs\nby Travis Addair - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, welcome back to our channel! I'm Travis Addair, and today we're diving into the fascinating world of Large Language Models (LLMs). We'll explore how to efficiently serve them to multiple users. Are you ready to level up your LLM game? Let's get started!\n#### END TRANSCRIPT ########", "author": "Travis Addair", "publication_date": "2022-10-15"}}
{"video": {"title": "Improving NLP Apps with Transfer Learning and Hugging Face", "transcript": "####Improving NLP Apps with Transfer Learning and Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Your Assistant, and today we're diving into the world of NLP apps. We're going to supercharge them with transfer learning and Hugging Face.\n\nTransfer learning is like a superpower for your NLP apps. It lets us use pre-trained models to our advantage. And with Hugging Face, it's never been easier!\n\nFirst, we'll demystify transfer learning. Then, we'll explore how to use pre-trained models from Hugging Face. And finally, we'll put our new skills to the test.\n\nRemember, the secret to successful transfer learning is choosing the right pre-trained model. It needs to be relevant to our task and data.\n\nSo, are you ready to take your NLP apps to the next level? Let's get started with Hugging Face and transfer learning!\n\nStay tuned for more thrilling videos on this topic. And don't forget to like, share, and subscribe for more tech content. Until next time, I'm Your Assistant, your guide in the world of AI.\n\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-04-10"}}
{"video": {"title": "Mastering AI Agentic Design Patterns with AutoGen", "transcript": "####Mastering AI Agentic Design Patterns with AutoGen\nby Chi Wang, Qingyun Wu - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Chi Wang, and today we're embarking on an exciting journey into the world of AI Agentic Design Patterns using AutoGen. If you're a Python newbie with a burning desire to automate complex workflows using AI agents, you're in luck!\n\nFirst things first, let's get a grip on what AutoGen is and how it makes building multi-agent systems with diverse roles and capabilities a breeze. AutoGen is a mighty framework that streamlines the implementation of complex AI applications.\n\nNow, let's dive into the four main agentic design patterns: Reflection, Tool use, Planning, and Multi-agent collaboration. We'll walk you through each pattern, showing you how to implement them like a pro using AutoGen.\n\nReflection is all about agents knowing their own strengths and weaknesses. With AutoGen, we can effortlessly implement this pattern to create self-aware agents.\n\nNext up, we'll explore Tool use. This pattern allows agents to use tools to reach their goals. We'll demonstrate how to harness AutoGen to create agents that can effectively use tools.\n\nThen, we'll delve into Planning. This pattern involves agents creating and following plans to achieve their goals. With AutoGen, we can implement this pattern to create agents that are strategic thinkers.\n\nLastly, we'll look at Multi-agent collaboration. This pattern involves multiple agents working together to achieve a common goal. We'll guide you on how to use AutoGen to create collaborative agents.\n\nThroughout this course, you'll be learning directly from Qingyun Wu and myself, the masterminds behind AutoGen. We're thrilled to share our expertise and help you leverage AutoGen effectively.\n\nRemember, practice makes perfect. So, don't just watch, get your hands dirty with the code.\n\nThat's a wrap for today's video. If you found this helpful, don't forget to like, share, and subscribe for more content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2023-04-01"}}
{"video": {"title": "Debugging Your Agentic RAG with LlamaIndex", "transcript": "####Debugging Your Agentic RAG with LlamaIndex\nby Jerry Liu - 2023-03-30\n\n#### BEGIN TRANSCRIPT ####\nHey there, fellow AI enthusiasts! Jerry Liu here, and today we're diving into the exciting world of Agentic RAG with LlamaIndex.\n\nBut wait, what's an Agentic RAG, you ask? Well, it's a powerful tool that uses large language models to generate responses to your queries. And like any tool, it can sometimes have a few hiccups. That's where we come in!\n\nToday, we're going to learn how to debug our Agentic RAG like a pro. We'll start by identifying common issues and how to spot them. Then, we'll dive into LlamaIndex's debugging tools to fix those pesky problems.\n\nBut wait, there's more! We'll also explore some best practices for debugging and controlling our Agentic RAG. Trust me, you won't want to miss this.\n\nSo, are you ready to become a debugging master with Agentic RAG and LlamaIndex? Let's get started!\n\nRemember, practice makes perfect. So keep trying, keep building, and most importantly, have fun!\n\nAnd don't forget to like, share, and subscribe for more exciting content. Until next time, happy debugging!\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-03-30"}}
{"video": {"title": "Evaluating Vulnerabilities in LLM Applications", "transcript": "####Evaluating Vulnerabilities in LLM Applications\nby Matteo Dora, Luca Martial - 2023-03-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Matteo Dora, and welcome back to our exciting journey into red teaming for LLM applications!\n\nIn this video, we're taking the next big leap - evaluating vulnerabilities.\n\nNow that we've uncovered potential vulnerabilities in our LLM applications, it's time to gauge their impact and prioritize them for fixing.\n\nWe'll explore how to assess the severity of a vulnerability, how to estimate its potential impact, and how to prioritize fixes based on these factors.\n\nRemember, not all vulnerabilities are equal, and it's crucial to focus on the ones that pose the most significant risk to our applications.\n\nSo, let's start evaluating those vulnerabilities and make our LLM applications safer.\n\nStay tuned for our next video where we'll discuss how to fix these vulnerabilities using red teaming techniques. Until then, keep exploring and learning.\n\nAnd remember, in the world of cybersecurity, the best defense is a good offense!\n\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-03-15"}}
{"video": {"title": "Mastering Knowledge Graphs for RAG with Neo4j and LangChain", "transcript": "####Mastering Knowledge Graphs for RAG with Neo4j and LangChain\nby Andreas Kollegger - 2023-04-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, Andreas Kollegger here! Today, we're embarking on an exciting journey into the realm of Knowledge Graphs for Retrieval Augmented Generation, or RAG for short.\n\nBut first, if you're new to LangChain, don't worry! I've got you covered with our short course 'LangChain: Chat with Your Data'. It's the perfect primer for this intermediate-level topic.\n\nNow, let's dive in. Knowledge graphs are a game-changer for your RAG applications. They provide more relevant context to Large Language Models, or LLMs, by structuring text data in a way that's easy to understand.\n\nIn this video, we're teaming up with Neo4j to show you how to use their query language, Cypher, to manage and retrieve data from knowledge graphs. Trust me, it's simpler than it sounds.\n\nLet's get our hands dirty with some knowledge graph queries. Don't worry, I'll be with you every step of the way. We'll start with the basics and gradually work our way up to more complex queries.\n\nOnce we've got the hang of that, we'll build our very own question-answering system. We'll use Neo4j and LangChain to chat with a knowledge graph of structured text documents. Imagine being able to ask your data questions and getting accurate answers in return. That's the power of RAG.\n\nBy the end of this video, you'll have a solid understanding of how to use knowledge graphs to improve your RAG applications. You'll be writing your own Cypher queries and even have your own question-answering system to show off.\n\nSo, are you ready to take your RAG applications to the next level? Let's do this! And remember, if you have any questions, feel free to leave them in the comments below. Happy learning!\n\n#### END TRANSCRIPT ########", "author": "Andreas Kollegger", "publication_date": "2023-04-01"}}
{"video": {"title": "Designing a Question-Answering App with NLP and Hugging Face", "transcript": "####Designing a Question-Answering App with NLP and Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, Assistant here! Today, we're diving into the fascinating world of question-answering with NLP. Imagine having an app that can understand and respond to user queries, just like a real person. That's the power of NLP!\n\nBut how does question-answering work? It's all about teaching a machine to understand the context of a question and then find the correct answer in a given text.\n\nAnd guess what? With Hugging Face, we can build a question-answering app in just a few simple steps. We'll show you how to prepare your data, train your model, and deploy your app.\n\nBut wait, there's more! We'll also cover some advanced techniques for improving your app's performance, like named entity recognition and dependency parsing. And don't worry, we'll explain everything in a clear and simple way, so you won't get lost in the details.\n\nSo, are you ready to design your own question-answering app with NLP and Hugging Face? Let's get started!\n\nThat's it for today's video. If you found it helpful, be sure to give it a thumbs up and subscribe for more content. And if you're ready to start building your own question-answering app, check out the links in the description for some great resources. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-04-05"}}
{"video": {"title": "Optimizing Model Performance with Quantization Techniques", "transcript": "####Optimizing Model Performance with Quantization Techniques\nby Younes Belkada - 2022-10-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! It's Your AI Guide, Younes Belkada, back with another exciting video. Today, we're diving into the world of advanced quantization techniques to supercharge your model's performance. We'll explore linear quantization variants, granularities, and even weights packing. So, buckle up and let's get this show on the road!\n#### END TRANSCRIPT ########", "author": "Younes Belkada", "publication_date": "2022-10-20"}}
{"video": {"title": "Maximize Your LLM Potential with Function-Calling and Data Extraction", "transcript": "####Maximize Your LLM Potential with Function-Calling and Data Extraction\nby Jiantao Jiao, Venkat Srinivasan - 2022-04-26\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao, and today we're diving into the world of Language Learning Models, or LLMs. We're going to show you how to maximize your LLM potential with function-calling and data extraction. If you're already familiar with LLMs and have some basic Python knowledge, you're in luck!\n\nFirst up, let's talk about function-calling. It's a game-changer for extending your LLMs with custom functionality. Imagine teaching your LLM to make calls to external functions. Mind-blowing, right?\n\nNow, let's get our hands dirty with some data extraction. We'll learn how to extract structured data from natural language inputs. This is a real-world skill that's super useful when dealing with messy data for analysis.\n\nBut wait, there's more! We've teamed up with Nexusflow to bring you an end-to-end application that processes customer service transcripts using LLMs. You'll see firsthand how function-calling and data extraction can take your application capabilities to the next level.\n\nRemember, practice makes perfect. So, don't just watch, get involved! Try out the techniques we'll cover and see how they can enhance your LLM and agent applications.\n\nThanks for watching and happy learning! Don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, this is Venkat Srinivasan signing off.\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-04-26"}}
{"video": {"title": "Privacy Preservation in GANs: Protecting Your Data", "transcript": "####Privacy Preservation in GANs: Protecting Your Data\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-03-02\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sharon Zhou, and today we're diving into the world of privacy preservation in GANs.\n\n[Video hook and introduction]\n\nGANs are a game-changer when it comes to generating realistic images, but they also raise some serious privacy concerns. Imagine if a GAN was used to create realistic images of people who don't exist, it could be used for some pretty shady stuff.\n\nBut don't worry, we've got you covered. In this video, we'll explore what privacy preservation in GANs looks like and what we can do to protect our data.\n\n[Body content]\n\nPrivacy preservation in GANs involves using some pretty cool techniques to ensure that the training data is kept under wraps and not misused. One technique is called differential privacy, which adds some noise to the training data to make it harder to identify individual data points.\n\nAnother technique is called federated learning, which allows multiple parties to train a GAN on their own data without sharing it with others. It's like having your cake and eating it too.\n\nBut it's not just about the technology. We also need to consider the social and ethical implications of GANs and use them responsibly. This means being transparent about how we're using GANs and obtaining informed consent from the people whose data we're using.\n\n[Conclusion and call to action]\n\nSo, there you have it, a quick overview of privacy preservation in GANs and what we can do to protect our data. If you want to learn more, be sure to check out our other videos on the topic. And if you have any questions or comments, leave them down below. We love hearing from you.\n\nThanks for watching, and we'll see you in the next video.\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-03-02"}}
{"video": {"title": "Granularity in Linear Quantization: Per Tensor, Per Channel, and Per Group", "transcript": "####Granularity in Linear Quantization: Per Tensor, Per Channel, and Per Group\nby Marc Sun, Younes Belkada - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, Quantization Enthusiasts! I'm Marc Sun, and today we're diving into the fascinating world of granularity in Linear Quantization. We'll be exploring per tensor, per channel, and per group quantization.\n\nFirst off, let's talk about per tensor quantization. This is the simplest form of quantization, where all weights in a tensor share the same quantization parameters. It's like a one-size-fits-all approach, but in the world of quantization.\n\nNext up, we'll discuss per channel quantization. This is where each channel in a weight tensor has its own set of quantization parameters. It's like giving each channel its own personalized quantization suit.\n\nFinally, we'll delve into per group quantization. This is a more advanced technique where weights are divided into groups, and each group has its own quantization parameters. It's like having a quantization party, where each group gets its own unique flavor.\n\nWe'll discuss the benefits and drawbacks of each method, and when to use each one. By the end of this video, you'll be a granularity guru, ready to take on the quantization world.\n\nRemember, this course is designed for an intermediate skill level, and it's brought to you in partnership with Hugging Face.\n\nThat's it for today's preview. If you're ready to master granularity in Linear Quantization, let's get started. And don't forget to like, share, and subscribe for more great content. See you in the course!\n#### END TRANSCRIPT ########", "author": "Marc Sun, Younes Belkada", "publication_date": "2022-01-15"}}
{"video": {"title": "Mastering AI Agentic Design Patterns with AutoGen", "transcript": "####Mastering AI Agentic Design Patterns with AutoGen\nby Chi Wang, Qingyun Wu - 2023-03-01\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Chi Wang and today we're embarking on an exciting journey into the world of AI Agentic Design Patterns using AutoGen. If you're a Python enthusiast with a knack for automating complex workflows, you're in luck!\n\nFirst things first, let's demystify AutoGen. It's a mighty framework that empowers us to build multi-agent systems with a variety of roles and capabilities. With AutoGen, we can create complex AI applications with a breeze.\n\nNow, let's get our hands dirty and explore the four main agentic design patterns. First up, we have Reflection. This is where our AI agents can think about their own behavior and adjust accordingly.\n\nNext, we have Tool Use. This pattern enables our agents to use external tools to complete tasks. Think of it like giving your AI agent a hammer to tackle a task.\n\nThe third pattern is Planning. This is where our agents can foresee future actions and make decisions based on those forecasts.\n\nLastly, we have Multi-agent Collaboration. This is where multiple agents team up to achieve a common goal. It's like a squad of superheroes, each with their own unique abilities, joining forces to save the day.\n\nAnd the cherry on top? You're learning directly from the masterminds behind AutoGen. I, Chi Wang, and my colleague Qingyun Wu are here to guide you every step of the way.\n\nSo, are you ready to transform the way you approach AI applications? Join us in this thrilling adventure with AutoGen. Remember, practice makes perfect. Keep coding, keep learning, and let's create something extraordinary together.\n\nDon't forget to hit that like button, subscribe, and ring the bell for more thrilling content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2023-03-01"}}
{"video": {"title": "Building Multi-Step Systems with ChatGPT", "transcript": "####Building Multi-Step Systems with ChatGPT: A Fun and Engaging Journey!\nby Andrew Ng - 2022-10-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Are you ready to dive into the world of large language models and build some amazing multi-step systems? Well, buckle up because we're about to embark on an exciting journey!\n\nIn this video, we'll explore how to efficiently build multi-step systems using ChatGPT. We'll learn how to split complex tasks into a pipeline of subtasks and evaluate outputs. And the best part? We'll have a ton of fun doing it!\n\nSo, what are you waiting for? Let's get started!\n#### END TRANSCRIPT ########", "author": "Andrew Ng", "publication_date": "2022-10-20"}}
{"video": {"title": "Building a Multi-User LLM Application with Python and Predibase's LoRAX Framework", "transcript": "####Building a Multi-User LLM Application with Python and Predibase's LoRAX Framework\nby Travis Addair - 2023-03-02\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Travis Addair and today we're going to have a blast building a multi-user LLM application using Python and Predibase's LoRAX framework.\n\nBut first, let's talk about what a multi-user LLM application is. It's an application that allows multiple users to interact with a language model at the same time. This can be useful for a variety of applications, such as chatbots and virtual assistants.\n\nNext, we'll dive into how to use Python and Predibase's LoRAX framework to build a multi-user LLM application. We'll start by fine-tuning a pre-trained language model on our specific task using LoRA. Once we have our fine-tuned model, we'll use LoRAX to serve it to multiple users at once.\n\nWe'll also talk about how to handle requests from multiple users and how to balance the load between multiple models. This will ensure that our application is scalable and can handle a large number of requests.\n\nFinally, we'll discuss some best practices for building multi-user LLM applications, such as how to handle input validation and how to monitor the performance of our application.\n\nThanks for watching and don't forget to like, comment, and subscribe for more videos on GenAI and LLM powered applications. See you in the next one!\n#### END TRANSCRIPT ########", "author": "Travis Addair", "publication_date": "2023-03-02"}}
{"video": {"title": "Building a Chatbot with NLP and Hugging Face", "transcript": "####Building a Chatbot with NLP and Hugging Face\nby Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Your Assistant here, and today we're diving into the exciting world of chatbot development with NLP. Imagine having a virtual assistant that can understand and respond to your queries, just like a real person. That's the power of NLP!\n\nFirst things first, let's talk about how chatbots work. It's all about teaching a machine to understand the context of a conversation, and then generate appropriate responses.\n\nWith Hugging Face, we can build a chatbot in just a few simple steps. We'll show you how to prepare your data, train your model, and deploy your app.\n\nBut wait, there's more! We'll also cover some advanced techniques for improving your chatbot's performance, like intent recognition and entity extraction. And don't worry, we'll explain everything in a clear and simple way, so you won't get lost in the details.\n\nSo, are you ready to build your own chatbot with NLP and Hugging Face? Let's get started!\n\nThat's it for today's video. If you found it helpful, be sure to give it a thumbs up and subscribe for more content. And if you're ready to start building your own chatbot, check out the links in the description for some great resources. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Bensouda Mourri, \u0141ukasz Kaiser, Eddy Shyu", "publication_date": "2023-04-25"}}
{"video": {"title": "Building a Multimodal RAG System", "transcript": "####Building a Multimodal RAG System\nby Sebastian Witalec - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Sebastian Witalec and today we're diving into the exciting world of multimodal RAG systems!\n\nBut first, let me explain what RAG stands for. It's short for Retrieval Augmented Generation. Essentially, it's a system that retrieves relevant context and reasons over it to generate more accurate answers. And in a multimodal RAG system, we can retrieve multimodal context and generate answers based on that context.\n\nSo, what are we going to do today? We'll start by preparing our multimodal dataset. Then, we'll build our RAG model and train it on our dataset. Finally, we'll evaluate our model and see how well it performs.\n\nBut why should you care? Well, the goal here is to build a system that can understand and reason over multimodal data. This is a powerful tool in many applications, from customer service to content recommendation.\n\nSo, are you ready to get started? Let's do this! And if you have any questions, don't hesitate to leave a comment. We're all here to learn. And don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Sebastian Witalec", "publication_date": "2023-03-25"}}
{"video": {"title": "Transfer Learning: Build Powerful AI Models with Less Data", "transcript": "Hi, I'm Laurence Moroney, and today we're going to explore the fascinating world of transfer learning and how it can help you build powerful AI models with less data and computation using TensorFlow.\n\n[Video hook and introduction]\n\nImagine being able to leverage the knowledge of a pre-trained model to achieve better results with less data and training time. Sounds too good to be true? Well, that's exactly what transfer learning can do for you! Let's dive in!\n\n[Body content]\n\nFirst, we'll discuss the concept of transfer learning and its benefits, such as reduced training time, improved performance, and the ability to work with smaller datasets.\n\nNext, we'll walk through using transfer learning in TensorFlow for a specific task, such as image classification or object detection. We'll cover techniques for selecting and adapting a pre-trained model, as well as fine-tuning its layers to better suit our new task.\n\nWe'll also discuss popular pre-trained models, such as VGG16, ResNet, and Inception, and their unique applications.\n\n[Conclusion and call to action]\n\nBy the end of this video, you'll have a solid understanding of transfer learning and how to use it for building powerful AI models with less data and computation in TensorFlow.\n\nDon't forget to like, share, and subscribe for more AI and machine learning content. Join me in the next video, where we'll explore the world of autoencoders and their applications in dimensionality reduction and anomaly detection. See you there!", "author": "Laurence Moroney", "publication_date": "2023-04-29"}}
{"video": {"title": "Machine Learning Math: Linear Algebra", "transcript": "####Machine Learning Math: Linear Algebra\nby Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig - 2022-02-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, Machine Learning enthusiasts! Today, we're diving into the fascinating world of linear algebra, the math that powers Machine Learning.\n\nDon't let the big words scare you. We're all about making complex concepts simple and fun. And yes, we'll be using Python to bring these concepts to life. So, get ready to code!\n\nRemember, practice makes perfect. So, keep coding, keep experimenting, and soon, you'll be a linear algebra pro!\n\nThat's all for today's video. If you enjoyed this journey, give us a thumbs up and don't forget to subscribe for more exciting content. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig", "publication_date": "2022-02-12"}}
{"video": {"title": "Evaluating LLM Inputs and Outputs", "transcript": "####Evaluating LLM Inputs and Outputs for Safety, Accuracy, and Relevance\nby Isa Fulford - 2022-10-19\n\n#### BEGIN TRANSCRIPT ####\nHey there, it's Isa Fulford! Today, we're going to have a blast learning how to evaluate LLM inputs and outputs for safety, accuracy, and relevance. Trust me, you won't want to miss this!\n\nFirst, let's talk about safety. We'll explore how to ensure your LLM isn't generating harmful or inappropriate content. Then, we'll dive into accuracy and learn how to check if your LLM's outputs are factually correct. And finally, we'll discuss relevance and how to make sure your LLM's responses are on point.\n\nSo, are you ready to become an LLM evaluation expert? Let's get started!\n#### END TRANSCRIPT ########", "author": "Isa Fulford", "publication_date": "2022-10-19"}}
{"video": {"title": "Machine Learning Specialization: Building ML Models from Scratch", "transcript": "####Machine Learning Specialization: Building ML Models from Scratch\nby Geoff Ladwig - 2022-10-04\n\n#### BEGIN TRANSCRIPT ####\nHey there, Geoff Ladwig here! Today, we're going to get our hands dirty and build machine learning models from scratch. Are you ready to unleash your coding skills and creativity in the world of ML? Let's do this!\n#### END TRANSCRIPT ########", "author": "Geoff Ladwig", "publication_date": "2022-10-04"}}
{"video": {"title": "Responsible AI Practices in Generative AI", "transcript": "####Responsible AI Practices in Generative AI\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-03-22\n\n#### BEGIN TRANSCRIPT ####\nHey there, Mike Chambers here, and today we're diving into the world of responsible AI practices in generative AI.\n\nFirst, we'll cover the basics of responsible AI, including the importance of transparency, accountability, and fairness in AI systems.\n\nWe'll also discuss the ethical considerations of generative AI, such as data privacy, bias, and misuse.\n\nThen, we'll dive into practical strategies for implementing responsible AI practices in generative AI, such as data governance, model interpretability, and user feedback.\n\nAnd don't forget about the legal considerations. We'll touch on the regulations and standards that apply to generative AI and how to comply with them.\n\nBy the end of this video, you'll have the knowledge and skills to implement responsible AI practices in generative AI.\n\nSo, let's get started! See you in the course.\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-03-22"}}
{"video": {"title": "Mistral AI: Harnessing the Power of Commercial Models", "transcript": "####Mistral AI: Unleashing the Potential of Commercial Models\nby Younes Belkada, Marc Sun - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, Younes Belkada here, and welcome back to our series on Mistral AI!\n\nToday, we're diving into the world of Mistral's commercial models. These models pack a punch with more advanced features and capabilities than their open-source counterparts, making them ideal for more demanding tasks.\n\nFrom small to large, these models offer a range of power and capabilities. But how do you pick the right one? It's all about matching the model to your needs.\n\nIf you need more power and capabilities, the large model might be your best bet. If you need something a little less powerful, the small or medium models might be more your speed.\n\nRemember, it's all about finding the model that fits your needs like a glove.\n\nIf you have any questions, just let us know. And don't forget to like, share, and subscribe for more updates. Until next time, happy exploring!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-25"}}
{"video": {"title": "Getting the Most Out of Llama 2 & 3 Models", "transcript": "####Getting the Most Out of Llama 2 & 3 Models\nby Amit Sangani - 2023-02-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Amit Sangani and today we're diving into the exciting world of Llama 2 & 3 Models.\n\nAre you ready to level up your AI game? In this beginner-friendly course, we'll be uncovering the secrets to prompting and selecting among Meta Llama 2 & 3 models like a pro.\n\nFirst, we'll be exploring the ins and outs of Meta Llama 2 Chat. We'll show you how to interact with it to get the most out of your prompts. And, we'll also be taking a look at Code Llama and how it can help you with your coding needs.\n\nBut wait, there's more! We'll also be discussing the importance of building safe and responsible AI applications. That's where Llama Guard comes in. We'll show you how you can use this model to ensure that your AI applications are safe and responsible.\n\nSo, are you ready to unlock the full potential of Llama 2 & 3 models? Let's get started!\n\nRemember, practice makes perfect. So, be sure to try out these best practices on your own and see how they work for you. And, if you have any questions or need further clarification, don't hesitate to reach out.\n\nThanks for watching and happy prompting!\n\nDon't forget to like, comment, and subscribe for more content like this. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Amit Sangani", "publication_date": "2023-02-17"}}
{"video": {"title": "Mistral AI: Building Powerful LLM Applications", "transcript": "####Mistral AI: Unleashing the Power of LLM Applications\nby Younes Belkada and Marc Sun - 2023-04-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today I'm joined by my co-host Marc Sun. We're diving into the world of Mistral AI and showing you how to build powerful LLM applications.\n\nIn this video, we'll be combining Mistral's open-source and commercial models, JSON mode, and user-defined functions to create some truly impressive LLM applications.\n\nWe'll be demonstrating how to use Mistral's API to integrate LLM outputs into larger software applications, allowing you to create everything from chatbots to text generation tools.\n\nBut that's not all! We'll also be providing tips and best practices for building LLM applications, including how to optimize performance and ensure accuracy.\n\nWhether you're a beginner or an experienced developer, Mistral AI has everything you need to build powerful LLM applications. And the best part? It's easy to use and integrates seamlessly with your existing software applications.\n\nSo, what are you waiting for? Let's get started!\n\nDon't forget to like, share, and subscribe for more content on Mistral AI. And a special thanks to our technology partner, Mistral AI, for making this video possible.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-04-20"}}
{"video": {"title": "TensorFlow: Advanced Sequence Models", "transcript": "####TensorFlow: Mastering Advanced Sequence Models\nby Laurence Moroney, Eddy Shyu - 2022-04-26\n\n#### BEGIN TRANSCRIPT ####\nHey there, TensorFlow enthusiasts! I'm Laurence Moroney, and today we're diving into the exciting world of advanced sequence models.\n\nSequence models are like the secret sauce of machine learning, perfect for time series data, natural language processing, and more. In this video, we'll show you how to use TensorFlow's Functional API to build models with multiple inputs and outputs, shared layers, and more.\n\nWe'll also share some pro tips for working with sequence models, and help you avoid common pitfalls.\n\nSo, whether you're a seasoned data scientist or just starting your machine learning journey, this video has something for you. Let's get started!\n\n[Demonstration of building advanced sequence models with multiple inputs and outputs, shared layers, etc.]\n\nAnd that's a wrap! Thanks for joining us on this TensorFlow adventure. Be sure to check out our other videos for more machine learning goodness. Until next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-04-26"}}
{"video": {"title": "Mastering AI Agentic Design Patterns with AutoGen", "transcript": "####Mastering AI Agentic Design Patterns with AutoGen\nby Chi Wang, Qingyun Wu - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! I'm Chi Wang, and I'm Qingyun Wu, and we're about to take you on an exciting journey into the world of AI agentic design patterns with AutoGen. Are you ready to build multi-agent systems with diverse roles and capabilities for implementing complex AI applications? Let's do this!\n\nIn this video, we'll show you how to use the AutoGen framework to automate workflows and leverage agentic design patterns like Reflection, Tool use, Planning, and Multi-agent collaboration. With just basic Python coding experience, you can master these skills and take your AI projects to the next level.\n\nJoin us as we explore the cutting-edge features of AutoGen and learn directly from the creators themselves. Get ready to revolutionize your AI development process with AutoGen. Don't miss out on this opportunity to level up your AI skills and collaborate with industry leaders like Microsoft and Penn State University.\n\nSo, what are you waiting for? Subscribe now and start your journey to becoming an AI agentic design expert! Let's get started!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2022-10-15"}}
{"video": {"title": "Handling Multi-Documents with Your Research Agent", "transcript": "Hi again, I'm Jerry Liu, and today we're diving into the exciting world of multi-document handling with your research agent.\n\nThat's right, we're going to learn how to make your agent navigate and analyze multiple documents at once. Because sometimes, the information you need is spread across multiple sources.\n\nFirst, we'll go over the basics of multi-document handling. It's like learning how to juggle before you start juggling.\n\nNext, we'll talk about how to tell your agent which documents to analyze. It's like giving your agent a shopping list.\n\nThen, we'll discuss how to make your agent analyze these documents in the right order. Because sometimes, the order matters.\n\nAnd finally, we'll go over some tips and tricks for handling multi-documents like a pro.\n\nSo, are you ready to turn your agent into a multi-document master? Let's get started!\n\nRemember, handling multi-documents is all about organization. So, don't be afraid to take your time and plan out your approach.\n\nThanks for watching and happy coding!", "author": "Jerry Liu", "publication_date": "2023-04-15"}}
{"video": {"title": "Unleashing the Power of LLMs with Function-Calling and Data Extraction", "transcript": "####Unleashing the Power of LLMs with Function-Calling and Data Extraction\nby Jiantao Jiao, Venkat Srinivasan - 2023-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao and today, I'm teaming up with my colleague Venkat Srinivasan to show you how to turbocharge your Language Learning Models (LLMs) with function-calling and data extraction.\n\nFirst things first, if you're new here, welcome! We recommend having some familiarity with LLMs and basic Python knowledge to get the most out of this video.\n\nNow, let's get started. Function-calling is a game-changer for LLMs. It allows you to extend your models with custom functionality, enabling them to form calls to external functions. This means you can teach your LLMs to do almost anything, from fetching the weather to ordering a pizza!\n\nBut wait, there's more. With data extraction, you can turn unstructured, natural language inputs into structured data that's ready for analysis. This is incredibly powerful for real-world applications, like processing customer service transcripts.\n\nLet's walk through an example together. We're going to build an end-to-end application that processes customer service transcripts using LLMs. We'll use function-calling to extract key information, like customer sentiment and issue categories.\n\nFollow along as we code this up in Python. Don't worry if you get stuck, we'll explain each step in detail.\n\nAnd there you have it! With just a few lines of code, we've turned our LLM into a powerful tool for processing customer service transcripts.\n\nBut this is just the beginning. With function-calling and data extraction, the possibilities are endless. So go ahead and try it out for yourself. And remember, if you have any questions, we're here to help.\n\nThanks for watching, and stay tuned for more tips and tricks on mastering LLMs. This is Jiantao Jiao and Venkat Srinivasan, signing off.\n\nOh, and one more thing. A big shoutout to our partners at Nexusflow for making this video possible.\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2023-02-15"}}
{"video": {"title": "Chaining Calls in LangChain", "transcript": "####Chaining Calls in LangChain\nby Harrison Chase, Andrew Ng - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're going to have some fun with chaining calls in LangChain.\n\nChaining calls is like the secret sauce that lets you connect multiple LLMs together. This can supercharge your application's capabilities.\n\nWe'll start with the basics and then move on to some more advanced techniques. By the end of this video, you'll be chaining calls like a pro.\n\nSo, let's dive in. Remember, practice makes perfect.\n\nThanks for watching. Don't forget to like, comment, and subscribe for more content on LLM application development. See you in the next video.\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-05"}}
{"video": {"title": "Building a Question Answering System with LangChain", "transcript": "####Building a Question Answering System with LangChain\nby Harrison Chase, Andrew Ng - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Harrison Chase, and today we're diving into the exciting world of LangChain to build a question answering system.\n\nImagine having a tool that can answer complex questions with ease. Sounds like something out of a sci-fi movie, right? Well, it's not!\n\nFirst, we'll demystify LangChain's question answering features. We'll explore the technology behind it and how it empowers our system to understand and answer questions.\n\nNext, we'll roll up our sleeves and get into the code. We'll leverage LangChain's question answering features to build our system.\n\nBut wait, there's more! We'll use agents and chained calls to supercharge our system. It'll be able to handle complex tasks and remember past interactions.\n\nNow, let's recap. You've learned how to use LangChain's question answering features, how to build a question answering system, and how to boost your system with agents and chained calls.\n\nSo, what's next? I challenge you to build your own question answering system. Make it unique. Make it powerful.\n\nThanks for watching. If you found this tutorial helpful, give it a thumbs up and don't forget to subscribe for more content like this. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Andrew Ng", "publication_date": "2023-04-25"}}
{"video": {"title": "Mastering Generative AI with Language Models", "transcript": "####Mastering Generative AI with Language Models\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-02-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Antje Barth, and today we're diving headfirst into the thrilling world of Generative AI with Language Models, or LLMs!\n\nBut first, let's get on the same page. What exactly is generative AI, and how does it work? Well, it's a type of artificial intelligence that can create new content, like images, music, or text, by learning patterns from existing data. And LLMs are the secret sauce that makes it all possible.\n\nTransformer architecture is the powerhouse behind LLMs. It uses self-attention mechanisms to process input sequences in parallel, making it faster and more efficient than traditional recurrent neural networks.\n\nNow, let's get our hands dirty and apply some training, tuning, and inference methods. With basic Python knowledge, you'll be able to follow along and gain practical skills in generative AI.\n\nWe'll also hear from researchers in the field about the challenges and opportunities of generative AI. From creating more personalized user experiences to generating new ideas and solutions, the possibilities are endless.\n\nAnd the best part? You'll be learning from expert AWS AI practitioners who actively build and deploy AI in business use-cases today.\n\nSo, are you ready to take your AI skills to the next level? Join us in this course and become a master of Generative AI with LLMs. See you there!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-02-15"}}
{"video": {"title": "Mistral AI: Harnessing the Power of Commercial LLMs", "transcript": "####Mistral AI: Unleashing the Potential of Commercial LLMs\nby Younes Belkada and Marc Sun - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! I'm Younes Belkada, and today we're diving into the exciting world of commercial LLMs with Mistral AI, alongside my co-host Marc Sun.\n\nMistral AI offers three commercial models: small, medium, and large. In this video, we'll guide you on how to access these models via web interface and API calls.\n\nFirst up, we'll check out the small model, a mighty tool perfect for beginners. We'll show you how to use it to generate text, answer questions, and more.\n\nNext, we'll delve into the medium and large models. These models offer even more advanced capabilities, including the ability to generate structured JSON responses.\n\nWe'll also demonstrate how to use Mistral's API to call user-defined Python functions. This means you can perform tasks like web searches or retrieving text from databases, enhancing the LLM's ability to find relevant information to answer your queries.\n\nSo, whether you're a newbie or a seasoned developer, Mistral AI's commercial models have got you covered. And the cherry on top? They offer even more advanced capabilities than the open-source models.\n\nRemember to like, share, and subscribe for more content on Mistral AI. And a big shoutout to our technology partner, Mistral AI, for making this video possible.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-03-25"}}
{"video": {"title": "Statistics for Machine Learning: Making Sense of Data", "transcript": "####Statistics for Machine Learning: Making Sense of Data\nby Elena Sanina - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Elena Sanina, and today we're going to make statistics your new best friend.\n\nStatistics is all about making sense of data. It's like having a secret decoder ring for your data. It helps us understand the patterns and relationships in our data, and make predictions about the future.\n\nLet's start with descriptive statistics. It's like summarizing a book in one sentence. We use measures like mean, median, and mode to describe our data.\n\nNext, let's talk about inferential statistics. It's like making predictions about a book based on the first chapter. We use techniques like hypothesis testing and confidence intervals to make predictions about our data.\n\nSo, that's statistics in a nutshell. It's not just numbers and equations, it's a superpower that helps us understand and predict our data.\n\nRemember, practice makes perfect. So, keep exploring, keep learning, and don't be afraid to make mistakes.\n\nJoin us in our next video, where we'll be diving deeper into probability. If you found this video helpful, give us a thumbs up and subscribe to our channel for more exciting content. See you next time!\n\n#### END TRANSCRIPT ########", "author": "Elena Sanina", "publication_date": "2023-03-25"}}
{"video": {"title": "Automating Business Workflows with Multi-AI Agent Systems", "transcript": "####Automating Business Workflows with Multi-AI Agent Systems\nby Jo\u00e3o Moura - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Welcome back to our channel. Today, we're going to explore the fascinating world of multi-AI agent systems with crewAI. Are you ready to automate your business workflows and surpass the capabilities of a single LLM? Let's dive in!\n\nSo, what are multi-AI agent systems? In simple terms, it's about designing and guiding a team of AI agents using natural language. By harnessing the power of multiple agents, you can handle complex tasks with ease and efficiency.\n\nWith crewAI as our partner, we can take automation to new heights. This open-source library allows you to automate repeatable, multi-step tasks, such as tailoring a resume to a job description or streamlining event planning processes.\n\nBut here's where it gets really exciting. By creating a team of AI agents, each with a specific role, goal, and backstory, you can tackle different tasks with unique expertise. This approach breaks down complex workflows into manageable chunks, making automation a breeze.\n\nIf you're new to the world of LLMs and looking to incorporate them into your professional work, this course is perfect for you. Join me as we delve into the world of multi-AI agent systems and transform the way you work. Stay tuned for more tips, tricks, and insights on how to supercharge your business workflows with crewAI. Until next time, happy automating!\n#### END TRANSCRIPT ########", "author": "Jo\u00e3o Moura", "publication_date": "2022-10-15"}}
{"video": {"title": "Take Your LLMs to the Next Level with Function-Calling and Data Extraction", "transcript": "####Take Your LLMs to the Next Level with Function-Calling and Data Extraction\nby Jiantao Jiao, Venkat Srinivasan - 2022-05-03\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Venkat Srinivasan and today we're taking your Language Learning Models, or LLMs, to the next level with function-calling and data extraction. If you're a beginner with some basic Python knowledge, you're in the right place!\n\nLet's dive in. Function-calling is a game-changer. It lets you extend your LLMs with custom functionality by teaching them to make calls to external functions. Pretty cool, huh?\n\nNext up, we'll explore data extraction. We'll learn how to extract structured data from natural language inputs, making real-world data usable for analysis.\n\nBut wait, there's more! In partnership with Nexusflow, we'll build an end-to-end application that processes customer service transcripts using LLMs. You'll see how function-calling and data extraction can take your applications to the next level.\n\nRemember, the best way to learn is by doing. So, get involved! Try out the techniques we'll cover and see how they can enhance your LLM and agent applications.\n\nThanks for watching and happy learning! Don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, this is Jiantao Jiao signing off.\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-05-03"}}
{"video": {"title": "Expanding LLM Capabilities with Function-Calling", "transcript": "Positive Points:\n\n- Clear introduction of the topic.\n- Use of active voice and simple language.\n- Concise and to the point.\n\nAreas for Improvement:\n\n- Add more humor to make the content more enjoyable.\n- Improve contrast and pacing to maintain interest.\n- Include more curiosity and stakes at the beginning.\n- Make the conclusion more memorable and engaging.\n- Improve the call to action to encourage viewers to take the next step.", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-10-15"}}
{"video": {"title": "Optimizing Performance in On-Device AI", "transcript": "####Optimizing Performance in On-Device AI\nby Krishna Sridhar - 2022-10-09\n\n#### BEGIN TRANSCRIPT ####\nHey there, AI enthusiasts! Krishna Sridhar here, your friendly neighborhood AI expert. Today, we're diving into the exciting world of On-Device AI. Are you ready to learn how to make your AI models run faster and smoother on edge devices? Let's get started!\n#### END TRANSCRIPT ########\n\nHey there, AI enthusiasts! Krishna Sridhar here, your friendly neighborhood AI expert. Today, we're diving into the exciting world of On-Device AI. Are you ready to learn how to make your AI models run faster and smoother on edge devices? Let's get started!\n\nFirst, let's talk about why optimizing performance in On-Device AI is so important. With the rise of edge computing, more and more AI applications are being run on devices like smartphones and smart home devices. But these devices have limited resources, so it's crucial to optimize the performance of your AI models to ensure they run efficiently.\n\nIn this video, we'll cover some valuable tips and tricks for optimizing performance in On-Device AI. We'll talk about techniques like model compression, quantization, and pruning, and how they can help you reduce the size and computational requirements of your AI models. We'll also discuss best practices for deploying your models on edge devices, and how to monitor and optimize their performance over time.\n\nBut don't worry, we'll keep things fun and engaging! We'll sprinkle in some humor and avoid conventional messages to keep you entertained and interested. And we'll make sure to translate any jargon into simpler words so that everyone can follow along.\n\nSo, are you ready to take your On-Device AI skills to the next level? Let's get started!\n\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-10-09"}}
{"video": {"title": "LangChain: The Ultimate Tool for Data-Driven Chatbots", "transcript": "####LangChain: The Ultimate Tool for Data-Driven Chatbots\nby Harrison Chase - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! I'm Harrison Chase, and today we're diving into the world of LangChain, the ultimate tool for creating data-driven chatbots.\n\nLangChain is a game-changer, allowing you to access and interact with various data sources. With over 80 unique loaders, you can handle different types of data, from PDFs to databases.\n\nBut we're not just stopping at data access. We're going to build a chatbot that can chat directly with information from your own documents and data.\n\nImagine having a personal assistant who can read and understand all your documents and data. Sounds awesome, right?\n\nI'll be your guide, making sure to keep things simple and easy to understand. By the end of this video, you'll have your own chatbot ready to assist you with your data needs.\n\nSo, are you ready to explore why LangChain is the ultimate tool for data-driven chatbots? Let's get started!\n\nRemember, if you have any questions, feel free to leave a comment. I'm always here to help. And don't forget to like, share, and subscribe for more exciting content.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-04-25"}}
{"video": {"title": "LangChain and Data Analysis: Unlocking Insights from Your Data", "transcript": "####LangChain and Data Analysis: Unlocking Insights from Your Data\nby Harrison Chase - 2023-04-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, data enthusiasts! I'm Harrison Chase, the mastermind behind LangChain, and today we're diving into the exciting world of data analysis with LangChain.\n\nAre you tired of sifting through mountains of data without any real insights? Well, buckle up, because LangChain is here to change the game!\n\nIn this video, we'll explore how LangChain can help you analyze your data and unlock hidden insights. We'll start with a quick overview of data analysis and some of the most popular data analysis libraries, like Pandas and NumPy.\n\nBut don't worry, we won't get bogged down in technical jargon. We'll keep things simple, fun, and engaging, just like LangChain itself!\n\nNext, we'll dive into some practical examples of how to use LangChain for data analysis. We'll cover everything from data cleaning and visualization to statistical analysis.\n\nBy the end of this video, you'll have a solid understanding of how to use LangChain for data analysis and how to unlock insights from your data like a pro.\n\nSo, are you ready to take your data analysis skills to the next level? Let's get started and unlock the full potential of LangChain!\n\nAnd remember, if you have any questions or need help along the way, don't hesitate to reach out to me on social media or through the LangChain website.\n\nThanks for watching, and happy analyzing!\n\n#### END TRANSCRIPT ########", "author": "Harrison Chase", "publication_date": "2023-04-25"}}
{"video": {"title": "Expanding LLM Capabilities with Function-Calling", "transcript": "####Expanding LLM Capabilities with Function-Calling\nby Jiantao Jiao - 2022-10-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jiantao Jiao, and today we're going to explore the exciting world of function-calling and data extraction with LLMs. Are you ready to take your LLM to the next level? Let's dive in!\n\nImagine being able to extend the capabilities of your LLM to new heights. With function-calling, we can make this a reality. We'll show you how to extract structured data from natural language inputs, making real-world data usable for analysis.\n\nBut wait, there's more! We'll also be building an end-to-end application that processes customer service transcripts using LLMs, with the help of our partner Nexusflow.\n\nSo, if you're ready to take your LLM game to the next level, stay tuned for some exciting insights and practical tips. Trust me, you won't want to miss this!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao", "publication_date": "2022-10-15"}}
{"video": {"title": "Mistral AI: The Power of User-Defined Functions", "transcript": "####Mistral AI: Unleashing the Power of User-Defined Functions\nby Younes Belkada, Marc Sun - 2023-02-21\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Younes Belkada, and today we're diving into the world of user-defined functions and how Mistral AI's API can supercharge your LLM capabilities.\n\nImagine being able to call user-defined Python functions for tasks like web searches or retrieving text from databases. With Mistral's API, you can do just that, enhancing your LLM's ability to find relevant information and answer user queries more accurately.\n\nAnd the best part? User-defined functions are a breeze to use. Just define the function in Python, and then call it via Mistral's API. It's that simple!\n\nSo, what does this mean for you? It means now is the perfect time to start exploring Mistral AI's API and see how user-defined functions can help you achieve your LLM goals more accurately.\n\nAnd don't forget about Mistral AI's JSON mode. With JSON mode, you can generate LLM responses in a structured JSON format, making it a snap to integrate LLM outputs into your larger software applications.\n\nSo, what are you waiting for? Start exploring Mistral AI today and see how its API and JSON mode can help you take your LLM capabilities to the next level. And don't forget to check out Mistral AI, our technology partner for this video.\n\nThanks for watching, and stay tuned for more exciting videos on Mistral AI and LLM. I'm Younes Belkada, and I'll catch you in the next one.\n#### END TRANSCRIPT ########", "author": "Younes Belkada, Marc Sun", "publication_date": "2023-02-21"}}
{"video": {"title": "Conclusion and Next Steps for Generative AI with LLMs", "transcript": "####Conclusion and Next Steps for Generative AI with LLMs\nby Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers - 2023-05-17\n\n#### BEGIN TRANSCRIPT ####\nHey there, Mike Chambers here, and today we're wrapping up our exciting journey into Generative AI with LLMs!\n\nWe've covered a lot of ground in this series, from the basics of the transformer architecture to advanced techniques for training and deploying LLMs. We've also discussed some of the ethical considerations surrounding this technology and some real-world applications of LLMs.\n\nBut this is just the beginning of the journey for Generative AI with LLMs. There are many exciting developments happening in this field, and we encourage you to continue exploring and learning about this technology.\n\nWe hope that this video series has given you a solid foundation in Generative AI with LLMs and some practical skills for working with this technology. And we can't wait to see what you create with LLMs in the future!\n\nSo, what's next? Keep an eye out for our upcoming videos on the latest developments in Generative AI with LLMs. And don't forget to subscribe to our channel and hit the notification bell so you don't miss any updates.\n\nThanks for joining us on this journey, and we'll see you in the next video!\n#### END TRANSCRIPT ########", "author": "Antje Barth, Chris Fregly, Shelbee Eigenbrode Instructor, Mike Chambers", "publication_date": "2023-05-17"}}
{"video": {"title": "Building AI Agents with LangGraph and Tavily: A Step-by-Step Guide", "transcript": "####Building AI Agents with LangGraph and Tavily: A Step-by-Step Guide\nby Harrison Chase, Rotem Weiss - 2023-04-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, Python enthusiasts! Today, we're diving into the world of AI agents with a step-by-step guide using LangGraph and Tavily's agentic search.\n\nLangGraph is an open-source framework that empowers you to build, debug, and maintain AI agents. It's like having the keys to the AI kingdom!\n\nBut wait, there's more! When you combine LangGraph with Tavily's agentic search, you're taking your AI to the next level. It enhances your agent's knowledge and performance, making your AI more powerful than ever.\n\nIn this course, you'll learn directly from Harrison Chase, the founder of LangChain, and Rotem Weiss, the founder of Tavily. They'll guide you through LangGraph's components and show you how to integrate agentic search capabilities.\n\nThis course is perfect for those with intermediate Python knowledge who want to master AI agent development.\n\nSo, are you ready to build your own AI agents? Let's dive in! Remember to like, share, and subscribe for more exciting content.\n\nHappy coding!\n#### END TRANSCRIPT ########", "author": "Harrison Chase, Rotem Weiss", "publication_date": "2023-04-10"}}
{"video": {"title": "TensorFlow for Computer Vision", "transcript": "####TensorFlow for Computer Vision\nby Laurence Moroney - 2022-01-15\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're diving into the fascinating world of computer vision with TensorFlow!\n\n[Video hook and introduction]\n\nAre you ready to build image recognition systems and explore the exciting world of computer vision? Then buckle up, because we're about to take off!\n\n[Body content]\n\nFirst, we'll cover the basics of computer vision and how TensorFlow fits into the picture. We'll explore essential concepts like convolutional neural networks (CNNs) and how they're used for image recognition.\n\nThen, we'll dive into building our first computer vision model. We'll use a pre-trained model to classify images and learn how to fine-tune it for even better results. You'll also discover how to use transfer learning to speed up the training process.\n\nWe'll also explore real-world applications of computer vision, like self-driving cars and facial recognition. Plus, we'll cover advanced topics like object detection and segmentation.\n\n[Conclusion and call to action]\n\nSo, are you ready to master computer vision with TensorFlow? Let's get started! Remember, practice makes perfect, so make sure to follow along and code with me. See you in the first lesson!\n\n\n#### END TRANSCRIPT ########", "author": "Laurence Moroney", "publication_date": "2022-01-15"}}
{"video": {"title": "Unleashing the Power of Summarization with LlamaIndex", "transcript": "####Unleashing the Power of Summarization with LlamaIndex\nby Jerry Liu - 2023-03-25\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Jerry Liu and today we're diving into the exciting world of summarization with LlamaIndex.\n\nIn our previous videos, we've learned how to build an agentic RAG and mastered document Q&A. But today, we're taking it to the next level and learning how to summarize our documents.\n\nWe'll start by understanding what makes a good summary and how to structure our data for optimal results. Then, we'll dive into building a summarization agent with LlamaIndex.\n\nOnce we've got that down, we'll look at how to fine-tune our agent to improve its accuracy and efficiency.\n\nBut what if our agent gets stuck? Don't worry, we'll also cover how to debug and guide our agent's reasoning process.\n\nBy the end of this video, you'll be a pro at building and managing agentic RAG systems for document summarization.\n\nSo, let's get started! And remember, practice makes perfect. So, don't just watch this video, try building your own summarization system with LlamaIndex.\n\nIf you found this video helpful, give it a thumbs up and subscribe to our channel for more exciting content. Until next time, happy coding!\n\n\n#### END TRANSCRIPT ########", "author": "Jerry Liu", "publication_date": "2023-03-25"}}
{"video": {"title": "Implementing Retrieval Augmented Generation for Database Interaction", "transcript": "####Implementing Retrieval Augmented Generation for Database Interaction\nby Adrian Gonzalez Sanchez - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Adrian Gonzalez Sanchez and today we're diving into the exciting world of Retrieval Augmented Generation (RAG) for database interaction.\n\nIf you're a fan of natural language processing and databases, you know how awesome it is to use natural language to interact with data. But what if I told you we could make your natural language interface even more powerful with RAG?\n\nIn this video, we'll explore how to implement RAG for database interaction using the Azure OpenAI Service. We'll start by introducing the concept of RAG and how it can be applied to database interaction.\n\nThen, we'll dive into the Azure OpenAI Service and learn how to use its Assistants API to implement RAG for your natural language interface. We'll provide hands-on examples to help you understand how to use this technique to make your interface more powerful.\n\nBy the end of this video, you'll have the skills to implement RAG for your own natural language interface for databases.\n\nSo, are you ready to take your natural language interface to the next level? Let's get started!\n\nRemember, if you have any questions or need further clarification, feel free to leave a comment below. And don't forget to like and subscribe for more exciting content on natural language processing and databases.\n\nUntil next time, happy coding!\n#### END TRANSCRIPT ########", "author": "Adrian Gonzalez Sanchez", "publication_date": "2023-04-05"}}
{"video": {"title": "Enhancing Security in On-Device AI", "transcript": "####Enhancing Security in On-Device AI\nby Krishna Sridhar - 2022-02-10\n\n#### BEGIN TRANSCRIPT ####\nHey there, tech enthusiasts! Krishna Sridhar here, and today we're diving into the exciting world of On-Device AI. We'll be discussing how to enhance security in this field, and trust me, you won't want to miss it!\n\nBut first, let's set the stage. On-Device AI is all about leveraging the local compute power of edge devices, like your smartphone. It's a game-changer, but it also comes with its own set of security challenges. That's where we come in!\n\nSo, are you ready to learn how to secure your AI inference on edge devices? Let's get started!\n#### END TRANSCRIPT ########", "author": "Krishna Sridhar", "publication_date": "2022-02-10"}}
{"video": {"title": "GANs Unleashed: Advanced Techniques for Image Generation", "transcript": "####GANs Unleashed: Advanced Techniques for Image Generation\nby Sharon Zhou, Eda Zhou, Eric Zelikman - 2023-02-20\n\n#### BEGIN TRANSCRIPT ####\nHey there, Eric Zelikman here, and today we're diving into some advanced techniques for image generation with GANs.\n\n[Video hook and introduction]\n\nIf you've watched our previous video on GANs, you know that they're a powerful tool for creating realistic images. But there's so much more to GANs than just the basics.\n\nIn this video, we'll be exploring some advanced techniques for improving the quality and diversity of the images generated by GANs.\n\n[Body content]\n\nOne technique is called style transfer. This involves training a GAN to generate images in the style of a particular artist or genre. For example, you could train a GAN to create images in the style of impressionist paintings.\n\nAnother technique is called super-resolution. This involves training a GAN to create high-resolution images from low-resolution inputs. This can be useful for enhancing the quality of old photos or videos.\n\nBut it's not all fun and games. These advanced techniques also come with their own set of challenges. For example, style transfer can be difficult to control, and super-resolution can introduce artifacts or distortions into the generated images.\n\nThat's why it's important to approach these techniques with caution and to carefully evaluate the results.\n\n[Conclusion and call to action]\n\nSo, that's a quick look at some advanced techniques for image generation with GANs. If you want to learn more, check out our other videos on the topic. And if you have any questions or comments, leave them down below. We love hearing from you.\n\nThanks for watching, and we'll see you in the next video.\n#### END TRANSCRIPT ########", "author": "Sharon Zhou, Eda Zhou, Eric Zelikman", "publication_date": "2023-02-20"}}
{"video": {"title": "Avoiding Common Pitfalls in LLM Red Teaming", "transcript": "####Avoiding Common Pitfalls in LLM Red Teaming\nby Matteo Dora, Luca Martial - 2023-04-26\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, I'm Matteo Dora, and welcome back to our series on red teaming for LLM applications.\n\nToday, we're diving into some common pitfalls in LLM red teaming and how to dodge them like a pro.\n\nWe'll cover topics like how to avoid tunnel vision, how to balance red teaming with other development tasks, and how to avoid common mistakes in vulnerability identification and evaluation.\n\nRemember, learning from our mistakes is a great way to improve our red teaming skills and knowledge.\n\nSo, let's start dodging these common pitfalls and make our LLM applications even safer.\n\nStay tuned for our next video where we'll wrap up our series on LLM red teaming and discuss some final thoughts. Until then, keep exploring and learning.\n\nAnd don't forget to hit that like button and subscribe for more content like this.\n\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-04-26"}}
{"video": {"title": "Troubleshooting AutoGen: Common Issues and Solutions", "transcript": "####Troubleshooting AutoGen: Common Issues and Solutions\nby Chi Wang, Qingyun Wu - 2023-04-12\n\n#### BEGIN TRANSCRIPT ####\nHey there, coding enthusiasts! Chi Wang here, and today we're diving into some common issues you might face while using AutoGen.\n\nWe'll kick things off by discussing some common problems that beginners encounter when building AI agents. Then, we'll provide you with solutions and tips to overcome these challenges.\n\nRemember, everyone faces obstacles when learning something new. The key is to keep practicing and learning from your mistakes.\n\nSo, let's get started and troubleshoot some common issues with AutoGen!\n\nAs always, if you have any questions, feel free to leave them in the comments. We're here to help you learn and grow.\n\nDon't forget to like, subscribe, and hit that notification bell for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Chi Wang, Qingyun Wu", "publication_date": "2023-04-12"}}
{"video": {"title": "Mastering Function-Calling and Data Extraction with LLMs", "transcript": "####Mastering Function-Calling and Data Extraction with LLMs\nby Jiantao Jiao, Venkat Srinivasan - 2022-01-01\n\n#### BEGIN TRANSCRIPT ####\nHello, I'm Jiantao Jiao and today we're diving into the thrilling world of Function-Calling and Data Extraction with Language Learning Models, or LLMs. If you're comfortable with LLMs and have some basic Python skills, you're in the right place!\n\nLet's kick things off with function-calling. It's a game-changer for expanding the capabilities of LLMs and agent applications. With function-calling, you can extend LLMs with custom functionality, enabling them to form calls to external functions. Pretty neat, right?\n\nNext, we'll explore data extraction. Imagine being able to extract structured data from natural language inputs. That's exactly what we'll be doing! This makes real-world data usable for analysis, opening up a whole new world of possibilities.\n\nBut wait, there's more! We'll also build an end-to-end application that processes customer service transcripts using LLMs. This is a practical, hands-on way to see how these concepts work in the real world.\n\nAnd guess what? We're partnering with Nexusflow to bring you this content. They're a leading name in the field, so you know you're learning from the best.\n\nSo, are you ready to take your understanding of LLMs to the next level? Let's get started! Remember, practice makes perfect and don't forget to have fun.\n\nThanks for watching. Don't forget to like, share, and subscribe for more exciting content. See you in the next video!\n#### END TRANSCRIPT ########", "author": "Jiantao Jiao, Venkat Srinivasan", "publication_date": "2022-01-01"}}
{"video": {"title": "Advanced Red Teaming Techniques for LLM Applications", "transcript": "####Advanced Red Teaming Techniques for LLM Applications\nby Matteo Dora, Luca Martial - 2023-04-05\n\n#### BEGIN TRANSCRIPT ####\n\nHey there, LLM enthusiasts! I'm Matteo Dora, and welcome back to our thrilling journey into the world of red teaming for LLM applications.\n\nToday, we're taking it up a notch and diving into some advanced red teaming techniques. We'll be exploring fuzzing, adversarial attacks, and how to leverage machine learning to supercharge our red teaming efforts.\n\nBut remember, with great power comes great responsibility. These advanced techniques are potent, but they also demand a solid understanding of LLM applications and red teaming concepts.\n\nSo, are you ready to level up your red teaming game and make your LLM applications even safer? Let's get started!\n\nStay tuned for our next video where we'll delve into some real-world case studies of LLM red teaming. Until then, keep exploring, keep learning, and most importantly, keep having fun!\n\n#### END TRANSCRIPT ########", "author": "Matteo Dora, Luca Martial", "publication_date": "2023-04-05"}}
{"video": {"title": "Building Sequence-to-Sequence Models with TensorFlow", "transcript": "####Building Sequence-to-Sequence Models with TensorFlow\nby Laurence Moroney, Eddy Shyu - 2022-02-26\n\n#### BEGIN TRANSCRIPT ####\nHey there, I'm Laurence Moroney, and today we're going to have a blast exploring how to build sequence-to-sequence models with TensorFlow.\n\nFirst, we'll chat about the basics of sequence-to-sequence models and how they're used for tasks like machine translation and text summarization. Then, we'll dive into how to implement these models using TensorFlow's Keras API.\n\n...\n\nThanks for tuning in! I hope this video helped you understand how to build sequence-to-sequence models with TensorFlow. If you found this video helpful, please give it a thumbs up and subscribe to our channel for more content like this. See you next time!\n#### END TRANSCRIPT ########", "author": "Laurence Moroney, Eddy Shyu", "publication_date": "2022-02-26"}}
